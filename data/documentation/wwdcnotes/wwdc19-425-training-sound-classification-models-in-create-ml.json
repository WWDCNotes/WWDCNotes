{"seeAlsoSections":[{"generated":true,"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-509-AUv3-Extensions-User-Presets","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-257-Accessibility-Inspector","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-252-Advances-in-CarPlay-Systems","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-723-Advances-in-Foundation","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-256-Advances-in-Speech-Recognition","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-104-Apple-Design-Awards","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-258-Architecting-Your-App-for-Multiple-Windows","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-514-Auditing-Web-Content-with-Web-Inspector","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-426-Building-Activity-Classification-Models-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-805-Building-Great-Shortcuts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-248-Creating-an-Accessible-Reading-Experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-810-Designing-AudioHaptic-Experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-806-Designing-Great-Shortcuts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-809-Designing-iPad-Apps-for-Mac","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-262-Embedding-and-Sharing-Visually-Rich-Links","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-253-Exploring-Tinted-Graphic-Complications","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-615-Game-Center-Player-Identifiers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-506-HEVC-Video-with-Alpha","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-507-HLS-Authoring-for-AirPlay-2-Video","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-429-LLDB-Beyond-po","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-250-Making-Apps-More-Accessible-With-Custom-Actions","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-508-Modernizing-Your-Audio-App","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-716-Streaming-Audio-on-watchOS-6","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-511-Supporting-Dark-Mode-in-Your-Web-Content","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-616-Supporting-New-Game-Controllers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-259-Targeting-Content-with-Multiple-Windows","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-424-Training-Object-Detection-Models-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-427-Training-Recommendation-Models-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-428-Training-Text-Classifiers-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-513-Understanding-CPU-Usage-with-Web-Inspector","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-244-Visual-Design-and-Accessibility","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-518-Whats-New-for-Web-Developers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-246-Window-Management-in-Your-Multitasking-App","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-254-Writing-Great-Accessibility-Labels"],"title":"Deep Dives into Topics"}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"identifier":"https:\/\/developer.apple.com\/wwdc19\/425","overridingTitle":"Watch Video (20 min)","type":"reference","isActive":true}},"primaryContentSections":[{"kind":"content","content":[{"text":"Overview","level":2,"type":"heading","anchor":"overview"},{"inlineContent":[{"text":"Sound classification is the task of taking a sound, and placing it into one of many categories.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Different ways to categorize the sound:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Instrument\/object that made the sound (guitar\/drums)"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Location\/texture of the sound (Nature\/City), even when there’s no particular sound that necessarily stands out","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Attributes\/property of the sound (Laugh\/cry)","type":"text"}]}]}],"type":"unorderedList"},{"inlineContent":[{"text":"When we tell Create ML to train a new model, the first thing Create ML is going to be doing when training this model is walking through each of the sound files we provided, and extracting audio features across the entire file.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"When testing, we can pass a sound with multiple classes: CreateML will separate each recognized class by time. We can even do microphone recording and see CreateML recognizing things live! How cool is that?"}],"type":"paragraph"},{"inlineContent":[{"text":"New framework for sound recognition: ","type":"text"},{"identifier":"https:\/\/developer.apple.com\/documentation\/soundanalysis","isActive":true,"type":"reference"},{"text":".","type":"text"}],"type":"paragraph"},{"text":"Written By","level":2,"type":"heading","anchor":"Written-By"},{"columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/5277837?v=4","type":"image"}]}]},{"size":4,"content":[{"type":"heading","anchor":"Federico-Zanetello","level":3,"text":"Federico Zanetello"},{"inlineContent":[{"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"overridingTitle":"Contributed Notes","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/github.com\/zntfdr","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/zntfdr.dev","isActive":true}],"type":"paragraph"}]}],"numberOfColumns":5,"type":"row"},{"inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","isActive":true,"type":"reference"}],"type":"paragraph"},{"text":"Related Sessions","level":2,"type":"heading","anchor":"Related-Sessions"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10020-Compose-advanced-models-with-Create-ML-Components","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10036-Discover-builtin-sound-classification-in-SoundAnalysis","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-430-Introducing-the-Create-ML-App"],"style":"list","type":"links"},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Legal Notice"}]}],"type":"small"},{"inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}]}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19"]]},"schemaVersion":{"patch":0,"major":0,"minor":3},"abstract":[{"text":"Learn how to quickly and easily create Core ML models capable of classifying the sounds heard in audio files and live audio streams. In addition to providing you the ability to train and evaluate these models, the Create ML app allows you to test the model performance in real-time using the microphone on your Mac. Leverage these on-device models in your app using the new Sound Analysis framework.","type":"text"}],"sections":[],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-425-Training-Sound-Classification-Models-in-Create-ML"},"kind":"article","metadata":{"role":"sampleCode","roleHeading":"WWDC19","modules":[{"name":"WWDC Notes"}],"title":"Training Sound Classification Models in Create ML"},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc19-425-training-sound-classification-models-in-create-ml"],"traits":[{"interfaceLanguage":"swift"}]}],"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-428-Training-Text-Classifiers-in-Create-ML":{"title":"Training Text Classifiers in Create ML","type":"topic","abstract":[{"type":"text","text":"Create ML now enables you to create models for Natural Language that are built on state-of-the-art techniques. Learn how these models can be easily trained and tested with the Create ML app. Gain insight into the powerful new options for transfer learning, word embeddings, and text catalogs."}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19-428-training-text-classifiers-in-create-ml","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-428-Training-Text-Classifiers-in-Create-ML"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-810-Designing-AudioHaptic-Experiences":{"title":"Designing Audio-Haptic Experiences","type":"topic","abstract":[{"type":"text","text":"Learn essential sound and haptic design principles and concepts for creating meaningful and delightful experiences that engage a wider range of human senses. Discover how to combine audio and haptics, using the Taptic Engine, to add a new level of realism and improve feedback in your app or game."}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19-810-designing-audiohaptic-experiences","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-810-Designing-AudioHaptic-Experiences"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-506-HEVC-Video-with-Alpha":{"title":"HEVC Video with Alpha","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-506-HEVC-Video-with-Alpha","role":"sampleCode","abstract":[{"type":"text","text":"With the addition of alpha channel support for HEVC video, you can now composite video over custom backgrounds in both your apps and on the web. Learn how to author compatible media, and the best practices for playback."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-506-hevc-video-with-alpha"},"https://zntfdr.dev":{"title":"Blog","url":"https:\/\/zntfdr.dev","type":"link","titleInlineContent":[{"text":"Blog","type":"text"}],"identifier":"https:\/\/zntfdr.dev"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-262-Embedding-and-Sharing-Visually-Rich-Links":{"title":"Embedding and Sharing Visually Rich Links","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-262-Embedding-and-Sharing-Visually-Rich-Links","role":"sampleCode","abstract":[{"type":"text","text":"The new Link Presentation framework enables app developers to easily present URLs in a rich, beautiful, and consistent way. Learn how to use Link Presentation to retrieve metadata from a URL, present the rich link content inside your app, and provide link metadata to the new share sheet experience in iOS."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-262-embedding-and-sharing-visually-rich-links"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-248-Creating-an-Accessible-Reading-Experience":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-248-creating-an-accessible-reading-experience","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-248-Creating-an-Accessible-Reading-Experience","type":"topic","abstract":[{"type":"text","text":"The styling and layout of text is a hallmark feature of an outstanding reading experience. Technologies such as CoreText and TextKit give you the tools you need to create a great text layout. Learn how to make an equally great accessible experience for VoiceOver by adopting the accessibility reading content protocol, adding automatic page turning, and customizing speech output."}],"title":"Creating an Accessible Reading Experience"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-257-Accessibility-Inspector":{"title":"Accessibility Inspector","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-257-Accessibility-Inspector","role":"sampleCode","abstract":[{"type":"text","text":"The Accessibility Inspector enables you to identify parts of your app that are not accessible. It provides feedback on how you can make them accessible, as well as simulating voice-over to help you identify what a Voice Over user would experience. Watch a live-demo of an app being fully debugged in the Accessibility Inspector, and learn how to leverage this powerful tool to make your apps better for everyone."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-257-accessibility-inspector"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-246-Window-Management-in-Your-Multitasking-App":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-246-Window-Management-in-Your-Multitasking-App","role":"sampleCode","abstract":[{"text":"Dive into the details of window management in your Multitasking app, including how to properly handle creating, refreshing, and closing windows. Hear about best practices for when to refresh the content in your window and learn how to ensure your app’s visual state is up-to-date in the switcher.","type":"text"}],"type":"topic","title":"Window Management in Your Multitasking App","url":"\/documentation\/wwdcnotes\/wwdc19-246-window-management-in-your-multitasking-app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19","role":"collectionGroup","abstract":[{"text":"Xcode 11, Swift 5.1, iOS 12, macOS 10.15, tvOS 13, watchOS 6.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"type":"codeVoice","code":"Combine"},{"text":", ","type":"text"},{"type":"codeVoice","code":"Core Haptics"},{"text":", ","type":"text"},{"code":"Create ML","type":"codeVoice"},{"type":"text","text":", and more."}],"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"type":"topic","title":"WWDC19","url":"\/documentation\/wwdcnotes\/wwdc19"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-250-Making-Apps-More-Accessible-With-Custom-Actions":{"title":"Making Apps More Accessible With Custom Actions","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-250-Making-Apps-More-Accessible-With-Custom-Actions","role":"sampleCode","abstract":[{"type":"text","text":"Custom Actions simplify the experience for people using assistive technologies with your app and they can help you reduce the number of swipes and taps that are required to navigate through your interface and perform interactions. Learn how to leverage custom actions for use in VoiceOver and Switch Control. New in iOS 13, bring custom actions to Full Keyboard Access and Voice Control on iOS."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-250-making-apps-more-accessible-with-custom-actions"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-429-LLDB-Beyond-po":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-429-LLDB-Beyond-po","role":"sampleCode","abstract":[{"text":"LLDB is a powerful tool for exploring and debugging your app at runtime. Discover the various ways to display values in your app, how to format custom data types, and how to extend LLDB using your own Python 3 scripts.","type":"text"}],"type":"topic","title":"LLDB: Beyond “po”","url":"\/documentation\/wwdcnotes\/wwdc19-429-lldb-beyond-po"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-427-Training-Recommendation-Models-in-Create-ML":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-427-training-recommendation-models-in-create-ml","role":"sampleCode","title":"Training Recommendation Models in Create ML","kind":"article","abstract":[{"type":"text","text":"Recommendation models for Core ML can enable a very personal experience for the customers using your app. They power suggestions for what music to play or what movie to see in the apps you use every day. Learn how you can easily create a custom Recommendation model from all sorts of data sources using the Create ML app. Gain a deeper understanding of how this kind of personalization is possible while maintaining user privacy. See an example of one of these recommenders in action."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-427-Training-Recommendation-Models-in-Create-ML"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-616-Supporting-New-Game-Controllers":{"title":"Supporting New Game Controllers","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-616-Supporting-New-Game-Controllers","role":"sampleCode","abstract":[{"type":"text","text":"With iOS 13, macOS Catalina, and tvOS 13, the Game Controller framework adds support for several well-known console game controllers. Get briefed about the newly-added controllers and understand how their inputs are delivered. Learn recommended best practices for handling optional buttons, and understand the right approach for support on macOS."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-616-supporting-new-game-controllers"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-716-Streaming-Audio-on-watchOS-6":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-716-Streaming-Audio-on-watchOS-6","role":"sampleCode","abstract":[{"text":"Streaming audio on Apple Watch allows customers to enjoy your content wherever they go without their iPhone. Learn about the streaming APIs brought over from iOS to allow watchOS apps to create independent audio consumption experiences. Find out how to set up your audio session for streaming and explore best practices to provide the best experience for people moving between different network conditions.","type":"text"}],"type":"topic","title":"Streaming Audio on watchOS 6","url":"\/documentation\/wwdcnotes\/wwdc19-716-streaming-audio-on-watchos-6"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-252-Advances-in-CarPlay-Systems":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-252-Advances-in-CarPlay-Systems","abstract":[{"type":"text","text":"CarPlay is a smarter, safer way to use your iPhone in the car. Learn how to update your vehicle system to take advantage of new features in iOS 13. Add support for dynamically changing screen sizes, second screens such as instrument clusters, and even irregularly shaped displays. Learn how to support “Hey Siri” for hands-free voice activation."}],"url":"\/documentation\/wwdcnotes\/wwdc19-252-advances-in-carplay-systems","title":"Advances in CarPlay Systems","role":"sampleCode","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10020-Compose-advanced-models-with-Create-ML-Components":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10020-Compose-advanced-models-with-Create-ML-Components","url":"\/documentation\/wwdcnotes\/wwdc22-10020-compose-advanced-models-with-create-ml-components","kind":"article","abstract":[{"text":"Take your custom machine learning models to the next level with Create ML Components. We’ll show you how to work with temporal data like video or audio and compose models that can count repetitive human actions or provide advanced sound classification. We’ll also share best practices on using incremental fitting to speed up model training with new data.","type":"text"}],"type":"topic","title":"Compose advanced models with Create ML Components"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-514-Auditing-Web-Content-with-Web-Inspector":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-514-Auditing-Web-Content-with-Web-Inspector","role":"sampleCode","abstract":[{"text":"Discover a new way to ensure your web content meets team coding standards and that you can deliver better code even without reliance on automated test systems. Find out how to use the Audit tool in Web Inspector to quickly and easily audit your web content during development so important compliance details don’t slip by.","type":"text"}],"type":"topic","title":"Auditing Web Content with Web Inspector","url":"\/documentation\/wwdcnotes\/wwdc19-514-auditing-web-content-with-web-inspector"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-426-Building-Activity-Classification-Models-in-Create-ML":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-426-Building-Activity-Classification-Models-in-Create-ML","role":"sampleCode","abstract":[{"text":"Your iPhone and Apple Watch are loaded with a number of powerful sensors including an accelerometer and gyroscope. Activity Classifiers can be trained on data from these sensors to bring some magic to your app, such as knowing when someone is running or swinging a bat. Learn how the Create ML app makes it easy to train and evaluate one of these Core ML models. Gain a deeper understanding of how to collect the raw data needed for training. See the use of these models in action.","type":"text"}],"type":"topic","title":"Building Activity Classification Models in Create ML","url":"\/documentation\/wwdcnotes\/wwdc19-426-building-activity-classification-models-in-create-ml"},"doc://WWDCNotes/documentation/WWDCNotes/zntfdr":{"url":"\/documentation\/wwdcnotes\/zntfdr","role":"sampleCode","kind":"article","type":"topic","title":"Federico Zanetello (214 notes)","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","abstract":[{"type":"text","text":"Software engineer with a strong passion for well-written code, thought-out composable architectures, automation, tests, and more."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-507-HLS-Authoring-for-AirPlay-2-Video":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-507-hls-authoring-for-airplay-2-video","role":"sampleCode","title":"HLS Authoring for AirPlay 2 Video","kind":"article","abstract":[{"type":"text","text":"AirPlay 2 Video lets you share video from Apple devices to popular smart TVs. Learn about the special considerations for seamless delivery of high quality video to these TVs, and how to utilize the validation tools to ensure your content is ready for primetime."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-507-HLS-Authoring-for-AirPlay-2-Video"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-509-AUv3-Extensions-User-Presets":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-509-AUv3-Extensions-User-Presets","role":"sampleCode","abstract":[{"text":"Audio Unit app extensions gives users a convenient way to create or modify audio in any iOS or macOS app that uses sound, including music production apps such as GarageBand or Logic Pro X. And now, with iOS 13, you can store user presets for your extensions that are accessible across applications.","type":"text"}],"type":"topic","title":"AUv3 Extensions User Presets","url":"\/documentation\/wwdcnotes\/wwdc19-509-auv3-extensions-user-presets"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-805-Building-Great-Shortcuts":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-805-Building-Great-Shortcuts","abstract":[{"text":"Shortcuts enable people to quickly and easily accomplish actions or get things done hands-free using Siri and the Shortcuts app. Join us for a tour of where shortcuts can appear, how you can customize the experience, and how your app’s shortcuts can be used with variables and actions from other apps.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc19-805-building-great-shortcuts","title":"Building Great Shortcuts","role":"sampleCode","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-809-Designing-iPad-Apps-for-Mac":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-809-Designing-iPad-Apps-for-Mac","role":"sampleCode","abstract":[{"text":"Discover how you can create a great Mac experience with your iPad app. Learn about essential techniques for adapting your iPad app’s layout and architecture for Mac, considerations for type and color, and how you can take advantage of macOS interfaces such as the menu bar, sidebar and window toolbar.","type":"text"}],"type":"topic","title":"Designing iPad Apps for Mac","url":"\/documentation\/wwdcnotes\/wwdc19-809-designing-ipad-apps-for-mac"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-104-Apple-Design-Awards":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-104-apple-design-awards","title":"Apple Design Awards","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-104-Apple-Design-Awards","kind":"article","abstract":[{"type":"text","text":"Join us for an unforgettable award ceremony celebrating developers and their outstanding work. The 2019 Apple Design Awards recognize state of the art iOS, macOS, watchOS, and tvOS apps that reflect excellence in design and innovation."}],"type":"topic"},"https://avatars.githubusercontent.com/u/5277837?v=4":{"alt":"Profile image of Federico Zanetello","type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/5277837?v=4","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/5277837?v=4","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-424-Training-Object-Detection-Models-in-Create-ML":{"title":"Training Object Detection Models in Create ML","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-424-Training-Object-Detection-Models-in-Create-ML","role":"sampleCode","abstract":[{"type":"text","text":"Custom Core ML models for Object Detection offer you an opportunity to add some real magic to your app. Learn how the Create ML app in Xcode makes it easy to train and evaluate these models. See how you can test the model performance directly within the app by taking advantage of Continuity Camera. It’s never been easier to build and deploy great Object Detection models for Core ML."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-424-training-object-detection-models-in-create-ml"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-508-Modernizing-Your-Audio-App":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-508-modernizing-your-audio-app","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-508-Modernizing-Your-Audio-App","type":"topic","abstract":[{"type":"text","text":"Apple platforms provide a comprehensive set of audio frameworks and technologies that are essential to creating a rich app experience. Learn about which frameworks and APIs are recommended to ensure that your app is well positioned for the future."}],"title":"Modernizing Your Audio App"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-256-Advances-in-Speech-Recognition":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-256-Advances-in-Speech-Recognition","abstract":[{"type":"text","text":"Speech Recognizer can now be used locally on iOS or macOS devices with no network connection. Learn how you can bring text-to-speech support to your app while maintaining privacy and eliminating the limitations of server-based processing. Speech recognition API has also been enhanced to provide richer analytics including speaking rate, pause duration, and voice quality."}],"url":"\/documentation\/wwdcnotes\/wwdc19-256-advances-in-speech-recognition","title":"Advances in Speech Recognition","role":"sampleCode","kind":"article","type":"topic"},"https://developer.apple.com/documentation/soundanalysis":{"title":"SoundAnalysis","url":"https:\/\/developer.apple.com\/documentation\/soundanalysis","type":"link","titleInlineContent":[{"type":"codeVoice","code":"SoundAnalysis"}],"identifier":"https:\/\/developer.apple.com\/documentation\/soundanalysis"},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","url":"\/documentation\/wwdcnotes","role":"collection","title":"WWDC Notes","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-518-Whats-New-for-Web-Developers":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-518-Whats-New-for-Web-Developers","abstract":[{"type":"text","text":"WebKit provides a rich set of classes designed to load, display, and manage web content in your app. Discover how to integrate your web content into powerful platform features including Dark Mode, new presentation features in Share Sheet, JavaScript payment APIs for Apple Pay, and more."}],"role":"sampleCode","title":"What’s New for Web Developers","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-518-whats-new-for-web-developers"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-258-Architecting-Your-App-for-Multiple-Windows":{"title":"Architecting Your App for Multiple Windows","type":"topic","abstract":[{"type":"text","text":"Dive into the details about what it means to support multitasking in iOS 13. Understand how previous best practices fit together with new ideas. Learn the nuances of structuring your application to support multiple windows, and how to instantiate your UI, handle windows coming and going, and manage your app’s underlying window resources."}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19-258-architecting-your-app-for-multiple-windows","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-258-Architecting-Your-App-for-Multiple-Windows"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-615-Game-Center-Player-Identifiers":{"title":"Game Center Player Identifiers","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-615-Game-Center-Player-Identifiers","role":"sampleCode","abstract":[{"type":"text","text":"Game Center now supports persistent player identifiers scoped to individual games or to a developer team ID. Understand how scoped identifiers enhance player privacy and see how to transition your apps and games onto the recommended API."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-615-game-center-player-identifiers"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-430-Introducing-the-Create-ML-App":{"title":"Introducing the Create ML App","url":"\/documentation\/wwdcnotes\/wwdc19-430-introducing-the-create-ml-app","role":"sampleCode","type":"topic","abstract":[{"text":"Bringing the power of Core ML to your app begins with one challenge. How do you create your model? The new Create ML app provides an intuitive workflow for model creation. See how to train, evaluate, test, and preview your models quickly in this easy-to-use tool. Get started with one of the many available templates handling a number of powerful machine learning tasks. Learn more about the many features for continuous model improvement and experimentation.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-430-Introducing-the-Create-ML-App","kind":"article"},"https://developer.apple.com/wwdc19/425":{"checksum":null,"url":"https:\/\/developer.apple.com\/wwdc19\/425","type":"download","identifier":"https:\/\/developer.apple.com\/wwdc19\/425"},"https://github.com/zntfdr":{"title":"GitHub","url":"https:\/\/github.com\/zntfdr","type":"link","titleInlineContent":[{"text":"GitHub","type":"text"}],"identifier":"https:\/\/github.com\/zntfdr"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-259-Targeting-Content-with-Multiple-Windows":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-259-Targeting-Content-with-Multiple-Windows","role":"sampleCode","abstract":[{"text":"Learn how to target content for a specific window in your app. Find out how to identify which scene the system should open from a notification, a shortcut item, and other user activities.","type":"text"}],"type":"topic","title":"Targeting Content with Multiple Windows","url":"\/documentation\/wwdcnotes\/wwdc19-259-targeting-content-with-multiple-windows"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-254-Writing-Great-Accessibility-Labels":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-254-Writing-Great-Accessibility-Labels","abstract":[{"text":"Great accessibility labels are the difference between someone using and loving your app or someone deleting your app. Experience VoiceOver as demonstrated by an Apple Accessibility engineer as she navigates complex UI and demonstrates how descriptive labels are an easy way to ensure your app is for everyone.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc19-254-writing-great-accessibility-labels","title":"Writing Great Accessibility Labels","role":"sampleCode","kind":"article","type":"topic"},"WWDCNotes.png":{"alt":null,"type":"image","identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-253-Exploring-Tinted-Graphic-Complications":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-253-Exploring-Tinted-Graphic-Complications","role":"sampleCode","abstract":[{"text":"Many Watch faces in watchOS 6 allow for customizing the tint color of content, allowing for even more personalization of Apple’s most personal device. Discover how you can use ClockKit data providers to offer full color and tint-ready options for each complication family type. This gives customers the ability to get up to date, important information at a glance, no matter which Watch face they choose.","type":"text"}],"type":"topic","title":"Exploring Tinted Graphic Complications","url":"\/documentation\/wwdcnotes\/wwdc19-253-exploring-tinted-graphic-complications"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-513-Understanding-CPU-Usage-with-Web-Inspector":{"title":"Understanding CPU Usage with Web Inspector","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-513-Understanding-CPU-Usage-with-Web-Inspector","role":"sampleCode","abstract":[{"type":"text","text":"As a developer of web content, you play an important role in fulfilling customer expectations for a high performance web experience while minimizing power use across all their devices. Discover new insights on how you can improve the power efficiency of your webpages in Safari, or embedded web content in your apps, by using this powerful new tool in Web Inspector. Learn new strategies to help you deliver dynamic experiences that use less CPU and save battery life."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-513-understanding-cpu-usage-with-web-inspector"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-806-Designing-Great-Shortcuts":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-806-designing-great-shortcuts","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-806-Designing-Great-Shortcuts","type":"topic","abstract":[{"type":"text","text":"Shortcuts allow people to access information and actions on the go or in the Shortcuts app. The best shortcuts take careful design planning to hone in on what can help expedite a person’s workflow with your app. Gain insights as to what makes a great shortcut and how to design the experience to be useful, beautiful, and responsive. See examples of how to map out the Siri dialog flow when using parameters to make your shortcuts flexible and helpful."}],"title":"Designing Great Shortcuts"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10036-Discover-builtin-sound-classification-in-SoundAnalysis":{"url":"\/documentation\/wwdcnotes\/wwdc21-10036-discover-builtin-sound-classification-in-soundanalysis","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10036-Discover-builtin-sound-classification-in-SoundAnalysis","abstract":[{"text":"Explore how you can use the Sound Analysis framework in your app to detect and classify discrete sounds from any audio source — including live sounds from a microphone or from a video or audio file — and identify precisely in a moment where that sound occurs. Learn how the built-in sound classifier makes it easy for you to identify over 300 different types of sounds without the need for a custom trained model. This includes a variety of noises, ranging from human sounds, musical instruments, animals, and various items.","type":"text"}],"title":"Discover built-in sound classification in SoundAnalysis","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-244-Visual-Design-and-Accessibility":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-244-Visual-Design-and-Accessibility","abstract":[{"type":"text","text":"Learn about the importance of supporting Large Text. Hear about Differentiate Without Color, a new API on iOS which can enable people with vision disorders such as color-blindness to easily use your app. Learn how to use it and how it can bring inclusivity to your app. Find out how to enable new Reduce Motion API to stop auto-play in your app for people who may be sensitive to motion."}],"role":"sampleCode","title":"Visual Design and Accessibility","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-244-visual-design-and-accessibility"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-511-Supporting-Dark-Mode-in-Your-Web-Content":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-511-Supporting-Dark-Mode-in-Your-Web-Content","abstract":[{"type":"text","text":"With system-wide Dark Mode support in iOS and macOS, you’ll want to make sure your web content is appropriately styled to reflect your users’  preference. Learn techniques to ensure your content looks its best when presented in Safari, embedded in other apps such as Mail, or when used in your apps. Discover the details and best practices for this new pillar in responsive web design."}],"role":"sampleCode","title":"Supporting Dark Mode in Your Web Content","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-511-supporting-dark-mode-in-your-web-content"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-723-Advances-in-Foundation":{"title":"Advances in Foundation","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-723-Advances-in-Foundation","role":"sampleCode","abstract":[{"type":"text","text":"The Foundation framework provides a base layer of functionality for apps and frameworks that’s used throughout the macOS, iOS, watchOS, and tvOS SDKs. Hear about valuable enhancements to Foundation collections, performance, internationalization features, and Swift integration."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-723-advances-in-foundation"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"link","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"}}}