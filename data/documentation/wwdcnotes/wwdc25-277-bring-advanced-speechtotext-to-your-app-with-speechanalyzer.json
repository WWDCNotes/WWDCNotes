{"sections":[],"primaryContentSections":[{"kind":"content","content":[{"level":2,"type":"heading","anchor":"overview","text":"Overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}]},{"level":2,"type":"heading","anchor":"Related-Sessions","text":"Related Sessions"},{"type":"links","style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices"]}]}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc25-277-bring-advanced-speechtotext-to-your-app-with-speechanalyzer"]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-277-Bring-advanced-speechtotext-to-your-app-with-SpeechAnalyzer"},"schemaVersion":{"major":0,"minor":3,"patch":0},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25"]]},"metadata":{"role":"sampleCode","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC25","title":"Bring advanced speech-to-text to your app with SpeechAnalyzer"},"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (19 min)","type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/277"}},"abstract":[{"type":"text","text":"Discover the new SpeechAnalyzer API for speech to text. We‚Äôll learn about the Swift API and its capabilities, which power features in Notes, Voice Memos, Journal, and more. We‚Äôll dive into details about how speech to text works and how SpeechAnalyzer and SpeechTranscriber can enable you to create exciting, performant features. And you‚Äôll learn how to incorporate SpeechAnalyzer and live transcription into your app with a code-along."}],"kind":"article","references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC25":{"kind":"article","images":[{"type":"icon","identifier":"WWDC25-Icon.png"},{"type":"card","identifier":"WWDC25.jpg"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25","url":"\/documentation\/wwdcnotes\/wwdc25","title":"WWDC25","abstract":[{"text":"Xcode 26, Swift 6.2, iOS\/macOS\/tvOS\/visionOS 26.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"code":"Foundation Models","type":"codeVoice"},{"text":", ","type":"text"},{"code":"AlarmKit","type":"codeVoice"},{"text":", ","type":"text"},{"code":"PermissionKit","type":"codeVoice"},{"text":", and more.","type":"text"}],"role":"collectionGroup","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices":{"abstract":[{"text":"Bring the latest advancements in Speech Synthesis to your apps. Learn how you can integrate your custom speech synthesizer and voices into iOS and macOS. We‚Äôll show you how SSML is used to generate expressive speech synthesis, and explore how Personal Voice can enable your augmentative and assistive communication app to speak on a person‚Äôs behalf in an authentic way.","type":"text"}],"role":"sampleCode","kind":"article","type":"topic","title":"Extend Speech Synthesis with personal and custom voices","url":"\/documentation\/wwdcnotes\/wwdc23-10033-extend-speech-synthesis-with-personal-and-custom-voices","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","titleInlineContent":[{"text":"Learn More‚Ä¶","type":"text"}],"url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"WWDC25-Icon.png":{"identifier":"WWDC25-Icon.png","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC25-Icon.png"}],"type":"image"},"WWDC25.jpg":{"identifier":"WWDC25.jpg","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC25.jpg"}],"alt":null,"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","role":"collection","title":"WWDC Notes","type":"topic","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"url":"\/documentation\/wwdcnotes"},"https://developer.apple.com/videos/play/wwdc2025/277":{"type":"download","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/277","checksum":null,"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/277"},"WWDCNotes.png":{"identifier":"WWDCNotes.png","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDCNotes.png"}],"type":"image"}}}