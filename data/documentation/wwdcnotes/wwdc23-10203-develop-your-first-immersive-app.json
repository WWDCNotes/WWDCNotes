{"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (31 min)","type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10203"}},"sections":[],"primaryContentSections":[{"kind":"content","content":[{"level":2,"anchor":"overview","type":"heading","text":"Overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Speakers: Peter Zion, RealityKit Tools"}]},{"level":2,"anchor":"Create-a-new-app-project-in-Xcode-0106","type":"heading","text":"Create a new app project in Xcode 01:06"},{"type":"paragraph","inlineContent":[{"text":"Two new options are presented when creating a new project for the visionOS platform:","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Initial Scene"}]},{"type":"text","text":" which allows us to specify the type of the initial scene that’s automatically included in the app"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"inlineContent":[{"type":"text","text":"Note: you can always add additional scenes later"}],"type":"emphasis"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"There are 2 initial scenes to choose from: "},{"inlineContent":[{"text":"Window","type":"text"}],"type":"strong"},{"type":"text","text":" and "},{"type":"strong","inlineContent":[{"type":"text","text":"Volume"}]}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"type":"text","text":"Window"}],"type":"strong"},{"text":" primarily used for present 2D content and can be resized in their planar dimension","type":"text"},{"text":" ","type":"text"},{"text":"* Learn more about windows in ","type":"text"},{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10109","type":"reference"}]}]},{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Volumes"}]},{"text":" are designed to present 3D content and cannot be adjusted by the person using the app","type":"text"},{"text":" ","type":"text"},{"text":"* Learn more about volumes in ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10113\/"}],"type":"paragraph"}]}],"type":"unorderedList"}]}],"type":"unorderedList"}]},{"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"text":"Immersive Space","type":"text"}],"type":"strong"},{"type":"text","text":" gives us the opportunity to add a starting point for immersive content to our app"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Immersive Space can be used to present unbounded content anywere on the infinite canvas"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"When your app activates this scene type, it moves from ","type":"text"},{"inlineContent":[{"type":"text","text":"Shared Space"}],"type":"strong"},{"text":" to ","type":"text"},{"inlineContent":[{"text":"Full Space","type":"text"}],"type":"strong"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Full Space provides access to dedicated rendering resources and can request permission to enable ARKit permissions","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"3 styles of immersive space: ","type":"text"},{"inlineContent":[{"type":"text","text":"Mixed Immersion"}],"type":"strong"},{"text":", ","type":"text"},{"inlineContent":[{"type":"text","text":"Progressive Immersion"}],"type":"strong"},{"text":", ","type":"text"},{"inlineContent":[{"text":"Full Immersion","type":"text"}],"type":"strong"},{"text":" ","type":"text"},{"text":"* ","type":"text"},{"inlineContent":[{"type":"text","text":"Mixed Immersion"}],"type":"strong"},{"text":" lets you place unbounded virtual content in a Full Space while maintaining passthrough","type":"text"},{"text":" ","type":"text"},{"text":"* ","type":"text"},{"inlineContent":[{"text":"Progressive Immersion","type":"text"}],"type":"strong"},{"text":" opens a portal for a roughly 180-degree view of your content","type":"text"},{"text":" ","type":"text"},{"text":"* ","type":"text"},{"inlineContent":[{"type":"text","text":"Full Immersion"}],"type":"strong"},{"text":" hides passthrough entirely and surrounds eople with your app’s environment","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Learn more about Immersive Spaces in "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10111\/"}],"type":"paragraph"}]}]}]}]},{"type":"aside","content":[{"inlineContent":[{"type":"text","text":"In general, we recommend apps always start in a window on this platform, and provide clear entry and exit controls so that people can decide when to be more immersed in your content."}],"type":"paragraph"}],"style":"note","name":"Note"},{"level":3,"anchor":"ContentView-0615","type":"heading","text":"ContentView 06:15"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Most of the prepared code is inside the "},{"type":"codeVoice","code":"ContentView.swift"},{"type":"text","text":" file, which uses new platform-specific features."}]},{"level":3,"anchor":"RealityView-0723","type":"heading","text":"RealityView 07:23"},{"type":"paragraph","inlineContent":[{"type":"text","text":"RealityView allows you to place Reality content into a SwiftUI view hierarchy and the initializer takes 2 closures as parameters: "},{"type":"strong","inlineContent":[{"text":"make closure","type":"text"}]},{"type":"text","text":", and an "},{"type":"strong","inlineContent":[{"type":"text","text":"update closure"}]},{"type":"text","text":"."}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Make closure"}]},{"text":" adds the initial RealityKit content to the view","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"inlineContent":[{"type":"text","text":"Update closure"}],"type":"strong"},{"text":" is optional but called when SwiftUI state changes","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"inlineContent":[{"type":"text","text":"Note: update closure is not a rendering update loop and is not called on every frame; only when the SwiftUI state changes"}],"type":"emphasis"}],"type":"paragraph"}]}],"type":"unorderedList"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Learn more about RealityView and gestures in "},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10080\/#:~:text=With%20RealityKit%2C%20you%20can%20augment,offers%20a%20lot%20of%20features.","isActive":true}]},{"level":2,"anchor":"Introduction-to-the-Simulator-0856","type":"heading","text":"Introduction to the Simulator 08:56"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Mimicks what somebody would see when wearing the device. This section walks through simulator controls."}]},{"level":2,"anchor":"How-to-use-Xcode-Previews-for-Quick-Iteration-1210","type":"heading","text":"How to use Xcode Previews for Quick Iteration 12:10"},{"type":"paragraph","inlineContent":[{"type":"text","text":"As with the simulator, Xcode previews are presented as a simulated device view. This section walks through the Xcode Previews controls, and mentions that there are advanced features such as creating custom camera angles. More information on this can be found in the developer documentation."}]},{"level":2,"anchor":"Introduction-to-Reality-Composer-Pro-1333","type":"heading","text":"Introduction to Reality Composer Pro 13:33"},{"type":"paragraph","inlineContent":[{"type":"text","text":"RealityKit content packages are Swift packages containing RealityKit content, and are processed at build time to optimize your content for runtime use. You can preview scenes by clicking on the content packages in your file hierarchy within Xcode, and can open those scenes to edit them inside Reality Composer Pro by clicking the button "},{"type":"codeVoice","code":"Open in Reality Composer Pro"},{"type":"text","text":" in the top right of the scene preview window."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Reality Composer Pro organizes its content into "},{"type":"strong","inlineContent":[{"text":"scenes","type":"text"}]},{"type":"text","text":". To create 3D content for a different scene in your app, simply create a new scene inside Reality Composer Pro that will target the new scene in your app (i.e. "},{"type":"codeVoice","code":"immersiveScene"},{"type":"text","text":" inside Reality Composer Pro could be used to render content inside your "},{"type":"codeVoice","code":"appImmersiveScene"},{"type":"text","text":" which would be different than content rendered in your app window or volume)."}]},{"level":3,"anchor":"2-more-key-details-to-understand-about-Immersive-Space-1600","type":"heading","text":"2 more key details to understand about Immersive Space 16:00"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Uses the inferred position of your feet as the origin of the content","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"When your apps run in a full space, they can request access to additional data such as the exact position and orientation of your hands"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"type":"text","text":"Note: this is not available in shared space"}],"type":"emphasis"}]}]}]}]}]},{"type":"paragraph","inlineContent":[{"text":"Learn more about accessible user data in ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10082\/#:~:text=ARKit%20uses%20sophisticated%20computer%20vision,the%20palm%20of%20your%20hand."}]},{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Navigating Reality Composer Pro "},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1017","isActive":true}]}]},{"level":3,"anchor":"Create-an-Immersive-Scene-2017","type":"heading","text":"Create an Immersive Scene 20:17"},{"type":"paragraph","inlineContent":[{"text":"The first scene in the body property within your ","type":"text"},{"code":"App.swift","type":"codeVoice"},{"text":" file is the one that will be presented by the app when it is launched. Add additional scenes to your app by adding them after the first scene.","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Adding multiple scenes to your App.swift file "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1277"}]}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"text":"How to preview immserive scenes in Xcode Previews ","type":"text"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1363","type":"reference","isActive":true}]}]}]}]},{"type":"aside","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"By default, previews are clipped to default scene bounds. If it’s presenting a view that loads content outside of these bounds, the content will not be visible. In order to support previewing immersive content that extends beyond these bounds, simply modify the view being prepared with .previewLayout(.sizeThatFits)."}]}],"style":"note","name":"Note"},{"syntax":null,"type":"codeListing","code":["#Preview {","    ImmersiveView()","        .previewLayout(.sizeThatFits)","}"]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"How to have your app open in Immserive Space "},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1427","type":"reference","isActive":true}]}]}]}]},{"level":3,"anchor":"Target-SwiftUI-Gestures-to-RealityKit-Entities-2537","type":"heading","text":"Target SwiftUI Gestures to RealityKit Entities 25:37"},{"type":"paragraph","inlineContent":[{"inlineContent":[{"text":"Gestures","type":"text"}],"type":"strong"},{"text":" allow SwiftUI views to respond to input events. ","type":"text"},{"inlineContent":[{"type":"text","text":"Entity targetting"}],"type":"strong"},{"text":" is how input events can be targetted to specific Reality entities (e.g. tapping a specific 3D model in Immersive Space). For entity targetting to work, entities must have both a ","type":"text"},{"code":"CollisionComponent","type":"codeVoice"},{"text":" and an ","type":"text"},{"code":"InputTargetComponent","type":"codeVoice"}]},{"type":"aside","content":[{"inlineContent":[{"type":"text","text":"Entity targeting is the glue that connects SwiftUI interactions to RealityKit content… In a more complex app, you can use entity targeting to trigger more sophisticated actions, such as presenting additional views, playing audio, or starting animations."}],"type":"paragraph"}],"style":"note","name":"Note"},{"level":2,"anchor":"Written-By","type":"heading","text":"Written By"},{"type":"row","numberOfColumns":5,"columns":[{"content":[{"inlineContent":[{"identifier":"stevenpaulhoward","type":"image"}],"type":"paragraph"}],"size":1},{"content":[{"level":3,"text":"stevenpaulhoward","type":"heading","anchor":"stevenpaulhoward"},{"inlineContent":[{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/stevenpaulhoward","overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"overridingTitle":"Contributed Notes","type":"reference","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/github.com\/stevenpaulhoward","type":"reference","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/x.com\/stevnhoward","type":"reference","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/","type":"reference","isActive":true}],"type":"paragraph"}],"size":4}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"}]},{"level":2,"anchor":"Related-Sessions","type":"heading","text":"Related Sessions"},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111215-Meet-UIKit-for-spatial-computing"],"style":"list"},{"type":"small","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Legal Notice"}]}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}]}],"schemaVersion":{"minor":3,"major":0,"patch":0},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app","interfaceLanguage":"swift"},"kind":"article","variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-10203-develop-your-first-immersive-app"]}],"metadata":{"roleHeading":"WWDC23","modules":[{"name":"WWDC Notes"}],"role":"sampleCode","title":"Develop your first immersive app"},"abstract":[{"type":"text","text":"Find out how you can build immersive apps for visionOS using Xcode and Reality Composer Pro. We’ll show you how to get started with a new visionOS project, use Xcode Previews for your SwiftUI development, and take advantage of RealityKit and RealityView to render 3D content."}],"references":{"https://developer.apple.com/videos/play/wwdc2023/10203/?time=1363":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1363","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1363","titleInlineContent":[{"type":"text","text":"22:43"}],"title":"22:43"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing":{"url":"\/documentation\/wwdcnotes\/wwdc23-10260-get-started-with-building-apps-for-spatial-computing","kind":"article","abstract":[{"type":"text","text":"Get ready to develop apps and games for visionOS! Discover the fundamental building blocks that make up spatial computing — windows, volumes, and spaces — and find out how you can use these elements to build engaging and immersive experiences."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","title":"Get started with building apps for spatial computing","role":"sampleCode"},"https://developer.apple.com/videos/play/wwdc2023/10082/#:~:text=ARKit%20uses%20sophisticated%20computer%20vision,the%20palm%20of%20your%20hand.":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10082\/#:~:text=ARKit%20uses%20sophisticated%20computer%20vision,the%20palm%20of%20your%20hand.","title":"Meet ARKit for Spatial Computing","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10082\/#:~:text=ARKit%20uses%20sophisticated%20computer%20vision,the%20palm%20of%20your%20hand.","type":"link","titleInlineContent":[{"type":"text","text":"Meet ARKit for Spatial Computing"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"type":"topic","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","abstract":[{"text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio.","type":"text"}],"title":"Build spatial experiences with RealityKit"},"https://developer.apple.com/videos/play/wwdc2023/10080/#:~:text=With%20RealityKit%2C%20you%20can%20augment,offers%20a%20lot%20of%20features.":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10080\/#:~:text=With%20RealityKit%2C%20you%20can%20augment,offers%20a%20lot%20of%20features.","title":"Build Spatial Experiences with RealityKit","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10080\/#:~:text=With%20RealityKit%2C%20you%20can%20augment,offers%20a%20lot%20of%20features.","type":"link","titleInlineContent":[{"type":"text","text":"Build Spatial Experiences with RealityKit"}]},"stevenpaulhoward.jpeg":{"identifier":"stevenpaulhoward.jpeg","type":"image","variants":[{"url":"\/images\/stevenpaulhoward.jpeg","traits":["1x","light"]}],"alt":null},"stevenpaulhoward":{"identifier":"stevenpaulhoward","type":"image","variants":[{"url":"\/images\/stevenpaulhoward.jpeg","traits":["1x","light"]}],"alt":"Profile image of stevenpaulhoward"},"https://":{"identifier":"https:\/\/","title":"Blog","url":"https:\/\/","type":"link","titleInlineContent":[{"type":"text","text":"Blog"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","type":"topic","title":"WWDC Notes","url":"\/documentation\/wwdcnotes","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"role":"collection"},"https://developer.apple.com/videos/play/wwdc2023/10203/?time=1427":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1427","title":"23:48","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1427","type":"link","titleInlineContent":[{"type":"emphasis","inlineContent":[{"text":"23:48","type":"text"}]}]},"WWDCNotes.png":{"identifier":"WWDCNotes.png","type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"alt":null},"https://developer.apple.com/videos/play/wwdc2023/10109":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10109","title":"Meet SwiftUI for Spatial Computing","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10109","type":"link","titleInlineContent":[{"type":"text","text":"Meet SwiftUI for Spatial Computing"}]},"https://x.com/stevnhoward":{"identifier":"https:\/\/x.com\/stevnhoward","title":"X\/Twitter","url":"https:\/\/x.com\/stevnhoward","type":"link","titleInlineContent":[{"type":"text","text":"X\/Twitter"}]},"doc://WWDCNotes/documentation/WWDCNotes/stevenpaulhoward":{"type":"topic","url":"\/documentation\/wwdcnotes\/stevenpaulhoward","images":[{"type":"card","identifier":"stevenpaulhoward.jpeg"},{"type":"icon","identifier":"stevenpaulhoward.jpeg"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/stevenpaulhoward","role":"sampleCode","kind":"article","abstract":[{"type":"text","text":"3D connoisseur"}],"title":"stevenpaulhoward (4 notes)"},"https://developer.apple.com/videos/play/wwdc2023/10111/":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10111\/","title":"Go Beyond the Window with SwiftUI","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10111\/","type":"link","titleInlineContent":[{"type":"text","text":"Go Beyond the Window with SwiftUI"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10082-Meet-ARKit-for-spatial-computing":{"kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc23-10082-meet-arkit-for-spatial-computing","type":"topic","abstract":[{"type":"text","text":"Discover how you can use ARKit’s tracking and scene understanding features to develop a whole new universe of immersive apps and games. Learn how visionOS and ARKit work together to help you create apps that understand a person’s surroundings — all while preserving privacy. Explore the latest updates to the ARKit API and follow along as we demonstrate how to take advantage of hand tracking and scene geometry in your apps."}],"title":"Meet ARKit for spatial computing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"SwiftData"},{"type":"text","text":", "},{"type":"codeVoice","code":"Observation"},{"text":", ","type":"text"},{"type":"codeVoice","code":"StoreKit"},{"text":" views, and more.","type":"text"}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","type":"topic","title":"WWDC23","url":"\/documentation\/wwdcnotes\/wwdc23","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"role":"collectionGroup"},"https://developer.apple.com/videos/play/wwdc2023/10113/":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10113\/","title":"Take SwiftUI to the next dimension","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10113\/","type":"link","titleInlineContent":[{"type":"text","text":"Take SwiftUI to the next dimension"}]},"https://github.com/stevenpaulhoward":{"identifier":"https:\/\/github.com\/stevenpaulhoward","title":"GitHub","url":"https:\/\/github.com\/stevenpaulhoward","type":"link","titleInlineContent":[{"type":"text","text":"GitHub"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10083-Meet-Reality-Composer-Pro":{"abstract":[{"text":"Discover how to easily compose, edit, and preview 3D content with Reality Composer Pro. Follow along as we explore this developer tool by setting up a new project, composing scenes, adding particle emitters and audio, and even previewing content on device.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10083-meet-reality-composer-pro","type":"topic","role":"sampleCode","title":"Meet Reality Composer Pro"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-111215-Meet-UIKit-for-spatial-computing":{"title":"Meet UIKit for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-111215-meet-uikit-for-spatial-computing","abstract":[{"text":"Learn how to bring your UIKit app to visionOS. We’ll show you how to build for a new destination, explore APIs and best practices for spatial computing, and take your content into the third dimension when you use SwiftUI with UIKit in visionOS.","type":"text"}],"type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111215-Meet-UIKit-for-spatial-computing","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10111-Go-beyond-the-window-with-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10111-go-beyond-the-window-with-swiftui","role":"sampleCode","kind":"article","type":"topic","title":"Go beyond the window with SwiftUI","abstract":[{"type":"text","text":"Get ready to launch into space — a new SwiftUI scene type that can help you make great immersive experiences for visionOS. We’ll show you how to create a new scene with ImmersiveSpace, place 3D content, and integrate RealityView. Explore how you can use the immersionStyle scene modifier to increase the level of immersion in an app and learn best practices for managing spaces, adding virtual hands with ARKit, adding support for SharePlay, and building an “out of this world” experience!"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10273-work-with-reality-composer-pro-content-in-xcode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","role":"sampleCode","kind":"article","abstract":[{"type":"text","text":"Learn how to bring content from Reality Composer Pro to life in Xcode. We’ll show you how to load 3D scenes into Xcode, integrate your content with your code, and add interactivity to your app. We’ll also share best practices and tips for using these tools together in your development workflow."}],"title":"Work with Reality Composer Pro content in Xcode"},"https://developer.apple.com/videos/play/wwdc2023/10203/?time=1277":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1277","title":"21:18","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1277","type":"link","titleInlineContent":[{"type":"emphasis","inlineContent":[{"text":"21:18","type":"text"}]}]},"https://developer.apple.com/wwdc23/10203":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10203","url":"https:\/\/developer.apple.com\/wwdc23\/10203","checksum":null,"type":"download"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"link","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10113-Take-SwiftUI-to-the-next-dimension":{"url":"\/documentation\/wwdcnotes\/wwdc23-10113-take-swiftui-to-the-next-dimension","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","abstract":[{"type":"text","text":"Get ready to add depth and dimension to your visionOS apps. Find out how to bring three-dimensional objects to your app using volumes, get to know the Model 3D API, and learn how to position and animate content. We’ll also show you how to use UI attachments in RealityView and support gestures in your content."}],"title":"Take SwiftUI to the next dimension","kind":"article","role":"sampleCode","type":"topic"},"https://developer.apple.com/videos/play/wwdc2023/10203/?time=1017":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1017","title":"16:58","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10203\/?time=1017","type":"link","titleInlineContent":[{"type":"emphasis","inlineContent":[{"text":"16:58","type":"text"}]}]}}}