{"abstract":[{"type":"text","text":"ARKit 2 makes it easy to develop vivid augmented reality experiences and enable apps to interact with the real world in entirely new ways. Discover how multiple iOS devices can simultaneously view an AR scene or play multiplayer AR games. Learn about new capabilities for tracking 2D images, and see how to detect known 3D objects like sculptures, toys, and furniture."}],"schemaVersion":{"patch":0,"minor":3,"major":0},"primaryContentSections":[{"kind":"content","content":[{"level":2,"text":"`ARWorldMap` persistence","type":"heading","anchor":"ARWorldMap-persistence"},{"type":"paragraph","inlineContent":[{"text":"After the user ends a session (say in front of a table and the user put objects on the table), the user can go back again another day in front of the same table and the app can recognize the table and put back all the objects as the user placed them as in the previous session","type":"text"}]},{"level":2,"text":"Multi-User Experiences","type":"heading","anchor":"Multi-User-Experiences"},{"inlineContent":[{"text":"The ","type":"text"},{"type":"codeVoice","code":"ARWorldMap"},{"text":" are sharable and this is why we can play an ar game at the same time with multiple devices","type":"text"}],"type":"paragraph"},{"anchor":"More-robust-tracking-and-plane-detection","level":2,"text":"More robust tracking and plane detection","type":"heading"},{"type":"paragraph","inlineContent":[{"text":"Both horizontal and from ARKit 1.5 vertical.","type":"text"}]},{"text":"(Real Time) Environment Texturing","type":"heading","anchor":"Real-Time-Environment-Texturing","level":2},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC18-602-bench"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Even if ARKit doesn’t know the whole scene (because the user didn’t spin 360-degrees around), ARKit will use CoreML to “hallucinate” the missing parts."}]},{"text":"Real Time Multiple 2D Images Tracking:","type":"heading","anchor":"Real-Time-Multiple-2D-Images-Tracking","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"Track position and orientation in each frame, pictures no need to be static"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC18-602-table"}]},{"inlineContent":[{"text":"You need to import the reference images to Xcode.","type":"text"}],"type":"paragraph"},{"level":2,"text":"Object Tracking","type":"heading","anchor":"Object-Tracking"},{"inlineContent":[{"text":"Track positions of fixed objects (you can move around them but the object can’t move), you need to import a 3d model of the object into xcode, Apple gives you a (free) app to scan the object and get the 3d object","type":"text"}],"type":"paragraph"},{"level":2,"text":"Face Tracking","type":"heading","anchor":"Face-Tracking"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Gaze tracking"}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"type":"image","identifier":"WWDC18-602-eye"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Tongue tracking (as in memojii)"}]}]}],"type":"unorderedList"},{"level":2,"text":"Written By","type":"heading","anchor":"Written-By"},{"columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"identifier":"zntfdr","type":"image"}]}]},{"size":4,"content":[{"anchor":"Federico-Zanetello","text":"Federico Zanetello","level":3,"type":"heading"},{"type":"paragraph","inlineContent":[{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","overridingTitle":"Contributed Notes","type":"reference","isActive":true,"overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}]},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/github.com\/zntfdr","type":"reference","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/zntfdr.dev","type":"reference","isActive":true}]}]}],"type":"row","numberOfColumns":5},{"inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference","isActive":true}],"type":"paragraph"},{"level":2,"text":"Related Sessions","type":"heading","anchor":"Related-Sessions"},{"style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC18-805-Creating-Great-AR-Experiences"],"type":"links"},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Legal Notice"}]}],"type":"small"},{"inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}],"type":"small"}]}],"kind":"article","variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc18-602-whats-new-in-arkit-2"],"traits":[{"interfaceLanguage":"swift"}]}],"metadata":{"roleHeading":"WWDC18","title":"What’s New in ARKit 2","modules":[{"name":"WWDC Notes"}],"role":"sampleCode"},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC18"]]},"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (57 min)","identifier":"https:\/\/developer.apple.com\/wwdc18\/602","isActive":true,"type":"reference"}},"sections":[],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC18-602-Whats-New-in-ARKit-2"},"references":{"doc://WWDCNotes/documentation/WWDCNotes/zntfdr":{"type":"topic","title":"Federico Zanetello (332 notes)","url":"\/documentation\/wwdcnotes\/zntfdr","abstract":[{"text":"Software engineer with a strong passion for well-written code, thought-out composable architectures, automation, tests, and more.","type":"text"}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","images":[{"type":"card","identifier":"zntfdr.jpeg"},{"type":"icon","identifier":"zntfdr.jpeg"}],"role":"sampleCode"},"zntfdr.jpeg":{"alt":null,"type":"image","variants":[{"url":"\/images\/zntfdr.jpeg","traits":["1x","light"]}],"identifier":"zntfdr.jpeg"},"doc://WWDCNotes/documentation/WWDCNotes":{"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"type":"topic","url":"\/documentation\/wwdcnotes","role":"collection","title":"WWDC Notes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"kind":"symbol"},"WWDC18-602-table":{"alt":null,"type":"image","variants":[{"url":"\/images\/WWDC18-602-table.png","traits":["1x","light"]}],"identifier":"WWDC18-602-table"},"zntfdr":{"alt":"Profile image of Federico Zanetello","type":"image","variants":[{"url":"\/images\/zntfdr.jpeg","traits":["1x","light"]}],"identifier":"zntfdr"},"WWDC18-602-eye":{"alt":null,"type":"image","variants":[{"url":"\/images\/WWDC18-602-eye.png","traits":["1x","light"]}],"identifier":"WWDC18-602-eye"},"WWDC18.jpeg":{"alt":null,"type":"image","variants":[{"url":"\/images\/WWDC18.jpeg","traits":["1x","light"]}],"identifier":"WWDC18.jpeg"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC18":{"abstract":[{"type":"text","text":"Xcode 10, Swift 4.2, iOS 12, macOS 10.14 (Mojave), tvOS 12, watchOS 5."}],"images":[{"type":"icon","identifier":"WWDC18-Icon.png"},{"type":"card","identifier":"WWDC18.jpeg"}],"url":"\/documentation\/wwdcnotes\/wwdc18","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC18","kind":"article","title":"WWDC18","role":"collectionGroup"},"https://developer.apple.com/wwdc18/602":{"type":"download","url":"https:\/\/developer.apple.com\/wwdc18\/602","checksum":null,"identifier":"https:\/\/developer.apple.com\/wwdc18\/602"},"WWDCNotes.png":{"alt":null,"type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"identifier":"WWDCNotes.png"},"WWDC18-602-bench":{"alt":null,"type":"image","variants":[{"url":"\/images\/WWDC18-602-bench.png","traits":["1x","light"]}],"identifier":"WWDC18-602-bench"},"https://zntfdr.dev":{"type":"link","title":"Blog","url":"https:\/\/zntfdr.dev","titleInlineContent":[{"type":"text","text":"Blog"}],"identifier":"https:\/\/zntfdr.dev"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC18-805-Creating-Great-AR-Experiences":{"role":"sampleCode","abstract":[{"type":"text","text":"Engaging AR experiences are easy to start and navigate, persuasively realistic, and highly immersive. Learn best practices for successfully bringing people into an AR experience, teaching them about how to interact and engage with virtual content, and making your AR content look beautiful and grounded in the real world."}],"type":"topic","title":"Creating Great AR Experiences","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc18-805-creating-great-ar-experiences","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC18-805-Creating-Great-AR-Experiences"},"WWDC18-Icon.png":{"alt":null,"type":"image","variants":[{"url":"\/images\/WWDC18-Icon.png","traits":["1x","light"]}],"identifier":"WWDC18-Icon.png"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"https://github.com/zntfdr":{"type":"link","title":"GitHub","url":"https:\/\/github.com\/zntfdr","titleInlineContent":[{"type":"text","text":"GitHub"}],"identifier":"https:\/\/github.com\/zntfdr"}}}