{"metadata":{"modules":[{"name":"WWDC Notes"}],"title":"Designing Great ML Experiences","roleHeading":"WWDC19","role":"sampleCode"},"kind":"article","sampleCodeDownload":{"kind":"sampleDownload","action":{"identifier":"https:\/\/developer.apple.com\/wwdc19\/803","type":"reference","overridingTitle":"Watch Video (57 min)","isActive":true}},"schemaVersion":{"major":0,"patch":0,"minor":3},"abstract":[{"text":"Machine learning enables new experiences that understand what we say, suggest things that we may love, and allow us to express ourselves in new, rich ways. Machine learning can make existing experiences better by automating mundane tasks and improving the accuracy and speed of interactions. Learn how to incorporate ML experiences into your apps, and gain practical approaches to designing user interfaces that feel effortlessly helpful.","type":"text"}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-803-Designing-Great-ML-Experiences","interfaceLanguage":"swift"},"sections":[],"primaryContentSections":[{"content":[{"level":2,"anchor":"overview","text":"Overview","type":"heading"},{"type":"paragraph","inlineContent":[{"type":"text","text":"This is a people\/tech talk on how to design Machine learning experiences. Some of the things listed here automatically translate to code, some are more heuristic."}]},{"type":"paragraph","inlineContent":[{"text":"Refer to the Apple’s ","type":"text"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/design\/human-interface-guidelines\/machine-learning\/overview\/introduction\/","isActive":true},{"text":".","type":"text"}]},{"level":2,"anchor":"Usage","text":"Usage","type":"heading"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Apple uses machine learning in ways that you may not expect, subtle ways that improve your experience with your devices: AirPods, FaceID, quick type, they all use ML."}]},{"type":"paragraph","inlineContent":[{"text":"A few examples:","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"In the keyboard, Apple increases or decreases the target tap area of the keyboard buttons based on the word you’re most likely to type."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"In Photos, Machine learning helps people create albums, edit photos and search for specific memories."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Searching for pictures based on what’s in a picture (e.g. dog) changes how we engage with our memories. The search even suggest word completion, suggest categories to search in."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"The new Apple watches use ML to detect heart problems.","type":"text"}]}]}]},{"level":2,"anchor":"Why-Machine-Learning","text":"Why Machine Learning","type":"heading"},{"type":"paragraph","inlineContent":[{"text":"Looking at categorizing pictures of dogs for example, functional programming would require plenty of different logic based on the breed etc, different photos angle etc, also you’d need to avoid making wrong detections (like a hyena, which is similar to a dog).","type":"text"},{"text":" ","type":"text"},{"text":"These are experiences that we want to create where we can’t just tell the computer what to do. And for many of these experiences, we can use machine learning to teach a computer what to do.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"In Machine Learning the function that we give input to get an output is called a model."}]},{"type":"paragraph","inlineContent":[{"text":"To design a great machine learning experience, we have to design both how it works and how it looks and feels. We have to design both the ","type":"text"},{"inlineContent":[{"type":"text","text":"model"}],"type":"strong"},{"text":" and the ","type":"text"},{"inlineContent":[{"type":"text","text":"interface"}],"type":"strong"},{"text":".","type":"text"}]},{"level":3,"anchor":"Model","text":"Model","type":"heading"},{"type":"paragraph","inlineContent":[{"text":"We consider the model as two parts:","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Data: What we use to teach the computer.","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Metrics: How we evaluate the data."}],"type":"paragraph"}]}]},{"level":3,"anchor":"Interface","text":"Interface","type":"heading"},{"type":"paragraph","inlineContent":[{"type":"text","text":"The ML interface can be split in two parts:"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Inputs: How people interact with the model and, if appropriate, provide input to improve the model."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Outputs: What the model outputs and how those model’s outputs are presented to people.","type":"text"}],"type":"paragraph"}]}]},{"level":3,"anchor":"Models-Data","text":"(Model’s) Data","type":"heading"},{"type":"paragraph","inlineContent":[{"text":"All the examples that we use for training the model are called Data.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"If we need to add a new class, we need more data.","type":"text"},{"text":" ","type":"text"},{"text":"If we need to improve one class, we need more data.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Data determines the behavior of the model.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"It’s important to collect data intentionally:","type":"text"},{"text":"\n","type":"text"},{"text":"if you don’t have data that captures an important scenario, it’s unlikely that your model is going to work well in that scenario.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Always think and cover all the possible scenarios (detecting people?  Do not use only white people in the train data, do not use only ID photos, use photos from different lighting conditions and angles).","type":"text"}]},{"level":3,"anchor":"Models-Metrics","text":"(Model’s) Metrics","type":"heading"},{"type":"paragraph","inlineContent":[{"text":"Metrics are how we define if an ML experience is good.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Even if the metrics numbers are good, this doesn’t mean that the user experience will be good. Always try the app in real scenarios, get customer feedback, etc.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The Metrics might evaluate different things that what makes a good experience."}]},{"type":"paragraph","inlineContent":[{"text":"Always evolve your metrics based on your product.","type":"text"}]},{"text":"(Interface’s) Outputs","anchor":"Interfaces-Outputs","type":"heading","level":3},{"inlineContent":[{"type":"text","text":"Different sets of outputs:"}],"type":"paragraph"},{"text":"Multiple Options","anchor":"Multiple-Options","type":"heading","level":4},{"inlineContent":[{"type":"text","text":"Allows to present multiple options to people."}],"type":"paragraph"},{"inlineContent":[{"text":"For example:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"In maps the app offers multiple routes, and the proposed routes are distinct by attributions (fastest, alternate, ..)."}]}]},{"content":[{"inlineContent":[{"text":"The Siri watch face does the same: it recommends things based on location, time, the user routine etc. Even better, the watch face learns more the more the user uses it, so that the first recommended option is always the one the user expects\/wants.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Attributions","anchor":"Attributions","type":"heading","level":4},{"inlineContent":[{"text":"Explanations that help people understand more about how your app makes decisions.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"For example:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"We saw an example above with the Map route above."}]}]},{"content":[{"inlineContent":[{"text":"On the App Store, the app recommends you other apps based on your past behaviour (and it shows it to the user with a text like “Recommended based on apps you downloaded”)","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"type":"text","text":"The attributions shouldn’t assume anything: if a user downloads a cooking app, don’t say “we recommend this because you’re into cooking“, you should say “we recommend this because you download Coocking app 123“."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"In short, relate to objects facts, not subjective tastes. Cite data sources."}],"type":"paragraph"},{"text":"Confidence","anchor":"Confidence","type":"heading","level":4},{"inlineContent":[{"text":"Measurement of certainty for an output.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Don’t show the confidence in your app unless your app is showing statistical predictions such as weather, sports results or election predictions, it might not work in other situations."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Use more human language\/images instead."}],"type":"paragraph"},{"inlineContent":[{"text":"Alternatively, provide ranges of confidence.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"For example when estimating arrival times, give a time range instead of saying 85% possibility to arrive home at 6pm."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"If the model confidence is low, ask for the user help."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"For example, you can ask the user to identify if the person the model think is PersonA, is really personA or not."}],"type":"paragraph"},{"text":"Limitations","anchor":"Limitations","type":"heading","level":4},{"inlineContent":[{"text":"Occurs when there’s a mismatch between people’s mental model of a feature and what the feature can actually do.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"For example in Memoji the app will alert users when there’s low lighting condition, the face is too far away etc.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Know your model limitation and promptly make sure that your user knows about it when it encounters one."},{"type":"text","text":" "},{"type":"text","text":"Explaining the limitations when they happen to help people learn to avoid these situations in the future."}],"type":"paragraph"},{"text":"(Interface’s) Inputs","anchor":"Interfaces-Inputs","type":"heading","level":3},{"text":"Calibration","anchor":"Calibration","type":"heading","level":4},{"inlineContent":[{"text":"Helps you get essential information for someone to engage in your experience.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Calibration can be done by collecting data of the user surroundings or biometric data.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"HomeCourt does this by asking the user to make a throw.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"FaceID does this by asking the user to rotate the face on activation.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Try to be quick and effortless.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Ask only for essential information.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Introduce, guide, and confirm the calibration (faceID does this nicely)"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Allow people to update their information\/calibration if possible\/needed."}],"type":"paragraph"},{"text":"Implicit Feedback","anchor":"Implicit-Feedback","type":"heading","level":4},{"inlineContent":[{"text":"Allows you to collect important information from interactions someone has with your experience.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"For example, faceID calibrates itself every time the user uses faceID.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Siri does this in the search screen of the iPhone and in the Siri watch face.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Strive to identify people’s intention"},{"type":"text","text":" "},{"type":"text","text":"Make interactions more accurate and delightful"}],"type":"paragraph"},{"text":"Explicit Feedback","anchor":"Explicit-Feedback","type":"heading","level":4},{"inlineContent":[{"type":"text","text":"Allows you to collect information but this time by asking specific questions about the results you’re showing."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Basically what Amazon\/e-commerces do: they offer you things based on past purchases, and they offer you to say “I’m not interested in this” “See less of this“ “hide suggestion”."}],"type":"paragraph"},{"inlineContent":[{"text":"Prioritize negative feedback over positive: for positive feedback look at the user behavior (as in, if he bookmark the item, purchase the item etc).","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Act immediately and persistently on user feedback: hide suggested items and stop suggesting those."}],"type":"paragraph"},{"text":"Corrections","anchor":"Corrections","type":"heading","level":4},{"inlineContent":[{"type":"text","text":"Allow people to fix a mistake a model has made by using familiar interfaces."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"When writing something, iOS sometimes suggests corrections here and there, but sometimes we want a special name instead of a word. Think Angie vs. angle. If the user correct the word to Angie, iOS learns this and will even suggest this next time."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"The photos.app does the same when we start a crop of a picture: initially the app will automatically crop and rotate for us, however it doesn’t commit the result, letting the user to adjust (nee, correct) the crop\/rotation."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Corrections are, therefore, an amazing pattern to optimize your results without feeling like extra work."}],"type":"paragraph"},{"text":"Written By","anchor":"Written-By","type":"heading","level":2},{"columns":[{"size":1,"content":[{"inlineContent":[{"identifier":"zntfdr","type":"image"}],"type":"paragraph"}]},{"size":4,"content":[{"text":"Federico Zanetello","anchor":"Federico-Zanetello","type":"heading","level":3},{"inlineContent":[{"isActive":true,"type":"reference","overridingTitle":"Contributed Notes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}]},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"isActive":true,"type":"reference","identifier":"https:\/\/github.com\/zntfdr"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"isActive":true,"type":"reference","identifier":"https:\/\/zntfdr.dev"}],"type":"paragraph"}]}],"numberOfColumns":5,"type":"row"},{"inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"isActive":true,"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference"}],"type":"paragraph"},{"text":"Related Sessions","anchor":"Related-Sessions","type":"heading","level":2},{"style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10126-Discoverable-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-209-Whats-New-in-Machine-Learning"],"type":"links"},{"inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}],"type":"small"},{"inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}],"type":"small"}],"kind":"content"}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19"]]},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc19-803-designing-great-ml-experiences"]}],"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10126-Discoverable-design":{"role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10126-Discoverable-design","abstract":[{"text":"Discover how you can create interactive, memorable experiences to onboard people into your app. We’ll take you through discoverable design practices and learn how you can craft explorable, fun interfaces that help people grasp the possibilities of your app at a glance. We’ll also show you how to apply this methodology to personalize your content and make your app easy to customize.","type":"text"}],"type":"topic","title":"Discoverable design","url":"\/documentation\/wwdcnotes\/wwdc21-10126-discoverable-design"},"zntfdr.jpeg":{"type":"image","identifier":"zntfdr.jpeg","alt":null,"variants":[{"url":"\/images\/zntfdr.jpeg","traits":["1x","light"]}]},"https://zntfdr.dev":{"title":"Blog","url":"https:\/\/zntfdr.dev","type":"link","titleInlineContent":[{"type":"text","text":"Blog"}],"identifier":"https:\/\/zntfdr.dev"},"https://developer.apple.com/wwdc19/803":{"checksum":null,"url":"https:\/\/developer.apple.com\/wwdc19\/803","type":"download","identifier":"https:\/\/developer.apple.com\/wwdc19\/803"},"https://developer.apple.com/design/human-interface-guidelines/machine-learning/overview/introduction/":{"title":"ML guideline here","url":"https:\/\/developer.apple.com\/design\/human-interface-guidelines\/machine-learning\/overview\/introduction\/","type":"link","titleInlineContent":[{"type":"text","text":"ML guideline here"}],"identifier":"https:\/\/developer.apple.com\/design\/human-interface-guidelines\/machine-learning\/overview\/introduction\/"},"WWDC19.jpeg":{"type":"image","identifier":"WWDC19.jpeg","alt":null,"variants":[{"url":"\/images\/WWDC19.jpeg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-209-Whats-New-in-Machine-Learning":{"abstract":[{"type":"text","text":"Core ML 3 has been greatly expanded to enable even more amazing, on-device machine learning capabilities in your app. Learn about the new Create ML app which makes it easy to build Core ML models for many tasks. Get an overview of model personalization; exciting updates in Vision, Natural Language, Sound, and Speech; and added support for cutting-edge model types."}],"title":"What’s New in Machine Learning","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-209-whats-new-in-machine-learning","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-209-Whats-New-in-Machine-Learning","type":"topic"},"https://github.com/zntfdr":{"title":"GitHub","url":"https:\/\/github.com\/zntfdr","type":"link","titleInlineContent":[{"type":"text","text":"GitHub"}],"identifier":"https:\/\/github.com\/zntfdr"},"zntfdr":{"type":"image","identifier":"zntfdr","alt":"Profile image of Federico Zanetello","variants":[{"url":"\/images\/zntfdr.jpeg","traits":["1x","light"]}]},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes/zntfdr":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","role":"sampleCode","images":[{"type":"card","identifier":"zntfdr.jpeg"},{"type":"icon","identifier":"zntfdr.jpeg"}],"kind":"article","type":"topic","abstract":[{"type":"text","text":"Software engineer with a strong passion for well-written code, thought-out composable architectures, automation, tests, and more."}],"url":"\/documentation\/wwdcnotes\/zntfdr","title":"Federico Zanetello (332 notes)"},"WWDC19-Icon.png":{"type":"image","identifier":"WWDC19-Icon.png","alt":null,"variants":[{"url":"\/images\/WWDC19-Icon.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes":{"title":"WWDC Notes","kind":"symbol","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"type":"topic","role":"collection","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","url":"\/documentation\/wwdcnotes"},"WWDCNotes.png":{"type":"image","identifier":"WWDCNotes.png","alt":null,"variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19":{"title":"WWDC19","url":"\/documentation\/wwdcnotes\/wwdc19","abstract":[{"type":"text","text":"Xcode 11, Swift 5.1, iOS 13, macOS 10.15 (Catalina), tvOS 13, watchOS 6."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"Combine","type":"codeVoice"},{"type":"text","text":", "},{"code":"Core Haptics","type":"codeVoice"},{"type":"text","text":", "},{"code":"Create ML","type":"codeVoice"},{"type":"text","text":", and more."}],"kind":"article","images":[{"type":"icon","identifier":"WWDC19-Icon.png"},{"type":"card","identifier":"WWDC19.jpeg"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19","role":"collectionGroup","type":"topic"}}}