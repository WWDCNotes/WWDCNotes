{"schemaVersion":{"minor":3,"patch":0,"major":0},"sections":[],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc25-315-get-started-with-mlx-for-apple-silicon"]}],"kind":"article","primaryContentSections":[{"content":[{"anchor":"overview","type":"heading","text":"Overview","level":2},{"type":"paragraph","inlineContent":[{"text":"üò± ‚ÄúNo Overview Available!‚Äù","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true}]},{"anchor":"Related-Sessions","type":"heading","text":"Related Sessions","level":2},{"type":"links","style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-298-Explore-large-language-models-on-Apple-silicon-with-MLX"]}],"kind":"content"}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25"]]},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-315-Get-started-with-MLX-for-Apple-silicon","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"MLX is a flexible and efficient array framework for numerical computing and machine learning on Apple silicon. We‚Äôll explore fundamental features including unified memory, lazy computation, and function transformations. We‚Äôll also look at more advanced techniques for building and accelerating machine learning models across Apple‚Äôs platforms using Swift and Python APIs."}],"sampleCodeDownload":{"action":{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/315","isActive":true,"overridingTitle":"Watch Video (19 min)"},"kind":"sampleDownload"},"metadata":{"roleHeading":"WWDC25","modules":[{"name":"WWDC Notes"}],"title":"Get started with MLX for Apple silicon","role":"sampleCode"},"references":{"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","title":"Learn More‚Ä¶","titleInlineContent":[{"text":"Learn More‚Ä¶","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-298-Explore-large-language-models-on-Apple-silicon-with-MLX":{"role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Discover MLX LM ‚Äì designed specifically to make working with large language models simple and efficient on Apple silicon. We‚Äôll cover how to fine-tune and run inference on state-of-the-art large language models on your Mac, and how to seamlessly integrate them into Swift-based applications and projects."}],"title":"Explore large language models on Apple silicon with MLX","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-298-Explore-large-language-models-on-Apple-silicon-with-MLX","url":"\/documentation\/wwdcnotes\/wwdc25-298-explore-large-language-models-on-apple-silicon-with-mlx","kind":"article"},"https://developer.apple.com/videos/play/wwdc2025/315":{"checksum":null,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/315","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/315","type":"download"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25":{"images":[{"type":"icon","identifier":"WWDC25-Icon.png"},{"type":"card","identifier":"WWDC25.jpg"}],"role":"collectionGroup","kind":"article","type":"topic","abstract":[{"type":"text","text":"Xcode 26, Swift 6.2, iOS\/macOS\/tvOS\/visionOS 26."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"Foundation Models"},{"type":"text","text":", "},{"type":"codeVoice","code":"AlarmKit"},{"type":"text","text":", "},{"type":"codeVoice","code":"PermissionKit"},{"type":"text","text":", and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25","title":"WWDC25","url":"\/documentation\/wwdcnotes\/wwdc25"},"WWDC25.jpg":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC25.jpg","traits":["1x","light"]}],"type":"image","alt":null,"identifier":"WWDC25.jpg"},"WWDCNotes.png":{"identifier":"WWDCNotes.png","alt":null,"type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}]},"WWDC25-Icon.png":{"identifier":"WWDC25-Icon.png","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC25-Icon.png"}],"type":"image","alt":null},"doc://WWDCNotes/documentation/WWDCNotes":{"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"role":"collection","kind":"symbol","type":"topic","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","url":"\/documentation\/wwdcnotes"}}}