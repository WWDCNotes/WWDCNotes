{"metadata":{"modules":[{"name":"WWDC Notes"}],"title":"Explore materials in Reality Composer Pro","role":"sampleCode","roleHeading":"WWDC23"},"kind":"article","sampleCodeDownload":{"action":{"isActive":true,"type":"reference","overridingTitle":"Watch Video (20 min)","identifier":"https:\/\/developer.apple.com\/wwdc23\/10202"},"kind":"sampleDownload"},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10202-explore-materials-in-reality-composer-pro"],"traits":[{"interfaceLanguage":"swift"}]}],"abstract":[{"type":"text","text":"Learn how Reality Composer Pro can help you alter the appearance of your 3D objects using RealityKit materials. We’ll introduce you to MaterialX and physically-based (PBR) shaders, show you how to design dynamic materials using the shader graph editor, and explore adding custom inputs to a material so that you can control it in your visionOS app."}],"seeAlsoSections":[{"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10239-Add-SharePlay-to-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10248-Analyze-hangs-with-Instruments","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10258-Animate-symbols-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10158-Animate-with-springs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10159-Beyond-scroll-views","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10170-Beyond-the-basics-of-structured-concurrency","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10028-Bring-widgets-to-life","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10027-Bring-widgets-to-new-places","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10093-Bring-your-Unity-VR-app-to-a-fully-immersive-space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10123-Bring-your-game-to-Mac-Part-1-Make-a-game-plan","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10124-Bring-your-game-to-Mac-Part-2-Compile-your-shaders","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10125-Bring-your-game-to-Mac-Part-3-Render-with-Metal","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10023-Build-a-multidevice-workout-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10036-Build-accessible-apps-with-SwiftUI-and-UIKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10154-Build-an-app-with-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10056-Build-better-documentbased-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10016-Build-custom-workouts-with-WorkoutKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10096-Build-great-games-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10252-Build-programmatic-UI-with-Xcode-Previews","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10006-Build-robust-and-resumable-file-transfers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10087-Build-spatial-SharePlay-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10029-Build-widgets-for-the-Smart-Stack-on-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10051-Create-a-great-ShazamKit-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10070-Create-a-great-spatial-playback-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10105-Create-a-more-responsive-camera-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10034-Create-accessible-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10257-Create-animated-symbols","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10088-Create-immersive-Unity-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10278-Create-practical-workflows-in-Xcode-Cloud","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10244-Create-rich-documentation-with-SwiftDocC","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10007-Create-seamless-experiences-with-Virtualization","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10101-Customize-ondevice-speech-recognition","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10226-Debug-with-structured-logging","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10160-Demystify-SwiftUI-performance","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10263-Deploy-passkeys-at-work","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10193-Design-Shortcuts-for-Spotlight","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10138-Design-and-build-apps-for-watchOS-10","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10078-Design-considerations-for-vision-and-motion","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10073-Design-for-spatial-input","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10075-Design-spatial-SharePlay-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10309-Design-widgets-for-the-Smart-Stack-on-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10115-Design-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10052-Discover-Calendar-and-EventKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10256-Discover-Continuity-Camera-for-tvOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10089-Discover-Metal-for-immersive-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10149-Discover-Observation-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10085-Discover-Quick-Look-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10155-Discover-String-Catalogs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10180-Discover-streamlined-location-updates","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10196-Dive-deeper-into-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10254-Do-more-with-Managed-Apple-IDs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10107-Embed-the-Photos-Picker-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10094-Enhance-your-iPad-and-iPhone-apps-for-the-Shared-Space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10167-Expand-on-Swift-macros","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10275-Explore-AirPlay-with-interstitials","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10012-Explore-App-Store-Connect-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10156-Explore-SwiftUI-animation","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10103-Explore-enhancements-to-App-Intents","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10192-Explore-enhancements-to-RoomPlan","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10271-Explore-immersive-sound-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10122-Explore-media-formats-for-the-web","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10037-Explore-pie-charts-and-interactivity-in-Swift-Charts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10095-Explore-rendering-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10142-Explore-testing-inapp-purchases","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10175-Fix-failures-faster-with-Xcode-test-reports","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10168-Generalize-APIs-with-parameter-packs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10060-Get-started-with-privacy-manifests","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10161-Inspectors-in-SwiftUI-Discover-the-details","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10104-Integrate-your-media-app-with-HomePod","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10281-Keep-up-with-the-keyboard","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10176-Lift-subjects-from-images-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10229-Make-features-discoverable-with-TipKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10189-Migrate-to-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10172-Mix-Swift-and-C++","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10195-Model-your-schema-with-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10127-Optimize-GPU-renderers-with-Metal","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10050-Optimize-machine-learning-for-Metal-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10035-Perform-accessibility-audits-for-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10266-Protect-your-Mac-app-with-environment-constraints","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10250-Prototype-with-Xcode-Playgrounds","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10002-Ready-set-relay-Protect-app-traffic-with-network-relays","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10262-Rediscover-Safari-developer-features","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10004-Reduce-network-delays-with-L4S","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10241-Share-files-with-SharePlay","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10224-Simplify-distribution-in-Xcode-and-Xcode-Cloud","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10102-Spotlight-your-app-with-App-Shortcuts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10137-Support-Cinematic-mode-videos-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10181-Support-HDR-images-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10188-Sync-to-iCloud-with-CKSyncEngine","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10162-The-SwiftUI-cookbook-for-focus","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10238-Tune-up-your-AirPlay-audio-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10057-Unleash-the-UIKit-trait-system","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10153-Unlock-the-power-of-grammatical-agreement","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10185-Update-Live-Activities-with-push-notifications","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10031-Update-your-app-for-watchOS-10","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10061-Verify-app-dependencies-with-digital-signatures","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10058-Whats-new-with-text-and-text-interactions","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10157-Wind-your-way-through-advanced-animations-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10166-Write-Swift-macros","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10128-Your-guide-to-Metal-ray-tracing"],"title":"Deep Dives into Topics","generated":true}],"primaryContentSections":[{"content":[{"level":1,"text":"Chapters","type":"heading","anchor":"Chapters"},{"inlineContent":[{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=0","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=55","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=218","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=626","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=796","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=1154","type":"reference","isActive":true}],"type":"paragraph"},{"level":1,"text":"Materials in visionOS","type":"heading","anchor":"Materials-in-visionOS"},{"inlineContent":[{"identifier":"WWDC23-10202-whatAreMaterials","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Materials are what define the appearance of the objects in 3D scenes. Materials can be simple, just a single color, or they can use images. We might apply a wood texture to the model of a chair or map an image of bricks to a wall. Materials can also be quite sophisticated. They might use animation to look like rippling water or change appearance based on viewing angle. Like iridescent sparkle of mother of pearl. Materials can even modify the geometry of the objects they are applied to."}],"type":"paragraph"},{"level":2,"text":"Physically Based Rendering","type":"heading","anchor":"Physically-Based-Rendering"},{"inlineContent":[{"text":"Materials in visionOS use Physically Based Rendering (PBR) to represent physical properties of real world objects, for example, how metallic or how rough an object looks.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-pbr"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Materials consist of one or more "},{"type":"strong","inlineContent":[{"type":"text","text":"shaders"}]},{"type":"text","text":". These are programs that do the actual work of computing the appearance of their material."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-shaders"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"With RealityKit 2 for iOS and iPadOS, Apple introduced CustomMaterial. Shaders in CustomMaterial are hand coded in Metal."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-metal"}],"type":"paragraph"},{"inlineContent":[{"inlineContent":[{"type":"text","text":"Surface shaders"}],"type":"strong"},{"text":" operate on the PBR attributes of models. ","type":"text"},{"inlineContent":[{"type":"text","text":"Geometry modifiers"}],"type":"strong"},{"text":" operate on the geometry of objects.","type":"text"}],"type":"paragraph"},{"level":2,"text":"ShaderGraphMaterial","type":"heading","anchor":"ShaderGraphMaterial"},{"inlineContent":[{"text":"In xrOS, a new type of material is been introduced: ","type":"text"},{"inlineContent":[{"type":"text","text":"ShaderGraphMaterial"}],"type":"strong"},{"text":".","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-shaderGraphMaterial"}],"type":"paragraph"},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"This is the exclusive way of creating custom materials for visionOS"}]},{"type":"text","text":". Based on the open standard "},{"type":"reference","identifier":"https:\/\/materialx.org","isActive":true},{"type":"text","text":"."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Supports 2 main types of shaders: "},{"type":"strong","inlineContent":[{"text":"Physically Based","type":"text"}]},{"type":"text","text":" and "},{"type":"strong","inlineContent":[{"type":"text","text":"Custom"}]},{"type":"text","text":"."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-shaderGraphMaterial2","type":"image"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"emphasis","inlineContent":[{"type":"text","text":"Physically based shader is intended for simpler use cases (e.g. constant, non-changing values)"}]}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"inlineContent":[{"type":"text","text":"Custom is intended for precise and custom control over 3D objects (e.g. animation, geometry modifiers, special effects, etc."}],"type":"emphasis"},{"text":")","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"type":"text","text":"ShaderGraphMaterial supports two main types of shaders, which we call Physically Based and Custom. Physically Based is a basic PBR shader. we configure this shader by providing constant, nonchanging values, like colors or images, for each property. Custom shaders, on the other hand, give us precise and custom control over the appearance of 3D objects."},{"type":"text","text":"\n"},{"type":"text","text":"Custom shaders can incorporate animation, adjust object’s geometry, and create special effects on the surface of the object, like a sparkly paint look."},{"type":"text","text":" "},{"type":"text","text":"we can build ShaderGraphMaterials using the Shader Graph editor right inside Reality Composer Pro."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-shaderGraphMaterial3"}],"type":"paragraph"},{"level":1,"text":"Material editing","type":"heading","anchor":"Material-editing"},{"inlineContent":[{"text":"Materials in xrOS can be created using Reality Composer Pro","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-realityComposerPro","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"For an introduction to the Reality composer pro app before starting with materials, please watch:"},{"type":"text","text":" "},{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083","type":"reference"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"The session will use the Yosemite Valley model and apply a topographical map appearance to it. All the objects we don’t need for this session have been hidden using the Deactivate command."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-yosemiteModel"}],"type":"paragraph"},{"level":2,"text":"Topography map","type":"heading","anchor":"Topography-map"},{"inlineContent":[{"type":"text","text":"Let’s add a topography feature. We’ll add a material showing the topography of our model by displaying contour lines along the slope of the terrain. It’ll look similar to the topographical map that we might have come across when planning a hike."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-yosemiteModelTopographic","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Let’s create a custom material containing a shader that will draw contour lines on our terrain. We want to draw lines on our terrain through all the areas that have the same elevation, like in this diagram. This blue line, for example, shows all points on the terrain at 1000 meters of elevation. Seen from above, it will look something like the diagram on the right.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-yosemiteModel2","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Add a material by clicking the ","type":"text"},{"type":"codeVoice","code":"+"},{"text":" icon inside the Project Browser. Under Materials, notice our two shader types: Physically Based and Custom. Choose Custom.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-yosemiteModel3"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"This reveals the Shader Graph of our editor."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-yosemiteModel4"}],"type":"paragraph"},{"inlineContent":[{"text":"New custom shaders start with two nodes, the surface node in purple and the outputs node in blue. the material’s active surface is the one connected to the custom surface input of the outputs node. The inputs on the surface are how we set our shader’s physically based, or PBR, parameters. Base color, for example.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Let’s give the material a descriptive name. TopographyMaterial sounds good. An important step is to assign our new material to our Yosemite Valley model. Select it in the project hierarchy. In the inspector, under Material Bindings, choose TopographyMaterial from the Binding menu.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-yosemiteModel5","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Notice the model changes from color to a simple gray. Our material is working, but it doesn’t do anything interesting yet. Select TopographyMaterial from the hierarchy to return to the Shader Graph editor. We’ll connect some nodes to our surface inputs to draw stripes on our model in the right places.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We’ll illustrate how our material will work with this example terrain. We need our material to decide where to draw topographical lines based on its location on our model. So first we’ll add a position node to our material. This node returns our rendering position in 3D space. We’re only interested in the height of position, so we’ll also add a node called separate to extract just the position’s Y-coordinate. Separate returns the Y-coordinate position, which increases with terrain height."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-yosemiteModel6"}],"type":"paragraph"},{"inlineContent":[{"text":"Let’s add these first two nodes to our material in Reality Composer Pro. Double-click on the background of the editor to add nodes. This brings up the New Node picker. we can browse through the list of all the available nodes, or search for nodes by name or keyword. Let’s type “position” and select the Position node from the list to insert it into our shader. Position outputs the location in 3D space where the material is being rendered.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-yosemiteModel7"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Our material varies with height, so let’s add a separate node to extract the Y component of position. Double-click the background to bring up the New Node picker again and add a Separate 3 node. To make connections in the editor, just click and drag from node outputs to node inputs like this."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-yosemiteModel8","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"These two nodes combined give us the height of the terrain. Next, we’ll take the output of the separate node and pass it to a modulo node. Modulo gives the remainder of dividing two values. We’ll use modulo to divide height by our desired topographical line spacing. The result looks like this. we can see height has been divided into bands. The height values inside each range start at 0 and increase to that range’s height. This will be important for our next step."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-yosemiteModel9"}],"type":"paragraph"},{"inlineContent":[{"text":"Let’s add the modulo node to our material in Reality Composer Pro. Instead of double-clicking to add a node and then connecting it, we can drag a new connection to an empty space to create a node that’s already connected in one step. In the New Node picker, type “modulo” and click to insert a Modulo node. Modulo has two inputs. The first is the dividend and the second is the divisor. we can conveniently set constant values on inputs in the inspector instead of connecting nodes. In the inspector, change the second argument to 0.1. This is the divisor and sets the width of our height ranges.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-yosemiteModel10"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We have just one more step to go before we can see our output. We’ll use an ifgreater node to determine where our repeating values fall in narrow height bands on our terrain. The ifgreater node will return a value representing one of the two band colors we see on screen, depending on the result of a comparison. When the height is greater than our shader topographical line width, we’ll choose a background color. And where the height falls within our desired line width, we’ll choose our topography line color."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-yosemiteModel11","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Let’s add the ifgreater node to our material and see the results. We want to compare the result of the modulo node to a value we choose for our topographical line width. So we’ll add an ifgreater node to do that comparison. Ifgreater compares its two inputs and returns one value when its first input is greater than its second input, and a different value when the first input is less than its second input. This ifgreater node is set to output floating point values, but we want to choose between two colors, one for our terrain and one for our topographical lines. In the inspector, under Type, change this node to output RGB. Next, let’s pick our two colors.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-yosemiteModel12"}],"type":"paragraph"},{"inlineContent":[{"text":"In the inspector, we’ll click on the color picker next to True Result and set our terrain color. Let’s use white.","type":"text"},{"text":"\n","type":"text"},{"text":"Let’s leave the False Result, which is our topographical line color, set to black.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"This will give us a lot of contrast with our white terrain. 0.002 is a good value for line width, so in the inspector, we’ll set the comparison value to 0.002. we’ll connect the ifgreater node’s output to our surface’s Diffuse Color input. Awesome, now our material is setting the color at every point on our terrain and we’ve made a topographical lines material."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-yosemiteModel13"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"This section jumps right into a walk-through tutorial on applying topography lines to a geographical diorama. Starts at "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=271"}],"type":"paragraph"},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Important!"}]},{"type":"text","text":" make sure we assign our new material to our model in the hierarchy. we do this by selecting custom material from the model’s Material Binding dropdown in the inspector "},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=349"},{"type":"text","text":"."}],"type":"paragraph"},{"level":1,"text":"Node graphs","type":"heading","anchor":"Node-graphs"},{"type":"aside","name":"Note","content":[{"inlineContent":[{"type":"emphasis","inlineContent":[{"type":"text","text":"Node graphs help simplify complex materials and let we create our own nodes to reuse parts of graphs."}]}],"type":"paragraph"}],"style":"note"},{"inlineContent":[{"text":"We’ll use node graphs to give a material a real topographical map look. Let’s add a second set of lines between the current lines of our material.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Here’s what our material looks like so far."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-nodeGraphs"}],"type":"paragraph"},{"inlineContent":[{"text":"And here’s what it will look like when we add our subdivisions.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-nodeGraphs2","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"We’ll start with the four nodes in our material that draw our topographical lines.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-nodeGraphs3"}],"type":"paragraph"},{"inlineContent":[{"text":"Then we’ll compose a node graph from them. This will combine our four nodes into a single node. Finally, we’ll create an instance of our node graph to reuse its functionality. One node graph will draw our original set of lines, and the instance of it will draw our second set of lines.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-nodeGraphs4"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Let’s go back into Reality Composer Pro and build it."}],"type":"paragraph"},{"inlineContent":[{"text":"Here is our topographical lines shader again. Drag to select these four nodes that compute the colors for our lines and where to draw them.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-nodeGraphs5","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"After selecting them, right-click and choose Compose Node Graph. Now the nodes appear as a single node that I can use inside other graphs. Let’s assign a descriptive name to our new node. Let’s call it Lines.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-nodeGraphs6"}],"type":"paragraph"},{"inlineContent":[{"text":"We’ll create a copy of this node graph to draw our second set of lines. For this, we’ll create an instance using the Create Instance command in the hierarchy.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-nodeGraphs7","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Instances are live copies that adopt any changes made to the original node graph. We’ll return to our material by selecting it. Let’s call our new instance SecondaryLines.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-nodeGraphs8"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We want our node graph and its instance to draw lines with different spacings and colors, so we’ll add two inputs, called Spacing and Color, to our original node graph to control these properties."},{"type":"text","text":" "},{"type":"text","text":"Let’s edit our original node graph by double-clicking it."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"we add inputs and outputs to our node graph in the inspector. First let’s add an input called Spacing and set its type to Float."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-nodeGraphs9","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We’ll also add an input called Color to control our topography line color. Set the type of the input to Color3."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-nodeGraphs10"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"I’ll connect these to the right places in our graph."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-nodeGraphs11"}],"type":"paragraph"},{"inlineContent":[{"text":"Let’s go back to our material by selecting it in the project hierarchy. Notice that our node graph now has the two inputs we created, and that our instance inherited these two new inputs. On the original Lines node graph, set spacing to the values we chose before. And let’s choose a smaller spacing and a lighter color for our instance node graph.","type":"text"},{"text":"\n","type":"text"},{"text":"The last step is to combine the outputs from our original and instance node graphs. I’ve conveniently chosen grayscale colors for both node graphs, so we can combine their colors using a multiply node.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-nodeGraphs12","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Quick Tips"}]}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Multi-select any set of nodes and right-click > Compose Node Graph to make reusable node components "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=681"},{"type":"text","text":"."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"In the project hierarchy, right-click > Create Instance to create an instance of our node graph "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=695"},{"type":"text","text":"."}]}]},{"content":[{"inlineContent":[{"text":"Add inputs and outputs to our node graph in the inspector ","type":"text"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=730"},{"text":".","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Instances"}]},{"text":" of node graphs are live copies that ","type":"text"},{"type":"strong","inlineContent":[{"text":"adopt any changes made to the original node graph","type":"text"}]},{"text":". They inherit inputs and outputs added to the original node graph it points to.","type":"text"}],"type":"paragraph"},{"level":1,"text":"Geometry modifiers","type":"heading","anchor":"Geometry-modifiers"},{"type":"aside","name":"Note","content":[{"type":"paragraph","inlineContent":[{"type":"emphasis","inlineContent":[{"type":"text","text":"These are a feature of custom materials we can use to modify our models in real time."}]}]}],"style":"note"},{"inlineContent":[{"text":"We’ll replace our static terrain model and recreate it using geometry modifiers and height data.","type":"text"},{"text":" ","type":"text"},{"text":"Then we’ll extend our geometry modifier to dynamically animate between two different terrains: Yosemite Valley and Catalina Island, California. When we’re done, we’ll have a dynamic terrain material that can animate between our two different locations. Let’s see how this is done. All the shaders we’ve looked at so far are surface shaders. These are shaders that set the physically based, or PBR, attributes for each pixel of our model as it’s rendered. Geometry modifiers are similar to surface shaders, but operate on the geometry of our objects instead. In fact, we build them right in the same editor in Reality Composer Pro.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Reminder","type":"text"}]},{"type":"text","text":" "},{"type":"emphasis","inlineContent":[{"text":"Surface shaders operate on the PBR attributes while Geometry modifiers operate on the geometry of objects.","type":"text"}]}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"This section jumps right into a walk-through tutorial on applying heightmaps to generate geometry, and animating between those heightmaps. Starts at "},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=826","isActive":true},{"type":"text","text":"."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Here is an overview of the geometry modifier we’re going to build that will create a terrain of Yosemite Valley using its height map data. We’ll start with a flat disk model, which contains some plain geometry. This will be our base surface. Next we’ll use our terrain height data, which is 2D data about the height at each location of our model, and use a geometry modifier to raise the terrain by the correct amount. This will result in the terrain we want."},{"type":"text","text":" "},{"type":"text","text":"Once shown the basic version, we’ll demonstrate a version that takes two sets of terrain heights and uses those to animate between our two locations of interest, Yosemite Valley and Catalina Island."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-geometryModifiers","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Here’s another view. We’ll start with a flat model, and our geometry modifier will move its vertices vertically using data from a 2D height map like this.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers2"}],"type":"paragraph"},{"inlineContent":[{"text":"The first thing we’ll do is use the Deactivate command to hide the prebuilt Yosemite Valley model.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers3"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We’ll generate the same Yosemite Valley model, but this time using our geometry modifier. I’ll start with a flat disk model in my Project Browser."},{"type":"text","text":" "},{"type":"text","text":"We can bring it in by dragging it into the Root entity in the project hierarchy."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-geometryModifiers4","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Here we created a new material named DynamicTerrainMaterial and assigned it to the disk. Let’s get to work on our geometry modifier. In the Shader Graph editor, we’ll need a geometry modifier surface. We’ll add this to our material alongside our PBR surface. We drag a connection from the Custom Geometry Modifier input of our output node and choose Geometry Modifier from the New Node UI.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers5"}],"type":"paragraph"},{"inlineContent":[{"text":"Let’s first apply our Yosemite Valley image to our surface. To read image data, we’ll use an image node.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers6"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"In the inspector, let’s assign our Yosemite Valley image to the image node’s Filename input."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-geometryModifiers7","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Things look a bit funny since the terrain is flat, but we’re going to fix that now.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-geometryModifiers8","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We’ll need the height data for our valley. It’s in an image file which contains height values instead of color data. Since this data is in an image, we’ll read it by adding another image node. Now assign our Yosemite Valley EXR image containing our height data to this new image node’s Filename input."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-geometryModifiers9","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Geometry modifiers can move the vertices of our model in any direction, but we’re only interested in moving them vertically, so let’s insert a Combine 3 node to create a 3D vector with only the Y component set. Now connect this to the GeometryModifier surface’s Model Position Offset input, and boom, our flat model has been transformed into Yosemite Valley."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers10"}],"type":"paragraph"},{"inlineContent":[{"text":"There’s one more step we need to take. When we move our vertices, we’ll also need to set the surface normal vectors of our model to match our new terrain shape. There are ways to compute these from the height data, but today we’re going to use an image that contains precomputed normals for this geometry. Let’s create another image node to read the normals.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers11"}],"type":"paragraph"},{"inlineContent":[{"text":"Since these are precomputed, we’ll connect them directly to our surface shader’s normal input for better accuracy. Our surface expects normals to have values between -1 and 1, but the normals in our image are between 0 and 1. I’ve remapped the values from the image using a remap node.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers12"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Now we’ve created the terrain from a flat geometry using height data. Next, let’s make our diorama dynamic and add the ability to morph from one terrain to another. In this case, we’ll add an animated transition to change Yosemite Valley to Catalina Island. To achieve this, we’ll first add another set of image nodes to our existing geometry shader. The nodes contain the heights, colors, and normals for our Catalina Island terrain. Then we’ll add mix nodes to blend between these two sets of heights, normals, and colors. Finally, we’ll connect a value to our mix nodes to control blending between our two sets of data."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers13"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Let’s build this in Reality Composer Pro now. OK, here’s our material so far."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers14"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Let’s add another set of image nodes containing the same data – heights, colors, and normals – for Catalina Island instead of Yosemite Valley."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers15"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Next we’ll add some mix nodes to blend between our two colors, heights, and normals."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers16"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Finally let’s connect a 0 to 1 constant to our mix nodes, which will control which terrain is shown. we’ll notice when I set my mixing constant to 1, the terrain shows Catalina Island. When I set the mixing constant to 0, we see Yosemite Valley."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10202-geometryModifiers17"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Now that we have a material that can transition between our two different terrains, let’s make this transition progress value changeable from our Swift code. We’ll use the Promote command to convert our progress value into an input on our material."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-geometryModifiers18","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Inputs on materials become properties of the material that can be accessed from the Swift code. Now our material is ready to be used in our Dioramas Swift app. Here’s the final version, which combines our topography lines and our dynamic terrain. This version has some additional refinements, like anti-aliased topography lines and ambient occlusion maps, all added using Shader Graph.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-geometryModifiers20","type":"image"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10202-geometryModifiers19","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Check those out in the sample for this session.","type":"text"}],"type":"paragraph"},{"level":2,"text":"Resources","type":"heading","anchor":"Resources"},{"inlineContent":[{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/documentation\/visionOS\/diorama"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/forums\/create\/question?&tag1=760030&tag2=796030"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/forums\/tags\/wwdc2023-10202"}],"type":"paragraph"},{"level":2,"text":"Related Videos","type":"heading","anchor":"Related-Videos"},{"inlineContent":[{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10096","type":"reference"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10095","type":"reference"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10086","type":"reference"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"overridingTitle":"Meet Reality Composer Pro","isActive":true,"overridingTitleInlineContent":[{"text":"Meet Reality Composer Pro","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083","type":"reference"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10100","type":"reference"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273","type":"reference"}],"type":"paragraph"},{"level":2,"text":"Written By","type":"heading","anchor":"Written-By"},{"type":"row","numberOfColumns":5,"columns":[{"content":[{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/40086690?v=4","type":"image"}]}],"size":1},{"content":[{"type":"heading","level":3,"text":"stevenpaulhoward","anchor":"stevenpaulhoward"},{"inlineContent":[{"type":"reference","overridingTitle":"Contributed Notes","overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"isActive":true,"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/stevenpaulhoward"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/github.com\/stevenpaulhoward"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/x.com\/stevnhoward"}],"type":"paragraph"}],"size":4}]},{"type":"row","numberOfColumns":5,"columns":[{"content":[{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4","type":"image"}]}],"size":1},{"content":[{"text":"laurent b","anchor":"laurent-b","level":3,"type":"heading"},{"inlineContent":[{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"overridingTitle":"Contributed Notes","isActive":true,"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/github.com\/multitudes","isActive":true,"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/laurentbrusa.hashnode.dev\/","isActive":true,"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/x.com\/wrmultitudes","isActive":true,"type":"reference"}],"type":"paragraph"}],"size":4}]},{"level":2,"text":"Related Sessions","type":"heading","anchor":"Related-Sessions"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10095-Explore-rendering-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10096-Build-great-games-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode"],"type":"links","style":"list"},{"inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}],"type":"small"},{"inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}],"kind":"content"}],"schemaVersion":{"minor":3,"patch":0,"major":0},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro","interfaceLanguage":"swift"},"sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"references":{"WWDC23-10202-yosemiteModelTopographic":{"alt":"the Yosemite Valley model finished version in Reality Composer Pro","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModelTopographic.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModelTopographic"},"WWDC23-10202-yosemiteModel4":{"alt":"the Yosemite Valley model in Reality Composer Pro","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel4.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel4"},"https://developer.apple.com/videos/play/wwdc2023/10202/?time=1154":{"titleInlineContent":[{"type":"text","text":"19:14 - Wrap-up"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=1154","title":"19:14 - Wrap-up","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=1154"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10137-Support-Cinematic-mode-videos-in-your-app":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10137-support-cinematic-mode-videos-in-your-app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10137-Support-Cinematic-mode-videos-in-your-app","kind":"article","abstract":[{"text":"Discover how the Cinematic Camera API helps your app work with Cinematic mode videos captured in the Camera app. We’ll share the fundamentals — including Decision layers — that make up Cinematic mode video, show you how to access and update Decisions in your app, and help you save and load those changes.","type":"text"}],"title":"Support Cinematic mode videos in your app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10166-Write-Swift-macros":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10166-write-swift-macros","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10166-Write-Swift-macros","kind":"article","abstract":[{"text":"Discover how you can use Swift macros to make your codebase more expressive and easier to read. Code along as we explore how macros can help you avoid writing repetitive code and find out how to use them in your app. We’ll share the building blocks of a macro, show you how to test it, and take you through how you can emit compilation errors from macros.","type":"text"}],"title":"Write Swift macros"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit":{"url":"\/documentation\/wwdcnotes\/wwdc23-10304-integrate-with-motorized-iphone-stands-using-dockkit","abstract":[{"type":"text","text":"Discover how you can create incredible photo and video experiences in your camera app when integrating with DockKit-compatible motorized stands. We’ll show how your app can automatically track subjects in live video across a 360-degree field of view, take direct control of the stand to customize framing, directly control the motors, and provide your own inference model for tracking other objects. Finally, we’ll demonstrate how to create a sense of emotion through dynamic device animations."}],"type":"topic","title":"Integrate with motorized iPhone stands using DockKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10028-Bring-widgets-to-life":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10028-bring-widgets-to-life","title":"Bring widgets to life","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10028-Bring-widgets-to-life","type":"topic","abstract":[{"text":"Learn how to make animated and interactive widgets for your apps and games. We’ll show you how to tweak animations for entry transitions and add interactivity using SwiftUI Button and Toggle so that you can create powerful moments right from the Home Screen and Lock Screen.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices","url":"\/documentation\/wwdcnotes\/wwdc23-10033-extend-speech-synthesis-with-personal-and-custom-voices","abstract":[{"text":"Bring the latest advancements in Speech Synthesis to your apps. Learn how you can integrate your custom speech synthesizer and voices into iOS and macOS. We’ll show you how SSML is used to generate expressive speech synthesis, and explore how Personal Voice can enable your augmentative and assistive communication app to speak on a person’s behalf in an authentic way.","type":"text"}],"title":"Extend Speech Synthesis with personal and custom voices","kind":"article","role":"sampleCode","type":"topic"},"https://github.com/stevenpaulhoward":{"titleInlineContent":[{"type":"text","text":"GitHub"}],"type":"link","url":"https:\/\/github.com\/stevenpaulhoward","title":"GitHub","identifier":"https:\/\/github.com\/stevenpaulhoward"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10012-Explore-App-Store-Connect-for-spatial-computing":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10012-Explore-App-Store-Connect-for-spatial-computing","abstract":[{"text":"App Store Connect provides the tools you need to test, submit, and manage your visionOS apps on the App Store. Explore basics and best practices for deploying your first spatial computing app, adding support for visionOS to an existing app, and managing compatibility. We’ll also show you how TestFlight for visionOS can help you test your apps and collect valuable feedback as you iterate.","type":"text"}],"kind":"article","title":"Explore App Store Connect for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-10012-explore-app-store-connect-for-spatial-computing"},"WWDC23-10202-geometryModifiers14":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers14.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers14"},"WWDC23-10202-nodeGraphs10":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs10.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs10"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10158-Animate-with-springs":{"title":"Animate with springs","type":"topic","abstract":[{"text":"Discover how you can bring life to your app with animation! We’ll show you how to create amazing animations when you take advantage of springs and help you learn how to use them in your app.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10158-animate-with-springs","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10158-Animate-with-springs","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10052-Discover-Calendar-and-EventKit":{"url":"\/documentation\/wwdcnotes\/wwdc23-10052-discover-calendar-and-eventkit","role":"sampleCode","abstract":[{"type":"text","text":"Discover how you can bring Calendar into your app and help people better manage their time. Find out how to create new events from your app, fetch events, and implement a virtual conference extension. We’ll also take you through some of the changes to calendar access levels that help your app stay connected without compromising the privacy of someone’s calendar data."}],"title":"Discover Calendar and EventKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10052-Discover-Calendar-and-EventKit","type":"topic","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc23-10100-optimize-app-power-and-performance-for-spatial-computing","abstract":[{"text":"Learn how you can create powerful apps and games for visionOS by optimizing for performance and efficiency. We’ll cover the unique power characteristics of the platform, explore building a performance plan, and share some of the tools and strategies to test and optimize your apps.","type":"text"}],"title":"Optimize app power and performance for spatial computing","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-yosemiteModel11":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel11.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel11"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10181-Support-HDR-images-in-your-app":{"kind":"article","title":"Support HDR images in your app","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10181-support-hdr-images-in-your-app","abstract":[{"text":"Learn how to identify, load, display, and create High Dynamic Range (HDR) still images in your app. Explore common HDR concepts and find out about the latest updates to the ISO specification. Learn how to identify and display HDR images with SwiftUI and UIKit, create them from ProRAW and RAW captures, and display them in CALayers. We’ll also take you through CoreGraphics support for ISO HDR and share best practices for HDR adoption.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10181-Support-HDR-images-in-your-app"},"https://developer.apple.com/forums/create/question?&tag1=760030&tag2=796030":{"titleInlineContent":[{"type":"text","text":"Have a question? Ask with tag wwdc2023-10202"}],"type":"link","url":"https:\/\/developer.apple.com\/forums\/create\/question?&tag1=760030&tag2=796030","title":"Have a question? Ask with tag wwdc2023-10202","identifier":"https:\/\/developer.apple.com\/forums\/create\/question?&tag1=760030&tag2=796030"},"WWDC23-10202-yosemiteModel7":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel7.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel7"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10072-Principles-of-spatial-design":{"kind":"article","title":"Principles of spatial design","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10072-principles-of-spatial-design","abstract":[{"text":"Discover the fundamentals of spatial design. Learn how to design with depth, scale, windows, and immersion, and apply best practices for creating comfortable, human-centered experiences that transform reality. Find out how you can use these spatial design principles to extend your existing app or bring a new idea to life.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10107-Embed-the-Photos-Picker-in-your-app":{"role":"sampleCode","title":"Embed the Photos Picker in your app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10107-Embed-the-Photos-Picker-in-your-app","abstract":[{"type":"text","text":"Discover how you can simply, safely, and securely access the Photos Library in your app. Learn how to get started with the embedded picker and explore the options menu and HDR still image support. We’ll also show you how to take advantage of UI customization options to help the picker blend into your existing interface."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10107-embed-the-photos-picker-in-your-app","type":"topic","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10258-Animate-symbols-in-your-app":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10258-animate-symbols-in-your-app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10258-Animate-symbols-in-your-app","kind":"article","abstract":[{"text":"Bring delight to your app with animated symbols. Explore the new Symbols framework, which features a unified API to create and configure symbol effects. Learn how SwiftUI, AppKit, and UIKit make it easy to animate symbols in user interfaces. Discover tips and tricks to seamlessly integrate the new animations alongside other app content. To get the most from this session, we recommend first watching “What’s new in SF Symbols 5.”","type":"text"}],"title":"Animate symbols in your app"},"https://developer.apple.com/videos/play/wwdc2023/10202?time=681":{"titleInlineContent":[{"type":"text","text":"11:21"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=681","title":"11:21","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=681"},"https://developer.apple.com/videos/play/wwdc2023/10202/?time=0":{"titleInlineContent":[{"type":"text","text":"0:00 - Introduction"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=0","title":"0:00 - Introduction","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=0"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10195-Model-your-schema-with-SwiftData":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10195-model-your-schema-with-swiftdata","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10195-Model-your-schema-with-SwiftData","kind":"article","abstract":[{"text":"Learn how to use schema macros and migration plans with SwiftData to build more complex features for your app. We’ll show you how to fine-tune your persistence with @Attribute and @Relationship options. Learn how to exclude properties from your data model with @Transient and migrate from one version of your schema to the next with ease.","type":"text"}],"title":"Model your schema with SwiftData"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10104-Integrate-your-media-app-with-HomePod":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10104-integrate-your-media-app-with-homepod","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10104-Integrate-your-media-app-with-HomePod","kind":"article","abstract":[{"text":"Learn how people can interact with your media app directly from HomePod. We’ll show you how to add a media intent to your iPhone or iPad app and help people stream your content to a HomePod speaker over AirPlay simply by using their voice. Explore implementation details and get tips and best practices on how to create a great experience for music, audiobooks, podcasts, meditations, or other media types.","type":"text"}],"title":"Integrate your media app with HomePod"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10196-Dive-deeper-into-SwiftData":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10196-dive-deeper-into-swiftdata","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10196-Dive-deeper-into-SwiftData","kind":"article","abstract":[{"text":"Learn how you can harness the power of SwiftData in your app. Find out how ModelContext and ModelContainer work together to persist your app’s data. We’ll show you how to track and make your changes manually and use SwiftData at scale with FetchDescriptor, SortDescriptor, and enumerate.","type":"text"}],"title":"Dive deeper into SwiftData"},"WWDC23-10202-nodeGraphs6":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs6.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs6"},"https://developer.apple.com/videos/play/wwdc2023/10273":{"titleInlineContent":[{"type":"text","text":"Work with Reality Composer Pro content in Xcode"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273","title":"Work with Reality Composer Pro content in Xcode","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10086-Explore-the-USD-ecosystem":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem","url":"\/documentation\/wwdcnotes\/wwdc23-10086-explore-the-usd-ecosystem","abstract":[{"text":"Discover the latest updates to Universal Scene Description (USD) on Apple platforms and learn how you can deliver great 3D content for your apps, games, and websites. Get to know USD for visionOS, explore MaterialX shaders and color management, and find out about some of the other improvements to the USD ecosystem.","type":"text"}],"title":"Explore the USD ecosystem","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing":{"title":"Get started with building apps for spatial computing","type":"topic","abstract":[{"text":"Get ready to develop apps and games for visionOS! Discover the fundamental building blocks that make up spatial computing — windows, volumes, and spaces — and find out how you can use these elements to build engaging and immersive experiences.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10260-get-started-with-building-apps-for-spatial-computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10111-Go-beyond-the-window-with-SwiftUI":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10111-go-beyond-the-window-with-swiftui","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","kind":"article","abstract":[{"text":"Get ready to launch into space — a new SwiftUI scene type that can help you make great immersive experiences for visionOS. We’ll show you how to create a new scene with ImmersiveSpace, place 3D content, and integrate RealityView. Explore how you can use the immersionStyle scene modifier to increase the level of immersion in an app and learn best practices for managing spaces, adding virtual hands with ARKit, adding support for SharePlay, and building an “out of this world” experience!","type":"text"}],"title":"Go beyond the window with SwiftUI"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10096-Build-great-games-for-spatial-computing":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10096-build-great-games-for-spatial-computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10096-Build-great-games-for-spatial-computing","kind":"article","abstract":[{"text":"Find out how you can develop great gaming experiences for visionOS. We’ll share some of the key building blocks that help you create games for this platform, explore how your experiences can fluidly move between levels of immersion, and provide a roadmap for exploring ARKit, RealityKit, Reality Composer Pro, Unity, Metal, and Compositor.","type":"text"}],"title":"Build great games for spatial computing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10006-Build-robust-and-resumable-file-transfers":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10006-Build-robust-and-resumable-file-transfers","url":"\/documentation\/wwdcnotes\/wwdc23-10006-build-robust-and-resumable-file-transfers","abstract":[{"text":"Find out how URLSession can help your apps transfer large files and recover from network interruptions. Learn how to pause and resume HTTP file transfers and support resumable uploads, and explore best practices for using URLSession to transfer files even when your app is suspended in the background.","type":"text"}],"title":"Build robust and resumable file transfers","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-geometryModifiers4":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers4.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers4"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10095-Explore-rendering-for-spatial-computing":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10095-explore-rendering-for-spatial-computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10095-Explore-rendering-for-spatial-computing","kind":"article","abstract":[{"text":"Find out how you can take control of RealityKit rendering to improve the look and feel of your apps and games on visionOS. Discover how you can customize lighting, add grounding shadows, and control tone mapping for your content. We’ll also go over best practices for two key treatments on the platform: rasterization rate maps and dynamic content scaling.","type":"text"}],"title":"Explore rendering for spatial computing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10058-Whats-new-with-text-and-text-interactions":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10058-whats-new-with-text-and-text-interactions","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10058-Whats-new-with-text-and-text-interactions","kind":"article","abstract":[{"text":"Text is an absolutely critical component of every app. Discover the latest features and enhancements for creating rich text experiences on Apple platforms. We’ll show you how to take advantage of common text elements and create entirely custom interactions for your app. Learn about updates to dictation, text loupe, and text selection, and explore improvements to text clipping, line wrapping, and hyphenation.","type":"text"}],"title":"What’s new with text and text interactions"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10029-Build-widgets-for-the-Smart-Stack-on-Apple-Watch":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10029-Build-widgets-for-the-Smart-Stack-on-Apple-Watch","abstract":[{"text":"Follow along as we build a widget for the Smart Stack on watchOS 10 using the latest SwiftUI and WidgetKit APIs. Learn tips, techniques, and best practices for creating widgets that show relevant information on Apple Watch.","type":"text"}],"kind":"article","title":"Build widgets for the Smart Stack on Apple Watch","url":"\/documentation\/wwdcnotes\/wwdc23-10029-build-widgets-for-the-smart-stack-on-apple-watch"},"https://github.com/multitudes":{"titleInlineContent":[{"type":"text","text":"GitHub"}],"type":"link","url":"https:\/\/github.com\/multitudes","title":"GitHub","identifier":"https:\/\/github.com\/multitudes"},"https://developer.apple.com/videos/play/wwdc2023/10083":{"titleInlineContent":[{"type":"text","text":"Meet Reality Composer Pro"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083","title":"Meet Reality Composer Pro","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10093-Bring-your-Unity-VR-app-to-a-fully-immersive-space":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10093-bring-your-unity-vr-app-to-a-fully-immersive-space","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10093-Bring-your-Unity-VR-app-to-a-fully-immersive-space","kind":"article","abstract":[{"text":"Discover how you can bring your existing Unity VR apps and games to visionOS. We’ll explore workflows that can help you get started and show you how to build for eyes and hands in your apps and games with the Unity Input System. Learn about Unity’s XR Interaction Toolkit, tips for foveated rendering, and best practices.","type":"text"}],"title":"Bring your Unity VR app to a fully immersive space"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10075-Design-spatial-SharePlay-experiences":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10075-design-spatial-shareplay-experiences","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10075-Design-spatial-SharePlay-experiences","kind":"article","abstract":[{"text":"Explore the types of shared activities you can create in your visionOS apps and find out how your apps can use Spatial Persona templates to support meaningful interactions between people. Discover how to design your UI around a shared context, handle immersive content in a shared activity, and more.","type":"text"}],"title":"Design spatial SharePlay experiences"},"WWDC23-10202-yosemiteModel9":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel9.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel9"},"WWDC23-10202-nodeGraphs5":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs5.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs5"},"WWDC23-10202-yosemiteModel8":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel8.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel8"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10159-Beyond-scroll-views":{"kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10159-Beyond-scroll-views","url":"\/documentation\/wwdcnotes\/wwdc23-10159-beyond-scroll-views","abstract":[{"type":"text","text":"Find out how you can take your scroll views to the next level with the latest APIs in SwiftUI. We’ll show you how to customize scroll views like never before. Explore the relationship between safe areas and a scroll view’s margins, learn how to interact with the content offset of a scroll view, and discover how you can add a bit of flair to your content with scroll transitions."}],"type":"topic","title":"Beyond scroll views"},"https://avatars.githubusercontent.com/u/29355828?v=4":{"alt":"Profile image of laurent b","type":"image","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4","traits":["1x","light"]}],"identifier":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression","url":"\/documentation\/wwdcnotes\/wwdc23-10047-use-core-ml-tools-for-machine-learning-model-compression","abstract":[{"text":"Discover how to reduce the footprint of machine learning models in your app with Core ML Tools. Learn how to use techniques like palettization, pruning, and quantization to dramatically reduce model size while still achieving great accuracy. Explore comparisons between compression during the training stages and on fully trained models, and learn how compressed models can run even faster when your app takes full advantage of the Apple Neural Engine.","type":"text"}],"title":"Use Core ML Tools for machine learning model compression","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10281-Keep-up-with-the-keyboard":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10281-Keep-up-with-the-keyboard","abstract":[{"text":"Each year, the keyboard evolves to support an increasing range of languages, sizes, and features. Discover how you can design your app to keep up with the keyboard, regardless of how it appears on a device. We’ll show you how to create frictionless text entry and share important architectural changes to help you understand how the keyboard works within the system.","type":"text"}],"kind":"article","title":"Keep up with the keyboard","url":"\/documentation\/wwdcnotes\/wwdc23-10281-keep-up-with-the-keyboard"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10073-Design-for-spatial-input":{"kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10073-Design-for-spatial-input","url":"\/documentation\/wwdcnotes\/wwdc23-10073-design-for-spatial-input","abstract":[{"type":"text","text":"Learn how to design great interactions for eyes and hands. We’ll share the design principles for spatial input, explore best practices around input methods, and help you create spatial experiences that are comfortable, intuitive, and satisfying."}],"type":"topic","title":"Design for spatial input"},"https://developer.apple.com/videos/play/wwdc2023/10202/?time=626":{"titleInlineContent":[{"type":"text","text":"10:26 - Node graphs"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=626","title":"10:26 - Node graphs","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=626"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit","abstract":[{"text":"Go beyond the window and learn how you can bring engaging and immersive 3D content to your apps with RealityKit. Discover how SwiftUI scenes work in tandem with RealityView and how you can embed your content into an entity hierarchy. We’ll also explore how you can blend virtual content and the real world using anchors, bring particle effects into your apps, add video content, and create more immersive experiences with portals.","type":"text"}],"kind":"article","title":"Enhance your spatial computing app with RealityKit","url":"\/documentation\/wwdcnotes\/wwdc23-10081-enhance-your-spatial-computing-app-with-realitykit"},"WWDC23-10202-nodeGraphs4":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs4.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs4"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10263-Deploy-passkeys-at-work":{"title":"Deploy passkeys at work","type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10263-deploy-passkeys-at-work","abstract":[{"type":"text","text":"Discover how you can take advantage of passkeys in managed environments at work. We’ll explore how passkeys can work well in enterprise environments through Managed Apple ID support for iCloud Keychain. We’ll also share how administrators can manage passkeys for specific devices using Access Management controls in Apple Business Manager and Apple School Manager."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10263-Deploy-passkeys-at-work","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10157-Wind-your-way-through-advanced-animations-in-SwiftUI":{"role":"sampleCode","type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10157-wind-your-way-through-advanced-animations-in-swiftui","title":"Wind your way through advanced animations in SwiftUI","abstract":[{"type":"text","text":"Discover how you can take animation to the next level with the latest updates to SwiftUI. Join us as we wind our way through animation and build out multiple steps, use keyframes to add coordinated multi-track animated effects, and combine APIs in unique ways to make your app spring to life."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10157-Wind-your-way-through-advanced-animations-in-SwiftUI"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10049-improve-core-ml-integration-with-async-prediction","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","kind":"article","abstract":[{"text":"Learn how to speed up machine learning features in your app with the latest Core ML execution engine improvements and find out how aggressive asset caching can help with inference and faster model loads. We’ll show you some of the latest options for async prediction and discuss considerations for balancing performance with overall memory usage to help you create a highly responsive app. Discover APIs to help you understand and maximize hardware utilization for your models.","type":"text"}],"title":"Improve Core ML integration with async prediction"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10125-Bring-your-game-to-Mac-Part-3-Render-with-Metal":{"kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10125-Bring-your-game-to-Mac-Part-3-Render-with-Metal","url":"\/documentation\/wwdcnotes\/wwdc23-10125-bring-your-game-to-mac-part-3-render-with-metal","abstract":[{"type":"text","text":"Discover how you can support Metal in your rendering code as we close out our three-part series on bringing your game to Mac. Once you’ve evaluated your existing Windows binary with the game porting toolkit and brought your HLSL shaders over to Metal, learn how you can optimally implement the features that high-end, modern games require. We’ll show you how to manage GPU resource bindings, residency, and synchronization. Find out how to optimize GPU commands submission, render rich visuals with MetalFX Upscaling, and more."}],"type":"topic","title":"Bring your game to Mac, Part 3: Render with Metal"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10138-Design-and-build-apps-for-watchOS-10":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10138-design-and-build-apps-for-watchos-10","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10138-Design-and-build-apps-for-watchOS-10","kind":"article","abstract":[{"text":"Dive into the details of watchOS design principles and learn how to apply them in your app using SwiftUI. We’ll show you how to build an app for the redesigned user interface to surface timely information, communicate focused content at a glance, and make navigation consistent and predictable.","type":"text"}],"title":"Design and build apps for watchOS 10"},"WWDC23-10202-shaderGraphMaterial":{"alt":"shaderGraphMaterial","type":"image","variants":[{"url":"\/images\/WWDC23-10202-shaderGraphMaterial.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-shaderGraphMaterial"},"WWDC23-10202-geometryModifiers18":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers18.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers18"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10037-Explore-pie-charts-and-interactivity-in-Swift-Charts":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10037-Explore-pie-charts-and-interactivity-in-Swift-Charts","url":"\/documentation\/wwdcnotes\/wwdc23-10037-explore-pie-charts-and-interactivity-in-swift-charts","abstract":[{"text":"Swift Charts has come full circle: Get ready to bake up pie and donut charts in your app with the latest improvements to the framework. Learn how to make your charts scrollable, explore the chart selection API for revealing additional details in your data, and find out how enabling additional interactivity can make your charts even more delightful.","type":"text"}],"title":"Explore pie charts and interactivity in Swift Charts","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10180-Discover-streamlined-location-updates":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10180-discover-streamlined-location-updates","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10180-Discover-streamlined-location-updates","kind":"article","abstract":[{"text":"Move into the future with Core Location! Meet the CLLocationUpdate class, designed for modern Swift concurrency, and learn how it simplifies getting location updates. We’ll show you how this class works with your apps when they run in the foreground or background and share some best practices.","type":"text"}],"title":"Discover streamlined location updates"},"WWDC23-10202-geometryModifiers2":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers2.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers2"},"WWDC23-10202-nodeGraphs2":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs2.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs2"},"https://x.com/stevnhoward":{"titleInlineContent":[{"type":"text","text":"X\/Twitter"}],"type":"link","url":"https:\/\/x.com\/stevnhoward","title":"X\/Twitter","identifier":"https:\/\/x.com\/stevnhoward"},"WWDC23-10202-geometryModifiers19":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers19.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers19"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10188-Sync-to-iCloud-with-CKSyncEngine":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10188-sync-to-icloud-with-cksyncengine","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10188-Sync-to-iCloud-with-CKSyncEngine","kind":"article","abstract":[{"text":"Discover how CKSyncEngine can help you sync people’s CloudKit data to iCloud. Learn how you can reduce the amount of code in your app when you let the system handle scheduling for your sync operations. We’ll share how you can automatically benefit from enhanced performance as CloudKit evolves, explore testing for your sync implementation, and more.","type":"text"}],"title":"Sync to iCloud with CKSyncEngine"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10309-Design-widgets-for-the-Smart-Stack-on-Apple-Watch":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10309-Design-widgets-for-the-Smart-Stack-on-Apple-Watch","abstract":[{"text":"Bring your widgets to watchOS with the new Smart Stack. We’ll show you how to use standard design layouts, color and iconography, and signal-based relevancy to ensure your app’s widgets are glanceable, distinctive and smart.","type":"text"}],"kind":"article","title":"Design widgets for the Smart Stack on Apple Watch","url":"\/documentation\/wwdcnotes\/wwdc23-10309-design-widgets-for-the-smart-stack-on-apple-watch"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing":{"role":"sampleCode","title":"Elevate your windowed app for spatial computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","abstract":[{"type":"text","text":"Discover how you can bring your multiplatform SwiftUI app to visionOS and the Shared Space. We’ll show you how to add the visionOS destination to an existing app and view your app in the Simulator. Explore how your SwiftUI code automatically adapts to support the unique context and presentation of the visionOS platform. Learn how you can update custom views, improve your app’s UI, and add features and controls specific to this platform."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10110-elevate-your-windowed-app-for-spatial-computing","type":"topic","kind":"article"},"WWDC23-10202-yosemiteModel13":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel13.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel13"},"https://developer.apple.com/forums/tags/wwdc2023-10202":{"titleInlineContent":[{"type":"text","text":"Search the forums for tag wwdc2023-10202"}],"type":"link","url":"https:\/\/developer.apple.com\/forums\/tags\/wwdc2023-10202","title":"Search the forums for tag wwdc2023-10202","identifier":"https:\/\/developer.apple.com\/forums\/tags\/wwdc2023-10202"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10060-Get-started-with-privacy-manifests":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10060-get-started-with-privacy-manifests","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10060-Get-started-with-privacy-manifests","kind":"article","abstract":[{"text":"Meet privacy manifests: a new tool that helps you accurately identify the privacy practices of your app’s dependencies. Find out how third-party SDK developers can use these manifests to share privacy practices for their frameworks. We’ll also share how Xcode can produce a full privacy report to help you more easily represent the privacy practices of all the code in your app.","type":"text"}],"title":"Get started with privacy manifests"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10076-Design-for-spatial-user-interfaces":{"role":"sampleCode","title":"Design for spatial user interfaces","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces","abstract":[{"type":"text","text":"Learn how to design great interfaces for spatial computing apps. We’ll share how your existing screen-based knowledge easily translates into creating great experiences for visionOS. Explore guidelines for UI components, materials, and typography and find out how you can design experiences that are familiar, legible, and easy to use."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10076-design-for-spatial-user-interfaces","type":"topic","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10172-Mix-Swift-and-C++":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10172-Mix-Swift-and-C++","abstract":[{"text":"Learn how you can use Swift in your C++ and Objective-C++ projects to make your code safer, faster, and easier to develop. We’ll show you how to use C++ and Swift APIs to incrementally incorporate Swift into your app.","type":"text"}],"kind":"article","title":"Mix Swift and C++","url":"\/documentation\/wwdcnotes\/wwdc23-10172-mix-swift-and-c++"},"https://developer.apple.com/documentation/visionOS/diorama":{"titleInlineContent":[{"type":"text","text":"Diorama - Code Sample"}],"type":"link","url":"https:\/\/developer.apple.com\/documentation\/visionOS\/diorama","title":"Diorama - Code Sample","identifier":"https:\/\/developer.apple.com\/documentation\/visionOS\/diorama"},"https://developer.apple.com/wwdc23/10202":{"checksum":null,"type":"download","url":"https:\/\/developer.apple.com\/wwdc23\/10202","identifier":"https:\/\/developer.apple.com\/wwdc23\/10202"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10175-Fix-failures-faster-with-Xcode-test-reports":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10175-fix-failures-faster-with-xcode-test-reports","title":"Fix failures faster with Xcode test reports","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10175-Fix-failures-faster-with-Xcode-test-reports","type":"topic","abstract":[{"text":"Discover how you can find, debug, and fix test failures faster with the test report in Xcode and Xcode Cloud. Learn how Xcode identifies failure patterns to help you find the right place to start investigating. We’ll also show you how to use the UI automation explorer and video recordings to understand the events that led up to your UI test failure.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/stevenpaulhoward":{"role":"sampleCode","type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/stevenpaulhoward","title":"stevenpaulhoward (4 notes)","abstract":[{"type":"text","text":"3D connoisseur"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/stevenpaulhoward"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10122-Explore-media-formats-for-the-web":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10122-explore-media-formats-for-the-web","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10122-Explore-media-formats-for-the-web","kind":"article","abstract":[{"text":"Learn about the latest image formats and video technologies supported in Safari 17. Discover how you can use JPEG XL, AVIF, and HEIC in your websites and experiences and learn how they differ from previous formats. We’ll also show you how the Managed Media Source API draws less power than Media Source Extensions (MSE) and explore how you can use it to more efficiently manage streaming video over 5G.","type":"text"}],"title":"Explore media formats for the web"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10185-Update-Live-Activities-with-push-notifications":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10185-Update-Live-Activities-with-push-notifications","url":"\/documentation\/wwdcnotes\/wwdc23-10185-update-live-activities-with-push-notifications","abstract":[{"text":"Discover how you can remotely update Live Activities in your app when you push content through Apple Push Notification service (APNs). We’ll show you how to configure your first Live Activity push locally so you can quickly iterate on your implementation. Learn best practices for determining your push priority and configuring alerting updates, and explore how to further improve your Live Activities with relevance score and stale date.","type":"text"}],"title":"Update Live Activities with push notifications","kind":"article","role":"sampleCode","type":"topic"},"https://developer.apple.com/videos/play/wwdc2023/10086":{"titleInlineContent":[{"type":"text","text":"Explore the USD ecosystem"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10086","title":"Explore the USD ecosystem","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10086"},"https://developer.apple.com/videos/play/wwdc2023/10202/?time=796":{"titleInlineContent":[{"type":"text","text":"13:16 - Geometry modifiers"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=796","title":"13:16 - Geometry modifiers","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=796"},"WWDC23-10202-shaderGraphMaterial2":{"alt":"shaderGraphMaterial","type":"image","variants":[{"url":"\/images\/WWDC23-10202-shaderGraphMaterial2.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-shaderGraphMaterial2"},"https://materialx.org":{"titleInlineContent":[{"type":"text","text":"MaterialX"}],"type":"link","url":"https:\/\/materialx.org","title":"MaterialX","identifier":"https:\/\/materialx.org"},"WWDC23-10202-shaderGraphMaterial3":{"alt":"shaderGraphMaterial","type":"image","variants":[{"url":"\/images\/WWDC23-10202-shaderGraphMaterial3.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-shaderGraphMaterial3"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10057-Unleash-the-UIKit-trait-system":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10057-Unleash-the-UIKit-trait-system","url":"\/documentation\/wwdcnotes\/wwdc23-10057-unleash-the-uikit-trait-system","abstract":[{"text":"Discover powerful enhancements to the trait system in UIKit. Learn how you can define custom traits to add your own data to UITraitCollection, modify the data propagated to view controllers and views with trait override APIs, and adopt APIs to improve flexibility and performance. We’ll also show you how to bridge UIKit traits with SwiftUI environment keys to seamlessly access data from both UIKit and SwiftUI components in your app.","type":"text"}],"title":"Unleash the UIKit trait system","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10176-Lift-subjects-from-images-in-your-app":{"kind":"article","title":"Lift subjects from images in your app","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10176-lift-subjects-from-images-in-your-app","abstract":[{"text":"Discover how you can easily pull the subject of an image from its background in your apps. Learn how to lift the primary subject or to access the subject at a given point with VisionKit. We’ll also share how you can lift subjects using Vision and combine that with lower-level frameworks like Core Image to create fun image effects and more complex compositing pipelines.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10176-Lift-subjects-from-images-in-your-app"},"https://developer.apple.com/videos/play/wwdc2023/10202?time=695":{"titleInlineContent":[{"type":"text","text":"11:35"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=695","title":"11:35","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=695"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10090-run-your-ipad-and-iphone-apps-in-the-shared-space","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","kind":"article","abstract":[{"text":"Discover how you can run your existing iPad and iPhone apps on Vision Pro. Learn how iPadOS and iOS apps operate on this platform, find out about the Designed for iPad experience, and explore the paths available for enhancing your app experience on visionOS.","type":"text"}],"title":"Run your iPad and iPhone apps in the Shared Space"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10089-Discover-Metal-for-immersive-apps":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10089-discover-metal-for-immersive-apps","title":"Discover Metal for immersive apps","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10089-Discover-Metal-for-immersive-apps","type":"topic","abstract":[{"text":"Find out how you can use Metal to render fully immersive experiences for visionOS. We’ll show you how to set up a rendering session on the platform and create a basic render loop, and share how you can make your experience interactive by incorporating spatial input.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10034-Create-accessible-spatial-experiences":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10034-create-accessible-spatial-experiences","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10034-Create-accessible-spatial-experiences","kind":"article","abstract":[{"text":"Learn how you can make spatial computing apps that work well for everyone. Like all Apple platforms, visionOS is designed for accessibility: We’ll share how we’ve reimagined assistive technologies like VoiceOver and Pointer Control and designed features like Dwell Control to help people interact in the way that works best for them. Learn best practices for vision, motor, cognitive, and hearing accessibility and help everyone enjoy immersive experiences for visionOS.","type":"text"}],"title":"Create accessible spatial experiences"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10156-Explore-SwiftUI-animation":{"abstract":[{"type":"text","text":"Explore SwiftUI’s powerful animation capabilities and find out how these features work together to produce impressive visual effects. Learn how SwiftUI refreshes the rendering of a view, determines what to animate, interpolates values over time, and propagates context for the current transaction."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10156-explore-swiftui-animation","title":"Explore SwiftUI animation","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10156-Explore-SwiftUI-animation","type":"topic","kind":"article","role":"sampleCode"},"https://developer.apple.com/videos/play/wwdc2023/10202?time=349":{"titleInlineContent":[{"type":"text","text":"5:48"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=349","title":"5:48","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=349"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10042-Explore-Natural-Language-multilingual-models":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models","url":"\/documentation\/wwdcnotes\/wwdc23-10042-explore-natural-language-multilingual-models","abstract":[{"text":"Learn how to create custom Natural Language models for text classification and word tagging using multilingual, transformer-based embeddings. We’ll show you how to train with less data and support up to 27 different languages across three scripts. Find out how to use these embeddings to fine-tune complex models trained in PyTorch and TensorFlow.","type":"text"}],"title":"Explore Natural Language multilingual models","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10150-optimize-carplay-for-vehicle-systems","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems","kind":"article","abstract":[{"text":"Discover how you can integrate CarPlay into modern vehicle systems. We’ll show you how to adjust CarPlay for any high-resolution display — regardless of configuration or size. Learn how you can use CarPlay-supplied metadata and video streams to show information on additional displays, and find out how advances in wireless connectivity, audio, and video encoding can help prepare your vehicle system for the next generation of CarPlay.","type":"text"}],"title":"Optimize CarPlay for vehicle systems"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10027-Bring-widgets-to-new-places":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10027-Bring-widgets-to-new-places","url":"\/documentation\/wwdcnotes\/wwdc23-10027-bring-widgets-to-new-places","abstract":[{"text":"The widget ecosystem is expanding: Discover how you can use the latest WidgetKit APIs to make your widget look great everywhere. We’ll show you how to identify your widget’s background, adjust layout dynamically, and prepare colors for vibrant rendering so that your widget can sit seamlessly in any environment.","type":"text"}],"title":"Bring widgets to new places","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10266-Protect-your-Mac-app-with-environment-constraints":{"url":"\/documentation\/wwdcnotes\/wwdc23-10266-protect-your-mac-app-with-environment-constraints","abstract":[{"type":"text","text":"Learn how to improve the security of your Mac app by adopting environment constraints. We’ll show you how to set limits on how processes are launched, make sure your Launch Agents and Launch Daemons aren’t tampered with, and prevent unwanted code from running in your address space."}],"type":"topic","title":"Protect your Mac app with environment constraints","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10266-Protect-your-Mac-app-with-environment-constraints","role":"sampleCode","kind":"article"},"https://avatars.githubusercontent.com/u/40086690?v=4":{"alt":"Profile image of stevenpaulhoward","type":"image","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/40086690?v=4","traits":["1x","light"]}],"identifier":"https:\/\/avatars.githubusercontent.com\/u\/40086690?v=4"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10224-Simplify-distribution-in-Xcode-and-Xcode-Cloud":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10224-Simplify-distribution-in-Xcode-and-Xcode-Cloud","url":"\/documentation\/wwdcnotes\/wwdc23-10224-simplify-distribution-in-xcode-and-xcode-cloud","abstract":[{"text":"Discover how to share your app using Xcode’s streamlined distribution, which allows you to submit your app to TestFlight or the App Store with one click. We’ll also show you how to use Xcode Cloud to simplify your distribution process by automatically including notes for testers in TestFlight, and use post-action to automatically notarize your Mac apps.","type":"text"}],"title":"Simplify distribution in Xcode and Xcode Cloud","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10168-Generalize-APIs-with-parameter-packs":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10168-Generalize-APIs-with-parameter-packs","abstract":[{"text":"Swift parameter packs are a powerful tool to expand what is possible in your generic code while also enabling you to simplify common generic patterns. We’ll show you how to abstract over types as well as the number of arguments in generic code and simplify common generic patterns to avoid overloads.","type":"text"}],"kind":"article","title":"Generalize APIs with parameter packs","url":"\/documentation\/wwdcnotes\/wwdc23-10168-generalize-apis-with-parameter-packs"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10091-evolve-your-arkit-app-for-spatial-experiences","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences","kind":"article","abstract":[{"text":"Discover how you can bring your app’s AR experience to visionOS. Learn how ARKit and RealityKit have evolved for spatial computing: We’ll highlight conceptual and API changes for those coming from iPadOS and iOS and guide you to sessions with more details to help you bring your AR experience to this platform.","type":"text"}],"title":"Evolve your ARKit app for spatial experiences"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10070-Create-a-great-spatial-playback-experience":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10070-Create-a-great-spatial-playback-experience","abstract":[{"text":"Get ready to support video in your visionOS app! Take a tour of the frameworks and APIs that power video playback and learn how you can update your app to play 3D content. We’ll also share tips for customizing playback to create a more immersive watching experience.","type":"text"}],"kind":"article","title":"Create a great spatial playback experience","url":"\/documentation\/wwdcnotes\/wwdc23-10070-create-a-great-spatial-playback-experience"},"WWDC23-10202-nodeGraphs9":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs9.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs9"},"WWDC23-10202-yosemiteModel6":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel6.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel6"},"WWDC23-10202-metal":{"alt":"Shaders in CustomMaterial are hand coded in Metal","type":"image","variants":[{"url":"\/images\/WWDC23-10202-metal.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-metal"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10102-Spotlight-your-app-with-App-Shortcuts":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10102-spotlight-your-app-with-app-shortcuts","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10102-Spotlight-your-app-with-App-Shortcuts","kind":"article","abstract":[{"text":"Discover how to use App Shortcuts to surface frequently used features from your app in Spotlight or through Siri. Find out how to configure search results for your app and learn best practices for creating great App Shortcuts. We’ll also show you how to build great visual and voice experiences and extend to other Apple devices like Apple Watch and HomePod.","type":"text"}],"title":"Spotlight your app with App Shortcuts"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10023-Build-a-multidevice-workout-app":{"url":"\/documentation\/wwdcnotes\/wwdc23-10023-build-a-multidevice-workout-app","role":"sampleCode","abstract":[{"type":"text","text":"Learn how you can get iPhone involved in your Apple Watch-based workout apps with HealthKit. We’ll show you how to mirror workouts between devices and take a ride with cycling data types. Plus, get to know HealthKit for iPad."}],"title":"Build a multi-device workout app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10023-Build-a-multidevice-workout-app","type":"topic","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10160-Demystify-SwiftUI-performance":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10160-Demystify-SwiftUI-performance","url":"\/documentation\/wwdcnotes\/wwdc23-10160-demystify-swiftui-performance","abstract":[{"text":"Learn how you can build a mental model for performance in SwiftUI and write faster, more efficient code. We’ll share some of the common causes behind performance issues and help you triage hangs and hitches in SwiftUI to create more responsive views in your app.","type":"text"}],"title":"Demystify SwiftUI performance","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10244-Create-rich-documentation-with-SwiftDocC":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10244-Create-rich-documentation-with-SwiftDocC","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10244-create-rich-documentation-with-swiftdocc","abstract":[{"text":"Learn how you can take advantage of the latest features in Swift-DocC to create rich and detailed documentation for your app or framework. We’ll show you how to use the Xcode 15 Documentation Preview editor to efficiently iterate on your existing project’s documentation, and explore expanded authoring capabilities like grid-based layouts, video support, and custom themes.","type":"text"}],"role":"sampleCode","kind":"article","title":"Create rich documentation with Swift-DocC"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10241-Share-files-with-SharePlay":{"kind":"article","title":"Share files with SharePlay","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10241-share-files-with-shareplay","abstract":[{"text":"Discover how to work with files and attachments in a SharePlay activity. We’ll explain how to use the GroupSessionJournal API to sync large amounts of data faster and show you how to adopt it in a demo of the sample app DrawTogether.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10241-Share-files-with-SharePlay"},"https://developer.apple.com/videos/play/wwdc2023/10096":{"titleInlineContent":[{"type":"text","text":"Build great games for spatial computing"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10096","title":"Build great games for spatial computing","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10096"},"doc://WWDCNotes/documentation/WWDCNotes/multitudes":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/multitudes","title":"laurent b (32 notes)","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","type":"topic","abstract":[{"text":"student at 42Berlin 🐬 | 🍎 Swift(UI) app dev  | speciality coffee ☕️ & cycling 🚴🏻‍♂️","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10087-Build-spatial-SharePlay-experiences":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10087-build-spatial-shareplay-experiences","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10087-Build-spatial-SharePlay-experiences","kind":"article","abstract":[{"text":"Discover how you can use the GroupActivities framework to build unique sharing and collaboration experiences for visionOS. We’ll introduce you to SharePlay on this platform, learn how to create experiences that make people feel present as if they were in the same space, and explore how immersive apps can respect shared context between participants.","type":"text"}],"title":"Build spatial SharePlay experiences"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10105-Create-a-more-responsive-camera-experience":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10105-Create-a-more-responsive-camera-experience","url":"\/documentation\/wwdcnotes\/wwdc23-10105-create-a-more-responsive-camera-experience","abstract":[{"text":"Discover how AVCapture and PhotoKit can help you create more responsive and delightful apps. Learn about the camera capture process and find out how deferred photo processing can help create the best quality photo. We’ll show you how zero shutter lag uses time travel to capture the perfect action photo, dive into building a responsive capture pipeline, and share how you can adopt the Video Effects API to recognize pre-defined gestures that trigger real-time video effects.","type":"text"}],"title":"Create a more responsive camera experience","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10123-Bring-your-game-to-Mac-Part-1-Make-a-game-plan":{"kind":"article","type":"topic","role":"sampleCode","title":"Bring your game to Mac, Part 1: Make a game plan","url":"\/documentation\/wwdcnotes\/wwdc23-10123-bring-your-game-to-mac-part-1-make-a-game-plan","abstract":[{"text":"Bring modern, high-end games to Mac and iPad with the powerful features of Metal and Apple silicon. Discover the game porting toolkit and learn how it can help you evaluate your existing Windows game for graphics feature compatibility and performance. We’ll share best practices and technical resources for handling audio, input, and advanced display features.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10123-Bring-your-game-to-Mac-Part-1-Make-a-game-plan"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","abstract":[{"text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio.","type":"text"}],"title":"Build spatial experiences with RealityKit","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10250-Prototype-with-Xcode-Playgrounds":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10250-Prototype-with-Xcode-Playgrounds","abstract":[{"text":"Speed up feature development by prototyping new code with Xcode Playgrounds, eliminating the need to keep rebuilding and relaunching your project to verify your changes. We’ll show you how using a playground in your project or package can help you try out your code in various scenarios and take a close look at the returned values, including complex structures and user interface elements, so you can quickly iterate on a feature before integrating it into your project.","type":"text"}],"kind":"article","title":"Prototype with Xcode Playgrounds","url":"\/documentation\/wwdcnotes\/wwdc23-10250-prototype-with-xcode-playgrounds"},"https://developer.apple.com/videos/play/wwdc2023/10100":{"titleInlineContent":[{"type":"text","text":"Optimize app power and performance for spatial computing"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10100","title":"Optimize app power and performance for spatial computing","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10100"},"https://developer.apple.com/videos/play/wwdc2023/10202/?time=218":{"titleInlineContent":[{"type":"text","text":"3:38 - Material editing"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=218","title":"3:38 - Material editing","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=218"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10044-discover-machine-learning-enhancements-in-create-ml","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","kind":"article","abstract":[{"text":"Find out how Create ML can help you do even more with machine learning models. Learn about the latest updates to image understanding and text-based tasks with multilingual BERT embeddings. Discover how easy it is to train models that can understand the content of images using multi-label classification. We’ll also share information about interactive model evaluation and the latest APIs for custom training data augmentations.","type":"text"}],"title":"Discover machine learning enhancements in Create ML"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10226-Debug-with-structured-logging":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10226-Debug-with-structured-logging","url":"\/documentation\/wwdcnotes\/wwdc23-10226-debug-with-structured-logging","abstract":[{"text":"Discover the debug console in Xcode 15 and learn how you can improve your diagnostic experience through logging. Explore how you can navigate your logs easily and efficiently using advanced filtering and improved visualization. We’ll also show you how to use the dwim-print command to evaluate expressions in your code while debugging.","type":"text"}],"title":"Debug with structured logging","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-geometryModifiers":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers"},"WWDC23-10202-nodeGraphs8":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs8.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs8"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10124-Bring-your-game-to-Mac-Part-2-Compile-your-shaders":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10124-Bring-your-game-to-Mac-Part-2-Compile-your-shaders","url":"\/documentation\/wwdcnotes\/wwdc23-10124-bring-your-game-to-mac-part-2-compile-your-shaders","abstract":[{"text":"Discover how the Metal shader converter streamlines the process of bringing your HLSL shaders to Metal as we continue our three-part series on bringing your game to Mac. Find out how to build a fast, end-to-end shader pipeline from DXIL that supports all shader stages and allows you to leverage the advanced features of Apple GPUs. We’ll also show you how to reduce app launch time and stutters by generating GPU binaries with the offline compiler.","type":"text"}],"title":"Bring your game to Mac, Part 2: Compile your shaders","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-yosemiteModel12":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel12.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel12"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10254-Do-more-with-Managed-Apple-IDs":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10254-Do-more-with-Managed-Apple-IDs","url":"\/documentation\/wwdcnotes\/wwdc23-10254-do-more-with-managed-apple-ids","abstract":[{"text":"Explore the latest updates to Managed Apple IDs and learn how you can use them in your organization. Take advantage of additional apps and services available to Managed Apple IDs, discover the Account-Driven Device Enrollment flow, and find out how to use access management controls to limit the devices and Apple services that Managed Apple IDs can access. We’ll also show you how to federate with your identity provider to automate creation and sync with your directory.","type":"text"}],"title":"Do more with Managed Apple IDs","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10094-Enhance-your-iPad-and-iPhone-apps-for-the-Shared-Space":{"kind":"article","title":"Enhance your iPad and iPhone apps for the Shared Space","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10094-enhance-your-ipad-and-iphone-apps-for-the-shared-space","abstract":[{"text":"Get ready to enhance your iPad and iPhone apps for the Shared Space! We’ll show you how to optimize your experience to make it feel great on visionOS and explore Designed for iPad app interaction, visual treatments, and media.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10094-Enhance-your-iPad-and-iPhone-apps-for-the-Shared-Space"},"WWDC23-10202-geometryModifiers20":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers20.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers20"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10050-Optimize-machine-learning-for-Metal-apps":{"kind":"article","title":"Optimize machine learning for Metal apps","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10050-optimize-machine-learning-for-metal-apps","abstract":[{"text":"Discover the latest enhancements to accelerated ML training in Metal. Find out about updates to PyTorch and TensorFlow, and learn about Metal acceleration for JAX. We’ll show you how MPS Graph can support faster ML inference when you use both the GPU and Apple Neural Engine, and share how the same API can rapidly integrate your Core ML and ONNX models.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10050-Optimize-machine-learning-for-Metal-apps"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10083-Meet-Reality-Composer-Pro":{"role":"sampleCode","type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10083-meet-reality-composer-pro","title":"Meet Reality Composer Pro","abstract":[{"type":"text","text":"Discover how to easily compose, edit, and preview 3D content with Reality Composer Pro. Follow along as we explore this developer tool by setting up a new project, composing scenes, adding particle emitters and audio, and even previewing content on device."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10262-Rediscover-Safari-developer-features":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10262-Rediscover-Safari-developer-features","url":"\/documentation\/wwdcnotes\/wwdc23-10262-rediscover-safari-developer-features","abstract":[{"text":"Get ready to explore Safari’s rich set of tools for web developers and designers. Learn how you can inspect web content, find out about Responsive Design Mode and WebDriver, and get started with simulators and devices. We’ll also show you how to pair with Vision Pro, make content inspectable in your apps, and use Open with Simulator in Responsive Design Mode to help you test your websites on any device.","type":"text"}],"title":"Rediscover Safari developer features","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10113-Take-SwiftUI-to-the-next-dimension":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","url":"\/documentation\/wwdcnotes\/wwdc23-10113-take-swiftui-to-the-next-dimension","abstract":[{"text":"Get ready to add depth and dimension to your visionOS apps. Find out how to bring three-dimensional objects to your app using volumes, get to know the Model 3D API, and learn how to position and animate content. We’ll also show you how to use UI attachments in RealityView and support gestures in your content.","type":"text"}],"title":"Take SwiftUI to the next dimension","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-geometryModifiers6":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers6.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers6"},"WWDC23-10202-yosemiteModel2":{"alt":"the Yosemite Valley model in Reality Composer Pro","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel2.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel2"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-111241-explore-3d-body-pose-and-person-segmentation-in-vision","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","kind":"article","abstract":[{"text":"Discover how to build person-centric features with Vision. Learn how to detect human body poses and measure individual joint locations in 3D space. We’ll also show you how to take advantage of person segmentation APIs to distinguish and segment up to four individuals in an image.","type":"text"}],"title":"Explore 3D body pose and person segmentation in Vision"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10031-Update-your-app-for-watchOS-10":{"kind":"article","title":"Update your app for watchOS 10","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10031-update-your-app-for-watchos-10","abstract":[{"text":"Join us as we update an Apple Watch app to take advantage of the latest features in watchOS 10. In this code-along, we’ll show you how to use the latest SwiftUI APIs to maximize glanceability and reorient app navigation around the Digital Crown.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10031-Update-your-app-for-watchOS-10"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10051-Create-a-great-ShazamKit-experience":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10051-Create-a-great-ShazamKit-experience","abstract":[{"text":"Discover how your app can offer a great audio matching experience with the latest updates to ShazamKit. We’ll take you through matching features, updates to audio recognition, and interactions with the Shazam library. Learn tips and best practices for using ShazamKit in your audio apps.","type":"text"}],"kind":"article","title":"Create a great ShazamKit experience","url":"\/documentation\/wwdcnotes\/wwdc23-10051-create-a-great-shazamkit-experience"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10002-Ready-set-relay-Protect-app-traffic-with-network-relays":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10002-Ready-set-relay-Protect-app-traffic-with-network-relays","url":"\/documentation\/wwdcnotes\/wwdc23-10002-ready-set-relay-protect-app-traffic-with-network-relays","abstract":[{"text":"Learn how relays can make your app’s network traffic more private and secure without the overhead of a VPN. We’ll show you how to integrate relay servers in your own app and explore how enterprise networks can use relays to securely access internal resources.","type":"text"}],"title":"Ready, set, relay: Protect app traffic with network relays","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-geometryModifiers8":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers8.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers8"},"WWDC23-10202-geometryModifiers10":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers10.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers10"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10035-Perform-accessibility-audits-for-your-app":{"kind":"article","title":"Perform accessibility audits for your app","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10035-perform-accessibility-audits-for-your-app","abstract":[{"text":"Discover how you can test your app for accessibility with every build. Learn how to perform automated audits for accessibility using XCTest and find out how to interpret the results. We’ll also share enhancements to the accessibility API that can help you improve UI test coverage.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10035-Perform-accessibility-audits-for-your-app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10149-Discover-Observation-in-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10149-Discover-Observation-in-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10149-discover-observation-in-swiftui","abstract":[{"text":"Simplify your SwiftUI data models with Observation. We’ll share how the Observable macro can help you simplify models and improve your app’s performance. Get to know Observation, learn the fundamentals of the macro, and find out how to migrate from ObservableObject to Observable.","type":"text"}],"title":"Discover Observation in SwiftUI","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10101-Customize-ondevice-speech-recognition":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10101-Customize-ondevice-speech-recognition","abstract":[{"text":"Find out how you can improve on-device speech recognition in your app by customizing the underlying model with additional vocabulary. We’ll share how speech recognition works on device and show you how to boost specific words and phrases for more predictable transcription. Learn how you can provide specific pronunciations for words and use template support to quickly generate a full set of custom phrases — all at runtime.","type":"text"}],"kind":"article","title":"Customize on-device speech recognition","url":"\/documentation\/wwdcnotes\/wwdc23-10101-customize-ondevice-speech-recognition"},"WWDC23-10202-geometryModifiers5":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers5.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers5"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10061-Verify-app-dependencies-with-digital-signatures":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10061-verify-app-dependencies-with-digital-signatures","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10061-Verify-app-dependencies-with-digital-signatures","kind":"article","abstract":[{"text":"Discover how you can help secure your app’s dependencies. We’ll show you how Xcode can automatically verify any signed XCFrameworks you include within a project. Learn how code signatures work, the benefits they provide to help protect your software supply chain, and how SDK developers can sign their XCFrameworks to help keep your apps secure.","type":"text"}],"title":"Verify app dependencies with digital signatures"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10233-enhance-your-apps-audio-experience-with-airpods","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods","kind":"article","abstract":[{"text":"Discover how you can create transformative audio experiences in your app using AirPods. Learn how to incorporate AirPods Automatic Switching, use AVAudioApplication to support Mute Control, and take advantage of Spatial Audio to create immersive soundscapes in your app or game.","type":"text"}],"title":"Enhance your app’s audio experience with AirPods"},"WWDC23-10202-nodeGraphs7":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs7.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs7"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10189-Migrate-to-SwiftData":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10189-migrate-to-swiftdata","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10189-Migrate-to-SwiftData","kind":"article","abstract":[{"text":"Discover how you can start using SwiftData in your apps. We’ll show you how to use Xcode to generate model classes from your existing Core Data object models, use SwiftData alongside your previous implementation, or even completely replace your existing solution.","type":"text"}],"title":"Migrate to SwiftData"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10193-Design-Shortcuts-for-Spotlight":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10193-Design-Shortcuts-for-Spotlight","url":"\/documentation\/wwdcnotes\/wwdc23-10193-design-shortcuts-for-spotlight","abstract":[{"text":"Learn about the latest updates to the visual language of App Shortcuts and find out how to design your shortcut to appear as a top hit in Spotlight. We’ll share how shortcuts can appear on iOS or iPadOS, and show you how to customize the visual appearance of a shortcut, personalize its order, select its correct behavior, and increase discoverability.","type":"text"}],"title":"Design Shortcuts for Spotlight","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","url":"\/documentation\/wwdcnotes\/wwdc23","abstract":[{"text":"Xcode 15, Swift 5.9, iOS 17, macOS 14, tvOS 17, visionOS 1, watchOS 10.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"code":"SwiftData","type":"codeVoice"},{"text":", ","type":"text"},{"code":"Observation","type":"codeVoice"},{"text":", ","type":"text"},{"code":"StoreKit","type":"codeVoice"},{"text":" views, and more.","type":"text"}],"title":"WWDC23","kind":"article","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"role":"collectionGroup","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10252-Build-programmatic-UI-with-Xcode-Previews":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10252-Build-programmatic-UI-with-Xcode-Previews","url":"\/documentation\/wwdcnotes\/wwdc23-10252-build-programmatic-ui-with-xcode-previews","abstract":[{"text":"Learn how you can use the #Preview macro on Xcode 15 to quickly iterate on your UI code written in SwiftUI, UIKit, or AppKit. Explore a collage of unique workflows for interacting with views right in the canvas, find out how to view multiple variations of UI simultaneously, and discover how you can travel through your widget’s timeline in seconds to test the transitions between entries. We’ll also show you how to add previews to libraries, provide sample assets, and preview your views in your physical devices to leverage their capabilities and existing data.","type":"text"}],"title":"Build programmatic UI with Xcode Previews","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10155-Discover-String-Catalogs":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10155-discover-string-catalogs","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10155-Discover-String-Catalogs","kind":"article","abstract":[{"text":"Discover how Xcode 15 makes it easy to localize your app by managing all of your strings in one place. We’ll show you how to extract, edit, export, and build strings in your project using String Catalogs. We’ll also share how you can adopt String Catalogs in existing projects at your own pace by choosing which files to migrate.","type":"text"}],"title":"Discover String Catalogs"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10056-Build-better-documentbased-apps":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10056-Build-better-documentbased-apps","url":"\/documentation\/wwdcnotes\/wwdc23-10056-build-better-documentbased-apps","abstract":[{"text":"Discover how you can use the latest features in iPadOS to improve your document-based apps. We’ll show you how to take advantage of UIDocument as well as existing desktop-class iPad and document-based APIs to add new features in your app. Find out how to convert data models to UIDocument, present documents with UIDocumentViewController, learn how to migrate your apps to the latest APIs, and explore best practices.","type":"text"}],"title":"Build better document-based apps","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-yosemiteModel":{"alt":"the Yosemite Valley model in Reality Composer Pro","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10238-Tune-up-your-AirPlay-audio-experience":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10238-Tune-up-your-AirPlay-audio-experience","url":"\/documentation\/wwdcnotes\/wwdc23-10238-tune-up-your-airplay-audio-experience","abstract":[{"text":"Learn how you can upgrade your app’s AirPlay audio experience to be more robust and responsive. We’ll show you how to adopt enhanced audio buffering with AVQueuePlayer, explore alternatives when building a custom player in your app, and share best practices.","type":"text"}],"title":"Tune up your AirPlay audio experience","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-nodeGraphs":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs"},"WWDC23-10202-pbr":{"alt":"Physically Based Rendering example","type":"image","variants":[{"url":"\/images\/WWDC23-10202-pbr.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-pbr"},"WWDC23-10202-realityComposerPro":{"alt":"Reality Composer Pro","type":"image","variants":[{"url":"\/images\/WWDC23-10202-realityComposerPro.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-realityComposerPro"},"WWDC23-10202-yosemiteModel10":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel10.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel10"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10103-Explore-enhancements-to-App-Intents":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10103-Explore-enhancements-to-App-Intents","url":"\/documentation\/wwdcnotes\/wwdc23-10103-explore-enhancements-to-app-intents","abstract":[{"text":"Bring your widgets to life with App Intents! Explore the latest updates and learn how you can take advantage of dynamic options and user interactivity to build better experiences for your App Shortcuts. We’ll share how you can integrate with Apple Pay, structure your code more efficiently, and take your Shortcuts app integration to the next level.","type":"text"}],"title":"Explore enhancements to App Intents","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10007-Create-seamless-experiences-with-Virtualization":{"type":"topic","abstract":[{"type":"text","text":"Discover the latest updates to the Virtualization framework. We’ll show you how to configure a virtual machine (VM) to automatically resize its display, take you through saving and restoring a running VM, and explore storage and performance options for Virtualization apps running on the desktop or in the data center."}],"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10007-create-seamless-experiences-with-virtualization","title":"Create seamless experiences with Virtualization","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10007-Create-seamless-experiences-with-Virtualization"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10153-Unlock-the-power-of-grammatical-agreement":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10153-unlock-the-power-of-grammatical-agreement","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10153-Unlock-the-power-of-grammatical-agreement","kind":"article","abstract":[{"text":"Discover how you can use automatic grammatical agreement in your apps and games to create inclusive and more natural-sounding expressions. We’ll share best practices for working with Foundation, showcase examples in multiple languages, and demonstrate how to use these APIs to enhance the user experience for your apps.","type":"text"}],"title":"Unlock the power of grammatical agreement"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10256-Discover-Continuity-Camera-for-tvOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10256-Discover-Continuity-Camera-for-tvOS","url":"\/documentation\/wwdcnotes\/wwdc23-10256-discover-continuity-camera-for-tvos","abstract":[{"text":"Discover how you can bring AVFoundation, AVFAudio, and AudioToolbox to your apps on tvOS and create camera and microphone experiences for the living room. Find out how to support tvOS in your existing iOS camera experience with the Device Discovery API, build apps that use iPhone as a webcam or FaceTime source, and explore special considerations when developing for tvOS. We’ll also show you how to enable audio recording for tvOS, and how to use echo cancellation to create great voice-driven experiences.","type":"text"}],"title":"Discover Continuity Camera for tvOS","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10229-Make-features-discoverable-with-TipKit":{"abstract":[{"type":"text","text":"Teach people how to use your app with TipKit! Learn how you can create effective educational moments through tips. We’ll share how you can build eligibility rules to reach the ideal audience, control tip frequency, and strategies for testing to ensure successful interactions."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10229-make-features-discoverable-with-tipkit","title":"Make features discoverable with TipKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10229-Make-features-discoverable-with-TipKit","type":"topic","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10036-Build-accessible-apps-with-SwiftUI-and-UIKit":{"url":"\/documentation\/wwdcnotes\/wwdc23-10036-build-accessible-apps-with-swiftui-and-uikit","abstract":[{"type":"text","text":"Discover how advancements in UI frameworks make it easier to build rich, accessible experiences. Find out how technologies like VoiceOver can better interact with your app’s interface through accessibility traits and actions. We’ll share the latest updates to SwiftUI that help you refine your accessibility experience and show you how to keep accessibility information up-to-date in your UIKit apps."}],"type":"topic","title":"Build accessible apps with SwiftUI and UIKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10036-Build-accessible-apps-with-SwiftUI-and-UIKit","role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10127-Optimize-GPU-renderers-with-Metal":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10127-Optimize-GPU-renderers-with-Metal","url":"\/documentation\/wwdcnotes\/wwdc23-10127-optimize-gpu-renderers-with-metal","abstract":[{"text":"Discover how to optimize your GPU renderer using the latest Metal features and best practices. We’ll show you how to use function specialization and parallel shader compilation to maintain responsive authoring workflows and the fastest rendering speeds, and help you tune your compute shaders for optimal performance.","type":"text"}],"title":"Optimize GPU renderers with Metal","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10004-Reduce-network-delays-with-L4S":{"kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10004-Reduce-network-delays-with-L4S","url":"\/documentation\/wwdcnotes\/wwdc23-10004-reduce-network-delays-with-l4s","abstract":[{"type":"text","text":"Streaming video, multiplayer games, and other real-time experiences depend on responsive, low latency networking. Learn how Low Latency, Low Loss, Scalable throughput (L4S) can reduce network delays and improve the overall experience in your app. We’ll show you how to set up and test your app, network, and server with L4S."}],"type":"topic","title":"Reduce network delays with L4S"},"https://developer.apple.com/videos/play/wwdc2023/10202/?time=55":{"titleInlineContent":[{"type":"text","text":"0:55 - Materials in xrOS"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=55","title":"0:55 - Materials in xrOS","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/?time=55"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10257-Create-animated-symbols":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10257-create-animated-symbols","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10257-Create-animated-symbols","kind":"article","abstract":[{"text":"Discover animation presets and learn how to use them with SF Symbols and custom symbols. We’ll show you how to experiment with different options and configurations to find the perfect animation for your app. Learn how to update custom symbols for animation using annotation features, find out how to modify your custom symbols with symbol components, and explore the redesigned export process to help keep symbols looking great on all platforms.","type":"text"}],"title":"Create animated symbols"},"https://developer.apple.com/videos/play/wwdc2023/10202?time=271":{"titleInlineContent":[{"type":"text","text":"4:31"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=271","title":"4:31","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=271"},"WWDC23-10202-geometryModifiers7":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers7.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers7"},"https://developer.apple.com/videos/play/wwdc2023/10202?time=730":{"titleInlineContent":[{"type":"text","text":"12:10"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=730","title":"12:10","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=730"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10078-Design-considerations-for-vision-and-motion":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10078-design-considerations-for-vision-and-motion","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10078-Design-considerations-for-vision-and-motion","kind":"article","abstract":[{"text":"Learn how to design engaging immersive experiences for visionOS that respect the limitations of human vision and motion perception. We’ll show you how you can use depth cues, contrast, focus, and motion to keep people comfortable as they enjoy your apps and games.","type":"text"}],"title":"Design considerations for vision and motion"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10278-Create-practical-workflows-in-Xcode-Cloud":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10278-Create-practical-workflows-in-Xcode-Cloud","url":"\/documentation\/wwdcnotes\/wwdc23-10278-create-practical-workflows-in-xcode-cloud","abstract":[{"text":"Learn how Xcode Cloud can help teams of all shapes and sizes in their development process. We’ll share different ways to configure actions to help you create simple yet powerful workflows, and show you how to extend Xcode Cloud when you integrate with additional tools.","type":"text"}],"title":"Create practical workflows in Xcode Cloud","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-yosemiteModel3":{"alt":"the Yosemite Valley model in Reality Composer Pro","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel3.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel3"},"https://laurentbrusa.hashnode.dev/":{"titleInlineContent":[{"type":"text","text":"Blog"}],"type":"link","url":"https:\/\/laurentbrusa.hashnode.dev\/","title":"Blog","identifier":"https:\/\/laurentbrusa.hashnode.dev\/"},"WWDCNotes.png":{"alt":null,"type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"identifier":"WWDCNotes.png"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10271-Explore-immersive-sound-design":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10271-explore-immersive-sound-design","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10271-Explore-immersive-sound-design","kind":"article","abstract":[{"text":"Discover how you can use sound to enhance the experience of your visionOS apps and games. Learn how Apple designers select sounds and build soundscapes to create textural, immersive experiences. We’ll share how you can enrich basic interactions in your app with sound when you place audio cues spatially, vary repetitive sounds, and build moments of sonic delight into your app.","type":"text"}],"title":"Explore immersive sound design"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10115-Design-with-SwiftUI":{"url":"\/documentation\/wwdcnotes\/wwdc23-10115-design-with-swiftui","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10115-Design-with-SwiftUI","kind":"article","title":"Design with SwiftUI","abstract":[{"text":"Discover how SwiftUI can help you quickly iterate and explore design ideas. Learn from Apple designers as they share how working with SwiftUI influenced the design of the Maps app in watchOS 10 and other elements of their work, and find out how you can incorporate these workflows in your own process.","type":"text"}],"type":"topic","role":"sampleCode"},"https://developer.apple.com/videos/play/wwdc2023/10095":{"titleInlineContent":[{"type":"text","text":"Explore rendering for spatial computing"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10095","title":"Explore rendering for spatial computing","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10095"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10088-Create-immersive-Unity-apps":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10088-create-immersive-unity-apps","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10088-Create-immersive-Unity-apps","kind":"article","abstract":[{"text":"Explore how you can use Unity to create engaging and immersive experiences for visionOS. We’ll share how Unity integrates seamlessly with Apple frameworks, take you through the tools you can use to build natively for the platform, and show you how volume cameras can bring your existing scenes into visionOS windows, volumes, and spaces.","type":"text"}],"title":"Create immersive Unity apps"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","url":"\/documentation\/wwdcnotes\/wwdc23-10273-work-with-reality-composer-pro-content-in-xcode","abstract":[{"text":"Learn how to bring content from Reality Composer Pro to life in Xcode. We’ll show you how to load 3D scenes into Xcode, integrate your content with your code, and add interactivity to your app. We’ll also share best practices and tips for using these tools together in your development workflow.","type":"text"}],"title":"Work with Reality Composer Pro content in Xcode","kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","role":"collection","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"type":"topic","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"url":"\/documentation\/wwdcnotes","kind":"symbol"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10071-Deliver-video-content-for-spatial-experiences":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences","abstract":[{"text":"Learn how to prepare and deliver video content for visionOS using HTTP Live Streaming (HLS). Discover the current HLS delivery process for media and explore how you can expand your delivery pipeline to support 3D content. Get up to speed with tips and techniques for spatial media streaming and adapting your existing caption production workflows for 3D. And find out how to share audio tracks across video variants and add spatial audio to make your video content more immersive.","type":"text"}],"kind":"article","title":"Deliver video content for spatial experiences","url":"\/documentation\/wwdcnotes\/wwdc23-10071-deliver-video-content-for-spatial-experiences"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10045-Detect-animal-poses-in-Vision":{"kind":"article","title":"Detect animal poses in Vision","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10045-detect-animal-poses-in-vision","abstract":[{"text":"Go beyond detecting cats and dogs in images. We’ll show you how to use Vision to detect the individual joints and poses of these animals as well — all in real time — and share how you can enable exciting features like animal tracking for a camera app, creative embellishment on an animal photo, and more. We’ll also explore other important enhancements to Vision and share best practices.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10192-Explore-enhancements-to-RoomPlan":{"url":"\/documentation\/wwdcnotes\/wwdc23-10192-explore-enhancements-to-roomplan","role":"sampleCode","abstract":[{"type":"text","text":"Join us for an exciting update to RoomPlan as we explore MultiRoom support and enhancements to room representations. Learn how you can scan areas with more detail, capture multiple rooms, and merge individual scans into one larger structure. We’ll also share workflows and best practices when working with RoomPlan results that you want to combine into your existing 3D model library."}],"title":"Explore enhancements to RoomPlan","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10192-Explore-enhancements-to-RoomPlan","type":"topic","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10248-Analyze-hangs-with-Instruments":{"title":"Analyze hangs with Instruments","type":"topic","abstract":[{"text":"User interface elements often mimic real-world interactions, including real-time responses. Apps with a noticeable delay in user interaction — a hang — can break that illusion and create frustration. We’ll show you how to use Instruments to analyze, understand, and fix hangs in your apps on all Apple platforms. Discover how you can efficiently navigate an Instruments trace document, interpret trace data, and record additional profiling data to better understand your specific hang.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10248-analyze-hangs-with-instruments","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10248-Analyze-hangs-with-Instruments","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10161-Inspectors-in-SwiftUI-Discover-the-details":{"url":"\/documentation\/wwdcnotes\/wwdc23-10161-inspectors-in-swiftui-discover-the-details","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10161-Inspectors-in-SwiftUI-Discover-the-details","kind":"article","title":"Inspectors in SwiftUI: Discover the details","abstract":[{"text":"Meet Inspectors — a structural API that can help bring a new level of detail to your apps. We’ll take you through the fundamentals of the API and show you how to adopt it. Learn about the latest updates to sheet presentation customizations and find out how you can combine the two to create perfect presentation experiences.","type":"text"}],"type":"topic","role":"sampleCode"},"WWDC23-10202-geometryModifiers11":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers11.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers11"},"WWDC23-10202-yosemiteModel5":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-yosemiteModel5.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-yosemiteModel5"},"WWDC23-10202-geometryModifiers12":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers12.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers12"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10154-Build-an-app-with-SwiftData":{"url":"\/documentation\/wwdcnotes\/wwdc23-10154-build-an-app-with-swiftdata","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10154-Build-an-app-with-SwiftData","kind":"article","title":"Build an app with SwiftData","abstract":[{"text":"Discover how SwiftData can help you persist data in your app. Code along with us as we bring SwiftData to a multi-platform SwiftUI app. Learn how to convert existing model classes into SwiftData models, set up the environment, reflect model layer changes in UI, and build document-based applications backed by SwiftData storage.","type":"text"}],"type":"topic","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10016-Build-custom-workouts-with-WorkoutKit":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10016-build-custom-workouts-with-workoutkit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10016-Build-custom-workouts-with-WorkoutKit","kind":"article","abstract":[{"text":"WorkoutKit makes it easy to create, preview, and schedule planned workouts for the Workout app on Apple Watch. Learn how to build custom intervals, create alerts, and use the built-in preview UI to send your own workout routines to Apple Watch.","type":"text"}],"title":"Build custom workouts with WorkoutKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10170-Beyond-the-basics-of-structured-concurrency":{"url":"\/documentation\/wwdcnotes\/wwdc23-10170-beyond-the-basics-of-structured-concurrency","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10170-Beyond-the-basics-of-structured-concurrency","kind":"article","title":"Beyond the basics of structured concurrency","abstract":[{"text":"It’s all about the task tree: Find out how structured concurrency can help your apps manage automatic task cancellation, task priority propagation, and useful task-local value patterns. Learn how to manage resources in your app with useful patterns and the latest task group APIs. We’ll show you how you can leverage the power of the task tree and task-local values to gain insight into distributed systems.","type":"text"}],"type":"topic","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10203-Develop-your-first-immersive-app":{"kind":"article","title":"Develop your first immersive app","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10203-develop-your-first-immersive-app","abstract":[{"text":"Find out how you can build immersive apps for visionOS using Xcode and Reality Composer Pro. We’ll show you how to get started with a new visionOS project, use Xcode Previews for your SwiftUI development, and take advantage of RealityKit and RealityView to render 3D content.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10085-Discover-Quick-Look-for-spatial-computing":{"abstract":[{"type":"text","text":"Learn how to use Quick Look on visionOS to add powerful previews for 3D content, spatial images and videos, and much more. We’ll show you the different ways that the system presents these experiences, demonstrate how someone can drag and drop Quick Look content from an app or website to create a separate window with that content, and explore how you can present Quick Look directly within an app."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10085-discover-quick-look-for-spatial-computing","title":"Discover Quick Look for spatial computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10085-Discover-Quick-Look-for-spatial-computing","type":"topic","kind":"article","role":"sampleCode"},"https://developer.apple.com/videos/play/wwdc2023/10202?time=826":{"titleInlineContent":[{"type":"text","text":"13:46"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=826","title":"13:46","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202?time=826"},"WWDC23-10202-geometryModifiers3":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers3.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers3"},"WWDC23-10202-geometryModifiers9":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers9.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers9"},"WWDC23-10202-whatAreMaterials":{"alt":"What Are Materials","type":"image","variants":[{"url":"\/images\/WWDC23-10202-whatAreMaterials.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-whatAreMaterials"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10167-Expand-on-Swift-macros":{"url":"\/documentation\/wwdcnotes\/wwdc23-10167-expand-on-swift-macros","abstract":[{"type":"text","text":"Discover how Swift macros can help you reduce boilerplate in your codebase and adopt complex features more easily. Learn how macros can analyze code, emit rich compiler errors to guide developers towards correct usage, and generate new code that is automatically incorporated back into your project. We’ll also take you through important concepts like macro roles, compiler plugins, and syntax trees."}],"type":"topic","title":"Expand on Swift macros","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10167-Expand-on-Swift-macros","role":"sampleCode","kind":"article"},"WWDC23-10202-nodeGraphs12":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs12.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs12"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10239-Add-SharePlay-to-your-app":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10239-Add-SharePlay-to-your-app","url":"\/documentation\/wwdcnotes\/wwdc23-10239-add-shareplay-to-your-app","abstract":[{"text":"Discover how your app can take advantage of SharePlay to turn any activity into a shareable experience with friends! We’ll share the latest updates to SharePlay, explore the benefits of creating shared activities, dive into some exciting use cases, and take you through best practices to create engaging and fun moments of connection in your app.","type":"text"}],"title":"Add SharePlay to your app","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-geometryModifiers16":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers16.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers16"},"WWDC23-10202-nodeGraphs11":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs11.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs11"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10128-Your-guide-to-Metal-ray-tracing":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10128-your-guide-to-metal-ray-tracing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10128-Your-guide-to-Metal-ray-tracing","kind":"article","abstract":[{"text":"Discover how you can enhance the visual quality of your games and apps with Metal ray tracing. We’ll take you through the fundamentals of the Metal ray tracing API. Explore the latest enhancements and techniques that will enable you to create larger and more complex scenes, reduce memory usage and build times, and efficiently render visual content like hair and fur.","type":"text"}],"title":"Your guide to Metal ray tracing"},"WWDC23-10202-shaders":{"alt":"shaders","type":"image","variants":[{"url":"\/images\/WWDC23-10202-shaders.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-shaders"},"WWDC23-10202-geometryModifiers13":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers13.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers13"},"WWDC23-10202-geometryModifiers15":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers15.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers15"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10162-The-SwiftUI-cookbook-for-focus":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10162-The-SwiftUI-cookbook-for-focus","url":"\/documentation\/wwdcnotes\/wwdc23-10162-the-swiftui-cookbook-for-focus","abstract":[{"text":"The SwiftUI team is back in the coding “kitchen” with powerful tools to shape your app’s focus experience. Join us and learn about the staple ingredients that support focus-driven interactions in your app. Discover focus interactions for custom views, find out about key-press handlers for keyboard input, and learn how to support movement and hierarchy with focus sections. We’ll also go through some tasty recipes for common focus patterns in your app.","type":"text"}],"title":"The SwiftUI cookbook for focus","kind":"article","role":"sampleCode","type":"topic"},"WWDC23-10202-nodeGraphs3":{"alt":"the Yosemite Valley model","type":"image","variants":[{"url":"\/images\/WWDC23-10202-nodeGraphs3.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-nodeGraphs3"},"WWDC23-10202-geometryModifiers17":{"alt":"Geometry modifiers","type":"image","variants":[{"url":"\/images\/WWDC23-10202-geometryModifiers17.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10202-geometryModifiers17"},"https://x.com/wrmultitudes":{"titleInlineContent":[{"type":"text","text":"X\/Twitter"}],"type":"link","url":"https:\/\/x.com\/wrmultitudes","title":"X\/Twitter","identifier":"https:\/\/x.com\/wrmultitudes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10275-Explore-AirPlay-with-interstitials":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10275-explore-airplay-with-interstitials","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10275-Explore-AirPlay-with-interstitials","kind":"article","abstract":[{"text":"Learn how you can use HLS Interstitials with AirPlay to create seamless transitions for your video content between advertisements. We’ll share best practices and tips for creating a great experience when sharing content from Apple devices to popular smart TVs.","type":"text"}],"title":"Explore AirPlay with interstitials"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10142-Explore-testing-inapp-purchases":{"url":"\/documentation\/wwdcnotes\/wwdc23-10142-explore-testing-inapp-purchases","role":"sampleCode","abstract":[{"type":"text","text":"Learn how you can test in-app purchases throughout development with StoreKit Testing in Xcode, App Store sandbox, and TestFlight. Explore how each tool functions and how you can combine them to build the right workflow for testing your apps and games. We’ll also share a sneak preview of how you can test Family Sharing for in-app purchases & subscriptions in the App Store sandbox."}],"title":"Explore testing in-app purchases","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10142-Explore-testing-inapp-purchases","type":"topic","kind":"article"}}}