{"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10101-Customize-ondevice-speech-recognition","interfaceLanguage":"swift"},"kind":"article","metadata":{"roleHeading":"WWDC23","role":"sampleCode","title":"Customize on-device speech recognition","modules":[{"name":"WWDC Notes"}]},"abstract":[{"type":"text","text":"Find out how you can improve on-device speech recognition in your app by customizing the underlying model with additional vocabulary. We‚Äôll share how speech recognition works on device and show you how to boost specific words and phrases for more predictable transcription. Learn how you can provide specific pronunciations for words and use template support to quickly generate a full set of custom phrases ‚Äî all at runtime."}],"primaryContentSections":[{"kind":"content","content":[{"level":2,"anchor":"overview","text":"Overview","type":"heading"},{"inlineContent":[{"type":"text","text":"For more on the Speech framework, check out ‚ÄúAdvances in Speech Recognition‚Äù from WWDC19."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}],"type":"paragraph"},{"inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","isActive":true,"type":"reference"}],"type":"paragraph"},{"level":2,"anchor":"Written-By","text":"Written By","type":"heading"},{"columns":[{"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4"}]}],"size":1},{"content":[{"anchor":"To-Do<doc<replace-this-with-your-GitHub-handle>>","level":3,"text":"[To Do](<doc:<replace this with your GitHub handle>>)","type":"heading"},{"inlineContent":[{"type":"text","text":"An amazing developer."}],"type":"paragraph"},{"inlineContent":[{"text":"[Contributed Notes](<doc:","type":"text"},{"text":">)","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/x.com\/Jeehut","isActive":true,"type":"reference"}],"type":"paragraph"}],"size":4}],"numberOfColumns":5,"type":"row"},{"level":2,"anchor":"Related-Sessions","text":"Related Sessions","type":"heading"},{"style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-256-Advances-in-Speech-Recognition"],"type":"links"},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Legal Notice"}]}],"type":"small"},{"inlineContent":[{"type":"text","text":"All content copyright ¬© 2012 ‚Äì 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}]}],"sections":[],"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"type":"reference","overridingTitle":"Watch Video","identifier":"https:\/\/developer.apple.com\/wwdc23\/10101"}},"schemaVersion":{"major":0,"minor":3,"patch":0},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-10101-customize-ondevice-speech-recognition"]}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes"]]},"references":{"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"type":"topic","role":"collection","url":"\/documentation\/wwdcnotes","title":"WWDC Notes","kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}]},"https://developer.apple.com/wwdc23/10101":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10101","type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc23\/10101"},"https://avatars.githubusercontent.com/u/123?v=4":{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4","type":"image","alt":"Profile image of To Do","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-256-Advances-in-Speech-Recognition":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-256-Advances-in-Speech-Recognition","kind":"article","type":"topic","abstract":[{"type":"text","text":"Speech Recognizer can now be used locally on iOS or macOS devices with no network connection. Learn how you can bring text-to-speech support to your app while maintaining privacy and eliminating the limitations of server-based processing. Speech recognition API has also been enhanced to provide richer analytics including speaking rate, pause duration, and voice quality."}],"title":"Advances in Speech Recognition","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-256-advances-in-speech-recognition"},"https://x.com/Jeehut":{"identifier":"https:\/\/x.com\/Jeehut","titleInlineContent":[{"type":"text","text":"X\/Twitter"}],"type":"link","title":"X\/Twitter","url":"https:\/\/x.com\/Jeehut"},"WWDCNotes.png":{"identifier":"WWDCNotes.png","type":"image","alt":null,"variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}]},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}],"type":"link","title":"Learn More‚Ä¶","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"}}}