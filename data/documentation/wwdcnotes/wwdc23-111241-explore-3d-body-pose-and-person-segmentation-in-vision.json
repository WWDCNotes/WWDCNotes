{"sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes"]]},"kind":"article","variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-111241-explore-3d-body-pose-and-person-segmentation-in-vision"],"traits":[{"interfaceLanguage":"swift"}]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","interfaceLanguage":"swift"},"abstract":[{"text":"Discover how to build person-centric features with Vision. Learn how to detect human body poses and measure individual joint locations in 3D space. We‚Äôll also show you how to take advantage of person segmentation APIs to distinguish and segment up to four individuals in an image.","type":"text"}],"primaryContentSections":[{"content":[{"anchor":"overview","text":"Overview","level":2,"type":"heading"},{"inlineContent":[{"type":"text","text":"To learn more about the latest features in Vision, check out ‚ÄúDetect animal poses in Vision‚Äù from WWDC23."}],"type":"paragraph"},{"inlineContent":[{"text":"üò± ‚ÄúNo Overview Available!‚Äù","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","isActive":true,"type":"reference"}],"type":"paragraph"},{"anchor":"Written-By","text":"Written By","level":2,"type":"heading"},{"numberOfColumns":5,"columns":[{"size":1,"content":[{"inlineContent":[{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4","type":"image"}],"type":"paragraph"}]},{"size":4,"content":[{"level":3,"text":"[To Do](<doc:<replace this with your GitHub handle>>)","type":"heading","anchor":"To-Do<doc<replace-this-with-your-GitHub-handle>>"},{"type":"paragraph","inlineContent":[{"type":"text","text":"An amazing developer."}]},{"type":"paragraph","inlineContent":[{"text":"[Contributed Notes](<doc:","type":"text"},{"text":">)","type":"text"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/x.com\/Jeehut"}]}]}],"type":"row"},{"anchor":"Related-Sessions","text":"Related Sessions","level":2,"type":"heading"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10176-Lift-subjects-from-images-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110429-Discover-advancements-in-iOS-camera-capture-Depth-focus-and-multitasking","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10653-Detect-Body-and-Hand-Pose-with-Vision"],"style":"list","type":"links"},{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}],"type":"small"},{"inlineContent":[{"type":"text","text":"All content copyright ¬© 2012 ‚Äì 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}],"kind":"content"}],"metadata":{"modules":[{"name":"WWDC Notes"}],"role":"sampleCode","title":"Explore 3D body pose and person segmentation in Vision","roleHeading":"WWDC23"},"sampleCodeDownload":{"action":{"overridingTitle":"Watch Video","isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc23\/111241"},"kind":"sampleDownload"},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10653-Detect-Body-and-Hand-Pose-with-Vision":{"abstract":[{"type":"text","text":"Explore how the Vision framework can help your app detect body and hand poses in photos and video. With pose detection, your app can analyze the poses, movements, and gestures of people to offer new video editing possibilities, or to perform action classification when paired with an action classifier built in Create ML. And we‚Äôll show you how you can bring gesture recognition into your app through hand pose, delivering a whole new form of interaction."}],"url":"\/documentation\/wwdcnotes\/wwdc20-10653-detect-body-and-hand-pose-with-vision","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10653-Detect-Body-and-Hand-Pose-with-Vision","title":"Detect Body and Hand Pose with Vision","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110429-Discover-advancements-in-iOS-camera-capture-Depth-focus-and-multitasking":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110429-Discover-advancements-in-iOS-camera-capture-Depth-focus-and-multitasking","role":"sampleCode","title":"Discover advancements in iOS camera capture: Depth, focus, and multitasking","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc22-110429-discover-advancements-in-ios-camera-capture-depth-focus-and-multitasking","abstract":[{"type":"text","text":"Discover how you can take advantage of advanced camera capture features in your app. We‚Äôll show you how to use the LiDAR scanner to create photo and video effects and perform accurate depth measurement. Learn how your app can use the camera for picture-in-picture or multitasking, control face-driven autofocus and autoexposure during camera capture, and more. We‚Äôll also share strategies for using multiple video outputs so that you can optimize live preview while capturing high-quality video output."}],"kind":"article"},"WWDCNotes.png":{"alt":null,"type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"identifier":"WWDCNotes.png"},"https://avatars.githubusercontent.com/u/123?v=4":{"alt":"Profile image of To Do","type":"image","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4","traits":["1x","light"]}],"identifier":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10176-Lift-subjects-from-images-in-your-app":{"title":"Lift subjects from images in your app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10176-Lift-subjects-from-images-in-your-app","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10176-lift-subjects-from-images-in-your-app","abstract":[{"text":"Discover how you can easily pull the subject of an image from its background in your apps. Learn how to lift the primary subject or to access the subject at a given point with VisionKit. We‚Äôll also share how you can lift subjects using Vision and combine that with lower-level frameworks like Core Image to create fun image effects and more complex compositing pipelines.","type":"text"}],"role":"sampleCode"},"https://developer.apple.com/wwdc23/111241":{"checksum":null,"type":"download","url":"https:\/\/developer.apple.com\/wwdc23\/111241","identifier":"https:\/\/developer.apple.com\/wwdc23\/111241"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"text":"Learn More‚Ä¶","type":"text"}],"type":"link","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10045-Detect-animal-poses-in-Vision":{"role":"sampleCode","title":"Detect animal poses in Vision","abstract":[{"type":"text","text":"Go beyond detecting cats and dogs in images. We‚Äôll show you how to use Vision to detect the individual joints and poses of these animals as well ‚Äî all in real time ‚Äî and share how you can enable exciting features like animal tracking for a camera app, creative embellishment on an animal photo, and more. We‚Äôll also explore other important enhancements to Vision and share best practices."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10045-detect-animal-poses-in-vision","type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision"},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"type":"topic","role":"collection","url":"\/documentation\/wwdcnotes","title":"WWDC Notes","kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}]},"https://x.com/Jeehut":{"titleInlineContent":[{"text":"X\/Twitter","type":"text"}],"type":"link","url":"https:\/\/x.com\/Jeehut","identifier":"https:\/\/x.com\/Jeehut","title":"X\/Twitter"}}}