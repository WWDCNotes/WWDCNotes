{"kind":"article","primaryContentSections":[{"content":[{"type":"heading","level":2,"anchor":"overview","text":"Overview"},{"inlineContent":[{"text":"üò± ‚ÄúNo Overview Available!‚Äù","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}],"type":"paragraph"},{"type":"heading","level":2,"anchor":"Related-Sessions","text":"Related Sessions"},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10020-Compose-advanced-models-with-Create-ML-Components","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10039-Classify-hand-poses-and-actions-with-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10099-Explore-the-Action-and-Vision-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10156-Control-training-in-Create-ML-with-Swift","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10653-Detect-Body-and-Hand-Pose-with-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-430-Introducing-the-Create-ML-App"],"style":"list"}],"kind":"content"}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2020\/10043","overridingTitle":"Watch Video (26 min)"}},"metadata":{"role":"sampleCode","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC20","title":"Build an Action Classifier with Create ML"},"sections":[],"abstract":[{"text":"Discover how to build Action Classification models in Create ML. With a custom action classifier, your app can recognize and understand body movements in real-time from videos or through a camera. We‚Äôll show you how to use samples to easily train a Core ML model to identify human actions like jumping jacks, squats, and dance moves. Learn how this is powered by the Body Pose estimation features of the Vision Framework. Get inspired to create apps that can provide coaching for fitness routines, deliver feedback on athletic form, and more.","type":"text"}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc20-10043-build-an-action-classifier-with-create-ml"]}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20"]]},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10043-Build-an-Action-Classifier-with-Create-ML"},"schemaVersion":{"minor":3,"major":0,"patch":0},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10099-Explore-the-Action-and-Vision-app":{"abstract":[{"type":"text","text":"It‚Äôs now easy to create an app for fitness or sports coaching that takes advantage of machine learning¬†‚Äî¬†and to prove it, we built our own. Learn how we designed the Action & Vision app using Object Detection and Action Classification in Create ML along with the new Body Pose Estimation, Trajectory Detection, and Contour Detection features in the Vision framework. Explore how you can create an immersive application for gameplay or training from setup to analysis and feedback. And follow along in Xcode with a full sample project."}],"url":"\/documentation\/wwdcnotes\/wwdc20-10099-explore-the-action-and-vision-app","type":"topic","role":"sampleCode","kind":"article","title":"Explore the Action & Vision app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10099-Explore-the-Action-and-Vision-app"},"WWDC20-Icon.png":{"alt":null,"identifier":"WWDC20-Icon.png","type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC20-Icon.png"}]},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"title":"Learn More‚Ä¶","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10020-Compose-advanced-models-with-Create-ML-Components":{"kind":"article","type":"topic","abstract":[{"text":"Take your custom machine learning models to the next level with Create ML Components. We‚Äôll show you how to work with temporal data like video or audio and compose models that can count repetitive human actions or provide advanced sound classification. We‚Äôll also share best practices on using incremental fitting to speed up model training with new data.","type":"text"}],"title":"Compose advanced models with Create ML Components","url":"\/documentation\/wwdcnotes\/wwdc22-10020-compose-advanced-models-with-create-ml-components","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10020-Compose-advanced-models-with-Create-ML-Components","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10039-Classify-hand-poses-and-actions-with-Create-ML":{"kind":"article","type":"topic","title":"Classify hand poses and actions with Create ML","abstract":[{"text":"With Create ML, your app‚Äôs ability to understand the expressiveness of the human hand has never been easier. Discover how you can build off the support for Hand Pose Detection in Vision and train custom Hand Pose and Hand Action classifiers using the Create ML app and framework. Learn how simple it is to collect data, train a model, and integrate it with Vision, Camera, and ARKit to create a fun, entertaining app experience.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10039-Classify-hand-poses-and-actions-with-Create-ML","url":"\/documentation\/wwdcnotes\/wwdc21-10039-classify-hand-poses-and-actions-with-create-ml","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes":{"images":[{"identifier":"WWDCNotes.png","type":"icon"}],"title":"WWDC Notes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","kind":"symbol","type":"topic","url":"\/documentation\/wwdcnotes","role":"collection"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-430-Introducing-the-Create-ML-App":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-430-Introducing-the-Create-ML-App","title":"Introducing the Create ML App","type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19-430-introducing-the-create-ml-app","abstract":[{"text":"Bringing the power of Core ML to your app begins with one challenge. How do you create your model? The new Create ML app provides an intuitive workflow for model creation. See how to train, evaluate, test, and preview your models quickly in this easy-to-use tool. Get started with one of the many available templates handling a number of powerful machine learning tasks. Learn more about the many features for continuous model improvement and experimentation.","type":"text"}],"role":"sampleCode"},"WWDC20.jpeg":{"identifier":"WWDC20.jpeg","alt":null,"type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDC20.jpeg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20":{"title":"WWDC20","kind":"article","abstract":[{"type":"text","text":"Xcode 12, Swift 5.3, iOS 14, macOS 11 (Big Sur), tvOS 14, watchOS 7."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"WidgetKit","type":"codeVoice"},{"type":"text","text":", "},{"code":"StoreKit Testing","type":"codeVoice"},{"type":"text","text":", and more."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20","images":[{"type":"icon","identifier":"WWDC20-Icon.png"},{"type":"card","identifier":"WWDC20.jpeg"}],"role":"collectionGroup","url":"\/documentation\/wwdcnotes\/wwdc20"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10653-Detect-Body-and-Hand-Pose-with-Vision":{"role":"sampleCode","title":"Detect Body and Hand Pose with Vision","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10653-Detect-Body-and-Hand-Pose-with-Vision","url":"\/documentation\/wwdcnotes\/wwdc20-10653-detect-body-and-hand-pose-with-vision","kind":"article","abstract":[{"type":"text","text":"Explore how the Vision framework can help your app detect body and hand poses in photos and video. With pose detection, your app can analyze the poses, movements, and gestures of people to offer new video editing possibilities, or to perform action classification when paired with an action classifier built in Create ML. And we‚Äôll show you how you can bring gesture recognition into your app through hand pose, delivering a whole new form of interaction."}]},"https://developer.apple.com/videos/play/wwdc2020/10043":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2020\/10043","checksum":null,"type":"download","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2020\/10043"},"WWDCNotes.png":{"alt":null,"variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"type":"image","identifier":"WWDCNotes.png"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10156-Control-training-in-Create-ML-with-Swift":{"title":"Control training in Create ML with Swift","kind":"article","abstract":[{"text":"With the Create ML framework you have more power than ever to easily develop models and automate workflows. We‚Äôll show you how to explore and interact with your machine learning models while you train them, helping you get a better model quickly. Discover how training control in Create ML can customize your training workflow with checkpointing APIs to pause, save, resume, and extend your training process. And find out how you can monitor your progress programmatically using Combine APIs.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10156-Control-training-in-Create-ML-with-Swift","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc20-10156-control-training-in-create-ml-with-swift"}}}