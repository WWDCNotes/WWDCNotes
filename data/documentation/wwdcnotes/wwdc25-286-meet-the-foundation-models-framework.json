{"sampleCodeDownload":{"action":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/286","isActive":true,"overridingTitle":"Watch Video (23 min)","type":"reference"},"kind":"sampleDownload"},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25"]]},"sections":[],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-286-Meet-the-Foundation-Models-framework"},"kind":"article","schemaVersion":{"major":0,"minor":3,"patch":0},"metadata":{"role":"sampleCode","modules":[{"name":"WWDC Notes"}],"title":"Meet the Foundation Models framework","roleHeading":"WWDC25"},"abstract":[{"text":"Learn how to tap into the on-device large language model behind Apple Intelligence! This high-level overview covers everything from guided generation for generating Swift data structures and streaming for responsive experiences, to tool calling for integrating data sources and sessions for context management. This session has no prerequisites.","type":"text"}],"primaryContentSections":[{"content":[{"text":"Key Takeaways","level":2,"anchor":"Key-Takeaways","type":"heading"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"üß† Built-in small on-device LLM model for general use","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"‚ö° Great for summarization, classification, tagging etc.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"üéØ ‚ÄúGuided generation‚Äù can use data provided by your app","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"üåä Partial results streamed as full (generated) Swift type","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"üè∑Ô∏è Specialized ‚Äúcontent tagging‚Äù adapter available (more later)"}]}]}]},{"columns":[{"content":[{"inlineContent":[{"type":"image","identifier":"WWDC25-286-Feature-Overview"}],"type":"paragraph"}],"size":1},{"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC25-286-Snapshots"}]}],"size":1}],"type":"row","numberOfColumns":2},{"columns":[{"content":[{"inlineContent":[{"type":"image","identifier":"WWDC25-286-Tool-Calling-How-It-Works"}],"type":"paragraph"}],"size":1},{"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC25-286-Tool-Output"}]}],"size":1}],"type":"row","numberOfColumns":2},{"text":"The model","level":2,"anchor":"The-model","type":"heading"},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC25-286-Prompting-Playground"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Optimize your prompt within Xcode using the ","type":"text"},{"type":"codeVoice","code":"#Playground"},{"text":" macro","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Model is an LLM with 3 billion parameters each quantized to 2 bits"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"(Author note: According to Claude this would be a small model about 750 MB in size)"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"It‚Äôs not designed for world knowledge or advanced reasoning"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Built for: Summarization, Extraction, Classification, Tagging, Composition, Revision"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"For special uses such as content tagging, specialized adapters should be used"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Continuous improvement over time based on developer feedback","type":"text"}]}]}]},{"text":"Guided generation","level":2,"anchor":"Guided-generation","type":"heading"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"By default, the output is unstructured natural language text","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Do not specify your desired output (like JSON) in the prompt"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use the "},{"type":"codeVoice","code":"@Generable"},{"type":"text","text":" macro to mark types you want to generate"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use the "},{"code":"@Guide(description:)","type":"codeVoice"},{"type":"text","text":" macro to describe & programmatically define possible values"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"For example specify an output type like so:"}]},{"code":["\/\/ Creating a Generable struct","@Generable","struct SearchSuggestions {","   @Guide (description: \"A list of suggested search terms\", .count(4))","   var searchTerms: [String]","}"],"syntax":"swift","type":"codeListing"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Then specify it as the "},{"type":"codeVoice","code":"generating"},{"type":"text","text":" type:"}]},{"code":["\/\/ Responding with a Generable type","let prompt = \"Generate a list of suggested search terms for an app about visiting famous landmarks.\"","let response = try await session.respond(to: prompt, generating: SearchSuggestions.self)","","print(response.content)","\/\/ SearchSuggestions(searchTerms: [\"Hot springs\", \"Watery wonders\", ...])"],"syntax":"swift","type":"codeListing"},{"type":"paragraph","inlineContent":[{"text":"Supported property types to be ","type":"text"},{"type":"codeVoice","code":"@Generable"},{"text":":","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"String"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Int","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Float","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Double"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Bool","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"[String]","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"any type that is also "},{"type":"codeVoice","code":"@Generable"},{"type":"text","text":" (for relationships)"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"arrays of any type that is also ","type":"text"},{"type":"codeVoice","code":"@Generable"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"recursive types also supported"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Example of a "},{"type":"codeVoice","code":"@Generable"},{"type":"text","text":" type showcasing all supported types:"}]},{"code":["@Generable","struct Itinerary {","   var destination: String","   var days: Int","   var budget: Float","   var rating: Double","   var requiresVisa: Bool","   var activities: [String]","   var emergencyContact: Person","   var relatedItineraries: [Itinerary]","}"],"syntax":"swift","type":"codeListing"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"You‚Äôre guaranteed to get structural correctness (‚Äúconstrained coding‚Äù)","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Helps the model to provide more accurate and faster results","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"text":"Learn more: ","type":"text"},{"isActive":true,"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-301-Deep-dive-into-the-Foundation-Models-framework"}]},{"text":"Snapshot streaming","level":2,"anchor":"Snapshot-streaming","type":"heading"},{"type":"paragraph","inlineContent":[{"text":"Rather than providing tokens (= partial words) during generation (like other LLMs), the Foundation models provide partial snapshots of the requested output type:","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC25-286-Snapshots"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Possible because "},{"type":"codeVoice","code":"@Generable"},{"type":"text","text":" macro produces a subtype "},{"type":"codeVoice","code":"PartiallyGenerated"},{"type":"text","text":" with all Optional fields"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"More robust and convenient representation of ‚Äústreaming output‚Äù than string tokens"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The "},{"type":"codeVoice","code":"PartiallyGenerated"},{"type":"text","text":" is what you get upon calling "},{"type":"codeVoice","code":"streamResponse(to:)"},{"type":"text","text":" (instead of "},{"type":"codeVoice","code":"respond(to:)"},{"type":"text","text":")"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Returns an "},{"type":"codeVoice","code":"AsyncSequence"},{"type":"text","text":" you can easily iterate over using "},{"type":"codeVoice","code":"for await"}],"type":"paragraph"}]}]},{"code":["let stream = session.streamResponse(to: \"Your prompt\", generating: Itinerary.self)","for try await partial in stream {","   print(partial)","   \/\/ => Itinerary.PartiallyGenerated(name: nil, days: nil)","   \/\/ => Itinerary.PartiallyGenerated(name: \"Mt.\", days: nil)","   \/\/ => Itinerary.PartiallyGenerated(name: \"Mt. Fuji\", days: nil)","   \/\/ => Itinerary.PartiallyGenerated(name: \"Mt. Fuji\", days: [])","   \/\/ => Itinerary.PartiallyGenerated(name: \"Mt. Fuji\", days: [Day.PartiallyGenerated(...)])","}"],"syntax":"swift","type":"codeListing"},{"text":"Best Practices for Streaming","level":3,"anchor":"Best-Practices-for-Streaming","type":"heading"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Use SwiftUI animations & transitions to hide latency (turn waiting into delight)","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Think carefully about view identity (especially when working with arrays)"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Property order matters for both the straming UI and model output quality","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Put more contextual fields that need data from other fields towards the end (e.g. ","type":"text"},{"type":"codeVoice","code":"summary"},{"text":")","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Learn more: "},{"type":"reference","isActive":true,"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-259-Codealong-Bring-ondevice-AI-to-your-app-using-the-Foundation-Models-framework"}]},{"text":"Tool calling","level":2,"anchor":"Tool-calling","type":"heading"},{"text":"Why you want to use it","level":3,"anchor":"Why-you-want-to-use-it","type":"heading"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Can do more, like identifying when more info\/action needed or deciding on tool usage"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Provide model with world knowledge, recent events, or personal data","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Gives model ability to cite sources to prevent hallucination by fact-checking"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Allows model to take actions in your app, the system, or the real world","type":"text"}],"type":"paragraph"}]}]},{"text":"How it works","level":3,"anchor":"How-it-works","type":"heading"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"You define tools with instructions, then pass a prompt","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"The model checks if any tool calls are needed and executes them","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Your tools produce output that is feeded back to the model"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Model combines tool output along with everything else for final response"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC25-286-Tool-Calling-How-It-Works","type":"image"}]},{"text":"Defining a tool","level":3,"anchor":"Defining-a-tool","type":"heading"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Define a type conforming to the "},{"type":"codeVoice","code":"Tool"},{"type":"text","text":" protocol, which requires "},{"type":"codeVoice","code":"name"},{"type":"text","text":" and "},{"type":"codeVoice","code":"description"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Implement the function ","type":"text"},{"code":"call(arguments:) async throws -> ToolOutput","type":"codeVoice"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The "},{"type":"codeVoice","code":"arguments"},{"type":"text","text":" parameter can be any "},{"type":"codeVoice","code":"@Generable"},{"type":"text","text":" type of your choice"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Initialize & return a "},{"type":"codeVoice","code":"ToolOutput"},{"type":"text","text":" which accepts either a "},{"type":"codeVoice","code":"String"},{"type":"text","text":" or "},{"type":"codeVoice","code":"GeneratedContent"},{"type":"text","text":" (dictionary)"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC25-286-Tool-Output","type":"image"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Tools must be passed upon initializing a "},{"code":"LanguageModelSession","type":"codeVoice"}]}]},{"content":[{"inlineContent":[{"text":"The session will autonomously use tools where needed, just use ","type":"text"},{"code":"session.respond(to:)","type":"codeVoice"},{"text":" like normal","type":"text"}],"type":"paragraph"}]}]},{"text":"Dynamic tools","level":3,"anchor":"Dynamic-tools","type":"heading"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use these for runtime-defined behaviors, with dynamic schema & parameterized names\/descriptions"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Learn more: "},{"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-301-Deep-dive-into-the-Foundation-Models-framework","isActive":true}]},{"text":"Stateful sessions","level":2,"anchor":"Stateful-sessions","type":"heading"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"By default new sessions prompt the general purpose model","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"You can pass "},{"type":"codeVoice","code":"instructions"},{"type":"text","text":" upon session initialization to provide the model its role"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"E.g. you could pass a response style or length restrictions as instructions","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Instructions should always come from the developer, not from the user (instructions get priority)"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"For security reasons, dont‚Äôt allow untrusted content in instructions"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Learn more: "},{"isActive":true,"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-248-Explore-prompt-design-and-safety-for-ondevice-foundation-models"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Past interactions are considered as part of the ‚Äútranscript‚Äù within a single session"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"You can access the "},{"type":"codeVoice","code":"transcript"},{"type":"text","text":" property on a session (e.g. to show in UI)"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use the "},{"code":"isResponding","type":"codeVoice"},{"type":"text","text":" property to prevent users from sending a new message while in progress"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Additional built-in specialized use-cases available as alternative models","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Pass to sessions‚Äô ","type":"text"},{"code":"model","type":"codeVoice"},{"text":" parameter, e.g.: ","type":"text"},{"code":"SystemLanguageModel(useCase: .contentTagging)","type":"codeVoice"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"More use cases may get added over time, check the docs: https:\/\/developer.apple.com\/documentation\/foundationmodels\/systemlanguagemodel\/usecase"}]},{"text":"Content tagging adapter","level":3,"anchor":"Content-tagging-adapter","type":"heading"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"First-class support for: Tag generation, entity extraction, and topic detection","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"By default trained to output topic tags, integrates with guided generation out-of-the-box:"}]}]}]},{"code":["@Generable","struct Result {","   let topics: [String]","}","","let session = LanguageModelSession(model: SystemLanguageModel(useCase: .contentTagging))","let response = try await session.respond(to: ..., generating: Result.self)"],"syntax":"swift","type":"codeListing"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"But you can specify custom "},{"type":"codeVoice","code":"@Generable"},{"type":"text","text":" types and custom instructions for detecting other things:"}],"type":"paragraph"}]}]},{"code":["@Generable","struct Top3ActionEmotionResult {","    @Guide(.maximumCount(3))","    let actions: [String]","    @Guide(.maximumCount(3))","    let emotions: [String]","}","","let session = LanguageModelSession(","    model: SystemLanguageModel(useCase: .contentTagging),","    instructions: \"Tag the 3 most important actions and emotions in the given input text.\"",")","let response = try await session.respond(to: ..., generating: Top3ActionEmotionResult.self)"],"syntax":"swift","type":"codeListing"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Make sure to check for availability as only supported by Apple Intelligence enabled devices:"}],"type":"paragraph"}]}]},{"code":["struct AvailabilityExample: View {","    private let model = SystemLanguageModel.default","","    var body: some View {","        switch model.availability {","        case .available:","            Text(\"Model is available\").foregroundStyle(.green)","        case .unavailable(let reason):","            Text(\"Model is unavailable\").foregroundStyle(.red)","            Text(\"Reason: \\(reason)\")","        }","    }","}"],"syntax":"swift","type":"codeListing"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Possible errors for requests: Guardrail violation, unsupported lanugage, context window exceeded"}]}]}]},{"text":"Developer experience","level":2,"anchor":"Developer-experience","type":"heading"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Keep in mind that LLMs are slower than traditional ML models","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"You can quantify delays in instruments to optimize your prompts"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Provide unexpected responses using Feedback assistant (choose ‚ÄúFoundation Models Framework‚Äù)"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Use the "},{"code":"LanguageModelFeedbackAttachment","type":"codeVoice"},{"type":"text","text":" type that conforms to "},{"code":"Encodable","type":"codeVoice"},{"type":"text","text":" to attach a JSON file"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"You can train your own adapter (but have to retrain with every Apple model update)","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"text":"Learn more about training your adapters in ","type":"text"},{"identifier":"https:\/\/developer.apple.com\/apple-intelligence\/foundation-models-adapter\/","isActive":true,"type":"reference"},{"text":".","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC25-286-Feature-Overview"}]},{"text":"Written By","level":2,"anchor":"Written-By","type":"heading"},{"columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"Jeehut"}]}]},{"size":4,"content":[{"level":3,"text":"Cihat G√ºnd√ºz","type":"heading","anchor":"Cihat-G%C3%BCnd%C3%BCz"},{"type":"paragraph","inlineContent":[{"overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"type":"reference","overridingTitle":"Contributed Notes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/Jeehut","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"https:\/\/github.com\/Jeehut","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"https:\/\/fline.dev","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"https:\/\/x.com\/Jeehut","isActive":true}]}]}],"type":"row","numberOfColumns":5},{"type":"thematicBreak"},{"type":"paragraph","inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}]},{"text":"Related Sessions","level":2,"anchor":"Related-Sessions","type":"heading"},{"style":"list","type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-360-Discover-machine-learning-and-AI-frameworks-on-Apple-platforms","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-248-Explore-prompt-design-and-safety-for-ondevice-foundation-models","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-259-Codealong-Bring-ondevice-AI-to-your-app-using-the-Foundation-Models-framework","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-301-Deep-dive-into-the-Foundation-Models-framework"]},{"type":"small","inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright ¬© 2012 ‚Äì 2025 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc25-286-meet-the-foundation-models-framework"],"traits":[{"interfaceLanguage":"swift"}]}],"references":{"WWDCNotes.png":{"variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"alt":null,"identifier":"WWDCNotes.png","type":"image"},"https://developer.apple.com/videos/play/wwdc2025/286":{"type":"download","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/286","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/286","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-360-Discover-machine-learning-and-AI-frameworks-on-Apple-platforms":{"abstract":[{"text":"Tour the latest updates to machine learning and AI frameworks available on Apple platforms. Whether you are an app developer ready to tap into Apple Intelligence, an ML engineer optimizing models for on-device deployment, or an AI enthusiast exploring the frontier of what is possible, we‚Äôll offer guidance to help select the right tools for your needs.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc25-360-discover-machine-learning-and-ai-frameworks-on-apple-platforms","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-360-Discover-machine-learning-and-AI-frameworks-on-Apple-platforms","type":"topic","kind":"article","role":"sampleCode","title":"Discover machine learning & AI frameworks on Apple platforms"},"WWDC25-286-Tool-Calling-How-It-Works":{"identifier":"WWDC25-286-Tool-Calling-How-It-Works","type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDC25-286-Tool-Calling-How-It-Works.jpeg","traits":["1x","light"]}],"alt":null},"WWDC25-286-Prompting-Playground":{"alt":null,"type":"image","identifier":"WWDC25-286-Prompting-Playground","variants":[{"url":"\/images\/WWDCNotes\/WWDC25-286-Prompting-Playground.jpeg","traits":["1x","light"]}]},"WWDC25-286-Tool-Output":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC25-286-Tool-Output.jpeg"}],"alt":null,"identifier":"WWDC25-286-Tool-Output","type":"image"},"Jeehut":{"identifier":"Jeehut","type":"image","variants":[{"url":"\/images\/WWDCNotes\/Jeehut.jpeg","traits":["1x","light"]}],"alt":"Profile image of Cihat G√ºnd√ºz"},"doc://WWDCNotes/documentation/WWDCNotes/Jeehut":{"title":"Cihat G√ºnd√ºz (66 notes)","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/jeehut","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/Jeehut","abstract":[{"text":"Spatial-first Indie Developer for Ô£ø Platforms. Actively contributing to Open Source since 2011!","type":"text"}],"images":[{"type":"card","identifier":"Jeehut.jpeg"},{"type":"icon","identifier":"Jeehut.jpeg"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-248-Explore-prompt-design-and-safety-for-ondevice-foundation-models":{"abstract":[{"type":"text","text":"Design generative AI experiences that leverage the strengths of the Foundation Models framework. We‚Äôll start by showing how to design prompts for the on-device large language model at the core of Apple Intelligence. Then, we‚Äôll introduce key ideas around AI safety, and offer concrete strategies to make your generative AI features safe, reliable, and delightful."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-248-Explore-prompt-design-and-safety-for-ondevice-foundation-models","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc25-248-explore-prompt-design-and-safety-for-ondevice-foundation-models","role":"sampleCode","title":"Explore prompt design & safety for on-device foundation models"},"WWDC25-Icon.png":{"alt":null,"type":"image","identifier":"WWDC25-Icon.png","variants":[{"url":"\/images\/WWDCNotes\/WWDC25-Icon.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-301-Deep-dive-into-the-Foundation-Models-framework":{"type":"topic","kind":"article","abstract":[{"text":"Level up with the Foundation Models framework. Learn how guided generation works under the hood, and use guides, regexes, and generation schemas to get custom structured responses. We‚Äôll show you how to use tool calling to let the model autonomously access external information and perform actions, for a personalized experience.","type":"text"}],"title":"Deep dive into the Foundation Models framework","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc25-301-deep-dive-into-the-foundation-models-framework","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-301-Deep-dive-into-the-Foundation-Models-framework"},"https://developer.apple.com/apple-intelligence/foundation-models-adapter/":{"title":"this developer article","url":"https:\/\/developer.apple.com\/apple-intelligence\/foundation-models-adapter\/","titleInlineContent":[{"text":"this developer article","type":"text"}],"identifier":"https:\/\/developer.apple.com\/apple-intelligence\/foundation-models-adapter\/","type":"link"},"https://github.com/Jeehut":{"identifier":"https:\/\/github.com\/Jeehut","type":"link","titleInlineContent":[{"type":"text","text":"GitHub"}],"title":"GitHub","url":"https:\/\/github.com\/Jeehut"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-259-Codealong-Bring-ondevice-AI-to-your-app-using-the-Foundation-Models-framework":{"role":"sampleCode","abstract":[{"type":"text","text":"Develop generative AI features for your SwiftUI apps using the Foundation Models framework. Get started by applying the basics of the framework to create an awesome feature. Watch step-by-step examples of how to complement the models with tools you build, stream results, and apply further optimizations for great performance."}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc25-259-codealong-bring-ondevice-ai-to-your-app-using-the-foundation-models-framework","title":"Code-along: Bring on-device AI to your app using the Foundation Models framework","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-259-Codealong-Bring-ondevice-AI-to-your-app-using-the-Foundation-Models-framework"},"https://x.com/Jeehut":{"type":"link","identifier":"https:\/\/x.com\/Jeehut","title":"X\/Twitter","titleInlineContent":[{"text":"X\/Twitter","type":"text"}],"url":"https:\/\/x.com\/Jeehut"},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","title":"WWDC Notes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"url":"\/documentation\/wwdcnotes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","type":"topic","role":"collection","images":[{"identifier":"WWDCNotes.png","type":"icon"}]},"https://fline.dev":{"title":"Blog","url":"https:\/\/fline.dev","titleInlineContent":[{"text":"Blog","type":"text"}],"identifier":"https:\/\/fline.dev","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25":{"abstract":[{"type":"text","text":"Xcode 26, Swift 6.2, iOS\/macOS\/tvOS\/visionOS 26."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"Foundation Models","type":"codeVoice"},{"type":"text","text":", "},{"code":"AlarmKit","type":"codeVoice"},{"type":"text","text":", "},{"code":"PermissionKit","type":"codeVoice"},{"type":"text","text":", and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25","url":"\/documentation\/wwdcnotes\/wwdc25","kind":"article","role":"collectionGroup","type":"topic","title":"WWDC25","images":[{"identifier":"WWDC25-Icon.png","type":"icon"},{"identifier":"WWDC25.jpg","type":"card"}]},"WWDC25-286-Feature-Overview":{"identifier":"WWDC25-286-Feature-Overview","type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDC25-286-Feature-Overview.jpeg","traits":["1x","light"]}],"alt":null},"Jeehut.jpeg":{"alt":null,"type":"image","identifier":"Jeehut.jpeg","variants":[{"url":"\/images\/WWDCNotes\/Jeehut.jpeg","traits":["1x","light"]}]},"WWDC25-286-Snapshots":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC25-286-Snapshots.jpeg"}],"alt":null,"identifier":"WWDC25-286-Snapshots","type":"image"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"WWDC25.jpg":{"alt":null,"type":"image","identifier":"WWDC25.jpg","variants":[{"url":"\/images\/WWDCNotes\/WWDC25.jpg","traits":["1x","light"]}]}}}