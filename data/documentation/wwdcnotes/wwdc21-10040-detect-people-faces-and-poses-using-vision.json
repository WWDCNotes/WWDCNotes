{"sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes"]]},"schemaVersion":{"major":0,"minor":3,"patch":0},"kind":"article","identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10040-Detect-people-faces-and-poses-using-Vision"},"abstract":[{"text":"Discover the latest updates to the Vision framework to help your apps detect people, faces, and poses. Meet the Person Segmentation API, which helps your app separate people in images from their surroundings, and explore the latest contiguous metrics for tracking pitch, yaw, and the roll of the human head. And learn how these capabilities can be combined with other APIs like Core Image to deliver anything from simple virtual backgrounds to rich offline compositing in an image-editing app.","type":"text"}],"primaryContentSections":[{"kind":"content","content":[{"type":"heading","level":2,"anchor":"overview","text":"Overview"},{"inlineContent":[{"text":"To get the most out of this session, we recommend watching ‚ÄúDetect Body and Hand Pose with Vision‚Äù from WWDC20 and ‚ÄúUnderstanding Images in Vision Framework‚Äù from WWDC19.","type":"text"},{"text":" ","type":"text"},{"text":"To learn even more about people analysis, see ‚ÄúDetect Body and Hand Pose with Vision‚Äù from WWDC20 and ‚ÄúUnderstanding Images in Vision Framework‚Äù from WWDC19.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:"},{"type":"text","text":" "},{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"reference","isActive":true}],"type":"paragraph"}]}],"metadata":{"roleHeading":"WWDC21","modules":[{"name":"WWDC Notes"}],"title":"Detect people, faces, and poses using Vision","role":"sampleCode"},"sampleCodeDownload":{"kind":"sampleDownload","action":{"identifier":"https:\/\/developer.apple.com\/wwdc21\/10040","overridingTitle":"Watch Video","type":"reference","isActive":true}},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc21-10040-detect-people-faces-and-poses-using-vision"]}],"references":{"WWDCNotes.png":{"identifier":"WWDCNotes.png","type":"image","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}]},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"title":"Learn More‚Ä¶","titleInlineContent":[{"text":"Learn More‚Ä¶","type":"text"}],"url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"link"},"https://developer.apple.com/wwdc21/10040":{"url":"https:\/\/developer.apple.com\/wwdc21\/10040","identifier":"https:\/\/developer.apple.com\/wwdc21\/10040","type":"download","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"type":"topic","role":"collection","url":"\/documentation\/wwdcnotes","title":"WWDC Notes","kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}]}}}