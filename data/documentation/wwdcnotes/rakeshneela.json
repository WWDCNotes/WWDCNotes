{"abstract":[{"text":"No Bio on GitHub","type":"text"}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/Contributors"]]},"primaryContentSections":[{"content":[{"text":"Links","anchor":"Links","level":2,"type":"heading"},{"items":[{"content":[{"inlineContent":[{"isActive":true,"type":"reference","identifier":"https:\/\/"}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Contributions","anchor":"Contributions","level":2,"type":"heading"},{"inlineContent":[{"text":"Contributed 1 session note in total. Their most active year was 2023.","type":"text"}],"type":"paragraph"},{"text":"2023","anchor":"2023","level":3,"type":"heading"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision"],"style":"list","type":"links"}],"kind":"content"}],"metadata":{"title":"Rakesh Neela (1 note)","roleHeading":"Contributors","images":[{"type":"card","identifier":"rakeshneela.jpeg"},{"type":"icon","identifier":"rakeshneela.jpeg"}],"modules":[{"name":"WWDC Notes"}],"role":"sampleCode"},"schemaVersion":{"patch":0,"major":0,"minor":3},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/rakeshneela"]}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/rakeshneela","interfaceLanguage":"swift"},"kind":"article","sections":[],"references":{"Contributors.jpeg":{"type":"image","alt":null,"variants":[{"url":"\/images\/Contributors.jpeg","traits":["1x","light"]}],"identifier":"Contributors.jpeg"},"rakeshneela.jpeg":{"type":"image","alt":null,"variants":[{"url":"\/images\/rakeshneela.jpeg","traits":["1x","light"]}],"identifier":"rakeshneela.jpeg"},"doc://WWDCNotes/documentation/WWDCNotes":{"title":"WWDC Notes","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"role":"collection","type":"topic","kind":"symbol","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","url":"\/documentation\/wwdcnotes"},"doc://WWDCNotes/documentation/WWDCNotes/Contributors":{"title":"Contributors","images":[{"identifier":"WWDCNotes.png","type":"icon"},{"identifier":"Contributors.jpeg","type":"card"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/Contributors","url":"\/documentation\/wwdcnotes\/contributors","abstract":[{"type":"text","text":"WWDCNotes is only possible thanks to these awesome volunteers! Contribute now to get listed here as well."}],"role":"article","type":"topic","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","abstract":[{"type":"text","text":"Discover how to build person-centric features with Vision. Learn how to detect human body poses and measure individual joint locations in 3D space. Weâ€™ll also show you how to take advantage of person segmentation APIs to distinguish and segment up to four individuals in an image."}],"title":"Explore 3D body pose and person segmentation in Vision","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-111241-explore-3d-body-pose-and-person-segmentation-in-vision","kind":"article"},"WWDCNotes.png":{"type":"image","alt":null,"variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"identifier":"WWDCNotes.png"},"https://":{"type":"link","url":"https:\/\/","identifier":"https:\/\/","titleInlineContent":[{"text":"Blog","type":"text"}],"title":"Blog"}}}