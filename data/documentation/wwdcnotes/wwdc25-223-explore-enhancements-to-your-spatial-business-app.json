{"abstract":[{"text":"Discover how the latest enhancements and APIs in visionOS 26 expand access and extend enterprise capabilities announced last year. Learn how these all-new features make it easy to build model training workflows, enhance video feeds, and enable you to align coordinate systems over a local network to develop collaborative experiences in your in-house app.","type":"text"}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25"]]},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc25-223-explore-enhancements-to-your-spatial-business-app"],"traits":[{"interfaceLanguage":"swift"}]}],"metadata":{"modules":[{"name":"WWDC Notes"}],"role":"sampleCode","roleHeading":"WWDC25","title":"Explore enhancements to your spatial business app"},"sampleCodeDownload":{"kind":"sampleDownload","action":{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/223","overridingTitle":"Watch Video (25 min)"}},"schemaVersion":{"patch":0,"minor":3,"major":0},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-223-Explore-enhancements-to-your-spatial-business-app","interfaceLanguage":"swift"},"primaryContentSections":[{"content":[{"anchor":"overview","text":"Overview","level":2,"type":"heading"},{"inlineContent":[{"text":"üò± ‚ÄúNo Overview Available!‚Äù","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true,"type":"reference"}],"type":"paragraph"},{"anchor":"Related-Sessions","text":"Related Sessions","level":2,"type":"heading"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10139-Introducing-enterprise-APIs-for-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10101-Explore-object-tracking-for-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10100-Create-enhanced-spatial-computing-experiences-with-ARKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-318-Share-visionOS-experiences-with-nearby-people"],"style":"list","type":"links"}],"kind":"content"}],"kind":"article","sections":[],"references":{"https://developer.apple.com/videos/play/wwdc2025/223":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/223","type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/223"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-318-Share-visionOS-experiences-with-nearby-people":{"abstract":[{"text":"Learn how to create shared experiences for people wearing Vision Pro in the same room. We‚Äôll show you how to integrate SharePlay and leverage ARKit in your app, introduce the updated window sharing flows for nearby and FaceTime participants, and cover new API designed for seamless collaboration. Discover best practices to make your collaborative features stand out, easily discoverable, and engaging for people together in the same space.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-318-Share-visionOS-experiences-with-nearby-people","kind":"article","title":"Share visionOS experiences with nearby people","role":"sampleCode","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc25-318-share-visionos-experiences-with-nearby-people"},"WWDC25-Icon.png":{"identifier":"WWDC25-Icon.png","type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC25-Icon.png"}],"alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10139-Introducing-enterprise-APIs-for-visionOS":{"title":"Introducing enterprise APIs for visionOS","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10139-Introducing-enterprise-APIs-for-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10139-introducing-enterprise-apis-for-visionos","kind":"article","type":"topic","abstract":[{"type":"text","text":"Find out how you can use new enterprise APIs for visionOS to create spatial experiences that enhance employee and customer productivity on Apple Vision Pro."}]},"WWDC25.jpg":{"identifier":"WWDC25.jpg","alt":null,"type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDC25.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes":{"url":"\/documentation\/wwdcnotes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","title":"WWDC Notes","type":"topic","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"kind":"symbol"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10100-Create-enhanced-spatial-computing-experiences-with-ARKit":{"url":"\/documentation\/wwdcnotes\/wwdc24-10100-create-enhanced-spatial-computing-experiences-with-arkit","type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10100-Create-enhanced-spatial-computing-experiences-with-ARKit","abstract":[{"type":"text","text":"Learn how to create captivating immersive experiences with ARKit‚Äôs latest features. Explore ways to use room tracking and object tracking to further engage with your surroundings. We‚Äôll also share how your app can react to changes in your environment‚Äôs lighting on this platform. Discover improvements in hand tracking and plane detection which can make your spatial experiences more intuitive."}],"title":"Create enhanced spatial computing experiences with ARKit","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25":{"images":[{"identifier":"WWDC25-Icon.png","type":"icon"},{"identifier":"WWDC25.jpg","type":"card"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc25","type":"topic","abstract":[{"type":"text","text":"Xcode 26, Swift 6.2, iOS\/macOS\/tvOS\/visionOS 26."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"Foundation Models","type":"codeVoice"},{"type":"text","text":", "},{"code":"AlarmKit","type":"codeVoice"},{"type":"text","text":", "},{"code":"PermissionKit","type":"codeVoice"},{"type":"text","text":", and more."}],"title":"WWDC25","role":"collectionGroup"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10101-Explore-object-tracking-for-visionOS":{"type":"topic","title":"Explore object tracking for visionOS","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10101-explore-object-tracking-for-visionos","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10101-Explore-object-tracking-for-visionOS","abstract":[{"type":"text","text":"Find out how you can use object tracking to turn real-world objects into virtual anchors in your visionOS app. Learn how you can build spatial experiences with object tracking from start to finish. Find out how to create a reference object using machine learning in Create ML and attach content relative to your target object in Reality Composer Pro, RealityKit or ARKit APIs."}]},"WWDCNotes.png":{"type":"image","alt":null,"identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}]},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","title":"Learn More‚Ä¶","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}]}}}