{"schemaVersion":{"major":0,"patch":0,"minor":3},"metadata":{"roleHeading":"WWDC21","role":"sampleCode","modules":[{"name":"WWDC Notes"}],"title":"Create 3D models with Object Capture"},"sections":[],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc21-10076-create-3d-models-with-object-capture"]}],"primaryContentSections":[{"content":[{"text":"Key Terms","type":"heading","level":2,"anchor":"Key-Terms"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"type":"text","text":"Photogrammetry"}],"type":"strong"},{"text":": computer vision technique (","type":"text"},{"identifier":"https:\/\/en.wikipedia.org\/wiki\/Photogrammetry","isActive":true,"type":"reference"},{"text":")","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Object Capture"}]},{"text":": Photogrammetry API provided by Apple to build apps which take a collection of images and create an AR model object.","type":"text"}]}]}]},{"text":"Object Capture Overview","type":"heading","level":2,"anchor":"Object-Capture-Overview"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Prior to API, we would need to hire a professional photographer to spend hours modeling it."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"With Object Capture:"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Take photos of object from every angle.","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Copy to Mac that supports Object Capture API.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Create a 3D geometric mesh as well as various material maps (Photogrammetry)"}]}]}]},{"text":"Capturing Photos","type":"heading","level":2,"anchor":"Capturing-Photos"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Pick an object that has sufficient texture detail (avoid transparency or highly reflective regions)"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Ensure the object is in focus, capture from all angles, get close to the object, 20-200 images"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Optionally, use ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/documentation\/realitykit\/taking_pictures_for_3d_object_capture"},{"text":" App – demonstrates how to capture photos.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"iPhone or iPad (stereo depth data to allow for recovery of actual object size), but you can also use DSLR or even a drone."}]}]}]},{"text":"API Details","type":"heading","level":2,"anchor":"API-Details"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Swift API in RealityKit (macOS)"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Silicon Macs or Intel Macs with 4GB AMD and 16GB RAM","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"isActive":true,"identifier":"https:\/\/developer.apple.com\/documentation\/realitykit\/creating_a_photogrammetry_command-line_app","type":"reference"},{"text":": command-line sample app provided by Apple to accept collection of images and turn them into an AR model","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"USDZ, USDA, or OBJ exports","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Detail: preview, reduced, medium, full, raw"}]}]}]},{"text":"Getting Started","type":"heading","level":2,"anchor":"Getting-Started"},{"text":"Basic Workflow","type":"heading","level":3,"anchor":"Basic-Workflow"},{"type":"orderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Create session – a fixed container (folder) of image samples (HEIC, JPG, PNG)","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Connect output stream","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Generate models","type":"text"}],"type":"paragraph"}]}]},{"text":"Creating a Session","type":"heading","level":3,"anchor":"Creating-a-Session"},{"type":"codeListing","code":["import RealityKit","","let inputFolderUrl = URL(fileURLWithPath: \"\/tmp\/Sneakers\/\", isDirectory: true)","let session = try! PhotogrammetrySession(input: inputFolderUrl,","configuration: PhotogrammetrySession.Configuration())"],"syntax":"swift"},{"text":"Connect Output Stream","type":"heading","level":3,"anchor":"Connect-Output-Stream"},{"type":"codeListing","code":["async {","    do {","        for try await output in session.outputs {","            switch output {","            case .requestProgress(let request, let fraction):","                print(\"Request progress: (fraction)\")","            case .requestComplete(let request, let result):","                if case .modelFile(let url) = result {","                    print(\"Request result output at (url).\")","                }","            case .requestError(let request, let error):","                print(\"Error: (request) error=(error)\")","            case .processingComplete:","                print(\"Completed!\")","                handleComplete()","            default:  \/\/ Or handle other messages...","                break","            }","        }","    } catch {","        print(\"Fatal session error! (error)\")","    }","}"],"syntax":"swift"},{"type":"paragraph","inlineContent":[{"inlineContent":[{"type":"text","text":"Output messages"}],"type":"strong"},{"text":" ","type":"text"},{"text":"• requestProgress progress of request","type":"text"},{"text":" ","type":"text"},{"text":"• requestComplete with model or bounds","type":"text"},{"text":" ","type":"text"},{"text":"• requestError for errors","type":"text"},{"text":" ","type":"text"},{"text":"• processingComplete when all requests have finished processing.","type":"text"}]},{"text":"Generating a Request","type":"heading","level":3,"anchor":"Generating-a-Request"},{"type":"codeListing","code":["try! session.process(requests: [","    .modelFile(\"\/tmp\/Outputs\/model-reduced.usdz\", detail: .reduced),","    .modelFile(\"\/tmp\/Outputs\/model-medium.usdz\", detail: .medium)","])"],"syntax":"swift"},{"text":"Interactive Workflow","type":"heading","level":2,"anchor":"Interactive-Workflow"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"More advanced (for interactive editing)","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Designed to allow several adjustments to preview model","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Watch ~17:00 for demo of sample app built by Apple"}],"type":"paragraph"}]}]},{"text":"Best Practices: Selecting the Right Output","type":"heading","level":2,"anchor":"Best-Practices-Selecting-the-Right-Output"},{"type":"paragraph","inlineContent":[{"type":"text","text":"![Output options. Shows reduced, medium, full, raw output options and deatils memory size, iOS compatibility, etc.][WWDC21-10076-output-options]"}]},{"text":"Written By","type":"heading","level":2,"anchor":"Written-By"},{"type":"row","columns":[{"content":[{"inlineContent":[{"identifier":"derrickshowers","type":"image"}],"type":"paragraph"}],"size":1},{"content":[{"type":"heading","level":3,"text":"Derrick Showers","anchor":"Derrick-Showers"},{"type":"paragraph","inlineContent":[{"isActive":true,"overridingTitle":"Contributed Notes","type":"reference","overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/derrickshowers"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/github.com\/derrickshowers"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/derrickshowers.com"}]}],"size":4}],"numberOfColumns":5},{"type":"thematicBreak"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference","isActive":true}]},{"text":"Related Sessions","type":"heading","level":2,"anchor":"Related-Sessions"},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10128-Bring-your-world-into-augmented-reality","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10141-Explore-USD-tools-and-rendering","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10077-Create-3D-workflows-with-USD"],"style":"list"},{"type":"small","inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"kind":"article","identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10076-Create-3D-models-with-Object-Capture","interfaceLanguage":"swift"},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21"]]},"abstract":[{"type":"text","text":"Object Capture provides a quick and easy way to create lifelike 3D models of real-world objects using just a few images. Learn how you can get started and bring your assets to life with Photogrammetry for macOS. And discover best practices with object selection and image capture to help you achieve the highest-quality results."}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"type":"reference","overridingTitle":"Watch Video (27 min)","identifier":"https:\/\/developer.apple.com\/wwdc21\/10076"}},"references":{"https://derrickshowers.com":{"type":"link","title":"Blog","identifier":"https:\/\/derrickshowers.com","titleInlineContent":[{"text":"Blog","type":"text"}],"url":"https:\/\/derrickshowers.com"},"derrickshowers.jpeg":{"variants":[{"url":"\/images\/WWDCNotes\/derrickshowers.jpeg","traits":["1x","light"]}],"alt":null,"identifier":"derrickshowers.jpeg","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/derrickshowers":{"title":"Derrick Showers (1 note)","role":"sampleCode","abstract":[{"text":"No Bio on GitHub","type":"text"}],"type":"topic","images":[{"type":"card","identifier":"derrickshowers.jpeg"},{"type":"icon","identifier":"derrickshowers.jpeg"}],"url":"\/documentation\/wwdcnotes\/derrickshowers","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/derrickshowers","kind":"article"},"WWDC21.jpeg":{"identifier":"WWDC21.jpeg","type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC21.jpeg"}],"alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10077-Create-3D-workflows-with-USD":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10077-Create-3D-workflows-with-USD","url":"\/documentation\/wwdcnotes\/wwdc21-10077-create-3d-workflows-with-usd","role":"sampleCode","type":"topic","kind":"article","title":"Create 3D workflows with USD","abstract":[{"text":"Discover the flexibility, versatility and power of Pixar’s Universal Scene Description (USD) for your 3D workflows. Learn how you can use the USD file format in your professional workflows for macOS: Scan 3D models of your real-world objects using Object Capture, utilize the potential of third-party digital content creation tools, and build high-quality rendered sequences.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21":{"abstract":[{"text":"Xcode 13, Swift 5.5, iOS 15, macOS 12 (Monterey), tvOS 15, watchOS 8.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"type":"codeVoice","code":"MusicKit"},{"text":", ","type":"text"},{"type":"codeVoice","code":"DocC"},{"text":", ","type":"text"},{"type":"codeVoice","code":"StoreKit 2"},{"text":", and more.","type":"text"}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21","role":"collectionGroup","title":"WWDC21","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc21","images":[{"type":"icon","identifier":"WWDC21-Icon.png"},{"type":"card","identifier":"WWDC21.jpeg"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"url":"\/documentation\/wwdcnotes","kind":"symbol","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"type":"topic","role":"collection","title":"WWDC Notes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10141-Explore-USD-tools-and-rendering":{"title":"Explore USD tools and rendering","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10141-Explore-USD-tools-and-rendering","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc22-10141-explore-usd-tools-and-rendering","type":"topic","abstract":[{"text":"Discover the latest advancements in tooling to help you generate, inspect, and convert Universal Scene Description (USD) assets. We’ll learn about updates to these tools and help you integrate them into your content creation pipeline. We’ll also explore the power of USD Hydra rendering, and show how you can integrate it into your own apps.","type":"text"}]},"derrickshowers":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/derrickshowers.jpeg"}],"identifier":"derrickshowers","alt":"Profile image of Derrick Showers"},"https://github.com/derrickshowers":{"titleInlineContent":[{"text":"GitHub","type":"text"}],"url":"https:\/\/github.com\/derrickshowers","title":"GitHub","identifier":"https:\/\/github.com\/derrickshowers","type":"link"},"https://developer.apple.com/wwdc21/10076":{"identifier":"https:\/\/developer.apple.com\/wwdc21\/10076","url":"https:\/\/developer.apple.com\/wwdc21\/10076","type":"download","checksum":null},"https://en.wikipedia.org/wiki/Photogrammetry":{"type":"link","title":"Wikipedia definition","identifier":"https:\/\/en.wikipedia.org\/wiki\/Photogrammetry","titleInlineContent":[{"text":"Wikipedia definition","type":"text"}],"url":"https:\/\/en.wikipedia.org\/wiki\/Photogrammetry"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10128-Bring-your-world-into-augmented-reality":{"kind":"article","title":"Bring your world into augmented reality","role":"sampleCode","abstract":[{"type":"text","text":"Follow along as we demonstrate how you can use Object Capture and RealityKit to bring real-world objects into an augmented reality game. We’ll show you how to capture detailed items using the Object Capture framework, add them to a RealityKit project in Xcode, apply stylized shaders and animations, and use them as part of an AR experience. We’ll also share best practices when working with ARKit, RealityKit, and Object Capture."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10128-Bring-your-world-into-augmented-reality","url":"\/documentation\/wwdcnotes\/wwdc22-10128-bring-your-world-into-augmented-reality","type":"topic"},"https://developer.apple.com/documentation/realitykit/taking_pictures_for_3d_object_capture":{"identifier":"https:\/\/developer.apple.com\/documentation\/realitykit\/taking_pictures_for_3d_object_capture","url":"https:\/\/developer.apple.com\/documentation\/realitykit\/taking_pictures_for_3d_object_capture","type":"link","title":"CaptureSample","titleInlineContent":[{"text":"CaptureSample","type":"text"}]},"https://developer.apple.com/documentation/realitykit/creating_a_photogrammetry_command-line_app":{"titleInlineContent":[{"text":"HellloPhotogrammetry","type":"text"}],"url":"https:\/\/developer.apple.com\/documentation\/realitykit\/creating_a_photogrammetry_command-line_app","title":"HellloPhotogrammetry","identifier":"https:\/\/developer.apple.com\/documentation\/realitykit\/creating_a_photogrammetry_command-line_app","type":"link"},"WWDCNotes.png":{"type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"identifier":"WWDCNotes.png","alt":null},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","title":"Contributions are welcome!","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}]},"WWDC21-Icon.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC21-Icon.png"}],"alt":null,"identifier":"WWDC21-Icon.png","type":"image"}}}