{"metadata":{"modules":[{"name":"WWDC Notes"}],"role":"sampleCode","title":"Create 3D models with Object Capture","roleHeading":"WWDC21"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc21-10076-create-3d-models-with-object-capture"]}],"abstract":[{"type":"text","text":"Object Capture provides a quick and easy way to create lifelike 3D models of real-world objects using just a few images. Learn how you can get started and bring your assets to life with Photogrammetry for macOS. And discover best practices with object selection and image capture to help you achieve the highest-quality results."}],"kind":"article","primaryContentSections":[{"kind":"content","content":[{"level":2,"anchor":"Key-Terms","type":"heading","text":"Key Terms"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"text":"Photogrammetry","type":"text"}]},{"type":"text","text":": computer vision technique ("},{"type":"reference","identifier":"https:\/\/en.wikipedia.org\/wiki\/Photogrammetry","isActive":true},{"type":"text","text":")"}]}]},{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Object Capture","type":"text"}]},{"type":"text","text":": Photogrammetry API provided by Apple to build apps which take a collection of images and create an AR model object."}],"type":"paragraph"}]}]},{"level":2,"anchor":"Object-Capture-Overview","type":"heading","text":"Object Capture Overview"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Prior to API, we would need to hire a professional photographer to spend hours modeling it.","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"With Object Capture:","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Take photos of object from every angle."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Copy to Mac that supports Object Capture API.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Create a 3D geometric mesh as well as various material maps (Photogrammetry)"}]}]}]},{"level":2,"anchor":"Capturing-Photos","type":"heading","text":"Capturing Photos"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Pick an object that has sufficient texture detail (avoid transparency or highly reflective regions)","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Ensure the object is in focus, capture from all angles, get close to the object, 20-200 images","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Optionally, use ","type":"text"},{"identifier":"https:\/\/developer.apple.com\/documentation\/realitykit\/taking_pictures_for_3d_object_capture","isActive":true,"type":"reference"},{"text":" App – demonstrates how to capture photos.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"iPhone or iPad (stereo depth data to allow for recovery of actual object size), but you can also use DSLR or even a drone."}],"type":"paragraph"}]}]},{"level":2,"anchor":"API-Details","type":"heading","text":"API Details"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Swift API in RealityKit (macOS)"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Silicon Macs or Intel Macs with 4GB AMD and 16GB RAM"}]}]},{"content":[{"inlineContent":[{"identifier":"https:\/\/developer.apple.com\/documentation\/realitykit\/creating_a_photogrammetry_command-line_app","type":"reference","isActive":true},{"text":": command-line sample app provided by Apple to accept collection of images and turn them into an AR model","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"USDZ, USDA, or OBJ exports"}]}]},{"content":[{"inlineContent":[{"text":"Detail: preview, reduced, medium, full, raw","type":"text"}],"type":"paragraph"}]}]},{"level":2,"anchor":"Getting-Started","type":"heading","text":"Getting Started"},{"level":3,"anchor":"Basic-Workflow","type":"heading","text":"Basic Workflow"},{"type":"orderedList","items":[{"content":[{"inlineContent":[{"text":"Create session – a fixed container (folder) of image samples (HEIC, JPG, PNG)","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Connect output stream"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Generate models"}],"type":"paragraph"}]}]},{"level":3,"anchor":"Creating-a-Session","type":"heading","text":"Creating a Session"},{"type":"codeListing","syntax":"swift","code":["import RealityKit","","let inputFolderUrl = URL(fileURLWithPath: \"\/tmp\/Sneakers\/\", isDirectory: true)","let session = try! PhotogrammetrySession(input: inputFolderUrl,","configuration: PhotogrammetrySession.Configuration())"]},{"level":3,"anchor":"Connect-Output-Stream","type":"heading","text":"Connect Output Stream"},{"type":"codeListing","syntax":"swift","code":["async {","    do {","        for try await output in session.outputs {","            switch output {","            case .requestProgress(let request, let fraction):","                print(\"Request progress: (fraction)\")","            case .requestComplete(let request, let result):","                if case .modelFile(let url) = result {","                    print(\"Request result output at (url).\")","                }","            case .requestError(let request, let error):","                print(\"Error: (request) error=(error)\")","            case .processingComplete:","                print(\"Completed!\")","                handleComplete()","            default:  \/\/ Or handle other messages...","                break","            }","        }","    } catch {","        print(\"Fatal session error! (error)\")","    }","}"]},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Output messages"}]},{"text":" ","type":"text"},{"text":"• requestProgress progress of request","type":"text"},{"text":" ","type":"text"},{"text":"• requestComplete with model or bounds","type":"text"},{"text":" ","type":"text"},{"text":"• requestError for errors","type":"text"},{"text":" ","type":"text"},{"text":"• processingComplete when all requests have finished processing.","type":"text"}],"type":"paragraph"},{"level":3,"anchor":"Generating-a-Request","type":"heading","text":"Generating a Request"},{"type":"codeListing","syntax":"swift","code":["try! session.process(requests: [","    .modelFile(\"\/tmp\/Outputs\/model-reduced.usdz\", detail: .reduced),","    .modelFile(\"\/tmp\/Outputs\/model-medium.usdz\", detail: .medium)","])"]},{"level":2,"anchor":"Interactive-Workflow","type":"heading","text":"Interactive Workflow"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"More advanced (for interactive editing)","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Designed to allow several adjustments to preview model"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Watch ~17:00 for demo of sample app built by Apple","type":"text"}]}]}]},{"level":2,"anchor":"Best-Practices-Selecting-the-Right-Output","type":"heading","text":"Best Practices: Selecting the Right Output"},{"inlineContent":[{"text":"![Output options. Shows reduced, medium, full, raw output options and deatils memory size, iOS compatibility, etc.][WWDC21-10076-output-options]","type":"text"}],"type":"paragraph"},{"level":2,"anchor":"Written-By","type":"heading","text":"Written By"},{"numberOfColumns":5,"type":"row","columns":[{"size":1,"content":[{"inlineContent":[{"identifier":"derrickshowers","type":"image"}],"type":"paragraph"}]},{"size":4,"content":[{"anchor":"Derrick-Showers","type":"heading","level":3,"text":"Derrick Showers"},{"type":"paragraph","inlineContent":[{"overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"overridingTitle":"Contributed Notes","type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/derrickshowers","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/github.com\/derrickshowers","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/derrickshowers.com","isActive":true}]}]}]},{"type":"thematicBreak"},{"inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true,"type":"reference"}],"type":"paragraph"},{"level":2,"anchor":"Related-Sessions","type":"heading","text":"Related Sessions"},{"type":"links","style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10128-Bring-your-world-into-augmented-reality","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10141-Explore-USD-tools-and-rendering","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10077-Create-3D-workflows-with-USD"]},{"inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}],"type":"small"},{"inlineContent":[{"text":"All content copyright © 2012 – 2025 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}],"type":"small"}]}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (27 min)","type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc21\/10076","isActive":true}},"schemaVersion":{"patch":0,"major":0,"minor":3},"sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21"]]},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10076-Create-3D-models-with-Object-Capture","interfaceLanguage":"swift"},"references":{"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","title":"WWDC Notes","type":"topic","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","url":"\/documentation\/wwdcnotes","role":"collection"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10077-Create-3D-workflows-with-USD":{"abstract":[{"type":"text","text":"Discover the flexibility, versatility and power of Pixar’s Universal Scene Description (USD) for your 3D workflows. Learn how you can use the USD file format in your professional workflows for macOS: Scan 3D models of your real-world objects using Object Capture, utilize the potential of third-party digital content creation tools, and build high-quality rendered sequences."}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10077-Create-3D-workflows-with-USD","url":"\/documentation\/wwdcnotes\/wwdc21-10077-create-3d-workflows-with-usd","kind":"article","type":"topic","title":"Create 3D workflows with USD"},"derrickshowers":{"type":"image","identifier":"derrickshowers","alt":"Profile image of Derrick Showers","variants":[{"url":"\/images\/WWDCNotes\/derrickshowers.jpeg","traits":["1x","light"]}]},"derrickshowers.jpeg":{"variants":[{"url":"\/images\/WWDCNotes\/derrickshowers.jpeg","traits":["1x","light"]}],"alt":null,"identifier":"derrickshowers.jpeg","type":"image"},"WWDC21-Icon.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC21-Icon.png"}],"type":"image","identifier":"WWDC21-Icon.png","alt":null},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!"},"https://github.com/derrickshowers":{"url":"https:\/\/github.com\/derrickshowers","identifier":"https:\/\/github.com\/derrickshowers","type":"link","titleInlineContent":[{"type":"text","text":"GitHub"}],"title":"GitHub"},"https://developer.apple.com/documentation/realitykit/taking_pictures_for_3d_object_capture":{"title":"CaptureSample","type":"link","url":"https:\/\/developer.apple.com\/documentation\/realitykit\/taking_pictures_for_3d_object_capture","identifier":"https:\/\/developer.apple.com\/documentation\/realitykit\/taking_pictures_for_3d_object_capture","titleInlineContent":[{"type":"text","text":"CaptureSample"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10128-Bring-your-world-into-augmented-reality":{"abstract":[{"type":"text","text":"Follow along as we demonstrate how you can use Object Capture and RealityKit to bring real-world objects into an augmented reality game. We’ll show you how to capture detailed items using the Object Capture framework, add them to a RealityKit project in Xcode, apply stylized shaders and animations, and use them as part of an AR experience. We’ll also share best practices when working with ARKit, RealityKit, and Object Capture."}],"url":"\/documentation\/wwdcnotes\/wwdc22-10128-bring-your-world-into-augmented-reality","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10128-Bring-your-world-into-augmented-reality","title":"Bring your world into augmented reality","role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21":{"url":"\/documentation\/wwdcnotes\/wwdc21","title":"WWDC21","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21","type":"topic","abstract":[{"type":"text","text":"Xcode 13, Swift 5.5, iOS 15, macOS 12 (Monterey), tvOS 15, watchOS 8."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"MusicKit"},{"type":"text","text":", "},{"type":"codeVoice","code":"DocC"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit 2"},{"type":"text","text":", and more."}],"kind":"article","role":"collectionGroup","images":[{"type":"icon","identifier":"WWDC21-Icon.png"},{"type":"card","identifier":"WWDC21.jpeg"}]},"https://developer.apple.com/documentation/realitykit/creating_a_photogrammetry_command-line_app":{"type":"link","identifier":"https:\/\/developer.apple.com\/documentation\/realitykit\/creating_a_photogrammetry_command-line_app","titleInlineContent":[{"text":"HellloPhotogrammetry","type":"text"}],"url":"https:\/\/developer.apple.com\/documentation\/realitykit\/creating_a_photogrammetry_command-line_app","title":"HellloPhotogrammetry"},"https://developer.apple.com/wwdc21/10076":{"checksum":null,"identifier":"https:\/\/developer.apple.com\/wwdc21\/10076","type":"download","url":"https:\/\/developer.apple.com\/wwdc21\/10076"},"doc://WWDCNotes/documentation/WWDCNotes/derrickshowers":{"abstract":[{"type":"text","text":"No Bio on GitHub"}],"type":"topic","title":"Derrick Showers (1 note)","images":[{"type":"card","identifier":"derrickshowers.jpeg"},{"type":"icon","identifier":"derrickshowers.jpeg"}],"role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/derrickshowers","url":"\/documentation\/wwdcnotes\/derrickshowers"},"WWDC21.jpeg":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC21.jpeg","traits":["1x","light"]}],"type":"image","identifier":"WWDC21.jpeg","alt":null},"https://derrickshowers.com":{"url":"https:\/\/derrickshowers.com","identifier":"https:\/\/derrickshowers.com","type":"link","titleInlineContent":[{"type":"text","text":"Blog"}],"title":"Blog"},"https://en.wikipedia.org/wiki/Photogrammetry":{"type":"link","identifier":"https:\/\/en.wikipedia.org\/wiki\/Photogrammetry","titleInlineContent":[{"type":"text","text":"Wikipedia definition"}],"url":"https:\/\/en.wikipedia.org\/wiki\/Photogrammetry","title":"Wikipedia definition"},"WWDCNotes.png":{"variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"type":"image","identifier":"WWDCNotes.png","alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10141-Explore-USD-tools-and-rendering":{"url":"\/documentation\/wwdcnotes\/wwdc22-10141-explore-usd-tools-and-rendering","abstract":[{"text":"Discover the latest advancements in tooling to help you generate, inspect, and convert Universal Scene Description (USD) assets. We’ll learn about updates to these tools and help you integrate them into your content creation pipeline. We’ll also explore the power of USD Hydra rendering, and show how you can integrate it into your own apps.","type":"text"}],"kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10141-Explore-USD-tools-and-rendering","title":"Explore USD tools and rendering"}}}