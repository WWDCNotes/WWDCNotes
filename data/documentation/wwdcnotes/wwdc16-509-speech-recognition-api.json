{"sampleCodeDownload":{"action":{"overridingTitle":"Watch Video (11 min)","identifier":"https:\/\/developer.apple.com\/wwdc16\/509","isActive":true,"type":"reference"},"kind":"sampleDownload"},"schemaVersion":{"major":0,"patch":0,"minor":3},"sections":[],"metadata":{"title":"Speech Recognition API","role":"sampleCode","roleHeading":"WWDC16","modules":[{"name":"WWDC Notes"}]},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC16"]]},"kind":"article","abstract":[{"type":"text","text":"iOS 10 brings a brand new Speech Recognition API that allows you to perform rapid and contextually informed speech recognition in both file-based and realtime scenarios. In this video, you will learn all about the new API and how to bring advanced speech recognition services into your apps."}],"primaryContentSections":[{"content":[{"anchor":"overview","level":2,"text":"Overview","type":"heading"},{"type":"paragraph","inlineContent":[{"text":"üò± ‚ÄúNo Overview Available!‚Äù","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}]},{"type":"heading","level":2,"text":"Related Sessions","anchor":"Related-Sessions"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-256-Advances-in-Speech-Recognition"],"type":"links","style":"list"},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Legal Notice"}]}],"type":"small"},{"inlineContent":[{"type":"text","text":"All content copyright ¬© 2012 ‚Äì 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}],"kind":"content"}],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc16-509-speech-recognition-api"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC16-509-Speech-Recognition-API","interfaceLanguage":"swift"},"references":{"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}],"type":"link","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC16":{"abstract":[{"text":"Xcode 8, Swift 3.0, iOS 10, macOS 10.12 (Sierra), tvOS 10, watchOS 3.","type":"text"}],"images":[{"type":"icon","identifier":"WWDC16-Icon.png"},{"type":"card","identifier":"WWDC16.jpeg"}],"role":"collectionGroup","type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc16","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC16","title":"WWDC16"},"WWDCNotes.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}],"type":"image","alt":null,"identifier":"WWDCNotes.png"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-256-Advances-in-Speech-Recognition":{"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19-256-advances-in-speech-recognition","role":"sampleCode","title":"Advances in Speech Recognition","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-256-Advances-in-Speech-Recognition","abstract":[{"type":"text","text":"Speech Recognizer can now be used locally on iOS or macOS devices with no network connection. Learn how you can bring text-to-speech support to your app while maintaining privacy and eliminating the limitations of server-based processing. Speech recognition API has also been enhanced to provide richer analytics including speaking rate, pause duration, and voice quality."}]},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"images":[{"identifier":"WWDCNotes.png","type":"icon"}],"url":"\/documentation\/wwdcnotes","title":"WWDC Notes"},"WWDC16.jpeg":{"type":"image","variants":[{"url":"\/images\/WWDC16.jpeg","traits":["1x","light"]}],"alt":null,"identifier":"WWDC16.jpeg"},"WWDC16-Icon.png":{"type":"image","variants":[{"url":"\/images\/WWDC16-Icon.png","traits":["1x","light"]}],"alt":null,"identifier":"WWDC16-Icon.png"},"https://developer.apple.com/wwdc16/509":{"type":"download","url":"https:\/\/developer.apple.com\/wwdc16\/509","identifier":"https:\/\/developer.apple.com\/wwdc16\/509","checksum":null}}}