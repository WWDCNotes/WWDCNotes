{"abstract":[{"type":"text","text":"Learn how to adopt spatial photos and videos in your apps. Explore the different types of stereoscopic media and find out how to capture spatial videos in your iOS app on iPhone 15 Pro. Discover the various ways to detect and present spatial media, including the new QuickLook Preview Application API in visionOS. And take a deep dive into the metadata and stereo concepts that make a photo or video spatial."}],"schemaVersion":{"major":0,"minor":3,"patch":0},"kind":"article","hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24"]]},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc24-10166-build-compelling-spatial-photo-and-video-experiences"]}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10166-Build-compelling-spatial-photo-and-video-experiences","interfaceLanguage":"swift"},"sections":[],"metadata":{"title":"Build compelling spatial photo and video experiences","modules":[{"name":"WWDC Notes"}],"role":"sampleCode","roleHeading":"WWDC24"},"sampleCodeDownload":{"action":{"type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc24\/10166","isActive":true,"overridingTitle":"Watch Video (21 min)"},"kind":"sampleDownload"},"primaryContentSections":[{"content":[{"level":2,"text":"Chapters","type":"heading","anchor":"Chapters"},{"type":"paragraph","inlineContent":[{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=0"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=67","isActive":true,"type":"reference"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=253"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=794"},{"text":"","type":"text"},{"text":"\n","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=1276"}]},{"level":2,"text":"Stereoscopic video experiences","type":"heading","anchor":"Stereoscopic-video-experiences"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Formats:"}]},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"3D video, like 3D movies available in Apple TV and Disney+. Renders flat."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Spatial video, captured on iPhone 15 pro and Vision Pro. Renders through a window."}]}]},{"content":[{"inlineContent":[{"text":"Apple Immersive video, for high-end professional content. 180 degree, 8k resolution, spatial audio.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"level":3,"text":"Full immersion","type":"heading","anchor":"Full-immersion"},{"type":"paragraph","inlineContent":[{"text":"3D video docks into an environment, screen moves backward and enlarges. (see also [Enhance video playback and immersion in your custom app environment]). Spatial video expands into its immersive presentation.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Content wraps around user."}]},{"type":"paragraph","inlineContent":[{"text":"Other stereo experiences:","type":"text"}]},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Spatial photos"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Custom video experiences"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Interactive 3D content","type":"text"}]}]}],"type":"unorderedList"},{"type":"paragraph","inlineContent":[{"type":"text","text":"See also: Bring your iOS or iPadOS game to visionOS"}]},{"level":2,"text":"New APIs","type":"heading","anchor":"New-APIs"},{"type":"paragraph","inlineContent":[{"type":"text","text":"No new frameworks, changes ar integrated into existing frameworks"}]},{"level":3,"text":"Capturing spatial video","type":"heading","anchor":"Capturing-spatial-video"},{"type":"paragraph","inlineContent":[{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=310","type":"reference"},{"text":" ","type":"text"},{"code":"isSpatialVideoCaptureSupported","type":"codeVoice"},{"text":" fails on hardware other than iPhone 15 Pro. Get full-formed spatial video file on disk.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=450","isActive":true},{"text":" improved video stabilization, and a great preview.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"“Wide” and “Ultrawide” cameras have different capture characteristics. Can cause noise level variation, or focus mismatch. Not detectable until playback on Vision Pro. So have added new variable "},{"code":"spatialCaptureDiscomfortReasons","type":"codeVoice"},{"type":"text","text":" on "},{"code":"AVCaptureDevice","type":"codeVoice"},{"type":"text","text":" for feedback while shooting. See iPhone Camera App for first-party UI example of this feedback."}]},{"level":3,"text":"Detecting spatial media","type":"heading","anchor":"Detecting-spatial-media"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Detection Methods"}]},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"PhotosPicker. Can filter library to show only "},{"code":".spatialMedia","type":"codeVoice"},{"type":"text","text":" assets."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"PhotoKit. Pass "},{"type":"codeVoice","code":"PHAssetMediaSubtype.spatialMedia"},{"type":"text","text":" to "},{"type":"codeVoice","code":"fetchAssets"},{"type":"text","text":" call. Can do just spatial photos or spatial videos."}]}]},{"content":[{"inlineContent":[{"text":"AVAssetPlaybackAssistant. ","type":"text"},{"code":".playbackConfigurationOptions","type":"codeVoice"},{"text":" can be configured for spatial assets.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Presentation Options"}]},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"PreviewApplication API (spawn Quicklook scene). See “What’s new in Quick Look for spatial computing”."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Element Fullscreen API (Javascript). Open spatial photos in Safari. See “Optimize for the Spatial Web”.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"AVPlayerViewController. Supports 2D and 3D video content, also HTTP Live Streaming for spatial video. Only displays as 3D if full screen. Shows 3D video, not spatial video. Use PreviewApplication if you need spatial video display.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"level":2,"text":"Create custom spatial media","type":"heading","anchor":"Create-custom-spatial-media"},{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=790","isActive":true},{"text":".","type":"text"},{"text":" ","type":"text"},{"text":"Two sample projects provided, for spatial video and spatial photos.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=821","isActive":true,"type":"reference"}]},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Projection. Spatial photos and videos always use the rectilinear projection."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Baseline, Field of View: camera properties."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Disparity adjustment"}]}]}],"type":"unorderedList"},{"type":"paragraph","inlineContent":[{"text":"Example: stereoscopic image of a hummingbird.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Note: the following metadata discussion is put into practice in the ","type":"text"},{"identifier":"https:\/\/developer.apple.com\/documentation\/ImageIO\/writing-spatial-photos","isActive":true,"type":"reference"},{"text":" sample app.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"For optimal image characteristics the left and right images should be stereo rectified, have optical axis alignment, and have no vertical disparity."},{"type":"text","text":" "},{"type":"text","text":"Rectilinear: straight lines in world are straight lines on image."},{"type":"text","text":" "},{"type":"text","text":"Horizontal baseline: 64 mm similar to human eye, 32 mm good for closeups, larger than 64 mm good for stereo landscape photography."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"FOV greater than 90 degrees is inefficient for rectilinear capture, 60 degrees used for this analysis."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Images must be coplanar (or stereorectified in post-production)."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Cropping: center axis of cameras should be at centers of images to keep good alignment. Vertical disparity, if present, makes images uncomfortable to view (same feature should have same Y coordinate in each eye)."}]},{"type":"paragraph","inlineContent":[{"text":"Vision Pro renderer uses the metadata to construct a camera model, renders different image for each eye.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Horizontal disparity adjustment: a hint to the renderer on where to place the zero parallax plane. Sometimes called convergence adjustment. Move left\/right frames horizontally to adjust disparity. This controls perception of how far away the 3D scene appears to be."}]},{"level":2,"text":"Wrap-up. Covered:","type":"heading","anchor":"Wrap-up-Covered"},{"items":[{"content":[{"inlineContent":[{"text":"multiple types of stereo media","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"capture, detect, and display spatial media"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"create your own spatial media","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"level":2,"text":"Written By","type":"heading","anchor":"Written-By"},{"type":"row","columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/418007?v=4"}]}]},{"size":4,"content":[{"level":3,"type":"heading","anchor":"Hal-Mueller","text":"Hal Mueller"},{"type":"paragraph","inlineContent":[{"isActive":true,"overridingTitle":"Contributed Notes","overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/halmueller","type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"isActive":true,"identifier":"https:\/\/github.com\/halmueller","type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"isActive":true,"identifier":"https:\/\/","type":"reference"}]}]}],"numberOfColumns":5},{"type":"paragraph","inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"isActive":true,"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"reference"}]},{"level":2,"text":"Related Sessions","type":"heading","anchor":"Related-Sessions"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10115-Enhance-the-immersion-of-media-viewing-in-custom-environments","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10065-Optimize-for-the-spatial-web","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10105-Whats-new-in-Quick-Look-for-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10093-Bring-your-iOS-or-iPadOS-game-to-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences"],"type":"links","style":"list"},{"type":"small","inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"seeAlsoSections":[{"title":"Deep Dives into Topics","generated":true,"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10184-A-Swift-Tour-Explore-Swifts-features-and-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10218-Accelerate-machine-learning-with-Metal","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10140-Add-personality-to-your-app-through-UX-writing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10173-Analyze-heap-memory","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10172-Break-into-the-RealityKit-debugger","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10067-Bring-context-to-todays-weather","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10220-Bring-expression-to-your-app-with-Genmoji","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10068-Bring-your-Live-Activity-to-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10133-Bring-your-app-to-Siri","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10210-Bring-your-apps-core-features-to-users-with-App-Intents","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10093-Bring-your-iOS-or-iPadOS-game-to-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10159-Bring-your-machine-learning-and-AI-models-to-Apple-silicon","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10069-Broadcast-updates-to-your-Live-Activities","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10204-Build-a-great-Lock-Screen-camera-capture-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10104-Build-a-spatial-drawing-app-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10084-Build-custom-swimming-workouts-with-WorkoutKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10066-Build-immersive-web-experiences-with-WebXR","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10185-Build-multilingualready-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10088-Capture-HDR-content-with-ScreenCaptureKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10073-Catch-up-on-accessibility-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10102-Compose-interactive-3D-content-in-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10170-Consume-noncopyable-types-in-Swift","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10138-Create-a-custom-data-store-with-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10087-Create-custom-environments-for-your-immersive-apps-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10152-Create-custom-hover-effects-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10151-Create-custom-visual-effects-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10100-Create-enhanced-spatial-computing-experiences-with-ARKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10070-Customize-feature-discovery-with-TipKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10201-Customize-spatial-Persona-templates-in-SharePlay","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10146-Demystify-SwiftUI-containers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10171-Demystify-explicitly-built-modules","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10161-Deploy-machine-learning-and-AI-models-ondevice-with-Core-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10176-Design-App-Intents-for-system-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10098-Design-Live-Activities-for-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10085-Design-advanced-games-for-Apple-platforms","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10086-Design-great-visionOS-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10096-Design-interactive-experiences-for-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10103-Discover-RealityKit-APIs-for-iOS-macOS-and-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10163-Discover-Swift-enhancements-in-the-Vision-framework","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10107-Discover-area-mode-for-Object-Capture","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10113-Discover-media-performance-metrics-in-AVFoundation","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10153-Dive-deep-into-volumes-and-immersive-spaces","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10147-Elevate-your-tab-and-sidebar-experience-in-iPadOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10114-Enhance-ad-experiences-with-HLS-interstitials","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10115-Enhance-the-immersion-of-media-viewing-in-custom-environments","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10145-Enhance-your-UI-animations-and-transitions","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-111801-Enhance-your-spatial-computing-app-with-RealityKit-audio","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10209-Enhanced-suggestions-for-your-journaling-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10132-Evolve-your-document-launch-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10062-Explore-App-Store-server-APIs-for-InApp-Purchase","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10217-Explore-Swift-performance","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10094-Explore-game-input-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10223-Explore-machine-learning-on-Apple-platforms","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10116-Explore-multiview-video-playback-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10101-Explore-object-tracking-for-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10216-Explore-the-Swift-on-Server-ecosystem","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10109-Explore-wellbeing-APIs-in-HealthKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10200-Extend-your-Xcode-Cloud-workflows","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10157-Extend-your-apps-controls-across-the-system","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10074-Get-started-with-Dynamic-Type","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10083-Get-started-with-HealthKit-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10168-Get-started-with-Writing-Tools","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10195-Go-further-with-Swift-Testing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10197-Go-small-with-Embedded-Swift","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10110-Implement-App-Store-Offers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10162-Keep-colors-consistent-across-captures","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10207-Migrate-your-TVML-app-to-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10169-Migrate-your-app-to-Swift-6","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10065-Optimize-for-the-spatial-web","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10186-Optimize-your-3D-assets-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10089-Port-advanced-games-to-Apple-platforms","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10092-Render-Metal-with-passthrough-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10198-Run-Break-Inspect-Explore-effective-debugging-in-LLDB","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10112-Say-hello-to-the-next-generation-of-CarPlay-design-system","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10214-Squeeze-the-most-out-of-Apple-Pencil","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10125-Streamline-signin-with-passkey-upgrades-and-credential-managers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10131-Support-semantic-search-with-Core-Spotlight","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10155-Swift-Charts-Vectorized-and-function-plots","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10150-SwiftUI-essentials","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10148-Tailor-macOS-windows-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10075-Track-model-changes-with-SwiftData-history","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10160-Train-your-machine-learning-and-AI-models-on-Apple-GPUs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10097-Unlock-the-power-of-places-with-MapKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10122-Use-CloudKit-Console-to-monitor-and-optimize-database-activity","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10177-Use-HDR-for-dynamic-image-experiences-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10149-Work-with-windows-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10181-Xcode-essentials"]}],"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10150-SwiftUI-essentials":{"abstract":[{"type":"text","text":"Join us on a tour of SwiftUI, Apple’s declarative user interface framework. Learn essential concepts for building apps in SwiftUI, like views, state variables, and layout. Discover the breadth of APIs for building fully featured experiences and crafting unique custom components. Whether you’re brand new to SwiftUI or an experienced developer, you’ll learn how to take advantage of what SwiftUI has to offer when building great apps."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10150-swiftui-essentials","title":"SwiftUI essentials","role":"sampleCode","kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10150-SwiftUI-essentials"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10159-Bring-your-machine-learning-and-AI-models-to-Apple-silicon":{"role":"sampleCode","type":"topic","title":"Bring your machine learning and AI models to Apple silicon","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10159-Bring-your-machine-learning-and-AI-models-to-Apple-silicon","url":"\/documentation\/wwdcnotes\/wwdc24-10159-bring-your-machine-learning-and-ai-models-to-apple-silicon","abstract":[{"text":"Learn how to optimize your machine learning and AI models to leverage the power of Apple silicon. Review model conversion workflows to prepare your models for on-device deployment. Understand model compression techniques that are compatible with Apple silicon, and at what stages in your model deployment workflow you can apply them. We’ll also explore the tradeoffs between storage size, latency, power usage and accuracy.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10200-Extend-your-Xcode-Cloud-workflows":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10200-Extend-your-Xcode-Cloud-workflows","kind":"article","role":"sampleCode","abstract":[{"type":"text","text":"Discover how Xcode Cloud can adapt to your development needs. We’ll show you how to streamline your workflows, automate testing and distribution with start conditions, custom aliases, custom scripts, webhooks, and the App Store Connect API."}],"title":"Extend your Xcode Cloud workflows","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10200-extend-your-xcode-cloud-workflows"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10197-Go-small-with-Embedded-Swift":{"role":"sampleCode","type":"topic","title":"Go small with Embedded Swift","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10197-Go-small-with-Embedded-Swift","url":"\/documentation\/wwdcnotes\/wwdc24-10197-go-small-with-embedded-swift","abstract":[{"text":"Embedded Swift brings the safety and expressivity of Swift to constrained environments. Explore how Embedded Swift runs on a variety of microcontrollers through a demonstration using an off-the-shelf Matter device. Learn how the Embedded Swift subset packs the benefits of Swift into a tiny footprint with no runtime, and discover plenty of resources to start your own Embedded Swift adventure.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10181-Xcode-essentials":{"title":"Xcode essentials","kind":"article","type":"topic","abstract":[{"text":"Edit, debug, commit, repeat. Explore the suite of tools in Xcode that help you iterate quickly when developing apps. Discover tips and tricks to help optimize and boost your development workflow.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10181-Xcode-essentials","url":"\/documentation\/wwdcnotes\/wwdc24-10181-xcode-essentials","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10069-Broadcast-updates-to-your-Live-Activities":{"title":"Broadcast updates to your Live Activities","kind":"article","type":"topic","abstract":[{"text":"With broadcast push notifications, your app can send updates to thousands of Live Activities with a single request. We’ll discover how broadcast push notifications work between an app, a server, and the Apple Push Notification service, then we’ll walk through best practices for this capability and how to implement it.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10069-Broadcast-updates-to-your-Live-Activities","url":"\/documentation\/wwdcnotes\/wwdc24-10069-broadcast-updates-to-your-live-activities","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10201-Customize-spatial-Persona-templates-in-SharePlay":{"title":"Customize spatial Persona templates in SharePlay","kind":"article","type":"topic","abstract":[{"text":"Learn how to use custom spatial Persona templates in your visionOS SharePlay experience to fine-tune the placement of Personas relative to your app. We’ll show you how to adopt custom spatial Persona templates in a sample app with SharePlay, move participants between seats, and test your changes in Simulator. We’ll also share best practices for designing custom spatial templates that will make your experience shine.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10201-Customize-spatial-Persona-templates-in-SharePlay","url":"\/documentation\/wwdcnotes\/wwdc24-10201-customize-spatial-persona-templates-in-shareplay","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24":{"kind":"article","role":"collectionGroup","type":"topic","abstract":[{"type":"text","text":"Xcode 16, Swift 6, iOS 18, macOS 15, tvOS 18, visionOS 2, watchOS 11."},{"type":"text","text":" "},{"type":"text","text":"New APIs: Swift Testing, "},{"code":"FinanceKit","type":"codeVoice"},{"type":"text","text":", "},{"code":"TabletopKit","type":"codeVoice"},{"type":"text","text":", and more."}],"title":"WWDC24","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"url":"\/documentation\/wwdcnotes\/wwdc24"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10086-Design-great-visionOS-apps":{"type":"topic","kind":"article","title":"Design great visionOS apps","url":"\/documentation\/wwdcnotes\/wwdc24-10086-design-great-visionos-apps","abstract":[{"text":"Find out how to create compelling spatial computing apps by embracing immersion, designing for eyes and hands, and taking advantage of depth, scale, and space. We’ll share several examples of great visionOS apps and explore how their designers approached creating new experiences for the platform.","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10086-Design-great-visionOS-apps"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10097-Unlock-the-power-of-places-with-MapKit":{"title":"Unlock the power of places with MapKit","kind":"article","type":"topic","abstract":[{"text":"Discover powerful new ways to integrate maps into your apps and websites with MapKit and MapKit JS.  Learn how to save and reference unique places using Place ID. Check out improvements to search that make it more efficient to find relevant places.  Get introduced to the new Place Card API that lets you display rich information about places so customers can explore destinations right in your app. And, we’ll show you quick ways to embed maps in your website with our simplified token provisioning and Web Embed API.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10097-Unlock-the-power-of-places-with-MapKit","url":"\/documentation\/wwdcnotes\/wwdc24-10097-unlock-the-power-of-places-with-mapkit","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10066-Build-immersive-web-experiences-with-WebXR":{"role":"sampleCode","type":"topic","title":"Build immersive web experiences with WebXR","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10066-Build-immersive-web-experiences-with-WebXR","url":"\/documentation\/wwdcnotes\/wwdc24-10066-build-immersive-web-experiences-with-webxr","abstract":[{"text":"Discover how WebXR empowers you to add fully immersive experiences to your website in visionOS. Find out how to build WebXR experiences that take full advantage of the input capabilities of visionOS, and learn how you can use Simulator to test WebXR experiences on macOS.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10103-Discover-RealityKit-APIs-for-iOS-macOS-and-visionOS":{"role":"sampleCode","type":"topic","title":"Discover RealityKit APIs for iOS, macOS and visionOS","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10103-Discover-RealityKit-APIs-for-iOS-macOS-and-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10103-discover-realitykit-apis-for-ios-macos-and-visionos","abstract":[{"type":"text","text":"Learn how new cross-platform APIs in RealityKit can help you build immersive apps for iOS, macOS, and visionOS. Check out the new hover effects, lights and shadows, and portal crossing features, and view them in action through real examples."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-111801-Enhance-your-spatial-computing-app-with-RealityKit-audio":{"title":"Enhance your spatial computing app with RealityKit audio","kind":"article","type":"topic","abstract":[{"text":"Elevate your spatial computing experience using RealityKit audio. Discover how spatial audio can make your 3D immersive experiences come to life. From ambient audio, reverb, to real-time procedural audio that can add character to your 3D content, learn how RealityKit audio APIs can help make your app more engaging.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-111801-Enhance-your-spatial-computing-app-with-RealityKit-audio","url":"\/documentation\/wwdcnotes\/wwdc24-111801-enhance-your-spatial-computing-app-with-realitykit-audio","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10065-Optimize-for-the-spatial-web":{"title":"Optimize for the spatial web","kind":"article","type":"topic","abstract":[{"text":"Discover how to make the most of visionOS capabilities on the web. Explore recent updates like improvements to selection highlighting, and the ability to present spatial photos and panorama images in fullscreen. Learn to take advantage of existing web standards for dictation and text-to-speech with WebSpeech, spatial soundscapes with WebAudio, and immersive experiences with WebXR.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10065-Optimize-for-the-spatial-web","url":"\/documentation\/wwdcnotes\/wwdc24-10065-optimize-for-the-spatial-web","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10168-Get-started-with-Writing-Tools":{"role":"sampleCode","type":"topic","title":"Get started with Writing Tools","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10168-Get-started-with-Writing-Tools","url":"\/documentation\/wwdcnotes\/wwdc24-10168-get-started-with-writing-tools","abstract":[{"text":"Learn how Writing Tools help users proofread, rewrite, and transform text in your app. Get the details on how Writing Tools interact with your app so users can refine what they have written in any text view. Understand how text is retrieved and processed, and how to support Writing Tools in custom text views.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10209-Enhanced-suggestions-for-your-journaling-app":{"role":"sampleCode","type":"topic","title":"Enhanced suggestions for your journaling app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10209-Enhanced-suggestions-for-your-journaling-app","url":"\/documentation\/wwdcnotes\/wwdc24-10209-enhanced-suggestions-for-your-journaling-app","abstract":[{"type":"text","text":"Find out how your journaling app can display journaling suggestions with richer content from the system. Explore new types of available content like state of mind data, reflection prompts, and support for third-party media content and motion-based activities."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10147-Elevate-your-tab-and-sidebar-experience-in-iPadOS":{"role":"sampleCode","type":"topic","title":"Elevate your tab and sidebar experience in iPadOS","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10147-Elevate-your-tab-and-sidebar-experience-in-iPadOS","url":"\/documentation\/wwdcnotes\/wwdc24-10147-elevate-your-tab-and-sidebar-experience-in-ipados","abstract":[{"text":"iPadOS 18 introduces a new navigation system that gives people the flexibility to choose between using a tab bar or sidebar. The newly redesigned tab bar provides more space for content and other functionality. Learn how to use SwiftUI and UIKit to enable customization features – like adding, removing and reordering tabs – to enable a more personal touch in your app.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10104-Build-a-spatial-drawing-app-with-RealityKit":{"role":"sampleCode","type":"topic","title":"Build a spatial drawing app with RealityKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10104-Build-a-spatial-drawing-app-with-RealityKit","url":"\/documentation\/wwdcnotes\/wwdc24-10104-build-a-spatial-drawing-app-with-realitykit","abstract":[{"text":"Harness the power of RealityKit through the process of building a spatial drawing app. As you create an eye-catching spatial experience that integrates RealityKit with ARKit and SwiftUI, you’ll explore how resources work in RealityKit and how to use features like low-level mesh and texture APIs to achieve fast updates of the users’ brush strokes.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10217-Explore-Swift-performance":{"kind":"article","title":"Explore Swift performance","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10217-explore-swift-performance","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10217-Explore-Swift-performance","role":"sampleCode","abstract":[{"type":"text","text":"Discover how Swift balances abstraction and performance. Learn what elements of performance to consider and how the Swift optimizer affects them. Explore the different features of Swift and how they’re implemented to further understand the tradeoffs available that can impact performance."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10162-Keep-colors-consistent-across-captures":{"role":"sampleCode","type":"topic","title":"Keep colors consistent across captures","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10162-Keep-colors-consistent-across-captures","url":"\/documentation\/wwdcnotes\/wwdc24-10162-keep-colors-consistent-across-captures","abstract":[{"text":"Meet the Constant Color API and find out how it can help people use your app to determine precise colors. You’ll learn how to adopt the API, explore its scientific and marketing potential, and discover best practices for making the most of the technology.","type":"text"}],"kind":"article"},"https://developer.apple.com/wwdc24/10166":{"url":"https:\/\/developer.apple.com\/wwdc24\/10166","type":"download","identifier":"https:\/\/developer.apple.com\/wwdc24\/10166","checksum":null},"https://developer.apple.com/videos/play/wwdc2024/10166/?time=790":{"titleInlineContent":[{"text":"File format discussion","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=790","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=790","title":"File format discussion"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10113-Discover-media-performance-metrics-in-AVFoundation":{"role":"sampleCode","type":"topic","title":"Discover media performance metrics in AVFoundation","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10113-Discover-media-performance-metrics-in-AVFoundation","url":"\/documentation\/wwdcnotes\/wwdc24-10113-discover-media-performance-metrics-in-avfoundation","abstract":[{"text":"Discover how you can monitor, analyze, and improve user experience with the new media performance APIs. Explore how to monitor AVPlayer performance for HLS assets using different AVMetricEvents, and learn how to use these metrics to understand and triage player performance issues.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10157-Extend-your-apps-controls-across-the-system":{"title":"Extend your app’s controls across the system","kind":"article","type":"topic","abstract":[{"text":"Bring your app’s controls to Control Center, the Lock Screen, and beyond. Learn how you can use WidgetKit to extend your app’s controls to the system experience. We’ll cover how you can to build a control, tailor its appearance, and make it configurable.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10157-Extend-your-apps-controls-across-the-system","url":"\/documentation\/wwdcnotes\/wwdc24-10157-extend-your-apps-controls-across-the-system","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10220-Bring-expression-to-your-app-with-Genmoji":{"role":"sampleCode","type":"topic","title":"Bring expression to your app with Genmoji","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10220-Bring-expression-to-your-app-with-Genmoji","url":"\/documentation\/wwdcnotes\/wwdc24-10220-bring-expression-to-your-app-with-genmoji","abstract":[{"type":"text","text":"Discover how to bring Genmoji to life in your app. We’ll go over how to render, store, and communicate text that includes Genmoji. If your app features a custom text engine, we’ll also cover techniques for adding support for Genmoji."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10094-Explore-game-input-in-visionOS":{"role":"sampleCode","type":"topic","title":"Explore game input in visionOS","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10094-Explore-game-input-in-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10094-explore-game-input-in-visionos","abstract":[{"type":"text","text":"Discover how to design and implement great input for your game in visionOS. Learn how system gestures let you provide frictionless ways for players to interact with your games. And explore best practices for supporting custom gestures and game controllers."}],"kind":"article"},"WWDCNotes.png":{"type":"image","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}],"identifier":"WWDCNotes.png"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10132-Evolve-your-document-launch-experience":{"role":"sampleCode","type":"topic","title":"Evolve your document launch experience","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10132-Evolve-your-document-launch-experience","url":"\/documentation\/wwdcnotes\/wwdc24-10132-evolve-your-document-launch-experience","abstract":[{"text":"Make your document-based app stand out, and bring its unique identity into focus with the new document launch experience. Learn how to leverage the new API to customize the first screen people see when they launch your app. Utilize the new system-provided design, and amend it with custom actions, delightful decorative views, and impressive animations.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10070-Customize-feature-discovery-with-TipKit":{"kind":"article","role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Focused on feature discovery, the TipKit framework makes it easy to display tips in your app. Now you can group tips so features are discovered in the ideal order, make tips reusable with custom tip identifiers, match the look and feel to your app, and sync tips using CloudKit. Learn how you can use the latest advances in TipKit to help people discover everything your app has to offer."}],"title":"Customize feature discovery with TipKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10070-Customize-feature-discovery-with-TipKit","url":"\/documentation\/wwdcnotes\/wwdc24-10070-customize-feature-discovery-with-tipkit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10146-Demystify-SwiftUI-containers":{"title":"Demystify SwiftUI containers","kind":"article","type":"topic","abstract":[{"text":"Learn about the capabilities of SwiftUI container views and build a mental model for how subviews are managed by their containers. Leverage new APIs to build your own custom containers, create modifiers to customize container content, and give your containers that extra polish that helps your apps stand out.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10146-Demystify-SwiftUI-containers","url":"\/documentation\/wwdcnotes\/wwdc24-10146-demystify-swiftui-containers","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10198-Run-Break-Inspect-Explore-effective-debugging-in-LLDB":{"role":"sampleCode","type":"topic","title":"Run, Break, Inspect: Explore effective debugging in LLDB","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10198-Run-Break-Inspect-Explore-effective-debugging-in-LLDB","url":"\/documentation\/wwdcnotes\/wwdc24-10198-run-break-inspect-explore-effective-debugging-in-lldb","abstract":[{"text":"Learn how to use LLDB to explore and debug codebases. We’ll show you how to make the most of crashlogs and backtraces, and how to supercharge breakpoints with actions and complex stop conditions. We’ll also explore how the “p” command and the latest features in Swift 6 can enhance your debugging experience.","type":"text"}],"kind":"article"},"https://developer.apple.com/videos/play/wwdc2024/10166/?time=253":{"titleInlineContent":[{"text":"4:13 - Tour of the new APIs","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=253","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=253","title":"4:13 - Tour of the new APIs"},"https://developer.apple.com/videos/play/wwdc2024/10166/?time=794":{"titleInlineContent":[{"text":"13:14 - Deep dive into spatial media formats","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=794","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=794","title":"13:14 - Deep dive into spatial media formats"},"https://github.com/halmueller":{"titleInlineContent":[{"text":"GitHub","type":"text"}],"url":"https:\/\/github.com\/halmueller","type":"link","identifier":"https:\/\/github.com\/halmueller","title":"GitHub"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10083-Get-started-with-HealthKit-in-visionOS":{"type":"topic","kind":"article","title":"Get started with HealthKit in visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10083-get-started-with-healthkit-in-visionos","abstract":[{"text":"Discover how to use HealthKit to create experiences that take full advantage of the spatial canvas. Learn the capabilities of HealthKit on the platform, find out how to bring an existing iPadOS app to visionOS, and explore the special considerations governing HealthKit during a Guest User session. You’ll also learn ways to use SwiftUI, Swift Charts, and Swift concurrency to craft innovative experiences with HealthKit.","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10083-Get-started-with-HealthKit-in-visionOS"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10110-Implement-App-Store-Offers":{"kind":"article","title":"Implement App Store Offers","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10110-implement-app-store-offers","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10110-Implement-App-Store-Offers","role":"sampleCode","abstract":[{"type":"text","text":"Learn how to engage customers with App Store Offers using App Store Connect, as well as the latest StoreKit features and APIs. Discover how you can set up win-back offers (a new way to re-engage previous subscribers) and generate offer codes for Mac apps. And find out how to test offers in sandbox and Xcode to make sure they work smoothly."}]},"https://developer.apple.com/videos/play/wwdc2024/10166/?time=450":{"titleInlineContent":[{"text":"Enhancements:","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=450","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=450","title":"Enhancements:"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10098-Design-Live-Activities-for-Apple-Watch":{"role":"sampleCode","type":"topic","title":"Design Live Activities for Apple Watch","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10098-Design-Live-Activities-for-Apple-Watch","url":"\/documentation\/wwdcnotes\/wwdc24-10098-design-live-activities-for-apple-watch","abstract":[{"text":"Starting in watchOS 11, Live Activities from your iOS app will automatically appear in the Smart Stack on a connected Apple Watch. Learn how to optimize the layout of your Live Activity for the wrist, and provide the right level of information and interactivity at the right time.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10186-Optimize-your-3D-assets-for-spatial-computing":{"role":"sampleCode","type":"topic","title":"Optimize your 3D assets for spatial computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10186-Optimize-your-3D-assets-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc24-10186-optimize-your-3d-assets-for-spatial-computing","abstract":[{"text":"Dive into an end-to-end workflow for optimized 3D asset creation. Discover best practices for optimizing meshes, materials, and textures in your digital content creation tool. Learn how to harness shader graph, baking, and material instances to enhance your 3D scene while optimizing performance. Take advantage of native tools to work more effectively with your assets and improve your app’s performance.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10216-Explore-the-Swift-on-Server-ecosystem":{"abstract":[{"type":"text","text":"Swift is a great language for writing your server applications, and powers critical services across Apple’s cloud products. We’ll explore tooling, delve into the Swift server package ecosystem, and demonstrate how to interact with databases and add observability to applications."}],"kind":"article","title":"Explore the Swift on Server ecosystem","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10216-Explore-the-Swift-on-Server-ecosystem","role":"sampleCode","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10216-explore-the-swift-on-server-ecosystem"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10068-Bring-your-Live-Activity-to-Apple-Watch":{"role":"sampleCode","type":"topic","title":"Bring your Live Activity to Apple Watch","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10068-Bring-your-Live-Activity-to-Apple-Watch","url":"\/documentation\/wwdcnotes\/wwdc24-10068-bring-your-live-activity-to-apple-watch","abstract":[{"type":"text","text":"Bring Live Activities into the Smart Stack on Apple Watch with iOS 18 and watchOS 11. We’ll cover how Live Activities are presented on Apple Watch, as well as how you can enhance their presentation for the Smart Stack. We’ll also explore additional considerations to ensure Live Activities on Apple Watch always present up-to-date information."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10153-Dive-deep-into-volumes-and-immersive-spaces":{"title":"Dive deep into volumes and immersive spaces","kind":"article","type":"topic","abstract":[{"text":"Discover powerful new ways to customize volumes and immersive spaces in visionOS. Learn to fine-tune how volumes resize and respond to people moving around them. Make volumes and immersive spaces interact through the power of coordinate conversions. Find out how to make your app react when people adjust immersion with the Digital Crown, and use a surrounding effect to dynamically customize the passthrough tint in your immersive space experience.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10153-Dive-deep-into-volumes-and-immersive-spaces","url":"\/documentation\/wwdcnotes\/wwdc24-10153-dive-deep-into-volumes-and-immersive-spaces","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10171-Demystify-explicitly-built-modules":{"title":"Demystify explicitly built modules","kind":"article","type":"topic","abstract":[{"text":"Explore how builds are changing in Xcode 16 with explicitly built modules. Discover how modules are used to build your code, how explicitly built modules improve transparency in compilation tasks, and how you can optimize your build by sharing modules across targets.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10171-Demystify-explicitly-built-modules","url":"\/documentation\/wwdcnotes\/wwdc24-10171-demystify-explicitly-built-modules","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10195-Go-further-with-Swift-Testing":{"role":"sampleCode","type":"topic","title":"Go further with Swift Testing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10195-Go-further-with-Swift-Testing","url":"\/documentation\/wwdcnotes\/wwdc24-10195-go-further-with-swift-testing","abstract":[{"text":"Learn how to write a sweet set of (test) suites using Swift Testing’s baked-in features. Discover how to take the building blocks further and use them to help expand tests to cover more scenarios, organize your tests across different suites, and optimize your tests to run in parallel.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10096-Design-interactive-experiences-for-visionOS":{"role":"sampleCode","type":"topic","title":"Design interactive experiences for visionOS","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10096-Design-interactive-experiences-for-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10096-design-interactive-experiences-for-visionos","abstract":[{"text":"Learn how you can design a compelling interactive narrative experience for Apple Vision Pro from the designers of Encounter Dinosaurs. Discover how these types of experiences differ from existing apps, media, and games, and explore how to design narratives that bring audiences into new worlds. Find out how you can create stories that adapt to any space and size, provide multiple levels of interaction to make them accessible to all, and use animation, spatial audio, and custom gestures to further immerse people in your experience.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10148-Tailor-macOS-windows-with-SwiftUI":{"role":"sampleCode","type":"topic","title":"Tailor macOS windows with SwiftUI","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10148-Tailor-macOS-windows-with-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc24-10148-tailor-macos-windows-with-swiftui","abstract":[{"type":"text","text":"Make your windows feel tailor-made for macOS. Fine-tune your app’s windows for focused purposes, ease of use, and to express functionality. Use SwiftUI to style window toolbars and backgrounds. Arrange your windows with precision, and make smart decisions about restoration and minimization."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10101-Explore-object-tracking-for-visionOS":{"role":"sampleCode","type":"topic","title":"Explore object tracking for visionOS","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10101-Explore-object-tracking-for-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10101-explore-object-tracking-for-visionos","abstract":[{"text":"Find out how you can use object tracking to turn real-world objects into virtual anchors in your visionOS app. Learn how you can build spatial experiences with object tracking from start to finish. Find out how to create a reference object using machine learning in Create ML and attach content relative to your target object in Reality Composer Pro, RealityKit or ARKit APIs.","type":"text"}],"kind":"article"},"https://developer.apple.com/videos/play/wwdc2024/10166/?time=0":{"titleInlineContent":[{"text":"0:00 - Introduction","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=0","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=0","title":"0:00 - Introduction"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10100-Create-enhanced-spatial-computing-experiences-with-ARKit":{"title":"Create enhanced spatial computing experiences with ARKit","kind":"article","type":"topic","abstract":[{"text":"Learn how to create captivating immersive experiences with ARKit’s latest features. Explore ways to use room tracking and object tracking to further engage with your surroundings. We’ll also share how your app can react to changes in your environment’s lighting on this platform. Discover improvements in hand tracking and plane detection which can make your spatial experiences more intuitive.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10100-Create-enhanced-spatial-computing-experiences-with-ARKit","url":"\/documentation\/wwdcnotes\/wwdc24-10100-create-enhanced-spatial-computing-experiences-with-arkit","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10116-Explore-multiview-video-playback-in-visionOS":{"type":"topic","role":"sampleCode","title":"Explore multiview video playback in visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10116-explore-multiview-video-playback-in-visionos","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10116-Explore-multiview-video-playback-in-visionOS","abstract":[{"type":"text","text":"Learn how AVExperienceController can enable playback of multiple videos on Apple Vision Pro. Review best practices for adoption and explore great use cases, like viewing a sports broadcast from different angles or watching multiple games simultaneously. And discover how to design a compelling and intuitive multiview experience in your app."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10062-Explore-App-Store-server-APIs-for-InApp-Purchase":{"role":"sampleCode","type":"topic","title":"Explore App Store server APIs for In-App Purchase","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10062-Explore-App-Store-server-APIs-for-InApp-Purchase","url":"\/documentation\/wwdcnotes\/wwdc24-10062-explore-app-store-server-apis-for-inapp-purchase","abstract":[{"text":"Learn how to leverage your server to build great In-App Purchase experiences with the latest updates to the App Store Server API, App Store Server Notifications, and the open source App Store Server Library. After a recap of current APIs, we’ll introduce updated endpoint functionality, new transaction fields, and a new notification type. We’ll also discuss best practices for the purchase lifecycle, delivering content, and targeting offers, so you can become a server power user.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10163-Discover-Swift-enhancements-in-the-Vision-framework":{"title":"Discover Swift enhancements in the Vision framework","kind":"article","type":"topic","abstract":[{"text":"The Vision Framework API has been redesigned to leverage modern Swift features like concurrency, making it easier and faster to integrate a wide array of Vision algorithms into your app. We’ll tour the updated API and share sample code, along with best practices, to help you get the benefits of this framework with less coding effort. We’ll also demonstrate two new features: image aesthetics and holistic body pose.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10163-Discover-Swift-enhancements-in-the-Vision-framework","url":"\/documentation\/wwdcnotes\/wwdc24-10163-discover-swift-enhancements-in-the-vision-framework","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10155-Swift-Charts-Vectorized-and-function-plots":{"title":"Swift Charts: Vectorized and function plots","kind":"article","type":"topic","abstract":[{"text":"The plot thickens! Learn how to render beautiful charts representing math functions and extensive datasets using function and vectorized plots in your app. Whether you’re looking to display functions common in aerodynamics, magnetism, and higher order field theory, or create large interactive heat maps, Swift Charts has you covered.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10155-Swift-Charts-Vectorized-and-function-plots","url":"\/documentation\/wwdcnotes\/wwdc24-10155-swift-charts-vectorized-and-function-plots","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10161-Deploy-machine-learning-and-AI-models-ondevice-with-Core-ML":{"title":"Deploy machine learning and AI models on-device with Core ML","kind":"article","type":"topic","abstract":[{"text":"Learn new ways to optimize speed and memory performance when you convert and run machine learning and AI models through Core ML. We’ll cover new options for model representations, performance insights, execution, and model stitching which can be used together to create compelling and private on-device experiences.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10161-Deploy-machine-learning-and-AI-models-ondevice-with-Core-ML","url":"\/documentation\/wwdcnotes\/wwdc24-10161-deploy-machine-learning-and-ai-models-ondevice-with-core-ml","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10125-Streamline-signin-with-passkey-upgrades-and-credential-managers":{"title":"Streamline sign-in with passkey upgrades and credential managers","kind":"article","type":"topic","abstract":[{"text":"Learn how to automatically upgrade existing, password-based accounts to use passkeys. We’ll share why and how to improve account security and ease of sign-in, information about new features available for credential manager apps, and how to make your app information shine in the new Passwords app.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10125-Streamline-signin-with-passkey-upgrades-and-credential-managers","url":"\/documentation\/wwdcnotes\/wwdc24-10125-streamline-signin-with-passkey-upgrades-and-credential-managers","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10172-Break-into-the-RealityKit-debugger":{"role":"sampleCode","type":"topic","title":"Break into the RealityKit debugger","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10172-Break-into-the-RealityKit-debugger","url":"\/documentation\/wwdcnotes\/wwdc24-10172-break-into-the-realitykit-debugger","abstract":[{"type":"text","text":"Meet the RealityKit debugger and discover how this new tool lets you inspect the entity hierarchy of spatial apps, debug rogue transformations, find missing entities, and detect which parts of your code are causing problems for your systems."}],"kind":"article"},"https://developer.apple.com/documentation/ImageIO/writing-spatial-photos":{"titleInlineContent":[{"text":"Writing spatial photos","type":"text"}],"url":"https:\/\/developer.apple.com\/documentation\/ImageIO\/writing-spatial-photos","type":"link","identifier":"https:\/\/developer.apple.com\/documentation\/ImageIO\/writing-spatial-photos","title":"Writing spatial photos"},"doc://WWDCNotes/documentation/WWDCNotes/halmueller":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/halmueller","abstract":[{"type":"text","text":"No Bio on GitHub"}],"title":"Hal Mueller (2 notes)","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/halmueller"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10140-Add-personality-to-your-app-through-UX-writing":{"role":"sampleCode","type":"topic","title":"Add personality to your app through UX writing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10140-Add-personality-to-your-app-through-UX-writing","url":"\/documentation\/wwdcnotes\/wwdc24-10140-add-personality-to-your-app-through-ux-writing","abstract":[{"text":"Every app has a personality that comes across in what you say — and how you say it. Learn how to define your app’s voice and modulate your tone for every situation, from celebratory notifications to error messages. We’ll help you get specific about your app’s purpose and audience and practice writing in different tones.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10207-Migrate-your-TVML-app-to-SwiftUI":{"role":"sampleCode","type":"topic","title":"Migrate your TVML app to SwiftUI","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10207-Migrate-your-TVML-app-to-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc24-10207-migrate-your-tvml-app-to-swiftui","abstract":[{"type":"text","text":"SwiftUI helps you build great apps on all Apple platforms and is the preferred toolkit for bringing your content into the living room with tvOS 18. Learn how to use SwiftUI to create familiar layouts and controls from TVMLKit, and get tips and best practices."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10088-Capture-HDR-content-with-ScreenCaptureKit":{"role":"sampleCode","type":"topic","title":"Capture HDR content with ScreenCaptureKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10088-Capture-HDR-content-with-ScreenCaptureKit","url":"\/documentation\/wwdcnotes\/wwdc24-10088-capture-hdr-content-with-screencapturekit","abstract":[{"type":"text","text":"Learn how to capture high dynamic colors using ScreenCaptureKit, and explore new features like HDR support, microphone capture, and straight-to-file recording."}],"kind":"article"},"https://avatars.githubusercontent.com/u/418007?v=4":{"type":"image","alt":"Profile image of Hal Mueller","variants":[{"traits":["1x","light"],"url":"https:\/\/avatars.githubusercontent.com\/u\/418007?v=4"}],"identifier":"https:\/\/avatars.githubusercontent.com\/u\/418007?v=4"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10073-Catch-up-on-accessibility-in-SwiftUI":{"role":"sampleCode","type":"topic","title":"Catch up on accessibility in SwiftUI","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10073-Catch-up-on-accessibility-in-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc24-10073-catch-up-on-accessibility-in-swiftui","abstract":[{"text":"SwiftUI makes it easy to build amazing experiences that are accessible to everyone. We’ll discover how assistive technologies understand and navigate your app through the rich accessibility elements provided by SwiftUI. We’ll also discuss how you can further customize these experiences by providing more information about your app’s content and interactions by using accessibility modifiers.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10112-Say-hello-to-the-next-generation-of-CarPlay-design-system":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10112-Say-hello-to-the-next-generation-of-CarPlay-design-system","kind":"article","role":"sampleCode","abstract":[{"type":"text","text":"Explore the design system at the heart of the next generation of CarPlay that allows each automaker to express your vehicle’s character and brand. Learn how gauges, layouts, dynamic content, and more are deeply customizable and adaptable, allowing you to express your own design philosophy and create an iconic, tailored look. This session is intended for automakers, system developers, and anyone designing a system that supports the next generation of CarPlay."}],"title":"Say hello to the next generation of CarPlay design system","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10112-say-hello-to-the-next-generation-of-carplay-design-system"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10184-A-Swift-Tour-Explore-Swifts-features-and-design":{"title":"A Swift Tour: Explore Swift’s features and design","kind":"article","type":"topic","abstract":[{"text":"Learn the essential features and design philosophy of the Swift programming language. We’ll explore how to model data, handle errors, use protocols, write concurrent code, and more while building up a Swift package that has a library, an HTTP server, and a command line client. Whether you’re just beginning your Swift journey or have been with us from the start, this talk will help you get the most out of the language.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10184-A-Swift-Tour-Explore-Swifts-features-and-design","url":"\/documentation\/wwdcnotes\/wwdc24-10184-a-swift-tour-explore-swifts-features-and-design","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10145-Enhance-your-UI-animations-and-transitions":{"role":"sampleCode","type":"topic","title":"Enhance your UI animations and transitions","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10145-Enhance-your-UI-animations-and-transitions","url":"\/documentation\/wwdcnotes\/wwdc24-10145-enhance-your-ui-animations-and-transitions","abstract":[{"type":"text","text":"Explore how to adopt the zoom transition in navigation and presentations to increase the sense of continuity in your app, and learn how to animate UIKit views with SwiftUI animations to make it easier to build animations that feel continuous."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10074-Get-started-with-Dynamic-Type":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10074-Get-started-with-Dynamic-Type","kind":"article","role":"sampleCode","abstract":[{"type":"text","text":"Dynamic Type lets people choose their preferred text size across the system and all of their apps. To help you get started supporting Dynamic Type, we’ll cover the fundamentals: How it works, how to find issues with scaling text in your app, and how to take practical steps using SwiftUI and UIKit to create a great Dynamic Type experience. We’ll also show how you can best use the Large Content Viewer to make navigation controls accessible to everyone."}],"title":"Get started with Dynamic Type","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10074-get-started-with-dynamic-type"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10169-Migrate-your-app-to-Swift-6":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10169-Migrate-your-app-to-Swift-6","kind":"article","role":"sampleCode","abstract":[{"type":"text","text":"Experience Swift 6 migration in action as we update an existing sample app. Learn how to migrate incrementally, module by module, and how the compiler helps you identify code that’s at risk of data races.  Discover different techniques for ensuring clear isolation boundaries and eliminating concurrent access to shared mutable state."}],"title":"Migrate your app to Swift 6","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10169-migrate-your-app-to-swift-6"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10204-Build-a-great-Lock-Screen-camera-capture-experience":{"abstract":[{"type":"text","text":"Find out how the LockedCameraCapture API can help you bring your capture application’s most useful information directly to the Lock Screen. Examine the API’s features and functionality, learn how to get started creating a capture extension, and find out how that extension behaves when the device is locked."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10204-Build-a-great-Lock-Screen-camera-capture-experience","url":"\/documentation\/wwdcnotes\/wwdc24-10204-build-a-great-lock-screen-camera-capture-experience","role":"sampleCode","kind":"article","type":"topic","title":"Build a great Lock Screen camera capture experience"},"doc://WWDCNotes/documentation/WWDCNotes":{"role":"collection","type":"topic","title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","url":"\/documentation\/wwdcnotes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"kind":"symbol"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10214-Squeeze-the-most-out-of-Apple-Pencil":{"role":"sampleCode","type":"topic","title":"Squeeze the most out of Apple Pencil","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10214-Squeeze-the-most-out-of-Apple-Pencil","url":"\/documentation\/wwdcnotes\/wwdc24-10214-squeeze-the-most-out-of-apple-pencil","abstract":[{"type":"text","text":"New in iOS 18, iPadOS 18, and visionOS 2, the PencilKit tool picker gains the ability to have completely custom tools, with custom attributes. Learn how to express your custom drawing experience in the tool picker using the same great tool picking experience available across the system. Discover how to access the new features of the Apple Pencil Pro, including roll angle, the squeeze gesture, and haptic feedback."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10223-Explore-machine-learning-on-Apple-platforms":{"type":"topic","kind":"article","title":"Explore machine learning on Apple platforms","url":"\/documentation\/wwdcnotes\/wwdc24-10223-explore-machine-learning-on-apple-platforms","abstract":[{"text":"Get started with an overview of machine learning frameworks on Apple platforms. Whether you’re implementing your first ML model, or an ML expert, we’ll offer guidance to help you select the right framework for your app’s needs.","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10223-Explore-machine-learning-on-Apple-platforms"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"link","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10107-Discover-area-mode-for-Object-Capture":{"role":"sampleCode","type":"topic","title":"Discover area mode for Object Capture","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10107-Discover-area-mode-for-Object-Capture","url":"\/documentation\/wwdcnotes\/wwdc24-10107-discover-area-mode-for-object-capture","abstract":[{"text":"Discover how area mode for Object Capture enables new 3D capture possibilities on iOS by extending the functionality of Object Capture to support capture and reconstruction of an area. Learn how to optimize the quality of iOS captures using the new macOS sample app for reconstruction, and find out how to view the final results with Quick Look on Apple Vision Pro, iPhone, iPad or Mac. Learn about improvements to 3D reconstruction, including a new API that allows you to create your own custom image processing pipelines.","type":"text"}],"kind":"article"},"https://developer.apple.com/videos/play/wwdc2024/10166/?time=1276":{"titleInlineContent":[{"text":"21:16 - Wrap-up","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=1276","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=1276","title":"21:16 - Wrap-up"},"https://":{"titleInlineContent":[{"text":"Blog","type":"text"}],"url":"https:\/\/","type":"link","identifier":"https:\/\/","title":"Blog"},"https://developer.apple.com/videos/play/wwdc2024/10166/?time=310":{"titleInlineContent":[{"text":"Code walkthrough: AVCaptureSession to capture spatial video.","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=310","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=310","title":"Code walkthrough: AVCaptureSession to capture spatial video."},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10087-Create-custom-environments-for-your-immersive-apps-in-visionOS":{"title":"Create custom environments for your immersive apps in visionOS","kind":"article","type":"topic","abstract":[{"text":"Discover how to create visually rich and performant customized app environments for Apple Vision Pro. Learn design guidelines, get expert recommendations, and explore techniques you can use in any digital content creation tool to begin building your immersive environment.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10087-Create-custom-environments-for-your-immersive-apps-in-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10087-create-custom-environments-for-your-immersive-apps-in-visionos","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU":{"role":"sampleCode","type":"topic","title":"Support real-time ML inference on the CPU","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU","url":"\/documentation\/wwdcnotes\/wwdc24-10211-support-realtime-ml-inference-on-the-cpu","abstract":[{"type":"text","text":"Discover how you can use BNNSGraph to accelerate the execution of your machine learning model on the CPU. We will show you how to use BNNSGraph to compile and execute a machine learning model on the CPU and share how it provides real-time guarantees such as no runtime memory allocation and single-threaded running for audio or signal processing models."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10085-Design-advanced-games-for-Apple-platforms":{"role":"sampleCode","type":"topic","title":"Design advanced games for Apple platforms","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10085-Design-advanced-games-for-Apple-platforms","url":"\/documentation\/wwdcnotes\/wwdc24-10085-design-advanced-games-for-apple-platforms","abstract":[{"text":"Learn how to adapt your high-end game so it feels at home on Mac, iPad, and iPhone. We’ll go over how to make your game look stunning on different displays, tailor your input and controls to be intuitive on each device, and take advantage of Apple technologies that deliver great player experiences.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10210-Bring-your-apps-core-features-to-users-with-App-Intents":{"kind":"article","role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Learn the principles of the App Intents framework, like intents, entities, and queries, and how you can harness them to expose your app’s most important functionality right where people need it most. Find out how to build deep integration between your app and the many system features built on top of App Intents, including Siri, controls and widgets, Apple Pencil, Shortcuts, the Action button, and more. Get tips on how to build your App Intents integrations efficiently to create the best experiences in every surface while still sharing code and core functionality."}],"title":"Bring your app’s core features to users with App Intents","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10210-Bring-your-apps-core-features-to-users-with-App-Intents","url":"\/documentation\/wwdcnotes\/wwdc24-10210-bring-your-apps-core-features-to-users-with-app-intents"},"https://developer.apple.com/videos/play/wwdc2024/10166/?time=821":{"titleInlineContent":[{"text":"Spatial metadata:","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=821","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=821","title":"Spatial metadata:"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10105-Whats-new-in-Quick-Look-for-visionOS":{"url":"\/documentation\/wwdcnotes\/wwdc24-10105-whats-new-in-quick-look-for-visionos","type":"topic","role":"sampleCode","kind":"article","title":"What’s new in Quick Look for visionOS","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10105-Whats-new-in-Quick-Look-for-visionOS","abstract":[{"type":"text","text":"Explore how Quick Look in visionOS can elevate file preview and editing experiences in your app. We’ll cover the integration of in-app and windowed Quick Look, as well as a brand-new API that customizes the windowed Quick Look experience in your app. We’ll also share the latest enhancements to viewing 3D models within Quick Look."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10160-Train-your-machine-learning-and-AI-models-on-Apple-GPUs":{"type":"topic","kind":"article","title":"Train your machine learning and AI models on Apple GPUs","url":"\/documentation\/wwdcnotes\/wwdc24-10160-train-your-machine-learning-and-ai-models-on-apple-gpus","abstract":[{"text":"Learn how to train your models on Apple Silicon with Metal for PyTorch, JAX and TensorFlow. Take advantage of new attention operations and quantization support for improved transformer model performance on your devices.","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10160-Train-your-machine-learning-and-AI-models-on-Apple-GPUs"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10151-Create-custom-visual-effects-with-SwiftUI":{"role":"sampleCode","type":"topic","title":"Create custom visual effects with SwiftUI","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10151-Create-custom-visual-effects-with-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc24-10151-create-custom-visual-effects-with-swiftui","abstract":[{"text":"Discover how to create stunning visual effects in SwiftUI. Learn to build unique scroll effects, rich color treatments, and custom transitions. We’ll also explore advanced graphic effects using Metal shaders and custom text rendering.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10133-Bring-your-app-to-Siri":{"role":"sampleCode","type":"topic","title":"Bring your app to Siri","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10133-Bring-your-app-to-Siri","url":"\/documentation\/wwdcnotes\/wwdc24-10133-bring-your-app-to-siri","abstract":[{"text":"Learn how to use App Intents to expose your app’s functionality to Siri. Understand which intents are already available for your use, and how to create custom intents to integrate actions from your app into the system. We’ll also cover what metadata to provide, making your entities searchable via Spotlight, annotating onscreen references, and much more.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10138-Create-a-custom-data-store-with-SwiftData":{"title":"Create a custom data store with SwiftData","kind":"article","type":"topic","abstract":[{"text":"Combine the power of SwiftData’s expressive, declarative modeling API with your own persistence backend. Learn how to build a custom data store and explore how to progressively add persistence features in your app. To get the most out of this session, watch “Meet SwiftData” and “Model your schema with SwiftData” from WWDC23.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10138-Create-a-custom-data-store-with-SwiftData","url":"\/documentation\/wwdcnotes\/wwdc24-10138-create-a-custom-data-store-with-swiftdata","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10170-Consume-noncopyable-types-in-Swift":{"role":"sampleCode","type":"topic","title":"Consume noncopyable types in Swift","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10170-Consume-noncopyable-types-in-Swift","url":"\/documentation\/wwdcnotes\/wwdc24-10170-consume-noncopyable-types-in-swift","abstract":[{"type":"text","text":"Get started with noncopyable types in Swift. Discover what copying means in Swift, when you might want to use a noncopyable type, and how value ownership lets you state your intentions clearly."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10093-Bring-your-iOS-or-iPadOS-game-to-visionOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10093-Bring-your-iOS-or-iPadOS-game-to-visionOS","kind":"article","role":"sampleCode","abstract":[{"type":"text","text":"Discover how to transform your iOS or iPadOS game into a uniquely visionOS experience. Increase the immersion (and fun factor!) with a 3D frame or an immersive background. And invite players further into your world by adding depth to the window with stereoscopy or head tracking."}],"title":"Bring your iOS or iPadOS game to visionOS","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10093-bring-your-ios-or-ipados-game-to-visionos"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10114-Enhance-ad-experiences-with-HLS-interstitials":{"title":"Enhance ad experiences with HLS interstitials","kind":"article","type":"topic","abstract":[{"text":"Explore how HLS Interstitials can help you seamlessly insert advertisements into your HLS content. We’ll also show you how to use integrated timeline to tune your UI experience and build SharePlay for interstitials.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10114-Enhance-ad-experiences-with-HLS-interstitials","url":"\/documentation\/wwdcnotes\/wwdc24-10114-enhance-ad-experiences-with-hls-interstitials","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10102-Compose-interactive-3D-content-in-Reality-Composer-Pro":{"type":"topic","role":"sampleCode","title":"Compose interactive 3D content in Reality Composer Pro","url":"\/documentation\/wwdcnotes\/wwdc24-10102-compose-interactive-3d-content-in-reality-composer-pro","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10102-Compose-interactive-3D-content-in-Reality-Composer-Pro","abstract":[{"type":"text","text":"Discover how the Timeline view in Reality Composer Pro can bring your 3D content to life. Learn how to create an animated story in which characters and objects interact with each other and the world around them using inverse kinematics, blend shapes, and skeletal poses. We’ll also show you how to use built-in and custom actions, sequence your actions, apply triggers, and implement natural movements."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10152-Create-custom-hover-effects-in-visionOS":{"type":"topic","kind":"article","title":"Create custom hover effects in visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10152-create-custom-hover-effects-in-visionos","abstract":[{"text":"Learn how to develop custom hover effects that update views when people look at them. Find out how to build an expanding button effect that combines opacity, scale, and clip effects. Discover best practices for creating effects that are comfortable and respect people’s accessibility needs.","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10152-Create-custom-hover-effects-in-visionOS"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10075-Track-model-changes-with-SwiftData-history":{"title":"Track model changes with SwiftData history","kind":"article","type":"topic","abstract":[{"text":"Reveal the history of your model’s changes with SwiftData! Use the history API to understand when data store changes occurred, and learn how to use this information to build features like remote server sync and out-of-process change handing in your app. We’ll also cover how you can build support for the history API into a custom data store.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10075-Track-model-changes-with-SwiftData-history","url":"\/documentation\/wwdcnotes\/wwdc24-10075-track-model-changes-with-swiftdata-history","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10067-Bring-context-to-todays-weather":{"title":"Bring context to today’s weather","kind":"article","type":"topic","abstract":[{"text":"Harness the power of WeatherKit to get detailed weather forecast data such as precipitation amounts by type, cloud cover by altitude, or maximum wind speed. Find out how you can summarize weather by different parts of the day and highlight significant upcoming changes to temperature or precipitation. Understand how you can compare current weather to the past through our Historical Comparisons dataset and dive into historical weather statistics for any location in the world. We’ll also explore how you can do all of this faster with our Swift and REST APIs.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10067-Bring-context-to-todays-weather","url":"\/documentation\/wwdcnotes\/wwdc24-10067-bring-context-to-todays-weather","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10071-Deliver-video-content-for-spatial-experiences":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences","role":"sampleCode","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10071-deliver-video-content-for-spatial-experiences","kind":"article","title":"Deliver video content for spatial experiences","abstract":[{"text":"Learn how to prepare and deliver video content for visionOS using HTTP Live Streaming (HLS). Discover the current HLS delivery process for media and explore how you can expand your delivery pipeline to support 3D content. Get up to speed with tips and techniques for spatial media streaming and adapting your existing caption production workflows for 3D. And find out how to share audio tracks across video variants and add spatial audio to make your video content more immersive.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10149-Work-with-windows-in-SwiftUI":{"title":"Work with windows in SwiftUI","kind":"article","type":"topic","abstract":[{"text":"Learn how to create great single and multi-window apps in visionOS, macOS, and iPadOS. Discover tools that let you programmatically open and close windows, adjust position and size, and even replace one window with another. We’ll also explore design principles for windows that help people use your app within their workflows.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10149-Work-with-windows-in-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc24-10149-work-with-windows-in-swiftui","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10092-Render-Metal-with-passthrough-in-visionOS":{"role":"sampleCode","type":"topic","title":"Render Metal with passthrough in visionOS","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10092-Render-Metal-with-passthrough-in-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10092-render-metal-with-passthrough-in-visionos","abstract":[{"type":"text","text":"Get ready to extend your Metal experiences for visionOS. Learn best practices for integrating your rendered content with people’s physical environments with passthrough. Find out how to position rendered content to match the physical world, reduce latency with trackable anchor prediction, and more."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10185-Build-multilingualready-apps":{"title":"Build multilingual-ready apps","kind":"article","type":"topic","abstract":[{"text":"Ensure your app works properly and effectively for multilingual users. Learn best practices for text input, display, search, and formatting. Get details on typing in multiple languages without switching between keyboards. And find out how the latest advances in the String Catalog can make localization even easier.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10185-Build-multilingualready-apps","url":"\/documentation\/wwdcnotes\/wwdc24-10185-build-multilingualready-apps","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10177-Use-HDR-for-dynamic-image-experiences-in-your-app":{"role":"sampleCode","type":"topic","title":"Use HDR for dynamic image experiences in your app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10177-Use-HDR-for-dynamic-image-experiences-in-your-app","url":"\/documentation\/wwdcnotes\/wwdc24-10177-use-hdr-for-dynamic-image-experiences-in-your-app","abstract":[{"type":"text","text":"Discover how to read and write HDR images and process HDR content in your app. Explore the new supported HDR image formats and advanced methods for displaying HDR images. Find out how HDR content can coexist with your user interface — and what to watch out for when adding HDR image support to your app."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10089-Port-advanced-games-to-Apple-platforms":{"title":"Port advanced games to Apple platforms","kind":"article","type":"topic","abstract":[{"text":"Discover how simple it can be to reach players on Apple platforms worldwide. We’ll show you how to evaluate your Windows executable on Apple silicon, start your game port with code samples, convert your shader code to Metal, and bring your game to Mac, iPhone, and iPad. Explore enhanced Metal tools that understand HLSL shaders to validate, debug, and profile your ported shaders on Metal.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10089-Port-advanced-games-to-Apple-platforms","url":"\/documentation\/wwdcnotes\/wwdc24-10089-port-advanced-games-to-apple-platforms","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10173-Analyze-heap-memory":{"role":"sampleCode","type":"topic","title":"Analyze heap memory","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10173-Analyze-heap-memory","url":"\/documentation\/wwdcnotes\/wwdc24-10173-analyze-heap-memory","abstract":[{"text":"Dive into the basis for your app’s dynamic memory: the heap! Explore how to use Instruments and Xcode to measure, analyze, and fix common heap issues. We’ll also cover some techniques and best practices for diagnosing transient growth, persistent growth, and leaks in your app.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10122-Use-CloudKit-Console-to-monitor-and-optimize-database-activity":{"abstract":[{"type":"text","text":"Discover the new observability features in CloudKit Console. Learn how to use Telemetry and Logging to troubleshoot and optimize your app. Find out how to set up alerts to monitor your application’s behavior and notifications to stay on top of the container events that are most important to you."}],"kind":"article","title":"Use CloudKit Console to monitor and optimize database activity","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10122-Use-CloudKit-Console-to-monitor-and-optimize-database-activity","role":"sampleCode","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10122-use-cloudkit-console-to-monitor-and-optimize-database-activity"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10218-Accelerate-machine-learning-with-Metal":{"title":"Accelerate machine learning with Metal","kind":"article","type":"topic","abstract":[{"text":"Learn how to accelerate your machine learning transformer models with new features in Metal Performance Shaders Graph. We’ll also cover how to improve your model’s compute bandwidth and quality, and visualize it in the all new MPSGraph viewer.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10218-Accelerate-machine-learning-with-Metal","url":"\/documentation\/wwdcnotes\/wwdc24-10218-accelerate-machine-learning-with-metal","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10084-Build-custom-swimming-workouts-with-WorkoutKit":{"title":"Build custom swimming workouts with WorkoutKit","kind":"article","type":"topic","abstract":[{"text":"Check out the latest in creating, customizing, and scheduling workouts using WorkoutKit. Sprint through the latest in pace and power alerts and expanded support for distance goals. And keep the momentum going with the benefits of custom step names.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10084-Build-custom-swimming-workouts-with-WorkoutKit","url":"\/documentation\/wwdcnotes\/wwdc24-10084-build-custom-swimming-workouts-with-workoutkit","role":"sampleCode"},"https://developer.apple.com/videos/play/wwdc2024/10166/?time=67":{"titleInlineContent":[{"text":"1:07 - Types of stereoscopic experiences","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=67","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10166\/?time=67","title":"1:07 - Types of stereoscopic experiences"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10176-Design-App-Intents-for-system-experiences":{"title":"Design App Intents for system experiences","kind":"article","type":"topic","abstract":[{"text":"App Intents power system experiences in controls, Spotlight, Siri, and more. Find out how to identify the functionality that’s best for App Intents, and how to use parameters to make these intents flexible. Learn how to use App Intents to allow people to take action outside your app, and see examples of when to navigate into your app to show contextual information.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10176-Design-App-Intents-for-system-experiences","url":"\/documentation\/wwdcnotes\/wwdc24-10176-design-app-intents-for-system-experiences","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10115-Enhance-the-immersion-of-media-viewing-in-custom-environments":{"abstract":[{"text":"Extend your media viewing experience using Reality Composer Pro components like Docking Region, Reverb, and Virtual Environment Probe. Find out how to further enhance immersion using Reflections, Tint Surroundings Effect, SharePlay, and the Immersive Environment Picker.","type":"text"}],"kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10115-Enhance-the-immersion-of-media-viewing-in-custom-environments","title":"Enhance the immersion of media viewing in custom environments","url":"\/documentation\/wwdcnotes\/wwdc24-10115-enhance-the-immersion-of-media-viewing-in-custom-environments"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10131-Support-semantic-search-with-Core-Spotlight":{"role":"sampleCode","type":"topic","title":"Support semantic search with Core Spotlight","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10131-Support-semantic-search-with-Core-Spotlight","url":"\/documentation\/wwdcnotes\/wwdc24-10131-support-semantic-search-with-core-spotlight","abstract":[{"type":"text","text":"Learn how to provide semantic search results in your app using Core Spotlight. Understand how to make your app’s content available in the user’s private, on-device index so people can search for items using natural language. We’ll also share how to optimize your app’s performance by scheduling indexing activities."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10109-Explore-wellbeing-APIs-in-HealthKit":{"abstract":[{"type":"text","text":"Learn how to incorporate mental health and wellbeing into your app using HealthKit. There are new APIs for State of Mind, as well as for Depression Risk and Anxiety Risk. We’ll dive into principles of emotion science to cover how reflecting on feelings can be beneficial, and how State of Mind can be used to represent different types of mood and emotion."}],"kind":"article","title":"Explore wellbeing APIs in HealthKit","type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10109-Explore-wellbeing-APIs-in-HealthKit","url":"\/documentation\/wwdcnotes\/wwdc24-10109-explore-wellbeing-apis-in-healthkit"}}}