{"kind":"article","hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22"]]},"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc22\/10026","type":"reference","overridingTitle":"Watch Video (14 min)"}},"metadata":{"modules":[{"name":"WWDC Notes"}],"title":"Add Live Text interaction to your app","role":"sampleCode","roleHeading":"WWDC22"},"primaryContentSections":[{"kind":"content","content":[{"type":"heading","text":"Overview","anchor":"overview","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:"},{"type":"text","text":" "},{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference","isActive":true}]},{"anchor":"Related-Sessions","type":"heading","level":2,"text":"Related Sessions"},{"style":"list","type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10048-Whats-new-in-VisionKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10025-Capture-machinereadable-codes-and-text-with-VisionKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10147-Create-a-great-video-playback-experience"]}]}],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc22-10026-add-live-text-interaction-to-your-app"],"traits":[{"interfaceLanguage":"swift"}]}],"schemaVersion":{"patch":0,"major":0,"minor":3},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10026-Add-Live-Text-interaction-to-your-app"},"abstract":[{"text":"Learn how you can bring Live Text support for still photos or paused video frames to your app. We‚Äôll share how you can easily enable text interactions, translation, data detection, and QR code scanning within any image view on iOS, iPadOS, or macOS. We‚Äôll also go over how to control interaction types, manage the supplementary interface, and resolve potential gesture conflicts.","type":"text"}],"sections":[],"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10147-Create-a-great-video-playback-experience":{"type":"topic","abstract":[{"type":"text","text":"Find out how you can use the latest iOS and iPadOS system media players to build amazing media apps. We‚Äôll share how we designed the updated player and give you best practices and tips to help you design media experiences of your own. We‚Äôll also explore Live Text for video and show you how to integrate interstitials and playback speed controls into your apps."}],"title":"Create a great video playback experience","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc22-10147-create-a-great-video-playback-experience","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10147-Create-a-great-video-playback-experience"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22":{"kind":"article","title":"WWDC22","role":"collectionGroup","url":"\/documentation\/wwdcnotes\/wwdc22","images":[{"identifier":"WWDC22-Icon.png","type":"icon"},{"identifier":"WWDC22.jpeg","type":"card"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22","abstract":[{"text":"Xcode 14, Swift 5.7, iOS 16, macOS 13 (Ventura), tvOS 16, watchOS 9.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"code":"WeatherKit","type":"codeVoice"},{"text":", ","type":"text"},{"code":"ScreenCaptureKit","type":"codeVoice"},{"text":", ","type":"text"},{"code":"Swift Regex","type":"codeVoice"},{"text":", and more.","type":"text"}]},"WWDCNotes.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}],"identifier":"WWDCNotes.png","type":"image","alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10048-Whats-new-in-VisionKit":{"type":"topic","title":"What‚Äôs new in VisionKit","abstract":[{"type":"text","text":"Discover how VisionKit can help people quickly lift subjects from images in your app and learn more about the content of an image with Visual Look Up. We‚Äôll also take a tour of the latest updates to VisionKit for Live Text interaction, data scanning, and expanded support for macOS apps."}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10048-Whats-new-in-VisionKit","url":"\/documentation\/wwdcnotes\/wwdc23-10048-whats-new-in-visionkit","role":"sampleCode"},"WWDC22.jpeg":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC22.jpeg"}],"identifier":"WWDC22.jpeg","type":"image","alt":null},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}],"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","type":"link","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"https://developer.apple.com/wwdc22/10026":{"checksum":null,"identifier":"https:\/\/developer.apple.com\/wwdc22\/10026","type":"download","url":"https:\/\/developer.apple.com\/wwdc22\/10026"},"WWDC22-Icon.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC22-Icon.png"}],"identifier":"WWDC22-Icon.png","type":"image","alt":null},"doc://WWDCNotes/documentation/WWDCNotes":{"title":"WWDC Notes","type":"topic","url":"\/documentation\/wwdcnotes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","kind":"symbol","role":"collection","images":[{"type":"icon","identifier":"WWDCNotes.png"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10025-Capture-machinereadable-codes-and-text-with-VisionKit":{"role":"sampleCode","abstract":[{"text":"Meet the Data Scanner in VisionKit: This framework combines AVCapture and Vision to enable live capture of machine-readable codes and text through a simple Swift API. We‚Äôll show you how to control the types of content your app can capture by specifying barcode symbologies and language selection. We‚Äôll also explore how you can enable guidance in your app, customize item highlighting or regions of interest, and handle interactions after your app detects an item.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc22-10025-capture-machinereadable-codes-and-text-with-visionkit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10025-Capture-machinereadable-codes-and-text-with-VisionKit","kind":"article","title":"Capture machine-readable codes and text with VisionKit"}}}