{"metadata":{"modules":[{"name":"WWDC Notes"}],"role":"sampleCode","title":"Add Live Text interaction to your app","roleHeading":"WWDC22"},"kind":"article","abstract":[{"type":"text","text":"Learn how you can bring Live Text support for still photos or paused video frames to your app. We‚Äôll share how you can easily enable text interactions, translation, data detection, and QR code scanning within any image view on iOS, iPadOS, or macOS. We‚Äôll also go over how to control interaction types, manage the supplementary interface, and resolve potential gesture conflicts."}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22"]]},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc22-10026-add-live-text-interaction-to-your-app"],"traits":[{"interfaceLanguage":"swift"}]}],"primaryContentSections":[{"content":[{"anchor":"overview","type":"heading","text":"Overview","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true}]},{"anchor":"Related-Sessions","type":"heading","text":"Related Sessions","level":2},{"style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10048-Whats-new-in-VisionKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10025-Capture-machinereadable-codes-and-text-with-VisionKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10147-Create-a-great-video-playback-experience"],"type":"links"},{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Legal Notice"}]}],"type":"small"},{"inlineContent":[{"type":"text","text":"All content copyright ¬© 2012 ‚Äì 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}],"kind":"content"}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10026-Add-Live-Text-interaction-to-your-app","interfaceLanguage":"swift"},"sections":[],"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"overridingTitle":"Watch Video (14 min)","type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc22\/10026"}},"schemaVersion":{"minor":3,"patch":0,"major":0},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10147-Create-a-great-video-playback-experience":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10147-Create-a-great-video-playback-experience","title":"Create a great video playback experience","type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10147-create-a-great-video-playback-experience","abstract":[{"text":"Find out how you can use the latest iOS and iPadOS system media players to build amazing media apps. We‚Äôll share how we designed the updated player and give you best practices and tips to help you design media experiences of your own. We‚Äôll also explore Live Text for video and show you how to integrate interstitials and playback speed controls into your apps.","type":"text"}]},"https://developer.apple.com/wwdc22/10026":{"type":"download","url":"https:\/\/developer.apple.com\/wwdc22\/10026","checksum":null,"identifier":"https:\/\/developer.apple.com\/wwdc22\/10026"},"WWDC22-Icon.png":{"type":"image","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC22-Icon.png"}],"identifier":"WWDC22-Icon.png"},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes","kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"title":"WWDC Notes","role":"collection"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22":{"abstract":[{"type":"text","text":"Xcode 14, Swift 5.7, iOS 16, macOS 13 (Ventura), tvOS 16, watchOS 9."},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"code":"WeatherKit","type":"codeVoice"},{"text":", ","type":"text"},{"code":"ScreenCaptureKit","type":"codeVoice"},{"text":", ","type":"text"},{"code":"Swift Regex","type":"codeVoice"},{"type":"text","text":", and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22","url":"\/documentation\/wwdcnotes\/wwdc22","title":"WWDC22","role":"collectionGroup","images":[{"type":"icon","identifier":"WWDC22-Icon.png"},{"type":"card","identifier":"WWDC22.jpeg"}],"type":"topic","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10048-Whats-new-in-VisionKit":{"url":"\/documentation\/wwdcnotes\/wwdc23-10048-whats-new-in-visionkit","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10048-Whats-new-in-VisionKit","title":"What‚Äôs new in VisionKit","abstract":[{"text":"Discover how VisionKit can help people quickly lift subjects from images in your app and learn more about the content of an image with Visual Look Up. We‚Äôll also take a tour of the latest updates to VisionKit for Live Text interaction, data scanning, and expanded support for macOS apps.","type":"text"}],"type":"topic","role":"sampleCode"},"WWDC22.jpeg":{"alt":null,"type":"image","identifier":"WWDC22.jpeg","variants":[{"url":"\/images\/WWDC22.jpeg","traits":["1x","light"]}]},"WWDCNotes.png":{"alt":null,"type":"image","identifier":"WWDCNotes.png","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}]},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}],"title":"Learn More‚Ä¶","type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10025-Capture-machinereadable-codes-and-text-with-VisionKit":{"url":"\/documentation\/wwdcnotes\/wwdc22-10025-capture-machinereadable-codes-and-text-with-visionkit","kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10025-Capture-machinereadable-codes-and-text-with-VisionKit","title":"Capture machine-readable codes and text with VisionKit","abstract":[{"type":"text","text":"Meet the Data Scanner in VisionKit: This framework combines AVCapture and Vision to enable live capture of machine-readable codes and text through a simple Swift API. We‚Äôll show you how to control the types of content your app can capture by specifying barcode symbologies and language selection. We‚Äôll also explore how you can enable guidance in your app, customize item highlighting or regions of interest, and handle interactions after your app detects an item."}]}}}