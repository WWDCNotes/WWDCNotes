{"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10078-Design-considerations-for-vision-and-motion"},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10078-design-considerations-for-vision-and-motion"],"traits":[{"interfaceLanguage":"swift"}]}],"primaryContentSections":[{"content":[{"level":2,"type":"heading","anchor":"overview","text":"Overview"},{"style":"note","type":"aside","content":[{"inlineContent":[{"type":"text","text":"Creating experiences in three dimensions makes use of unique modalities such as depth and full field of view."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We will introduce you to how a person may experience this new level of immersion through visual cues and motion information from 3D content, and where human limitations may interfere with comfort of people experiencing your apps."}],"type":"paragraph"}],"name":"Note"},{"level":1,"type":"heading","anchor":"Visual-depth-cues","text":"Visual depth cues"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Your content needs to give the viewer the right visual depth clues, as well-designed 3D content helps the brain to perceive depth"}]}]},{"content":[{"inlineContent":[{"text":"Vision comfort requires agreement between the depth intended by you and the depth perceived by the viewer","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"The brain relies on the eye muscles to converge the line of sight and fixate the eyes at the image depth to perceive a single image, so it needs correct visual depth cues to converge the eyes correctly"}],"type":"paragraph"}]}]},{"inlineContent":[{"type":"image","identifier":"WWDC23-10078-Eyes_Converge"}],"type":"paragraph"},{"level":2,"type":"heading","anchor":"How-to-use-image-cues-to-maintain-vision-comfort","text":"How to use image cues to maintain vision comfort"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Color perception helps us recognize familiar size cues","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Blur gives a sense of depth"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"The relative size of an image can be used to provide depth information","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Gentle motion can help to figure out how far away you need to look","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Missing visual depth cues can be added with a background, light and shadow, occlusion, and texture density","type":"text"}],"type":"paragraph"}]}]},{"inlineContent":[{"type":"image","identifier":"WWDC23-10078-Depth_Cues"}],"type":"paragraph"},{"level":3,"type":"heading","anchor":"Conflicting-cues-are-troublesome","text":"Conflicting cues are troublesome"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Correct visual cues that can be confusing, like repeating patterns","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"You can avoid double vision by using smaller pieces of the pattern or breaking up the pattern with another design"}],"type":"paragraph"}]}]},{"inlineContent":[{"identifier":"WWDC23-10078-Patterns","type":"image"}],"type":"paragraph"},{"style":"note","type":"aside","content":[{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Warning","type":"text"}]},{"type":"text","text":" "},{"type":"text","text":"If you decide to create stereo video content manually, it is extremely important to have the correct depth cues and also the correct disparity for each eye"}],"type":"paragraph"}],"name":"Note"},{"level":1,"type":"heading","anchor":"Content-parameters","text":"Content parameters"},{"level":2,"type":"heading","anchor":"Depth","text":"Depth"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Content that requires the eyes to be fixed for a long time, like reading, is most comfortable when it is placed farther than arms-length distance"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Allow the content depth to be adjusted"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Reserve content closest to the viewer for momentary visual effort experiences or for inviting direct interaction"}],"type":"paragraph"}]}]},{"level":2,"type":"heading","anchor":"Size-and-contrast","text":"Size and contrast"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Content size and contrast should match the particular visual experience you are designing to allow for vision comfort For example:","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Higher contrast for reading text","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Lower contrast, transparency, or blur to redirect visual attention elsewhere","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Choose the right font size, window size, and depth for long reading. Doing this will make it easy to read without having to move your head or body"}]}]}]},{"inlineContent":[{"identifier":"WWDC23-10078-Font_Window_Size","type":"image"}],"type":"paragraph"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"When a large portion of the field of view is dark, slow down the transition to a bright scene to give time to the eye for brightness adaptation"}],"type":"paragraph"}]}]},{"level":1,"type":"heading","anchor":"Eye-effort","text":"Eye effort"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"It’s most comfortable for people to look downwards or left and right"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Upward and diagonal eye rotation takes the most eye-muscle effort"}],"type":"paragraph"}]}]},{"inlineContent":[{"type":"image","identifier":"WWDC23-10078-Eye_Effort"}],"type":"paragraph"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Content requiring extended reading or elongated target fixations should be placed towards the center and slightly below line of sight"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Design for natural breaks in your experience to allow the person’s eyes to rest","type":"text"}],"type":"paragraph"}]}]},{"level":1,"type":"heading","anchor":"Motion-of-virtual-objects","text":"Motion of virtual objects"},{"inlineContent":[{"type":"text","text":"You might feel motion discomfort like dizziness or an upset stomach when the visual motion information doesn’t match the vestibular data"}],"type":"paragraph"},{"style":"note","type":"aside","content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"type":"text","text":"Note"}],"type":"strong"},{"type":"text","text":" "},{"type":"text","text":"Well-designed content enables the brain to perceive the world as stationary"}]}],"name":"Note"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"When virtual objects, cover a large part of the field of view and move, the viewer’s brain might interpret the visual motion of the objects as if the viewer themself is moving"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Make the objects semitransparent when they move, so the passthrough content is clearly visible during the motion"}],"type":"paragraph"}]}]},{"level":1,"type":"heading","anchor":"Head-locked-content","text":"Head-locked content"},{"style":"note","type":"aside","content":[{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Warning"}]},{"type":"text","text":" "},{"type":"text","text":"When possible, avoid content that is anchored to the user’s head"}],"type":"paragraph"}],"name":"Note"},{"inlineContent":[{"text":"If head-locked views are necessary:","type":"text"}],"type":"paragraph"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Consider using a smaller window near the center of the view and farther away from the person"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Use a lazy-follow animation"}],"type":"paragraph"}]}]},{"level":1,"type":"heading","anchor":"Motion-in-windows","text":"Motion in windows"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"When a window’s content moves, the viewer’s brain might think that the viewer themself is moving","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Be mindful about camera motions","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Keep the content horizon aligned with the real horizon","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Move the camera in a way that the motion of the focus of expansion is slow and predictable"}]}]},{"content":[{"inlineContent":[{"text":"Keep the focus of expansion within the field of view","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Avoid fast turns or pure rotational motion","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Keep objects small and at a larger distance"}]}]}]},{"inlineContent":[{"identifier":"WWDC23-10078-Focus_Expansion","type":"image"}],"type":"paragraph"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"If possible, use plain textures with low luminance contrast","type":"text"}],"type":"paragraph"}]}]},{"level":1,"type":"heading","anchor":"Oscillating-motion","text":"Oscillating motion"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Avoid oscillations in general, and in particular those with frequencies around 0.2 Hz (1 oscillation every 5 seconds)"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Keep the amplitude of the motion low and make the content semitransparent"}]}]}]},{"style":"note","type":"aside","content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"text":"Note","type":"text"}],"type":"strong"},{"text":" ","type":"text"},{"text":"It’s always a good idea to provide an oscillation-free alternative through the Reduce Motion accessibility setting","type":"text"}]}],"name":"Note"},{"level":2,"type":"heading","anchor":"Written-By","text":"Written By"},{"type":"row","columns":[{"size":1,"content":[{"inlineContent":[{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/72805?v=4"}],"type":"paragraph"}]},{"size":4,"content":[{"level":3,"anchor":"Cristian-Díaz","text":"Cristian Díaz","type":"heading"},{"inlineContent":[{"overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"type":"reference","overridingTitle":"Contributed Notes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/elkraneo","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"https:\/\/github.com\/elkraneo","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"https:\/\/x.com\/elkraneo","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"https:\/\/elkraneo.com","isActive":true}],"type":"paragraph"}]}],"numberOfColumns":5},{"inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"reference","isActive":true}],"type":"paragraph"},{"level":2,"type":"heading","anchor":"Related-Sessions","text":"Related Sessions"},{"style":"list","type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10073-Design-for-spatial-input","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces"]},{"inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}],"type":"small"},{"inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}],"kind":"content"}],"metadata":{"modules":[{"name":"WWDC Notes"}],"title":"Design considerations for vision and motion","role":"sampleCode","roleHeading":"WWDC23"},"kind":"article","schemaVersion":{"patch":0,"minor":3,"major":0},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"abstract":[{"type":"text","text":"Learn how to design engaging immersive experiences for visionOS that respect the limitations of human vision and motion perception. We’ll show you how you can use depth cues, contrast, focus, and motion to keep people comfortable as they enjoy your apps and games."}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"overridingTitle":"Watch Video (15 min)","type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc23\/10078"}},"sections":[],"references":{"WWDC23-10078-Eye_Effort":{"identifier":"WWDC23-10078-Eye_Effort","type":"image","variants":[{"url":"\/images\/WWDC23-10078-Eye_Effort.jpeg","traits":["1x","light"]}],"alt":"Comfort versus effort in eye direction"},"WWDC23-10078-Font_Window_Size":{"identifier":"WWDC23-10078-Font_Window_Size","type":"image","variants":[{"url":"\/images\/WWDC23-10078-Font_Window_Size.png","traits":["1x","light"]}],"alt":"Do’s and don’ts for fonts and window sizes"},"doc://WWDCNotes/documentation/WWDCNotes/elkraneo":{"url":"\/documentation\/wwdcnotes\/elkraneo","title":"Cristian Díaz (3 notes)","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/elkraneo","type":"topic","role":"sampleCode","abstract":[{"type":"text","text":"It’s a reminder of a sauce that I loved once"}],"kind":"article"},"https://github.com/elkraneo":{"url":"https:\/\/github.com\/elkraneo","identifier":"https:\/\/github.com\/elkraneo","type":"link","titleInlineContent":[{"text":"GitHub","type":"text"}],"title":"GitHub"},"WWDC23-10078-Patterns":{"identifier":"WWDC23-10078-Patterns","type":"image","variants":[{"url":"\/images\/WWDC23-10078-Patterns.jpeg","traits":["1x","light"]}],"alt":"Suggestions for patterns display"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10073-Design-for-spatial-input":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10073-Design-for-spatial-input","title":"Design for spatial input","type":"topic","role":"sampleCode","abstract":[{"type":"text","text":"Learn how to design great interactions for eyes and hands. We’ll share the design principles for spatial input, explore best practices around input methods, and help you create spatial experiences that are comfortable, intuitive, and satisfying."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10073-design-for-spatial-input"},"WWDC23-10078-Focus_Expansion":{"identifier":"WWDC23-10078-Focus_Expansion","type":"image","variants":[{"url":"\/images\/WWDC23-10078-Focus_Expansion.jpeg","traits":["1x","light"]}],"alt":"The focus of expansion is the point where all the pixels appear to be coming from"},"WWDCNotes.png":{"identifier":"WWDCNotes.png","type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"alt":null},"https://elkraneo.com":{"url":"https:\/\/elkraneo.com","identifier":"https:\/\/elkraneo.com","type":"link","titleInlineContent":[{"text":"Blog","type":"text"}],"title":"Blog"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10076-Design-for-spatial-user-interfaces":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces","abstract":[{"text":"Learn how to design great interfaces for spatial computing apps. We’ll share how your existing screen-based knowledge easily translates into creating great experiences for visionOS. Explore guidelines for UI components, materials, and typography and find out how you can design experiences that are familiar, legible, and easy to use.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10076-design-for-spatial-user-interfaces","kind":"article","type":"topic","title":"Design for spatial user interfaces"},"https://developer.apple.com/wwdc23/10078":{"url":"https:\/\/developer.apple.com\/wwdc23\/10078","identifier":"https:\/\/developer.apple.com\/wwdc23\/10078","type":"download","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"kind":"article","abstract":[{"text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"code":"SwiftData","type":"codeVoice"},{"text":", ","type":"text"},{"code":"Observation","type":"codeVoice"},{"text":", ","type":"text"},{"type":"codeVoice","code":"StoreKit"},{"type":"text","text":" views, and more."}],"type":"topic","role":"collectionGroup","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","title":"WWDC23","url":"\/documentation\/wwdcnotes\/wwdc23"},"WWDC23-10078-Eyes_Converge":{"identifier":"WWDC23-10078-Eyes_Converge","type":"image","variants":[{"url":"\/images\/WWDC23-10078-Eyes_Converge.jpeg","traits":["1x","light"]}],"alt":"Diagram illustrating the convergence of the eyes on an image"},"WWDC23-10078-Depth_Cues":{"identifier":"WWDC23-10078-Depth_Cues","type":"image","variants":[{"url":"\/images\/WWDC23-10078-Depth_Cues.jpeg","traits":["1x","light"]}],"alt":"Lime picture with a variety of depth clues"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10072-Principles-of-spatial-design":{"type":"topic","title":"Principles of spatial design","abstract":[{"text":"Discover the fundamentals of spatial design. Learn how to design with depth, scale, windows, and immersion, and apply best practices for creating comfortable, human-centered experiences that transform reality. Find out how you can use these spatial design principles to extend your existing app or bring a new idea to life.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10072-principles-of-spatial-design","kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design"},"https://x.com/elkraneo":{"url":"https:\/\/x.com\/elkraneo","identifier":"https:\/\/x.com\/elkraneo","type":"link","titleInlineContent":[{"text":"X\/Twitter","type":"text"}],"title":"X\/Twitter"},"doc://WWDCNotes/documentation/WWDCNotes":{"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","url":"\/documentation\/wwdcnotes","kind":"symbol","role":"collection","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"images":[{"identifier":"WWDCNotes.png","type":"icon"}]},"https://avatars.githubusercontent.com/u/72805?v=4":{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/72805?v=4","type":"image","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/72805?v=4","traits":["1x","light"]}],"alt":"Profile image of Cristian Díaz"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"link","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"title":"Contributions are welcome!"}}}