{"schemaVersion":{"major":0,"minor":3,"patch":0},"primaryContentSections":[{"content":[{"type":"heading","level":2,"text":"Overview","anchor":"Overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Apple’s ecosystem of machine learning tools, including "},{"type":"codeVoice","code":"Create ML"},{"type":"text","text":", allows you to build and deploy models in your apps."}]},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Create ML consists of the Create ML App, "},{"type":"codeVoice","code":"Create ML Framework"},{"type":"text","text":", and underlying Components."}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Train models with a click in the "},{"code":"Create ML App","type":"codeVoice"},{"type":"text","text":"."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Use the frameworks directly for automating model creation or on-device personalization.","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Create ML leverages system frameworks like ","type":"text"},{"code":"Vision","type":"codeVoice"},{"text":", ","type":"text"},{"code":"Natural Language","type":"codeVoice"},{"text":", and ","type":"text"},{"code":"Sound Analysis","type":"codeVoice"},{"text":" to customize models with your training data.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The output of Create ML is a model that you can deploy in your app using these system frameworks."}]}]}],"type":"unorderedList"},{"name":"If you’re new to machine learning check out","content":[{"type":"paragraph","inlineContent":[{"text":"","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/developer.apple.com\/wwdc24\/10223","isActive":true,"type":"reference"}]}],"style":"note","type":"aside"},{"text":"App Enhancements","anchor":"App-Enhancements","level":2,"type":"heading"},{"inlineContent":[{"text":"The Create ML App on your Mac is the easiest place to start building custom machine learning models.","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"text":"Create models to predict content in images, videos, or tabular data.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Detect objects in images, sounds in audio files, human actions in videos, or activities.","type":"text"}]}]}],"type":"unorderedList"},{"inlineContent":[{"text":"Ensure your annotations align with your expectations before training. For example, if your app detects both a coffee cup and its surface separately, it indicates annotation issues. Avoid duplicate predictions for a better user experience.","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"text":"In the Create ML App, view your data source distribution with the explore option.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Drill into specific objects or class labels to visualize annotations."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Preview your data source to ensure annotations match expectations, especially for image-based models like image classification and hand pose classification.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Object Tracking","anchor":"Object-Tracking","level":2,"type":"heading"},{"inlineContent":[{"type":"text","text":"Create ML simplifies integrating machine learning into your apps across all Apple operating systems."}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Object tracking in Create ML enhances spatial computing experiences, ideal for Apple Vision Pro."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The new Spatial Category in Create ML includes a template for tracking the spatial location and orientation of objects."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Training an object tracker begins with your training data, like all Create ML templates."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The Create ML App streamlines the training process."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Simply provide a 3D asset of your object, and the app handles the rest.","type":"text"}]}]}],"type":"unorderedList"},{"name":"For a full workflow, of building an object tracking experience and deploying it on Apple Vision Pro check","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":""},{"type":"text","text":" "},{"overridingTitle":"Explore object tracking for visionOS","identifier":"https:\/\/developer.apple.com\/wwdc24\/10223","type":"reference","overridingTitleInlineContent":[{"text":"Explore object tracking for visionOS","type":"text"}],"isActive":true}]}],"style":"note","type":"aside"},{"text":"Components","anchor":"Components","level":2,"type":"heading"},{"text":"Classification","anchor":"Classification","level":3,"type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Time-series in Create ML Components consists of uniformly sampled numerical data changing over time, such as:","type":"text"}]},{"items":[{"content":[{"inlineContent":[{"text":"Accelerometer","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"GPS location"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Temperature","type":"text"}]}]}],"type":"unorderedList"}]},{"content":[{"inlineContent":[{"text":"A powerful, general-purpose time series ","type":"text"},{"inlineContent":[{"type":"text","text":"classifier"}],"type":"strong"},{"text":" component now classifies gestures like pinch, snap, or clench using accelerometer data from your Apple Watch.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Forecasting","anchor":"Forecasting","level":3,"type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Time-series forecasting is a new model type in Create ML.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"It learns from historical data to predict future values over time.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"The ","type":"text"},{"inlineContent":[{"type":"text","text":"forecaster"}],"type":"strong"},{"text":" is a versatile component, suitable for predicting future values in various contexts, including audio, accelerometer, and sales, by analyzing historical data.","type":"text"}]}]}],"type":"unorderedList"},{"text":"Date Components","anchor":"Date-Components","level":3,"type":"heading"},{"items":[{"content":[{"inlineContent":[{"text":"Extract date components to identify trends in the data.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Weekday extraction helps the model learn weekly variations, and month extraction aids in learning annual variations.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Use the ","type":"text"},{"type":"codeVoice","code":"DateFeatureExtractor"},{"text":" component to easily extract features from dates.","type":"text"}]}]}],"type":"unorderedList"},{"syntax":"swift","code":["let featureExtractor = DateFeatureExtractor<Float>(features: ([.month, .weekday])","\/\/ create a DateFeatureExtractor with month and weekday feature components.","","let preprocessingEstimator = ColumnSelector<_, Date>(.include(columnNames: [\"Date\"]),","transformer: OptionalUnwrapper().appending(featureExtractor))","\/\/compose a ColumnSelector and featureExtractor together into a pipeline.","",".appending(","    ColumnConcatenator<Float>(","        columnSelection: .all, ","        concatenatedColumnName: \"Features\"","        \/\/add a ColumnConcatenator component, to combine all the features into a shaped array.","    )",")","let preprocessor = try await preprocessingEstimator.fitted(to: dataFrame)","\/\/ use pre-processing pipeline to fit data frame","","let featuresDataFrame = try await preprocessor.applied(to: dataFrame)","","let features = featuresDataFrame[\"Features\", MLShapedArray<Float>.self]",".filled(with: MLShappedArray<Float>())","let annotations = dataFrame[\"Quantity\", Float.self]",".filled(with: 0.0)",".map({ MLShapedArray<Float>(scalars: [Float($0)], shape: [1]) })","\/\/ extract the features column and the quantity column, both as columns of MLShapedArray",""],"type":"codeListing"},{"text":"Features","anchor":"Features","level":3,"type":"heading"},{"inlineContent":[{"text":"Training a Forecaster model:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Split the training data into two parts:"}]}]}],"type":"unorderedList"},{"syntax":"swift","code":["\/\/ Training split","let trainingPortion = 0..<10_000","let training = zip(features[trainingPortion], annotations[trainingPortion])","    .map(AnnotatedFeature.init)","","\/\/ Validation split","let validationPortion = 10_000..<12_000","let validation = zip(features[validationPortion], annotations[validationPortion])","    .map(AnnotatedFeature.init)","","\/\/ Train","let configuration = LinearTimeSeriesForecasterConfiguration(","    inputWindowSize: 15,","    forecastWindowSize: 3",")","","let estimator = LinearTimeSeriesForecaster<Float>(configuration: configuration)","let model = try await estimator.fitted(to: training, validatedOn: validation)","","\/\/ Perform predictions","let predictions = try await model.applied(to: validation(\\.feature))",""],"type":"codeListing"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Pick how many days in the future to predict."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Your context should be longer than your prediction window."}]}]},{"content":[{"inlineContent":[{"text":"Create a series forecaster, configure the ","type":"text"},{"type":"codeVoice","code":"inputWindowSize"},{"text":" and ","type":"text"},{"type":"codeVoice","code":"forecastWindowSize"},{"text":", and train using the fitted method.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Once training completes, you can make predictions.","type":"text"}]}]}],"type":"unorderedList"},{"text":"Written By","anchor":"Written-By","level":2,"type":"heading"},{"columns":[{"content":[{"inlineContent":[{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/20319411?v=4","type":"image"}],"type":"paragraph"}],"size":1},{"content":[{"anchor":"Ramit-Sharma","text":"Ramit Sharma","type":"heading","level":3},{"inlineContent":[{"type":"reference","isActive":true,"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/RamitSharma991","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"overridingTitle":"Contributed Notes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/github.com\/RamitSharma991"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/x.com\/iosDev_ramit"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/"}],"type":"paragraph"}],"size":4}],"numberOfColumns":5,"type":"row"},{"inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"isActive":true,"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"reference"}],"type":"paragraph"},{"text":"Related Sessions","anchor":"Related-Sessions","level":2,"type":"heading"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110332-Whats-new-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10019-Get-to-know-Create-ML-Components","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10037-Build-dynamic-iOS-apps-with-the-Create-ML-framework","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10223-Explore-machine-learning-on-Apple-platforms"],"style":"list","type":"links"},{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}],"type":"small"},{"inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}],"type":"small"}],"kind":"content"}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc24-10183-whats-new-in-create-ml"]}],"sampleCodeDownload":{"action":{"overridingTitle":"Watch Video","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc24\/10183","type":"reference"},"kind":"sampleDownload"},"seeAlsoSections":[{"title":"Updated Tools & Frameworks","generated":true,"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10134-Whats-new-in-App-Intents","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10063-Whats-new-in-App-Store-Connect","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10124-Whats-new-in-AppKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10164-Whats-new-in-DockKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10105-Whats-new-in-Quick-Look-for-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10188-Whats-new-in-SF-Symbols-6","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10061-Whats-new-in-StoreKit-and-InApp-Purchase","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10136-Whats-new-in-Swift","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10137-Whats-new-in-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10144-Whats-new-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10118-Whats-new-in-UIKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10106-Whats-new-in-USD-and-MaterialX","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10108-Whats-new-in-Wallet-and-Apple-Pay","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10135-Whats-new-in-Xcode-16","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10143-Whats-new-in-device-management","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10212-Whats-new-in-location-authorization","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10123-Whats-new-in-privacy","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10205-Whats-new-in-watchOS-11"]}],"metadata":{"title":"What’s new in Create ML","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC24","role":"sampleCode"},"kind":"article","identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10183-Whats-new-in-Create-ML","interfaceLanguage":"swift"},"sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24"]]},"abstract":[{"type":"text","text":"Explore updates to Create ML, including interactive data source previews and a new template for building object tracking models for visionOS apps. We’ll also cover important framework improvements, including new time-series forecasting and classification APIs."}],"references":{"https://x.com/iosDev_ramit":{"title":"X\/Twitter","titleInlineContent":[{"type":"text","text":"X\/Twitter"}],"url":"https:\/\/x.com\/iosDev_ramit","type":"link","identifier":"https:\/\/x.com\/iosDev_ramit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10105-Whats-new-in-Quick-Look-for-visionOS":{"title":"What’s new in Quick Look for visionOS","type":"topic","abstract":[{"text":"Explore how Quick Look in visionOS can elevate file preview and editing experiences in your app. We’ll cover the integration of in-app and windowed Quick Look, as well as a brand-new API that customizes the windowed Quick Look experience in your app. We’ll also share the latest enhancements to viewing 3D models within Quick Look.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10105-whats-new-in-quick-look-for-visionos","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10105-Whats-new-in-Quick-Look-for-visionOS"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10144-Whats-new-in-SwiftUI":{"title":"What’s new in SwiftUI","type":"topic","abstract":[{"text":"Learn how you can use SwiftUI to build great apps for any Apple platform. Explore a fresh new look and feel for tabs and documents on iPadOS. Improve your window management with new windowing APIs, and gain more control over immersive spaces and volumes in your visionOS apps. We’ll also take you through other exciting refinements that help you make expressive charts, customize and layout text, and so much more.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10144-whats-new-in-swiftui","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10144-Whats-new-in-SwiftUI"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10136-Whats-new-in-Swift":{"title":"What’s new in Swift","type":"topic","abstract":[{"text":"Join us for an update on Swift. We’ll briefly go through a history of Swift over the past decade, and show you how the community has grown through workgroups, expanded the package ecosystem, and increased platform support. We’ll introduce you to a new language mode that achieves data-race safety by default, and a language subset that lets you run Swift on highly constrained systems. We’ll also explore some language updates including noncopyable types, typed throws, and improved C++ interoperability.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10136-whats-new-in-swift","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10136-Whats-new-in-Swift"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10205-Whats-new-in-watchOS-11":{"title":"What’s new in watchOS 11","type":"topic","abstract":[{"text":"Explore new opportunities on Apple Watch, including bringing Double Tap support to your watchOS app, making your Smart Stack widgets even more relevant and interactive, and displaying your iOS Live Activities in the Smart Stack.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10205-whats-new-in-watchos-11","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10205-Whats-new-in-watchOS-11"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10123-Whats-new-in-privacy":{"title":"What’s new in privacy","type":"topic","abstract":[{"text":"At Apple, we believe privacy is a fundamental human right. Learn about new and improved permission flows and other features that manage data in a privacy-preserving way, so that you can focus on creating great app experiences.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10123-whats-new-in-privacy","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10123-Whats-new-in-privacy"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10019-Get-to-know-Create-ML-Components":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10019-Get-to-know-Create-ML-Components","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc22-10019-get-to-know-create-ml-components","type":"topic","title":"Get to know Create ML Components","abstract":[{"text":"Create ML makes it easy to build custom machine learning models for image classification, object detection, sound classification, hand pose classification, action classification, tabular data regression, and more. And with the Create ML Components framework, you can further customize underlying tasks and improve your model. We’ll explore the feature extractors, transformers, and estimators that make up these tasks, and show you how you can combine them with other components and pre-processing steps to build custom tasks for concepts like image regression.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10108-Whats-new-in-Wallet-and-Apple-Pay":{"title":"What’s new in Wallet and Apple Pay","type":"topic","abstract":[{"text":"Take passes and payments to the next level with new enhancements to Wallet and Apple Pay. Make your event tickets shine with rich pass designs in Wallet, and bring great Apple Pay experiences to even more people with third-party browser support. We’ll also look at how to disburse funds with Apple Pay on the Web and highlight new API changes that help you integrate Apple Pay into even more purchasing flows.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10108-whats-new-in-wallet-and-apple-pay","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10108-Whats-new-in-Wallet-and-Apple-Pay"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24","title":"WWDC24","abstract":[{"type":"text","text":"Xcode 16, Swift 6, iOS 18, macOS 15, tvOS 18, visionOS 2, watchOS 11."},{"type":"text","text":" "},{"type":"text","text":"New APIs: Swift Testing, "},{"type":"codeVoice","code":"FinanceKit"},{"type":"text","text":", "},{"type":"codeVoice","code":"TabletopKit"},{"type":"text","text":", and more."}],"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"type":"topic","kind":"article","role":"collectionGroup","url":"\/documentation\/wwdcnotes\/wwdc24"},"WWDCNotes.png":{"identifier":"WWDCNotes.png","alt":null,"type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10143-Whats-new-in-device-management":{"title":"What’s new in device management","type":"topic","abstract":[{"text":"Learn about the latest management capabilities for iOS, iPadOS, macOS, and visionOS, then discover the latest changes to Apple Business Manager and Apple School Manager. We’ll also share updates to Activation Lock, SoftwareUpdate, and Safari management.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10143-whats-new-in-device-management","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10143-Whats-new-in-device-management"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10037-Build-dynamic-iOS-apps-with-the-Create-ML-framework":{"url":"\/documentation\/wwdcnotes\/wwdc21-10037-build-dynamic-ios-apps-with-the-create-ml-framework","role":"sampleCode","title":"Build dynamic iOS apps with the Create ML framework","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10037-Build-dynamic-iOS-apps-with-the-Create-ML-framework","kind":"article","abstract":[{"text":"Discover how your app can train Core ML models fully on device with the Create ML framework, enabling adaptive and customized app experiences, all while preserving data privacy. We’ll explore the types of models that can be created on-the-fly for image-based tasks like Style Transfer and Image Classification, audio tasks like custom Sound Classification, or tasks that build on a rich set of Text Classification, Tabular Data Classification, and Tabular Regressors. And we’ll take you through the many opportunities these models offer to make your app more personal and dynamic.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10188-Whats-new-in-SF-Symbols-6":{"title":"What’s new in SF Symbols 6","type":"topic","abstract":[{"text":"Explore the latest updates to SF Symbols, Apple’s library of iconography designed to integrate seamlessly with San Francisco, the system font for all Apple platforms. Learn how the new Wiggle, Rotate, and Breathe animation presets can bring vitality to your interface. To get the most out of this session, we recommend first watching “What’s new in SF Symbols 5” from WWDC23.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10188-whats-new-in-sf-symbols-6","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10188-Whats-new-in-SF-Symbols-6"},"doc://WWDCNotes/documentation/WWDCNotes":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","url":"\/documentation\/wwdcnotes","type":"topic","title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"kind":"symbol"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10106-Whats-new-in-USD-and-MaterialX":{"title":"What’s new in USD and MaterialX","type":"topic","abstract":[{"text":"Explore updates to Universal Scene Description and MaterialX support on Apple platforms. Discover how these technologies provide a foundation for 3D content creation and delivery, and learn how they can help streamline your workflows for creating great spatial experiences. Learn about USD and MaterialX support in RealityKit and Storm, advancements in our system-provided tooling, and more.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10106-whats-new-in-usd-and-materialx","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10106-Whats-new-in-USD-and-MaterialX"},"https://":{"titleInlineContent":[{"text":"Blog","type":"text"}],"type":"link","identifier":"https:\/\/","title":"Blog","url":"https:\/\/"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10164-Whats-new-in-DockKit":{"title":"What’s new in DockKit","type":"topic","abstract":[{"text":"Discover how intelligent tracking in DockKit allows for smoother transitions between subjects. We will cover what intelligent tracking is, how it uses an ML model to select and track subjects, and how you can use it in your app.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10164-whats-new-in-dockkit","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10164-Whats-new-in-DockKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10223-Explore-machine-learning-on-Apple-platforms":{"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10223-explore-machine-learning-on-apple-platforms","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10223-Explore-machine-learning-on-Apple-platforms","title":"Explore machine learning on Apple platforms","abstract":[{"type":"text","text":"Get started with an overview of machine learning frameworks on Apple platforms. Whether you’re implementing your first ML model, or an ML expert, we’ll offer guidance to help you select the right framework for your app’s needs."}]},"doc://WWDCNotes/documentation/WWDCNotes/RamitSharma991":{"abstract":[{"text":"Indie iOS Dev. Swift, SwiftUI, Obj-C, UX and related.","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/RamitSharma991","title":"Ramit Sharma (13 notes)","url":"\/documentation\/wwdcnotes\/ramitsharma991","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10063-Whats-new-in-App-Store-Connect":{"role":"sampleCode","abstract":[{"text":"Explore new features for discovery, testing, and marketing. Find out how to nominate your apps for featuring on the App Store, share exciting moments (like a version launch) with marketing assets generated for you, deep link to specific content in your app from custom product pages, use the latest enhancements to TestFlight, and more.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc24-10063-whats-new-in-app-store-connect","type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10063-Whats-new-in-App-Store-Connect","title":"What’s new in App Store Connect"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"type":"link","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110332-Whats-new-in-Create-ML":{"abstract":[{"type":"text","text":"Discover the latest updates to Create ML. We’ll share improvements to Create ML’s evaluation tools that can help you understand how your custom models will perform on real-world data. Learn how you can check model performance on each type of image in your test data and identify problems within individual images to help you troubleshoot mistaken classifications, poorly labeled data, and other errors. We’ll also show you how to test your model with iPhone and iPad in live preview using Continuity Camera, and share how you can take Action Classification even further with the new Repetition Counting capabilities of the Create ML Components framework."}],"title":"What’s new in Create ML","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110332-Whats-new-in-Create-ML","url":"\/documentation\/wwdcnotes\/wwdc22-110332-whats-new-in-create-ml","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10118-Whats-new-in-UIKit":{"title":"What’s new in UIKit","type":"topic","abstract":[{"text":"Explore everything new in UIKit, including tab and document launch experiences, transitions, and text and input changes. We’ll also discuss better-than-ever interoperability between UIKit and SwiftUI animations and gestures, as well as general improvements throughout UIKit.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10118-whats-new-in-uikit","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10118-Whats-new-in-UIKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10124-Whats-new-in-AppKit":{"title":"What’s new in AppKit","type":"topic","abstract":[{"text":"Discover the latest advances in Mac app development. Get an overview of the new features in macOS Sequoia, and how to adopt them in your app. Explore new ways to integrate your existing code with SwiftUI. Learn about the improvements made to numerous AppKit controls, like toolbars, menus, text input, and more.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10124-whats-new-in-appkit","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10124-Whats-new-in-AppKit"},"https://avatars.githubusercontent.com/u/20319411?v=4":{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/20319411?v=4","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/20319411?v=4","traits":["1x","light"]}],"alt":"Profile image of Ramit Sharma"},"https://github.com/RamitSharma991":{"titleInlineContent":[{"type":"text","text":"GitHub"}],"type":"link","identifier":"https:\/\/github.com\/RamitSharma991","title":"GitHub","url":"https:\/\/github.com\/RamitSharma991"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10134-Whats-new-in-App-Intents":{"title":"What’s new in App Intents","type":"topic","abstract":[{"text":"Learn about improvements and refinements to App Intents, and discover how this framework can help you expose your app’s functionality to Siri and all-new features. We’ll show you how to make your entities more meaningful to the platform with the Transferable API, File Representations, new IntentFile APIs, and Spotlight Indexing, opening up powerful functionality in Siri and the Shortcuts app. Empower your intents to take people deep into your app with URL Representable Entities. Explore new techniques to model your entities and intents with new APIs for error handling and union values","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10134-whats-new-in-app-intents","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10134-Whats-new-in-App-Intents"},"https://developer.apple.com/wwdc24/10223":{"titleInlineContent":[{"text":"Explore machine learning on Apple platforms","type":"text"}],"type":"link","identifier":"https:\/\/developer.apple.com\/wwdc24\/10223","title":"Explore machine learning on Apple platforms","url":"https:\/\/developer.apple.com\/wwdc24\/10223"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10061-Whats-new-in-StoreKit-and-InApp-Purchase":{"title":"What’s new in StoreKit and In-App Purchase","type":"topic","abstract":[{"text":"Learn how to build and deliver even better purchase experiences using the App Store In-App Purchase system. We’ll demo new StoreKit views control styles and new APIs to improve your subscription customization, discuss new fields for transaction-level information, and explore new testability in Xcode. We’ll also review an important StoreKit deprecation.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10061-whats-new-in-storekit-and-inapp-purchase","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10061-Whats-new-in-StoreKit-and-InApp-Purchase"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10135-Whats-new-in-Xcode-16":{"title":"What’s new in Xcode 16","type":"topic","abstract":[{"text":"Discover the latest productivity and performance improvements in Xcode 16. Learn about enhancements to code completion, diagnostics, and Xcode Previews. Find out more about updates in builds and explore improvements in debugging and Instruments.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10135-whats-new-in-xcode-16","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10135-Whats-new-in-Xcode-16"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10137-Whats-new-in-SwiftData":{"title":"What’s new in SwiftData","type":"topic","abstract":[{"text":"SwiftData makes it easy to add persistence to your app with its expressive, declarative API. Learn about refinements to SwiftData, including compound uniqueness constraints, faster queries with #Index, queries in Xcode previews, and rich predicate expressions. Join us to explore how you can use all of these features to express richer models and improve performance in your app.","type":"text"},{"text":" ","type":"text"},{"text":"To discover how to build a custom data store or use the history API in SwiftData, watch “Create a custom data store with SwiftData” and “Track model changes with SwiftData history”.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10137-whats-new-in-swiftdata","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10137-Whats-new-in-SwiftData"},"https://developer.apple.com/wwdc24/10183":{"type":"download","identifier":"https:\/\/developer.apple.com\/wwdc24\/10183","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc24\/10183"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10212-Whats-new-in-location-authorization":{"title":"What’s new in location authorization","type":"topic","abstract":[{"text":"Location authorization is turning 2.0. Learn about new recommendations and techniques to get the authorization you need, and a new system of diagnostics that can let you know when an authorization goal can’t be met.","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10212-whats-new-in-location-authorization","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10212-Whats-new-in-location-authorization"}}}