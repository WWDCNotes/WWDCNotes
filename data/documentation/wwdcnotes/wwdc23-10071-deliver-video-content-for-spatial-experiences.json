{"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10071-deliver-video-content-for-spatial-experiences"],"traits":[{"interfaceLanguage":"swift"}]}],"abstract":[{"type":"text","text":"Learn how to prepare and deliver video content for visionOS using HTTP Live Streaming (HLS). Discover the current HLS delivery process for media and explore how you can expand your delivery pipeline to support 3D content. Get up to speed with tips and techniques for spatial media streaming and adapting your existing caption production workflows for 3D. And find out how to share audio tracks across video variants and add spatial audio to make your video content more immersive."}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences"},"metadata":{"roleHeading":"WWDC23","role":"sampleCode","modules":[{"name":"WWDC Notes"}],"title":"Deliver video content for spatial experiences"},"sampleCodeDownload":{"action":{"type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc23\/10071","isActive":true,"overridingTitle":"Watch Video (16 min)"},"kind":"sampleDownload"},"schemaVersion":{"major":0,"patch":0,"minor":3},"kind":"article","primaryContentSections":[{"content":[{"text":"Chapters:","type":"heading","anchor":"Chapters","level":2},{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10071?time=41","isActive":true,"type":"reference"},{"text":" Deliver 2D content","type":"text"},{"text":"\n","type":"text"},{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10071?time=320","isActive":true,"type":"reference"},{"text":" Deliver 3D content","type":"text"}]},{"text":"Intro","type":"heading","anchor":"Intro","level":2},{"type":"paragraph","inlineContent":[{"text":"In this talk, we’re going to look at how to prepare and deliver streaming content for spatial experiences. We’ll start with a brief review of the current steps in producing, preparing, and delivering 2D media using HTTP Live Streaming. also known as HLS. With 2D content preparation and delivery covered, we’ll turn to 3D video content – what’s supported and updates to the steps just described.","type":"text"}]},{"text":"Content pipeline","type":"heading","anchor":"Content-pipeline","level":1},{"type":"paragraph","inlineContent":[{"text":"Considering the content pipeline, we’ll start with media encoding of video, audio, and captions. Then, those media resources need to be packaged, ready for HLS delivery. This is how 2D content is delivered today. The goal of delivering 3D content is to build upon current 2D processes.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-contentPipeline"}]},{"type":"paragraph","inlineContent":[{"text":"HLS adds new support for fragmented MP4 timed metadata that allows an important adaptation.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Please note the HTTP Live Streaming page on the Apple Developer website, which provides links to documentation, tools, example streams, developer forums, and other resources. This is where more details covered in this talk will be made available over time."}]},{"text":"2D audiovisual media","type":"heading","anchor":"2D-audiovisual-media","level":1},{"type":"paragraph","inlineContent":[{"text":"Delivery of 2D audiovisual content is the same.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Media functionality is built upon existing technologies:","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"AVFoundation, HTTP Live Streaming","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Standards-based formats such as fragmented MP4, WebVTT","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Our goal is that delivering 2D audiovisual content to this platform should be the same as all our other platforms. This is achieved by building upon Apple Media technology such as HTTP Live Streaming, AVFoundation, Core Media, and standards-based formats such as the ISO-based media file format, often thought of as MPEG-4. This is done all while supporting a new spatial experiences paradigm. For a deep dive into how to best support playback of audiovisual media, see the session:"}]},{"type":"paragraph","inlineContent":[{"isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10070","type":"reference"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"For video, encode the source video. Edit it to the right length and color correct it for the bitrate tiers that matter to you. Here you’ll make choices of how you configure and use video encoders such as HEVC, short for High Efficiency Video Coding. While support for existing 2D audiovisual media you deliver to other Apple platforms is fully supported, take note of these playback capabilities."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-audiovisualMedia"}]},{"type":"paragraph","inlineContent":[{"text":"This platform supports playback of up to 4K resolution, allowing your highest-quality video to be experienced. The display’s refresh rate is 90 Hertz, And for 24-frames-per-second video, a special 96-hertz mode may be used automatically. There’s support for standard and high dynamic range.","type":"text"}]},{"text":"2D video playback capabilities","type":"heading","anchor":"2D-video-playback-capabilities","level":3},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Up to 4K resolution video playback","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"90Hz display refresh rate","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Color pipeline supports Standard & High-Dynamic Range content"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-audiovisualMedia2","type":"image"}]},{"text":"Encode audio","type":"heading","anchor":"Encode-audio","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"For your video’s corresponding audio, identify and produce the number of source audio streams you need. The number depends upon the set of spoken languages you are targeting and the roles of that audio. One role might be main dialogue, another, audio descriptions."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-audiovisualMedia3"}]},{"type":"paragraph","inlineContent":[{"text":"Encode these sources for delivery with HLS in mind. You may want to deliver Spatial Audio, along with a fallback stereo audio track. This ensures a great experience for those devices supporting Spatial Audio and reliable playback everywhere. The HLS Developer page has links to documentation on preparing audio.","type":"text"}]},{"text":"Prepare captions","type":"heading","anchor":"Prepare-captions","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"And then there are captions. Here, captions includes both subtitles and closed captions to cover different languages and roles. The term “subtitles” is used for transcriptions of spoken text providing translations in different languages for viewers that may not speak the language or for establishing the settings time and place."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-audiovisualMedia4","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Closed captions is like subtitles but is intended when the audio can’t be heard by the viewer. Close captions provide a transcription of not only the dialogue but also of sound effects and other relevant audio cues. There might also be subtitles for the Deaf and hard of hearing, SDH, serving the same purpose. Akin to video and audio encoding, you should produce caption files and formats supported by HLS, most commonly WebVTT."}]},{"text":"Package for HLS delivery","type":"heading","anchor":"Package-for-HLS-delivery","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"With source video, audio, and captions in hand, next comes packaging. Packaging is a process that transforms the source media into various types of segments for reliable delivery. This can be done with Apple’s HLS tools available at the earlier HLS streaming page. Some content providers might use their own production tools, hardware, or workflows. Others might be vendors delivering those services and tools to the first group. The goal of packaging is to produce a set of media segments, the media playlists that drive their use, and a multivariant playlist that ties them all together."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-audiovisualMedia5","type":"image"}]},{"text":"Segmenting a movie file","type":"heading","anchor":"Segmenting-a-movie-file","level":1},{"type":"paragraph","inlineContent":[{"text":"Two kinds of HLS media segments are most typically used today. Fragmented MP4 media segments are produced by starting with an already encoded movie file of video or audio and generating a number of resources. These resources are known as media segments.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-audiovisualMedia6"}]},{"type":"paragraph","inlineContent":[{"text":"It is these segments that are retrieved by client devices during playback.","type":"text"}]},{"text":"Segmenting captions","type":"heading","anchor":"Segmenting-captions","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"Subtitle files also require segmenting. This is done with a subtitle-segmenting tool to generate media segments. A source WebVTT file may be split into any number of WebVTT files for the target segment duration."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-audiovisualMedia7"}]},{"text":"Deliver with HLS","type":"heading","anchor":"Deliver-with-HLS","level":1},{"type":"paragraph","inlineContent":[{"text":"Finally, the collection of HLS resources is hosted on a web server for HTTP delivery. This might be to one server that serves clients directly or to an origin server used with a content delivery network, or a CDN.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-audiovisualMedia8","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Either way, it is these resources that are delivered to client devices for playback.","type":"text"}]},{"text":"3D audiovisual media","type":"heading","anchor":"3D-audiovisual-media","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"Now that we’ve reviewed the 2D production and delivery pipeline, let’s turn to 3D content and the differences taking advantage of new spatial capabilities. We will again look at source encoding, packaging, and delivery, focusing on differences between 2D content and 3D stereoscopic content. So, we’re talking about 3D video."}]},{"text":"3D video","type":"heading","anchor":"3D-video","level":1},{"type":"paragraph","inlineContent":[{"text":"Let’s deconstruct this term. First, it’s video, so a sequence of frames in a movie track or a network stream. The “3D” in “3D video” is used interchangeably with stereoscopic, which provides an image for the left eye, and another very similar image from a slightly different perspective for the right eye.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-threeDAudiovisualMedia","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"These differences between the left and right images, called parallax, causes you to perceive three-dimensional depth in the video when presented."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-threeDAudiovisualMedia2","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"While there are choices in how 3D video frames might be carried there are some guiding principles that seem useful.","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"All video frames should be carried in one video track","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Both left and right eye images for a time are in each compressed video frame","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Coding efficiency","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Support on Apple silicon","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Compatible with 2D video"}]}]}]},{"type":"paragraph","inlineContent":[{"text":"By using a single video track for all stereo frames, traditional production with 2D video tracks is preserved. Both the left and right images or views, for any display time is in a single compressed frame. If you have a frame in your hands, you have both views or the stereo pair. It should be efficient, ideally, it’s supported by Apple silicon, and to the greatest degree possible, it should be decodable by non-3D-aware playback, allowing the video to be auditioned in 2D workflows.","type":"text"}]},{"text":"Multiview video compression","type":"heading","anchor":"Multiview-video-compression","level":1},{"text":"Multiview HEVC compression used for 3D","type":"heading","anchor":"Multiview-HEVC-compression-used-for-3D","level":3},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Also known as “MV-HEVC”","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Extensions to HEVC defined in ISO\/IEC 23008-2 (same as ITU H.265)"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Carries multiple views in each compressed frame","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"We use a left eye view and a right eye view for 3D video","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"To deliver stereo frames, we introduce the use of multiview HEVC, also called “MV-HEVC.” It’s an extension of HEVC. The “MV” is multiview. Carrying more than one view in each frame, each frame has a pair of compressed left and right images."}]},{"text":"MV-HEVC","type":"heading","anchor":"MV-HEVC","level":2},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"MV-HEVC is HEVC, so Apple silicon used"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Carries base HEVC 2D view data as-is","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Uses difference between left and right views"}]}]},{"content":[{"inlineContent":[{"text":"Stores original plus this difference (called 2D Plus Delta)","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Efficiency between 2D frames and between views within 3D frames"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Because MV-HEVC is HEVC at its heart, Apple silicon supports it. In MV-HEVC stores the base HEVC 2D view in each compressed frame. Encoding determines a difference, or delta, between the left and right images"}]},{"type":"paragraph","inlineContent":[{"text":"This technique, known as 2D Plus Delta, means that 2D decoders can find and use the base 2D view, for example the left eye. But 3D decoders can calculate the other view to present both views to the corresponding eyes.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Efficiency is achieved because the differences between base 2D images uses standard HEVC techniques, and just the differences between the left and right eye views are described in the stereo frames.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-threeDAudiovisualMedia3"}]},{"text":"In video track signaling","type":"heading","anchor":"In-video-track-signaling","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"The video format description, or the visual sample entry in MPEG-4, indicates the coding type, the codec, the dimensions of each view, and other details necessary to decode the video frames."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-threeDAudiovisualMedia4"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"A new extension to the video format description is introduced. Termed the Video Extended Usage box, it serves as a lightweight, easily discoverable signal that the video is stereoscopic, and which stereo eye views are present. For HLS delivery, this will be both left and right. A specification describing this new VEXU box is available with the SDK."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-threeDAudiovisualMedia5"}]},{"type":"paragraph","inlineContent":[{"text":"Its structure will evolve, and that will be described in the specification.","type":"text"}]},{"text":"3D video encoding","type":"heading","anchor":"3D-video-encoding","level":1},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Similar to 2D video production using HEVC or other codecs","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"3D video requires Multiview HEVC to carry stereoscopic frames","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Local movies containing MV-HEVC should behave like movies with 2D video","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"text":"Like 2D content, 3D video uses HEVC, except this time, the variation called MV-HEVC. This is required to carry the stereoscopic views. Like with 2D production, local movies with MV-HEVC can be used and should behave like other 2D video.","type":"text"}]},{"text":"Stereoscopic depth","type":"heading","anchor":"Stereoscopic-depth","level":1},{"type":"paragraph","inlineContent":[{"text":"Having both a left and a right image presented to the corresponding eye produces a perception of stereoscopic depth, providing a sense of relative depth.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-threeDAudiovisualMedia6","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"An object in the video scene might be perceived nearer or farther than another due to the differing amounts of parallax."},{"type":"text","text":" "},{"type":"text","text":"Three primary zones of stereoscopic depth can be defined. They are the screen plane with no parallax cues; negative parallax, which will cause objects to be perceived in front of the screen plane; and positive parallax, which will cause objects to be perceived behind the screen plane. If an element like a caption is rendered with no parallax in the same area of the frame as negative parallax cues, then a depth conflict will be created and cause discomfort when viewing."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-threeDAudiovisualMedia7"}]},{"text":"Captions and 3D video","type":"heading","anchor":"Captions-and-3D-video","level":1},{"type":"paragraph","inlineContent":[{"text":"Question. Given stereoscopic parallax and potential for depth conflict, how involved is producing captions for 3D video?","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Can we support the following? Playback works for horizontal captions, playback works across languages, including for vertical captions, and playback works when accessibility settings is used to adjust the user’s preferred caption sizing. Well, the answer is yes. With stereoscopic video using the approach I’ll next describe, captions should just work as is, while also allowing the same 2D caption assets to be shared between 2D and 3D experiences. This is possible by including the new timed metadata I mentioned earlier."}]},{"text":"Adapting captions to 3D video","type":"heading","anchor":"Adapting-captions-to-3D-video","level":1},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Important to avoid depth conflict in playback of 3D video"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Done by characterizing parallax across left and right views of the video frame"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"This is termed a parallax contour"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"This parallax contour is recorded as a metadata item in a timed metadata track corresponding to each video frame’s timing","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"With stereoscopic video, avoiding depth conflict and visual elements overlaying the video is important. Instead of requiring new caption formats or changes to existing formats, we offer a way to characterize each video frame’s parallax. This can vary across the frame with some areas apparently closer and some farther from the viewer. We call this a parallax contour, and it is recorded as metadata in a metadata track that is synchronized with a video track’s frames."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-threeDAudiovisualMedia8","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"If we tile the 3D video and indicate the depth parallax for each tile, we can use that to ensure that captions never interfere with elements in the stereo video. During playback, the parallax of the caption will be automatically adjusted to avoid depth conflict.","type":"text"}]},{"text":"Adaptive parallax","type":"heading","anchor":"Adaptive-parallax","level":1},{"type":"paragraph","inlineContent":[{"text":"Each metadata item with such a parallax video contour describes a 2D tiling of the associated video with the minimum parallax value associated with each tile.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-threeDAudiovisualMedia9"}]},{"type":"paragraph","inlineContent":[{"text":"Each video frame’s presentation should be associated with a metadata item describing the video frame’s contour. We recommend a 10 by 10 tiling as a good balance between storage and resolution to characterize different areas of parallax in the video.","type":"text"}]},{"text":"Produce adaptive parallax metadata","type":"heading","anchor":"Produce-adaptive-parallax-metadata","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"Considering how this parallax metadata is produced, start with left and right views for each frame. This can be done in production with two synchronized video tracks and doesn’t require MV-HEVC. Then, perform parallax or disparity analysis to create parallax information suitable for describing the tiling."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-threeDAudiovisualMedia10","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"For each stereo frame, this is then packaged in a metadata payload for the next step. A specification describing the format of this metadata is available with the SDK."}]},{"text":"Produce adaptive parallax metadata","type":"heading","anchor":"Produce-adaptive-parallax-metadata","level":1},{"type":"paragraph","inlineContent":[{"text":"This parallax information is packaged in metadata samples and written into a timed metadata track. The metadata track will be associated with the corresponding video it describes.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-threeDAudiovisualMedia11"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The metadata and video track should be multiplexed with the video so that HLS packaging will produce video segments with both the video and the parallax metadata."}]},{"type":"paragraph","inlineContent":[]},{"text":"Captions and 3D video","type":"heading","anchor":"Captions-and-3D-video","level":1},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Reuse your 2D captions with your 3D video","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Your 2D production remains the same"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Add the parallax contour metadata to your","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"3D video source movies","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Captions you might already produce for 2D can be reused with 3D. This means the processes used today or the vendor you might work with can continue to work in 2D with your 3D production. Also, this means your 3D content is agnostic to the choice of languages, horizontal and vertical layout, or potential use of accessibility subtitle preferences by users. By adding the described parallax metadata, the platform adapts dynamically to the parallax metadata you build."}]},{"text":"Audio and 3D video","type":"heading","anchor":"Audio-and-3D-video","level":1},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Same audio as 2D","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Spatial audio playback with head tracking","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Share same audio across 2D and 3D experiences"}]}]}]},{"type":"paragraph","inlineContent":[{"text":"As for audio use with 3D video, you can use the same audio use for 2D delivery. As the platform supports head tracking, consider using a Spatial Audio format. To share the same audio between 2D and 3D experiences, the video should match timingwise, having the same edits. If they differ, you will need to separate audio tracks between the 2D and 3D assets.","type":"text"}]},{"text":"Package 3D assets","type":"heading","anchor":"Package-3D-assets","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"Turning to packaging of 3D, updated HLS tools take care of the details, with 3D assets making the process nearly identical to that with 2D. Most production systems, which do not use Apple’s tools, will be able to use the new specs that are being released to build equivalent functionality."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-threeDAudiovisualMedia13","type":"image"}]},{"text":"HLS multivariant playlist format update","type":"heading","anchor":"HLS-multivariant-playlist-format-update","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"New REQ-VIDEO-LAYOUT attribute"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"For EXT-X-STREAM-INF tag for video content"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Required on 3D video streams to indicate it is stereoscopic video"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Video Channel Specifier can have values CH-STEREO or CH-MONO or a mix","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"text":"EXT-X-VERSION is updated to version 12","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"If you’re building your own playlists or inspecting them, take note of a few changes. REQ-VIDEO-LAYOUT is a new tag for video streams to indicate video is stereoscopic. The attribute value indicates if the video is stereo or not. Note that if your asset is loaded as 3D, it won’t switch to 2D or vice versa. 2D Video is unchanged and can be mixed with 3D video in the same playlist. REQ-VIDEO-LAYOUT requires a new version of the HLS spec, so the version is updated to 12. This is documented with the SDK.","type":"text"},{"text":" ","type":"text"},{"text":"Here’s an example multivariant playlist with the change of the version number to 12, and using REQ-VIDEO-LAYOUT for the 3D video stream.","type":"text"}]},{"syntax":null,"type":"codeListing","code":["#EXTM3U","#EXT-X-VERSION:12","","...","","#-- Video - 3D (MV-HEVC)","#EXT-X-STREAM-INF:BANDWIDTH=19500000, CODECS=\"hvc1.2.20000000.H150.B0, ec-3\", ...","REQ-VIDEO-LAYOUT=\"CH-STEREO\"","3D\/prog_index.m3u8","","#-- Video - 2D (HEVC) I-Frame stream","#EXT-X-I-FRAME-STREAM-INF:BANDWIDTH=1800000, CODECS=\"hvc1.2.20000000.L123.B0\", ...,","URI=\"2D\/iframe_index.m3u8\""]},{"type":"paragraph","inlineContent":[{"type":"text","text":"For the best navigation experience, you should include a 2D iFrame stream to the multivariant playlist to support thumbnail scrubbing."}]},{"text":"Deliver with HLS","type":"heading","anchor":"Deliver-with-HLS","level":1},{"type":"paragraph","inlineContent":[{"text":"Finally, HLS delivery works the same with 3D assets.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10071-threeDAudiovisualMedia14"}]},{"text":"3D packaging and delivery","type":"heading","anchor":"3D-packaging-and-delivery","level":1},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Prepare your source assets","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Use updated packaging tools","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Hosting for delivery is the same","type":"text"},{"text":"\n","type":"text"},{"text":"Delivering 3D assets is largely the same as delivering 2D assets, but there are some things you can do to optimize the experience. Prepare your source assets, noting to use MV-HEVC for 3D video, and including the new parallax contour metadata. Audio and caption production can be the same. Use updated packaging to produce the relevant segments and playlists. Hosting remains the same.","type":"text"}],"type":"paragraph"}]}]},{"text":"Consider visual comfort","type":"heading","anchor":"Consider-visual-comfort","level":1},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"3D visual experiences should be comfortable to watch"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Potential comfort issues: Extreme parallax, high motion, window violations"}]}]},{"content":[{"inlineContent":[{"text":"Screen size or field of view (FOV) affects comfort","type":"text"},{"text":"\n","type":"text"},{"text":"I want to emphasize that visual comfort is a key content-design goal for 3D experiences. 3D content should be comfortable to watch for sufficiently long durations. Some 3D content characteristics that could potentially cause comfort issues include extreme parallax, both negative and positive, high motion in the content causing focusing difficulties; as well as depth conflicts resulting from something termed “window violations.” Screen size may affect viewing comfort, depending on how much of the screen is in the viewer’s horizontal field of view. Note that the user can affect the screen size by positioning it nearer or farther.","type":"text"}],"type":"paragraph"}]}]},{"text":"2D and 3D content production recap","type":"heading","anchor":"2D-and-3D-content-production-recap","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"So in our journey, we’ve looked at 2D and 3D delivery with HTTP Live Streaming. For video, I introduced MV-HEVC. For audio, we noted that the same audio streams can be used across 2D and 3D. For captions, the same streams can likewise be used across 2D and 3D. Finally, a new timed metadata format is introduced to characterize the 3D videos’ parallax, allowing the same captions to be used."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10071-threeDAudiovisualMedia15","type":"image"}]},{"text":"Wrap Up","type":"heading","anchor":"Wrap-Up","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"With some small modifications to your current 2D pipeline, you can support 3D content using MV-HEVC. You can even continue to use all your existing captions from 2D assets. But if you provide timed metadata, those captions can be unobscured and provide a comfortable viewing experience."}]},{"text":"Check out also","type":"heading","anchor":"Check-out-also","level":1},{"type":"paragraph","inlineContent":[{"overridingTitleInlineContent":[{"type":"text","text":"Create a great spatial playback experience - WWDC23"}],"type":"reference","overridingTitle":"Create a great spatial playback experience - WWDC23","identifier":"https:\/\/developer.apple.com\/wwdc23\/10070","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc23\/10081","isActive":true}]},{"text":"Resources","type":"heading","anchor":"Resources","level":1},{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/developer.apple.com\/av-foundation\/HEVC-Stereo-Video-Profile.pdf","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/forums\/create\/question?tag1=795030&tag2=744030","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/av-foundation\/Stereo-Video-ISOBMFF-Extensions.pdf","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/forums\/tags\/wwdc2023-10071","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/av-foundation\/Video-Contour-Map-Metadata.pdf","type":"reference","isActive":true}]},{"text":"Written By","type":"heading","anchor":"Written-By","level":2},{"numberOfColumns":5,"columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4"}]}]},{"size":4,"content":[{"anchor":"laurent-b","type":"heading","level":3,"text":"laurent b"},{"inlineContent":[{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","overridingTitle":"Contributed Notes","type":"reference","overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"identifier":"https:\/\/github.com\/multitudes","type":"reference","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"identifier":"https:\/\/laurentbrusa.hashnode.dev\/","type":"reference","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"identifier":"https:\/\/x.com\/wrmultitudes","type":"reference","isActive":true}],"type":"paragraph"}]}],"type":"row"},{"type":"paragraph","inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"isActive":true,"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"reference"}]},{"text":"Related Sessions","type":"heading","anchor":"Related-Sessions","level":2},{"type":"links","style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10070-Create-a-great-spatial-playback-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit"]},{"type":"small","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Legal Notice"}]}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"seeAlsoSections":[{"title":"Deep Dives into Topics","identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10239-Add-SharePlay-to-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10248-Analyze-hangs-with-Instruments","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10258-Animate-symbols-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10158-Animate-with-springs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10159-Beyond-scroll-views","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10170-Beyond-the-basics-of-structured-concurrency","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10028-Bring-widgets-to-life","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10027-Bring-widgets-to-new-places","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10093-Bring-your-Unity-VR-app-to-a-fully-immersive-space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10123-Bring-your-game-to-Mac-Part-1-Make-a-game-plan","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10124-Bring-your-game-to-Mac-Part-2-Compile-your-shaders","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10125-Bring-your-game-to-Mac-Part-3-Render-with-Metal","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10023-Build-a-multidevice-workout-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10036-Build-accessible-apps-with-SwiftUI-and-UIKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10154-Build-an-app-with-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10056-Build-better-documentbased-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10016-Build-custom-workouts-with-WorkoutKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10096-Build-great-games-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10252-Build-programmatic-UI-with-Xcode-Previews","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10006-Build-robust-and-resumable-file-transfers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10087-Build-spatial-SharePlay-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10029-Build-widgets-for-the-Smart-Stack-on-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10051-Create-a-great-ShazamKit-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10070-Create-a-great-spatial-playback-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10105-Create-a-more-responsive-camera-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10034-Create-accessible-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10257-Create-animated-symbols","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10088-Create-immersive-Unity-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10278-Create-practical-workflows-in-Xcode-Cloud","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10244-Create-rich-documentation-with-SwiftDocC","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10007-Create-seamless-experiences-with-Virtualization","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10101-Customize-ondevice-speech-recognition","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10226-Debug-with-structured-logging","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10160-Demystify-SwiftUI-performance","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10263-Deploy-passkeys-at-work","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10193-Design-Shortcuts-for-Spotlight","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10138-Design-and-build-apps-for-watchOS-10","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10078-Design-considerations-for-vision-and-motion","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10073-Design-for-spatial-input","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10075-Design-spatial-SharePlay-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10309-Design-widgets-for-the-Smart-Stack-on-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10115-Design-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10052-Discover-Calendar-and-EventKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10256-Discover-Continuity-Camera-for-tvOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10089-Discover-Metal-for-immersive-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10149-Discover-Observation-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10085-Discover-Quick-Look-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10155-Discover-String-Catalogs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10180-Discover-streamlined-location-updates","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10196-Dive-deeper-into-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10254-Do-more-with-Managed-Apple-IDs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10107-Embed-the-Photos-Picker-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10094-Enhance-your-iPad-and-iPhone-apps-for-the-Shared-Space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10167-Expand-on-Swift-macros","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10275-Explore-AirPlay-with-interstitials","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10012-Explore-App-Store-Connect-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10156-Explore-SwiftUI-animation","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10103-Explore-enhancements-to-App-Intents","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10192-Explore-enhancements-to-RoomPlan","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10271-Explore-immersive-sound-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10122-Explore-media-formats-for-the-web","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10037-Explore-pie-charts-and-interactivity-in-Swift-Charts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10095-Explore-rendering-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10142-Explore-testing-inapp-purchases","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10175-Fix-failures-faster-with-Xcode-test-reports","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10168-Generalize-APIs-with-parameter-packs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10060-Get-started-with-privacy-manifests","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10161-Inspectors-in-SwiftUI-Discover-the-details","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10104-Integrate-your-media-app-with-HomePod","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10281-Keep-up-with-the-keyboard","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10176-Lift-subjects-from-images-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10229-Make-features-discoverable-with-TipKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10189-Migrate-to-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10172-Mix-Swift-and-C++","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10195-Model-your-schema-with-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10127-Optimize-GPU-renderers-with-Metal","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10050-Optimize-machine-learning-for-Metal-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10035-Perform-accessibility-audits-for-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10266-Protect-your-Mac-app-with-environment-constraints","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10250-Prototype-with-Xcode-Playgrounds","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10002-Ready-set-relay-Protect-app-traffic-with-network-relays","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10262-Rediscover-Safari-developer-features","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10004-Reduce-network-delays-with-L4S","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10241-Share-files-with-SharePlay","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10224-Simplify-distribution-in-Xcode-and-Xcode-Cloud","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10102-Spotlight-your-app-with-App-Shortcuts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10137-Support-Cinematic-mode-videos-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10181-Support-HDR-images-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10188-Sync-to-iCloud-with-CKSyncEngine","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10162-The-SwiftUI-cookbook-for-focus","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10238-Tune-up-your-AirPlay-audio-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10057-Unleash-the-UIKit-trait-system","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10153-Unlock-the-power-of-grammatical-agreement","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10185-Update-Live-Activities-with-push-notifications","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10031-Update-your-app-for-watchOS-10","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10061-Verify-app-dependencies-with-digital-signatures","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10058-Whats-new-with-text-and-text-interactions","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10157-Wind-your-way-through-advanced-animations-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10166-Write-Swift-macros","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10128-Your-guide-to-Metal-ray-tracing"],"generated":true}],"sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"references":{"WWDC23-10071-audiovisualMedia":{"alt":"2D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-audiovisualMedia.jpg"}],"identifier":"WWDC23-10071-audiovisualMedia","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10100-optimize-app-power-and-performance-for-spatial-computing","title":"Optimize app power and performance for spatial computing","abstract":[{"text":"Learn how you can create powerful apps and games for visionOS by optimizing for performance and efficiency. We’ll cover the unique power characteristics of the platform, explore building a performance plan, and share some of the tools and strategies to test and optimize your apps.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10256-Discover-Continuity-Camera-for-tvOS":{"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10256-Discover-Continuity-Camera-for-tvOS","url":"\/documentation\/wwdcnotes\/wwdc23-10256-discover-continuity-camera-for-tvos","kind":"article","role":"sampleCode","abstract":[{"text":"Discover how you can bring AVFoundation, AVFAudio, and AudioToolbox to your apps on tvOS and create camera and microphone experiences for the living room. Find out how to support tvOS in your existing iOS camera experience with the Device Discovery API, build apps that use iPhone as a webcam or FaceTime source, and explore special considerations when developing for tvOS. We’ll also show you how to enable audio recording for tvOS, and how to use echo cancellation to create great voice-driven experiences.","type":"text"}],"title":"Discover Continuity Camera for tvOS"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10042-Explore-Natural-Language-multilingual-models":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10042-explore-natural-language-multilingual-models","title":"Explore Natural Language multilingual models","abstract":[{"type":"text","text":"Learn how to create custom Natural Language models for text classification and word tagging using multilingual, transformer-based embeddings. We’ll show you how to train with less data and support up to 27 different languages across three scripts. Find out how to use these embeddings to fine-tune complex models trained in PyTorch and TensorFlow."}]},"https://developer.apple.com/wwdc23/10081":{"titleInlineContent":[{"type":"text","text":"Enhance your spatial computing app with RealityKit - WWDC23"}],"url":"https:\/\/developer.apple.com\/wwdc23\/10081","title":"Enhance your spatial computing app with RealityKit - WWDC23","identifier":"https:\/\/developer.apple.com\/wwdc23\/10081","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space":{"kind":"article","role":"sampleCode","title":"Run your iPad and iPhone apps in the Shared Space","abstract":[{"type":"text","text":"Discover how you can run your existing iPad and iPhone apps on Vision Pro. Learn how iPadOS and iOS apps operate on this platform, find out about the Designed for iPad experience, and explore the paths available for enhancing your app experience on visionOS."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","url":"\/documentation\/wwdcnotes\/wwdc23-10090-run-your-ipad-and-iphone-apps-in-the-shared-space","type":"topic"},"WWDC23-10071-audiovisualMedia5":{"alt":"2D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-audiovisualMedia5.jpg"}],"identifier":"WWDC23-10071-audiovisualMedia5","type":"image"},"WWDC23-10071-threeDAudiovisualMedia8":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia8.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia8","type":"image"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10160-Demystify-SwiftUI-performance":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10160-Demystify-SwiftUI-performance","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10160-demystify-swiftui-performance","title":"Demystify SwiftUI performance","abstract":[{"type":"text","text":"Learn how you can build a mental model for performance in SwiftUI and write faster, more efficient code. We’ll share some of the common causes behind performance issues and help you triage hangs and hitches in SwiftUI to create more responsive views in your app."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10035-Perform-accessibility-audits-for-your-app":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10035-Perform-accessibility-audits-for-your-app","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10035-perform-accessibility-audits-for-your-app","title":"Perform accessibility audits for your app","abstract":[{"type":"text","text":"Discover how you can test your app for accessibility with every build. Learn how to perform automated audits for accessibility using XCTest and find out how to interpret the results. We’ll also share enhancements to the accessibility API that can help you improve UI test coverage."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10273-work-with-reality-composer-pro-content-in-xcode","abstract":[{"text":"Learn how to bring content from Reality Composer Pro to life in Xcode. We’ll show you how to load 3D scenes into Xcode, integrate your content with your code, and add interactivity to your app. We’ll also share best practices and tips for using these tools together in your development workflow.","type":"text"}],"type":"topic","title":"Work with Reality Composer Pro content in Xcode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10058-Whats-new-with-text-and-text-interactions":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10058-Whats-new-with-text-and-text-interactions","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10058-whats-new-with-text-and-text-interactions","title":"What’s new with text and text interactions","abstract":[{"text":"Text is an absolutely critical component of every app. Discover the latest features and enhancements for creating rich text experiences on Apple platforms. We’ll show you how to take advantage of common text elements and create entirely custom interactions for your app. Learn about updates to dictation, text loupe, and text selection, and explore improvements to text clipping, line wrapping, and hyphenation.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10262-Rediscover-Safari-developer-features":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10262-Rediscover-Safari-developer-features","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10262-rediscover-safari-developer-features","title":"Rediscover Safari developer features","abstract":[{"type":"text","text":"Get ready to explore Safari’s rich set of tools for web developers and designers. Learn how you can inspect web content, find out about Responsive Design Mode and WebDriver, and get started with simulators and devices. We’ll also show you how to pair with Vision Pro, make content inspectable in your apps, and use Open with Simulator in Responsive Design Mode to help you test your websites on any device."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10103-Explore-enhancements-to-App-Intents":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10103-Explore-enhancements-to-App-Intents","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10103-explore-enhancements-to-app-intents","abstract":[{"text":"Bring your widgets to life with App Intents! Explore the latest updates and learn how you can take advantage of dynamic options and user interactivity to build better experiences for your App Shortcuts. We’ll share how you can integrate with Apple Pay, structure your code more efficiently, and take your Shortcuts app integration to the next level.","type":"text"}],"type":"topic","title":"Explore enhancements to App Intents"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10238-Tune-up-your-AirPlay-audio-experience":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10238-Tune-up-your-AirPlay-audio-experience","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10238-tune-up-your-airplay-audio-experience","abstract":[{"text":"Learn how you can upgrade your app’s AirPlay audio experience to be more robust and responsive. We’ll show you how to adopt enhanced audio buffering with AVQueuePlayer, explore alternatives when building a custom player in your app, and share best practices.","type":"text"}],"type":"topic","title":"Tune up your AirPlay audio experience"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10180-Discover-streamlined-location-updates":{"title":"Discover streamlined location updates","url":"\/documentation\/wwdcnotes\/wwdc23-10180-discover-streamlined-location-updates","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10180-Discover-streamlined-location-updates","role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Move into the future with Core Location! Meet the CLLocationUpdate class, designed for modern Swift concurrency, and learn how it simplifies getting location updates. We’ll show you how this class works with your apps when they run in the foreground or background and share some best practices."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10278-Create-practical-workflows-in-Xcode-Cloud":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10278-Create-practical-workflows-in-Xcode-Cloud","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10278-create-practical-workflows-in-xcode-cloud","title":"Create practical workflows in Xcode Cloud","abstract":[{"text":"Learn how Xcode Cloud can help teams of all shapes and sizes in their development process. We’ll share different ways to configure actions to help you create simple yet powerful workflows, and show you how to extend Xcode Cloud when you integrate with additional tools.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10031-Update-your-app-for-watchOS-10":{"abstract":[{"text":"Join us as we update an Apple Watch app to take advantage of the latest features in watchOS 10. In this code-along, we’ll show you how to use the latest SwiftUI APIs to maximize glanceability and reorient app navigation around the Digital Crown.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10031-update-your-app-for-watchos-10","kind":"article","type":"topic","title":"Update your app for watchOS 10","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10031-Update-your-app-for-watchOS-10","role":"sampleCode"},"WWDC23-10071-threeDAudiovisualMedia2":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia2.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia2","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-111241-explore-3d-body-pose-and-person-segmentation-in-vision","title":"Explore 3D body pose and person segmentation in Vision","abstract":[{"text":"Discover how to build person-centric features with Vision. Learn how to detect human body poses and measure individual joint locations in 3D space. We’ll also show you how to take advantage of person segmentation APIs to distinguish and segment up to four individuals in an image.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10123-Bring-your-game-to-Mac-Part-1-Make-a-game-plan":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10123-Bring-your-game-to-Mac-Part-1-Make-a-game-plan","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10123-bring-your-game-to-mac-part-1-make-a-game-plan","title":"Bring your game to Mac, Part 1: Make a game plan","abstract":[{"type":"text","text":"Bring modern, high-end games to Mac and iPad with the powerful features of Metal and Apple silicon. Discover the game porting toolkit and learn how it can help you evaluate your existing Windows game for graphics feature compatibility and performance. We’ll share best practices and technical resources for handling audio, input, and advanced display features."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10072-Principles-of-spatial-design":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10072-principles-of-spatial-design","title":"Principles of spatial design","abstract":[{"text":"Discover the fundamentals of spatial design. Learn how to design with depth, scale, windows, and immersion, and apply best practices for creating comfortable, human-centered experiences that transform reality. Find out how you can use these spatial design principles to extend your existing app or bring a new idea to life.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices","kind":"article","abstract":[{"text":"Bring the latest advancements in Speech Synthesis to your apps. Learn how you can integrate your custom speech synthesizer and voices into iOS and macOS. We’ll show you how SSML is used to generate expressive speech synthesis, and explore how Personal Voice can enable your augmentative and assistive communication app to speak on a person’s behalf in an authentic way.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10033-extend-speech-synthesis-with-personal-and-custom-voices","title":"Extend Speech Synthesis with personal and custom voices","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10158-Animate-with-springs":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10158-Animate-with-springs","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10158-animate-with-springs","title":"Animate with springs","abstract":[{"text":"Discover how you can bring life to your app with animation! We’ll show you how to create amazing animations when you take advantage of springs and help you learn how to use them in your app.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10002-Ready-set-relay-Protect-app-traffic-with-network-relays":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10002-Ready-set-relay-Protect-app-traffic-with-network-relays","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10002-ready-set-relay-protect-app-traffic-with-network-relays","title":"Ready, set, relay: Protect app traffic with network relays","abstract":[{"text":"Learn how relays can make your app’s network traffic more private and secure without the overhead of a VPN. We’ll show you how to integrate relay servers in your own app and explore how enterprise networks can use relays to securely access internal resources.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10104-Integrate-your-media-app-with-HomePod":{"url":"\/documentation\/wwdcnotes\/wwdc23-10104-integrate-your-media-app-with-homepod","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10104-Integrate-your-media-app-with-HomePod","kind":"article","title":"Integrate your media app with HomePod","type":"topic","role":"sampleCode","abstract":[{"text":"Learn how people can interact with your media app directly from HomePod. We’ll show you how to add a media intent to your iPhone or iPad app and help people stream your content to a HomePod speaker over AirPlay simply by using their voice. Explore implementation details and get tips and best practices on how to create a great experience for music, audiobooks, podcasts, meditations, or other media types.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10061-Verify-app-dependencies-with-digital-signatures":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10061-Verify-app-dependencies-with-digital-signatures","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10061-verify-app-dependencies-with-digital-signatures","title":"Verify app dependencies with digital signatures","abstract":[{"text":"Discover how you can help secure your app’s dependencies. We’ll show you how Xcode can automatically verify any signed XCFrameworks you include within a project. Learn how code signatures work, the benefits they provide to help protect your software supply chain, and how SDK developers can sign their XCFrameworks to help keep your apps secure.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10202-explore-materials-in-reality-composer-pro","title":"Explore materials in Reality Composer Pro","abstract":[{"text":"Learn how Reality Composer Pro can help you alter the appearance of your 3D objects using RealityKit materials. We’ll introduce you to MaterialX and physically-based (PBR) shaders, show you how to design dynamic materials using the shader graph editor, and explore adding custom inputs to a material so that you can control it in your visionOS app.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10096-Build-great-games-for-spatial-computing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10096-Build-great-games-for-spatial-computing","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10096-build-great-games-for-spatial-computing","title":"Build great games for spatial computing","abstract":[{"text":"Find out how you can develop great gaming experiences for visionOS. We’ll share some of the key building blocks that help you create games for this platform, explore how your experiences can fluidly move between levels of immersion, and provide a roadmap for exploring ARKit, RealityKit, Reality Composer Pro, Unity, Metal, and Compositor.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10113-Take-SwiftUI-to-the-next-dimension":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10113-take-swiftui-to-the-next-dimension","title":"Take SwiftUI to the next dimension","abstract":[{"text":"Get ready to add depth and dimension to your visionOS apps. Find out how to bring three-dimensional objects to your app using volumes, get to know the Model 3D API, and learn how to position and animate content. We’ll also show you how to use UI attachments in RealityView and support gestures in your content.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10172-Mix-Swift-and-C++":{"abstract":[{"text":"Learn how you can use Swift in your C++ and Objective-C++ projects to make your code safer, faster, and easier to develop. We’ll show you how to use C++ and Swift APIs to incrementally incorporate Swift into your app.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10172-Mix-Swift-and-C++","title":"Mix Swift and C++","url":"\/documentation\/wwdcnotes\/wwdc23-10172-mix-swift-and-c++","type":"topic","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10263-Deploy-passkeys-at-work":{"url":"\/documentation\/wwdcnotes\/wwdc23-10263-deploy-passkeys-at-work","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10263-Deploy-passkeys-at-work","kind":"article","title":"Deploy passkeys at work","type":"topic","role":"sampleCode","abstract":[{"text":"Discover how you can take advantage of passkeys in managed environments at work. We’ll explore how passkeys can work well in enterprise environments through Managed Apple ID support for iCloud Keychain. We’ll also share how administrators can manage passkeys for specific devices using Access Management controls in Apple Business Manager and Apple School Manager.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10226-Debug-with-structured-logging":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10226-Debug-with-structured-logging","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10226-debug-with-structured-logging","title":"Debug with structured logging","abstract":[{"type":"text","text":"Discover the debug console in Xcode 15 and learn how you can improve your diagnostic experience through logging. Explore how you can navigate your logs easily and efficiently using advanced filtering and improved visualization. We’ll also show you how to use the dwim-print command to evaluate expressions in your code while debugging."}]},"WWDC23-10071-audiovisualMedia4":{"alt":"2D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-audiovisualMedia4.jpg"}],"identifier":"WWDC23-10071-audiovisualMedia4","type":"image"},"WWDC23-10071-threeDAudiovisualMedia11":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia11.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia11","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10036-Build-accessible-apps-with-SwiftUI-and-UIKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10036-Build-accessible-apps-with-SwiftUI-and-UIKit","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10036-build-accessible-apps-with-swiftui-and-uikit","title":"Build accessible apps with SwiftUI and UIKit","abstract":[{"type":"text","text":"Discover how advancements in UI frameworks make it easier to build rich, accessible experiences. Find out how technologies like VoiceOver can better interact with your app’s interface through accessibility traits and actions. We’ll share the latest updates to SwiftUI that help you refine your accessibility experience and show you how to keep accessibility information up-to-date in your UIKit apps."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10107-Embed-the-Photos-Picker-in-your-app":{"title":"Embed the Photos Picker in your app","url":"\/documentation\/wwdcnotes\/wwdc23-10107-embed-the-photos-picker-in-your-app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10107-Embed-the-Photos-Picker-in-your-app","role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Discover how you can simply, safely, and securely access the Photos Library in your app. Learn how to get started with the embedded picker and explore the options menu and HDR still image support. We’ll also show you how to take advantage of UI customization options to help the picker blend into your existing interface."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10195-Model-your-schema-with-SwiftData":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10195-Model-your-schema-with-SwiftData","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10195-model-your-schema-with-swiftdata","title":"Model your schema with SwiftData","abstract":[{"text":"Learn how to use schema macros and migration plans with SwiftData to build more complex features for your app. We’ll show you how to fine-tune your persistence with @Attribute and @Relationship options. Learn how to exclude properties from your data model with @Transient and migrate from one version of your schema to the next with ease.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10229-Make-features-discoverable-with-TipKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10229-Make-features-discoverable-with-TipKit","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10229-make-features-discoverable-with-tipkit","title":"Make features discoverable with TipKit","abstract":[{"type":"text","text":"Teach people how to use your app with TipKit! Learn how you can create effective educational moments through tips. We’ll share how you can build eligibility rules to reach the ideal audience, control tip frequency, and strategies for testing to ensure successful interactions."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10266-Protect-your-Mac-app-with-environment-constraints":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10266-Protect-your-Mac-app-with-environment-constraints","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10266-protect-your-mac-app-with-environment-constraints","title":"Protect your Mac app with environment constraints","abstract":[{"text":"Learn how to improve the security of your Mac app by adopting environment constraints. We’ll show you how to set limits on how processes are launched, make sure your Launch Agents and Launch Daemons aren’t tampered with, and prevent unwanted code from running in your address space.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10157-Wind-your-way-through-advanced-animations-in-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10157-Wind-your-way-through-advanced-animations-in-SwiftUI","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10157-wind-your-way-through-advanced-animations-in-swiftui","title":"Wind your way through advanced animations in SwiftUI","abstract":[{"type":"text","text":"Discover how you can take animation to the next level with the latest updates to SwiftUI. Join us as we wind our way through animation and build out multiple steps, use keyframes to add coordinated multi-track animated effects, and combine APIs in unique ways to make your app spring to life."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10142-Explore-testing-inapp-purchases":{"kind":"article","type":"topic","title":"Explore testing in-app purchases","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10142-Explore-testing-inapp-purchases","url":"\/documentation\/wwdcnotes\/wwdc23-10142-explore-testing-inapp-purchases","role":"sampleCode","abstract":[{"type":"text","text":"Learn how you can test in-app purchases throughout development with StoreKit Testing in Xcode, App Store sandbox, and TestFlight. Explore how each tool functions and how you can combine them to build the right workflow for testing your apps and games. We’ll also share a sneak preview of how you can test Family Sharing for in-app purchases & subscriptions in the App Store sandbox."}]},"WWDC23-10071-threeDAudiovisualMedia13":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia13.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia13","type":"image"},"WWDC23-10071-threeDAudiovisualMedia4":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia4.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia4","type":"image"},"https://developer.apple.com/forums/create/question?tag1=795030&tag2=744030":{"titleInlineContent":[{"type":"text","text":"Have a question? Ask with tag wwdc2023-10071"}],"url":"https:\/\/developer.apple.com\/forums\/create\/question?tag1=795030&tag2=744030","title":"Have a question? Ask with tag wwdc2023-10071","identifier":"https:\/\/developer.apple.com\/forums\/create\/question?tag1=795030&tag2=744030","type":"link"},"https://github.com/multitudes":{"titleInlineContent":[{"type":"text","text":"GitHub"}],"url":"https:\/\/github.com\/multitudes","title":"GitHub","identifier":"https:\/\/github.com\/multitudes","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10250-Prototype-with-Xcode-Playgrounds":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10250-Prototype-with-Xcode-Playgrounds","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10250-prototype-with-xcode-playgrounds","title":"Prototype with Xcode Playgrounds","abstract":[{"type":"text","text":"Speed up feature development by prototyping new code with Xcode Playgrounds, eliminating the need to keep rebuilding and relaunching your project to verify your changes. We’ll show you how using a playground in your project or package can help you try out your code in various scenarios and take a close look at the returned values, including complex structures and user interface elements, so you can quickly iterate on a feature before integrating it into your project."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10181-Support-HDR-images-in-your-app":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10181-Support-HDR-images-in-your-app","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10181-support-hdr-images-in-your-app","title":"Support HDR images in your app","abstract":[{"type":"text","text":"Learn how to identify, load, display, and create High Dynamic Range (HDR) still images in your app. Explore common HDR concepts and find out about the latest updates to the ISO specification. Learn how to identify and display HDR images with SwiftUI and UIKit, create them from ProRAW and RAW captures, and display them in CALayers. We’ll also take you through CoreGraphics support for ISO HDR and share best practices for HDR adoption."}],"role":"sampleCode","kind":"article"},"https://laurentbrusa.hashnode.dev/":{"titleInlineContent":[{"type":"text","text":"Blog"}],"url":"https:\/\/laurentbrusa.hashnode.dev\/","title":"Blog","identifier":"https:\/\/laurentbrusa.hashnode.dev\/","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10137-Support-Cinematic-mode-videos-in-your-app":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10137-Support-Cinematic-mode-videos-in-your-app","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10137-support-cinematic-mode-videos-in-your-app","title":"Support Cinematic mode videos in your app","abstract":[{"type":"text","text":"Discover how the Cinematic Camera API helps your app work with Cinematic mode videos captured in the Camera app. We’ll share the fundamentals — including Decision layers — that make up Cinematic mode video, show you how to access and update Decisions in your app, and help you save and load those changes."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10057-Unleash-the-UIKit-trait-system":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10057-Unleash-the-UIKit-trait-system","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10057-unleash-the-uikit-trait-system","title":"Unleash the UIKit trait system","abstract":[{"text":"Discover powerful enhancements to the trait system in UIKit. Learn how you can define custom traits to add your own data to UITraitCollection, modify the data propagated to view controllers and views with trait override APIs, and adopt APIs to improve flexibility and performance. We’ll also show you how to bridge UIKit traits with SwiftUI environment keys to seamlessly access data from both UIKit and SwiftUI components in your app.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10233-enhance-your-apps-audio-experience-with-airpods","title":"Enhance your app’s audio experience with AirPods","abstract":[{"text":"Discover how you can create transformative audio experiences in your app using AirPods. Learn how to incorporate AirPods Automatic Switching, use AVAudioApplication to support Mute Control, and take advantage of Spatial Audio to create immersive soundscapes in your app or game.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10088-Create-immersive-Unity-apps":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10088-Create-immersive-Unity-apps","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10088-create-immersive-unity-apps","title":"Create immersive Unity apps","abstract":[{"text":"Explore how you can use Unity to create engaging and immersive experiences for visionOS. We’ll share how Unity integrates seamlessly with Apple frameworks, take you through the tools you can use to build natively for the platform, and show you how volume cameras can bring your existing scenes into visionOS windows, volumes, and spaces.","type":"text"}],"role":"sampleCode","kind":"article"},"https://avatars.githubusercontent.com/u/29355828?v=4":{"alt":"Profile image of laurent b","variants":[{"traits":["1x","light"],"url":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4"}],"identifier":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10281-Keep-up-with-the-keyboard":{"abstract":[{"type":"text","text":"Each year, the keyboard evolves to support an increasing range of languages, sizes, and features. Discover how you can design your app to keep up with the keyboard, regardless of how it appears on a device. We’ll show you how to create frictionless text entry and share important architectural changes to help you understand how the keyboard works within the system."}],"type":"topic","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10281-Keep-up-with-the-keyboard","url":"\/documentation\/wwdcnotes\/wwdc23-10281-keep-up-with-the-keyboard","title":"Keep up with the keyboard"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10196-Dive-deeper-into-SwiftData":{"abstract":[{"text":"Learn how you can harness the power of SwiftData in your app. Find out how ModelContext and ModelContainer work together to persist your app’s data. We’ll show you how to track and make your changes manually and use SwiftData at scale with FetchDescriptor, SortDescriptor, and enumerate.","type":"text"}],"type":"topic","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10196-Dive-deeper-into-SwiftData","url":"\/documentation\/wwdcnotes\/wwdc23-10196-dive-deeper-into-swiftdata","title":"Dive deeper into SwiftData"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10170-Beyond-the-basics-of-structured-concurrency":{"title":"Beyond the basics of structured concurrency","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10170-Beyond-the-basics-of-structured-concurrency","kind":"article","abstract":[{"text":"It’s all about the task tree: Find out how structured concurrency can help your apps manage automatic task cancellation, task priority propagation, and useful task-local value patterns. Learn how to manage resources in your app with useful patterns and the latest task group APIs. We’ll show you how you can leverage the power of the task tree and task-local values to gain insight into distributed systems.","type":"text"}],"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10170-beyond-the-basics-of-structured-concurrency"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10029-Build-widgets-for-the-Smart-Stack-on-Apple-Watch":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10029-Build-widgets-for-the-Smart-Stack-on-Apple-Watch","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10029-build-widgets-for-the-smart-stack-on-apple-watch","title":"Build widgets for the Smart Stack on Apple Watch","abstract":[{"text":"Follow along as we build a widget for the Smart Stack on watchOS 10 using the latest SwiftUI and WidgetKit APIs. Learn tips, techniques, and best practices for creating widgets that show relevant information on Apple Watch.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10239-Add-SharePlay-to-your-app":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10239-Add-SharePlay-to-your-app","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10239-add-shareplay-to-your-app","title":"Add SharePlay to your app","abstract":[{"type":"text","text":"Discover how your app can take advantage of SharePlay to turn any activity into a shareable experience with friends! We’ll share the latest updates to SharePlay, explore the benefits of creating shared activities, dive into some exciting use cases, and take you through best practices to create engaging and fun moments of connection in your app."}],"role":"sampleCode","kind":"article"},"WWDCNotes.png":{"alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}],"identifier":"WWDCNotes.png","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10049-improve-core-ml-integration-with-async-prediction","title":"Improve Core ML integration with async prediction","abstract":[{"type":"text","text":"Learn how to speed up machine learning features in your app with the latest Core ML execution engine improvements and find out how aggressive asset caching can help with inference and faster model loads. We’ll show you some of the latest options for async prediction and discuss considerations for balancing performance with overall memory usage to help you create a highly responsive app. Discover APIs to help you understand and maximize hardware utilization for your models."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10166-Write-Swift-macros":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10166-Write-Swift-macros","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10166-write-swift-macros","title":"Write Swift macros","abstract":[{"text":"Discover how you can use Swift macros to make your codebase more expressive and easier to read. Code along as we explore how macros can help you avoid writing repetitive code and find out how to use them in your app. We’ll share the building blocks of a macro, show you how to test it, and take you through how you can emit compilation errors from macros.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10168-Generalize-APIs-with-parameter-packs":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10168-Generalize-APIs-with-parameter-packs","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10168-generalize-apis-with-parameter-packs","title":"Generalize APIs with parameter packs","abstract":[{"text":"Swift parameter packs are a powerful tool to expand what is possible in your generic code while also enabling you to simplify common generic patterns. We’ll show you how to abstract over types as well as the number of arguments in generic code and simplify common generic patterns to avoid overloads.","type":"text"}]},"https://developer.apple.com/wwdc23/10071?time=320":{"titleInlineContent":[{"type":"text","text":"05:20"}],"url":"https:\/\/developer.apple.com\/wwdc23\/10071?time=320","title":"05:20","identifier":"https:\/\/developer.apple.com\/wwdc23\/10071?time=320","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10073-Design-for-spatial-input":{"kind":"article","type":"topic","abstract":[{"type":"text","text":"Learn how to design great interactions for eyes and hands. We’ll share the design principles for spatial input, explore best practices around input methods, and help you create spatial experiences that are comfortable, intuitive, and satisfying."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10073-Design-for-spatial-input","url":"\/documentation\/wwdcnotes\/wwdc23-10073-design-for-spatial-input","role":"sampleCode","title":"Design for spatial input"},"WWDC23-10071-audiovisualMedia3":{"alt":"2D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-audiovisualMedia3.jpg"}],"identifier":"WWDC23-10071-audiovisualMedia3","type":"image"},"https://developer.apple.com/wwdc23/10071":{"url":"https:\/\/developer.apple.com\/wwdc23\/10071","identifier":"https:\/\/developer.apple.com\/wwdc23\/10071","type":"download","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10309-Design-widgets-for-the-Smart-Stack-on-Apple-Watch":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10309-Design-widgets-for-the-Smart-Stack-on-Apple-Watch","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10309-design-widgets-for-the-smart-stack-on-apple-watch","title":"Design widgets for the Smart Stack on Apple Watch","abstract":[{"text":"Bring your widgets to watchOS with the new Smart Stack. We’ll show you how to use standard design layouts, color and iconography, and signal-based relevancy to ensure your app’s widgets are glanceable, distinctive and smart.","type":"text"}]},"WWDC23-10071-audiovisualMedia8":{"alt":"2D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-audiovisualMedia8.jpg"}],"identifier":"WWDC23-10071-audiovisualMedia8","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing":{"role":"sampleCode","title":"Get started with building apps for spatial computing","abstract":[{"type":"text","text":"Get ready to develop apps and games for visionOS! Discover the fundamental building blocks that make up spatial computing — windows, volumes, and spaces — and find out how you can use these elements to build engaging and immersive experiences."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc23-10260-get-started-with-building-apps-for-spatial-computing","type":"topic","kind":"article"},"WWDC23-10071-threeDAudiovisualMedia6":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia6.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia6","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10257-Create-animated-symbols":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10257-Create-animated-symbols","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10257-create-animated-symbols","title":"Create animated symbols","abstract":[{"text":"Discover animation presets and learn how to use them with SF Symbols and custom symbols. We’ll show you how to experiment with different options and configurations to find the perfect animation for your app. Learn how to update custom symbols for animation using annotation features, find out how to modify your custom symbols with symbol components, and explore the redesigned export process to help keep symbols looking great on all platforms.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10115-Design-with-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10115-Design-with-SwiftUI","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10115-design-with-swiftui","title":"Design with SwiftUI","abstract":[{"type":"text","text":"Discover how SwiftUI can help you quickly iterate and explore design ideas. Learn from Apple designers as they share how working with SwiftUI influenced the design of the Maps app in watchOS 10 and other elements of their work, and find out how you can incorporate these workflows in your own process."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10193-Design-Shortcuts-for-Spotlight":{"title":"Design Shortcuts for Spotlight","kind":"article","type":"topic","role":"sampleCode","abstract":[{"type":"text","text":"Learn about the latest updates to the visual language of App Shortcuts and find out how to design your shortcut to appear as a top hit in Spotlight. We’ll share how shortcuts can appear on iOS or iPadOS, and show you how to customize the visual appearance of a shortcut, personalize its order, select its correct behavior, and increase discoverability."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10193-Design-Shortcuts-for-Spotlight","url":"\/documentation\/wwdcnotes\/wwdc23-10193-design-shortcuts-for-spotlight"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10189-Migrate-to-SwiftData":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10189-Migrate-to-SwiftData","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10189-migrate-to-swiftdata","title":"Migrate to SwiftData","abstract":[{"text":"Discover how you can start using SwiftData in your apps. We’ll show you how to use Xcode to generate model classes from your existing Core Data object models, use SwiftData alongside your previous implementation, or even completely replace your existing solution.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10052-Discover-Calendar-and-EventKit":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10052-Discover-Calendar-and-EventKit","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10052-discover-calendar-and-eventkit","title":"Discover Calendar and EventKit","abstract":[{"text":"Discover how you can bring Calendar into your app and help people better manage their time. Find out how to create new events from your app, fetch events, and implement a virtual conference extension. We’ll also take you through some of the changes to calendar access levels that help your app stay connected without compromising the privacy of someone’s calendar data.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10004-Reduce-network-delays-with-L4S":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10004-Reduce-network-delays-with-L4S","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10004-reduce-network-delays-with-l4s","title":"Reduce network delays with L4S","abstract":[{"text":"Streaming video, multiplayer games, and other real-time experiences depend on responsive, low latency networking. Learn how Low Latency, Low Loss, Scalable throughput (L4S) can reduce network delays and improve the overall experience in your app. We’ll show you how to set up and test your app, network, and server with L4S.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10122-Explore-media-formats-for-the-web":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10122-Explore-media-formats-for-the-web","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10122-explore-media-formats-for-the-web","abstract":[{"text":"Learn about the latest image formats and video technologies supported in Safari 17. Discover how you can use JPEG XL, AVIF, and HEIC in your websites and experiences and learn how they differ from previous formats. We’ll also show you how the Managed Media Source API draws less power than Media Source Extensions (MSE) and explore how you can use it to more efficiently manage streaming video over 5G.","type":"text"}],"type":"topic","title":"Explore media formats for the web"},"https://developer.apple.com/av-foundation/Video-Contour-Map-Metadata.pdf":{"titleInlineContent":[{"type":"text","text":"Video Contour Map Payload Metadata within the QuickTime Movie File Format"}],"url":"https:\/\/developer.apple.com\/av-foundation\/Video-Contour-Map-Metadata.pdf","title":"Video Contour Map Payload Metadata within the QuickTime Movie File Format","identifier":"https:\/\/developer.apple.com\/av-foundation\/Video-Contour-Map-Metadata.pdf","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10075-Design-spatial-SharePlay-experiences":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10075-Design-spatial-SharePlay-experiences","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10075-design-spatial-shareplay-experiences","title":"Design spatial SharePlay experiences","abstract":[{"text":"Explore the types of shared activities you can create in your visionOS apps and find out how your apps can use Spatial Persona templates to support meaningful interactions between people. Discover how to design your UI around a shared context, handle immersive content in a shared activity, and more.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"role":"collectionGroup","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23","title":"WWDC23","abstract":[{"text":"Xcode 15, Swift 5.9, iOS 17, macOS 14, tvOS 17, visionOS 1, watchOS 10.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"type":"codeVoice","code":"SwiftData"},{"text":", ","type":"text"},{"type":"codeVoice","code":"Observation"},{"text":", ","type":"text"},{"type":"codeVoice","code":"StoreKit"},{"text":" views, and more.","type":"text"}],"images":[{"identifier":"WWDCNotes.png","type":"icon"}]},"https://developer.apple.com/wwdc23/10070":{"titleInlineContent":[{"type":"text","text":"Create a great spatial playback experience - WWDC23"}],"url":"https:\/\/developer.apple.com\/wwdc23\/10070","title":"Create a great spatial playback experience - WWDC23","identifier":"https:\/\/developer.apple.com\/wwdc23\/10070","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10304-integrate-with-motorized-iphone-stands-using-dockkit","title":"Integrate with motorized iPhone stands using DockKit","abstract":[{"text":"Discover how you can create incredible photo and video experiences in your camera app when integrating with DockKit-compatible motorized stands. We’ll show how your app can automatically track subjects in live video across a 360-degree field of view, take direct control of the stand to customize framing, directly control the motors, and provide your own inference model for tracking other objects. Finally, we’ll demonstrate how to create a sense of emotion through dynamic device animations.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10078-Design-considerations-for-vision-and-motion":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10078-Design-considerations-for-vision-and-motion","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10078-design-considerations-for-vision-and-motion","title":"Design considerations for vision and motion","abstract":[{"type":"text","text":"Learn how to design engaging immersive experiences for visionOS that respect the limitations of human vision and motion perception. We’ll show you how you can use depth cues, contrast, focus, and motion to keep people comfortable as they enjoy your apps and games."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10149-Discover-Observation-in-SwiftUI":{"url":"\/documentation\/wwdcnotes\/wwdc23-10149-discover-observation-in-swiftui","kind":"article","role":"sampleCode","title":"Discover Observation in SwiftUI","type":"topic","abstract":[{"text":"Simplify your SwiftUI data models with Observation. We’ll share how the Observable macro can help you simplify models and improve your app’s performance. Get to know Observation, learn the fundamentals of the macro, and find out how to migrate from ObservableObject to Observable.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10149-Discover-Observation-in-SwiftUI"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10159-Beyond-scroll-views":{"url":"\/documentation\/wwdcnotes\/wwdc23-10159-beyond-scroll-views","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10159-Beyond-scroll-views","kind":"article","abstract":[{"text":"Find out how you can take your scroll views to the next level with the latest APIs in SwiftUI. We’ll show you how to customize scroll views like never before. Explore the relationship between safe areas and a scroll view’s margins, learn how to interact with the content offset of a scroll view, and discover how you can add a bit of flair to your content with scroll transitions.","type":"text"}],"type":"topic","title":"Beyond scroll views"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10252-Build-programmatic-UI-with-Xcode-Previews":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10252-Build-programmatic-UI-with-Xcode-Previews","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10252-build-programmatic-ui-with-xcode-previews","title":"Build programmatic UI with Xcode Previews","abstract":[{"text":"Learn how you can use the #Preview macro on Xcode 15 to quickly iterate on your UI code written in SwiftUI, UIKit, or AppKit. Explore a collage of unique workflows for interacting with views right in the canvas, find out how to view multiple variations of UI simultaneously, and discover how you can travel through your widget’s timeline in seconds to test the transitions between entries. We’ll also show you how to add previews to libraries, provide sample assets, and preview your views in your physical devices to leverage their capabilities and existing data.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10027-Bring-widgets-to-new-places":{"abstract":[{"text":"The widget ecosystem is expanding: Discover how you can use the latest WidgetKit APIs to make your widget look great everywhere. We’ll show you how to identify your widget’s background, adjust layout dynamically, and prepare colors for vibrant rendering so that your widget can sit seamlessly in any environment.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10027-Bring-widgets-to-new-places","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10027-bring-widgets-to-new-places","title":"Bring widgets to new places","kind":"article","role":"sampleCode"},"WWDC23-10071-threeDAudiovisualMedia5":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia5.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia5","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10161-Inspectors-in-SwiftUI-Discover-the-details":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10161-Inspectors-in-SwiftUI-Discover-the-details","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10161-inspectors-in-swiftui-discover-the-details","title":"Inspectors in SwiftUI: Discover the details","abstract":[{"text":"Meet Inspectors — a structural API that can help bring a new level of detail to your apps. We’ll take you through the fundamentals of the API and show you how to adopt it. Learn about the latest updates to sheet presentation customizations and find out how you can combine the two to create perfect presentation experiences.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10095-Explore-rendering-for-spatial-computing":{"url":"\/documentation\/wwdcnotes\/wwdc23-10095-explore-rendering-for-spatial-computing","kind":"article","role":"sampleCode","title":"Explore rendering for spatial computing","type":"topic","abstract":[{"text":"Find out how you can take control of RealityKit rendering to improve the look and feel of your apps and games on visionOS. Discover how you can customize lighting, add grounding shadows, and control tone mapping for your content. We’ll also go over best practices for two key treatments on the platform: rasterization rate maps and dynamic content scaling.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10095-Explore-rendering-for-spatial-computing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10124-Bring-your-game-to-Mac-Part-2-Compile-your-shaders":{"title":"Bring your game to Mac, Part 2: Compile your shaders","url":"\/documentation\/wwdcnotes\/wwdc23-10124-bring-your-game-to-mac-part-2-compile-your-shaders","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10124-Bring-your-game-to-Mac-Part-2-Compile-your-shaders","role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Discover how the Metal shader converter streamlines the process of bringing your HLSL shaders to Metal as we continue our three-part series on bringing your game to Mac. Find out how to build a fast, end-to-end shader pipeline from DXIL that supports all shader stages and allows you to leverage the advanced features of Apple GPUs. We’ll also show you how to reduce app launch time and stutters by generating GPU binaries with the offline compiler."}],"kind":"article"},"WWDC23-10071-threeDAudiovisualMedia10":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia10.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia10","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10094-Enhance-your-iPad-and-iPhone-apps-for-the-Shared-Space":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10094-Enhance-your-iPad-and-iPhone-apps-for-the-Shared-Space","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10094-enhance-your-ipad-and-iphone-apps-for-the-shared-space","title":"Enhance your iPad and iPhone apps for the Shared Space","abstract":[{"text":"Get ready to enhance your iPad and iPhone apps for the Shared Space! We’ll show you how to optimize your experience to make it feel great on visionOS and explore Designed for iPad app interaction, visual treatments, and media.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10125-Bring-your-game-to-Mac-Part-3-Render-with-Metal":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10125-Bring-your-game-to-Mac-Part-3-Render-with-Metal","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10125-bring-your-game-to-mac-part-3-render-with-metal","title":"Bring your game to Mac, Part 3: Render with Metal","abstract":[{"text":"Discover how you can support Metal in your rendering code as we close out our three-part series on bringing your game to Mac. Once you’ve evaluated your existing Windows binary with the game porting toolkit and brought your HLSL shaders over to Metal, learn how you can optimally implement the features that high-end, modern games require. We’ll show you how to manage GPU resource bindings, residency, and synchronization. Find out how to optimize GPU commands submission, render rich visuals with MetalFX Upscaling, and more.","type":"text"}]},"https://developer.apple.com/av-foundation/HEVC-Stereo-Video-Profile.pdf":{"titleInlineContent":[{"type":"text","text":"Apple HEVC Stereo Video Interoperability Profile"}],"url":"https:\/\/developer.apple.com\/av-foundation\/HEVC-Stereo-Video-Profile.pdf","title":"Apple HEVC Stereo Video Interoperability Profile","identifier":"https:\/\/developer.apple.com\/av-foundation\/HEVC-Stereo-Video-Profile.pdf","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10167-Expand-on-Swift-macros":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10167-Expand-on-Swift-macros","kind":"article","title":"Expand on Swift macros","abstract":[{"type":"text","text":"Discover how Swift macros can help you reduce boilerplate in your codebase and adopt complex features more easily. Learn how macros can analyze code, emit rich compiler errors to guide developers towards correct usage, and generate new code that is automatically incorporated back into your project. We’ll also take you through important concepts like macro roles, compiler plugins, and syntax trees."}],"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10167-expand-on-swift-macros"},"https://developer.apple.com/wwdc23/10071?time=41":{"titleInlineContent":[{"type":"text","text":"00:41"}],"url":"https:\/\/developer.apple.com\/wwdc23\/10071?time=41","title":"00:41","identifier":"https:\/\/developer.apple.com\/wwdc23\/10071?time=41","type":"link"},"https://x.com/wrmultitudes":{"titleInlineContent":[{"type":"text","text":"X\/Twitter"}],"url":"https:\/\/x.com\/wrmultitudes","title":"X\/Twitter","identifier":"https:\/\/x.com\/wrmultitudes","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10254-Do-more-with-Managed-Apple-IDs":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10254-Do-more-with-Managed-Apple-IDs","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10254-do-more-with-managed-apple-ids","title":"Do more with Managed Apple IDs","abstract":[{"text":"Explore the latest updates to Managed Apple IDs and learn how you can use them in your organization. Take advantage of additional apps and services available to Managed Apple IDs, discover the Account-Driven Device Enrollment flow, and find out how to use access management controls to limit the devices and Apple services that Managed Apple IDs can access. We’ll also show you how to federate with your identity provider to automate creation and sync with your directory.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10224-Simplify-distribution-in-Xcode-and-Xcode-Cloud":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10224-Simplify-distribution-in-Xcode-and-Xcode-Cloud","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10224-simplify-distribution-in-xcode-and-xcode-cloud","title":"Simplify distribution in Xcode and Xcode Cloud","abstract":[{"text":"Discover how to share your app using Xcode’s streamlined distribution, which allows you to submit your app to TestFlight or the App Store with one click. We’ll also show you how to use Xcode Cloud to simplify your distribution process by automatically including notes for testers in TestFlight, and use post-action to automatically notarize your Mac apps.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10089-Discover-Metal-for-immersive-apps":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10089-Discover-Metal-for-immersive-apps","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10089-discover-metal-for-immersive-apps","abstract":[{"text":"Find out how you can use Metal to render fully immersive experiences for visionOS. We’ll show you how to set up a rendering session on the platform and create a basic render loop, and share how you can make your experience interactive by incorporating spatial input.","type":"text"}],"type":"topic","title":"Discover Metal for immersive apps"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10101-Customize-ondevice-speech-recognition":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10101-Customize-ondevice-speech-recognition","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10101-customize-ondevice-speech-recognition","title":"Customize on-device speech recognition","abstract":[{"type":"text","text":"Find out how you can improve on-device speech recognition in your app by customizing the underlying model with additional vocabulary. We’ll share how speech recognition works on device and show you how to boost specific words and phrases for more predictable transcription. Learn how you can provide specific pronunciations for words and use template support to quickly generate a full set of custom phrases — all at runtime."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10044-discover-machine-learning-enhancements-in-create-ml","title":"Discover machine learning enhancements in Create ML","abstract":[{"type":"text","text":"Find out how Create ML can help you do even more with machine learning models. Learn about the latest updates to image understanding and text-based tasks with multilingual BERT embeddings. Discover how easy it is to train models that can understand the content of images using multi-label classification. We’ll also share information about interactive model evaluation and the latest APIs for custom training data augmentations."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10248-Analyze-hangs-with-Instruments":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10248-Analyze-hangs-with-Instruments","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10248-analyze-hangs-with-instruments","title":"Analyze hangs with Instruments","abstract":[{"text":"User interface elements often mimic real-world interactions, including real-time responses. Apps with a noticeable delay in user interaction — a hang — can break that illusion and create frustration. We’ll show you how to use Instruments to analyze, understand, and fix hangs in your apps on all Apple platforms. Discover how you can efficiently navigate an Instruments trace document, interpret trace data, and record additional profiling data to better understand your specific hang.","type":"text"}]},"WWDC23-10071-threeDAudiovisualMedia15":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia15.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia15","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10093-Bring-your-Unity-VR-app-to-a-fully-immersive-space":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10093-Bring-your-Unity-VR-app-to-a-fully-immersive-space","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10093-bring-your-unity-vr-app-to-a-fully-immersive-space","abstract":[{"text":"Discover how you can bring your existing Unity VR apps and games to visionOS. We’ll explore workflows that can help you get started and show you how to build for eyes and hands in your apps and games with the Unity Input System. Learn about Unity’s XR Interaction Toolkit, tips for foveated rendering, and best practices.","type":"text"}],"type":"topic","title":"Bring your Unity VR app to a fully immersive space"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10271-Explore-immersive-sound-design":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10271-Explore-immersive-sound-design","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10271-explore-immersive-sound-design","title":"Explore immersive sound design","abstract":[{"type":"text","text":"Discover how you can use sound to enhance the experience of your visionOS apps and games. Learn how Apple designers select sounds and build soundscapes to create textural, immersive experiences. We’ll share how you can enrich basic interactions in your app with sound when you place audio cues spatially, vary repetitive sounds, and build moments of sonic delight into your app."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10012-Explore-App-Store-Connect-for-spatial-computing":{"abstract":[{"text":"App Store Connect provides the tools you need to test, submit, and manage your visionOS apps on the App Store. Explore basics and best practices for deploying your first spatial computing app, adding support for visionOS to an existing app, and managing compatibility. We’ll also show you how TestFlight for visionOS can help you test your apps and collect valuable feedback as you iterate.","type":"text"}],"type":"topic","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10012-Explore-App-Store-Connect-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc23-10012-explore-app-store-connect-for-spatial-computing","title":"Explore App Store Connect for spatial computing"},"https://developer.apple.com/av-foundation/Stereo-Video-ISOBMFF-Extensions.pdf":{"titleInlineContent":[{"type":"text","text":"ISO Base Media File Format and Apple HEVC Stereo Video"}],"url":"https:\/\/developer.apple.com\/av-foundation\/Stereo-Video-ISOBMFF-Extensions.pdf","title":"ISO Base Media File Format and Apple HEVC Stereo Video","identifier":"https:\/\/developer.apple.com\/av-foundation\/Stereo-Video-ISOBMFF-Extensions.pdf","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10070-Create-a-great-spatial-playback-experience":{"url":"\/documentation\/wwdcnotes\/wwdc23-10070-create-a-great-spatial-playback-experience","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10070-Create-a-great-spatial-playback-experience","kind":"article","abstract":[{"text":"Get ready to support video in your visionOS app! Take a tour of the frameworks and APIs that power video playback and learn how you can update your app to play 3D content. We’ll also share tips for customizing playback to create a more immersive watching experience.","type":"text"}],"type":"topic","title":"Create a great spatial playback experience"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10175-Fix-failures-faster-with-Xcode-test-reports":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10175-Fix-failures-faster-with-Xcode-test-reports","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10175-fix-failures-faster-with-xcode-test-reports","title":"Fix failures faster with Xcode test reports","abstract":[{"text":"Discover how you can find, debug, and fix test failures faster with the test report in Xcode and Xcode Cloud. Learn how Xcode identifies failure patterns to help you find the right place to start investigating. We’ll also show you how to use the UI automation explorer and video recordings to understand the events that led up to your UI test failure.","type":"text"}],"role":"sampleCode","kind":"article"},"WWDC23-10071-threeDAudiovisualMedia14":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia14.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia14","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10006-Build-robust-and-resumable-file-transfers":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10006-Build-robust-and-resumable-file-transfers","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10006-build-robust-and-resumable-file-transfers","abstract":[{"text":"Find out how URLSession can help your apps transfer large files and recover from network interruptions. Learn how to pause and resume HTTP file transfers and support resumable uploads, and explore best practices for using URLSession to transfer files even when your app is suspended in the background.","type":"text"}],"type":"topic","title":"Build robust and resumable file transfers"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10111-Go-beyond-the-window-with-SwiftUI":{"url":"\/documentation\/wwdcnotes\/wwdc23-10111-go-beyond-the-window-with-swiftui","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","kind":"article","abstract":[{"text":"Get ready to launch into space — a new SwiftUI scene type that can help you make great immersive experiences for visionOS. We’ll show you how to create a new scene with ImmersiveSpace, place 3D content, and integrate RealityView. Explore how you can use the immersionStyle scene modifier to increase the level of immersion in an app and learn best practices for managing spaces, adding virtual hands with ARKit, adding support for SharePlay, and building an “out of this world” experience!","type":"text"}],"type":"topic","title":"Go beyond the window with SwiftUI"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10138-Design-and-build-apps-for-watchOS-10":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10138-Design-and-build-apps-for-watchOS-10","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10138-design-and-build-apps-for-watchos-10","title":"Design and build apps for watchOS 10","abstract":[{"text":"Dive into the details of watchOS design principles and learn how to apply them in your app using SwiftUI. We’ll show you how to build an app for the redesigned user interface to surface timely information, communicate focused content at a glance, and make navigation consistent and predictable.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10176-Lift-subjects-from-images-in-your-app":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10176-lift-subjects-from-images-in-your-app","kind":"article","abstract":[{"type":"text","text":"Discover how you can easily pull the subject of an image from its background in your apps. Learn how to lift the primary subject or to access the subject at a given point with VisionKit. We’ll also share how you can lift subjects using Vision and combine that with lower-level frameworks like Core Image to create fun image effects and more complex compositing pipelines."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10176-Lift-subjects-from-images-in-your-app","title":"Lift subjects from images in your app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10275-Explore-AirPlay-with-interstitials":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10275-Explore-AirPlay-with-interstitials","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10275-explore-airplay-with-interstitials","title":"Explore AirPlay with interstitials","abstract":[{"text":"Learn how you can use HLS Interstitials with AirPlay to create seamless transitions for your video content between advertisements. We’ll share best practices and tips for creating a great experience when sharing content from Apple devices to popular smart TVs.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/multitudes":{"abstract":[{"type":"text","text":"student at 42Berlin 🐬 | 🍎 Swift(UI) app dev  | speciality coffee ☕️ & cycling 🚴🏻‍♂️"}],"type":"topic","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","url":"\/documentation\/wwdcnotes\/multitudes","title":"laurent b (32 notes)"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10241-Share-files-with-SharePlay":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10241-Share-files-with-SharePlay","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10241-share-files-with-shareplay","title":"Share files with SharePlay","abstract":[{"text":"Discover how to work with files and attachments in a SharePlay activity. We’ll explain how to use the GroupSessionJournal API to sync large amounts of data faster and show you how to adopt it in a demo of the sample app DrawTogether.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10185-Update-Live-Activities-with-push-notifications":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10185-Update-Live-Activities-with-push-notifications","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10185-update-live-activities-with-push-notifications","title":"Update Live Activities with push notifications","abstract":[{"text":"Discover how you can remotely update Live Activities in your app when you push content through Apple Push Notification service (APNs). We’ll show you how to configure your first Live Activity push locally so you can quickly iterate on your implementation. Learn best practices for determining your push priority and configuring alerting updates, and explore how to further improve your Live Activities with relevance score and stale date.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10086-Explore-the-USD-ecosystem":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10086-explore-the-usd-ecosystem","title":"Explore the USD ecosystem","abstract":[{"text":"Discover the latest updates to Universal Scene Description (USD) on Apple platforms and learn how you can deliver great 3D content for your apps, games, and websites. Get to know USD for visionOS, explore MaterialX shaders and color management, and find out about some of the other improvements to the USD ecosystem.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10102-Spotlight-your-app-with-App-Shortcuts":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10102-Spotlight-your-app-with-App-Shortcuts","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10102-spotlight-your-app-with-app-shortcuts","title":"Spotlight your app with App Shortcuts","abstract":[{"text":"Discover how to use App Shortcuts to surface frequently used features from your app in Spotlight or through Siri. Find out how to configure search results for your app and learn best practices for creating great App Shortcuts. We’ll also show you how to build great visual and voice experiences and extend to other Apple devices like Apple Watch and HomePod.","type":"text"}]},"WWDC23-10071-contentPipeline":{"alt":"Content pipeline","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-contentPipeline.jpg"}],"identifier":"WWDC23-10071-contentPipeline","type":"image"},"WWDC23-10071-threeDAudiovisualMedia9":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia9.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia9","type":"image"},"WWDC23-10071-audiovisualMedia2":{"alt":"2D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-audiovisualMedia2.jpg"}],"identifier":"WWDC23-10071-audiovisualMedia2","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10154-Build-an-app-with-SwiftData":{"role":"sampleCode","abstract":[{"type":"text","text":"Discover how SwiftData can help you persist data in your app. Code along with us as we bring SwiftData to a multi-platform SwiftUI app. Learn how to convert existing model classes into SwiftData models, set up the environment, reflect model layer changes in UI, and build document-based applications backed by SwiftData storage."}],"type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10154-Build-an-app-with-SwiftData","url":"\/documentation\/wwdcnotes\/wwdc23-10154-build-an-app-with-swiftdata","title":"Build an app with SwiftData"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10258-Animate-symbols-in-your-app":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10258-Animate-symbols-in-your-app","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10258-animate-symbols-in-your-app","title":"Animate symbols in your app","abstract":[{"text":"Bring delight to your app with animated symbols. Explore the new Symbols framework, which features a unified API to create and configure symbol effects. Learn how SwiftUI, AppKit, and UIKit make it easy to animate symbols in user interfaces. Discover tips and tricks to seamlessly integrate the new animations alongside other app content. To get the most from this session, we recommend first watching “What’s new in SF Symbols 5.”","type":"text"}]},"WWDC23-10071-threeDAudiovisualMedia3":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia3.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia3","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10047-use-core-ml-tools-for-machine-learning-model-compression","title":"Use Core ML Tools for machine learning model compression","abstract":[{"type":"text","text":"Discover how to reduce the footprint of machine learning models in your app with Core ML Tools. Learn how to use techniques like palettization, pruning, and quantization to dramatically reduce model size while still achieving great accuracy. Explore comparisons between compression during the training stages and on fully trained models, and learn how compressed models can run even faster when your app takes full advantage of the Apple Neural Engine."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10105-Create-a-more-responsive-camera-experience":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10105-Create-a-more-responsive-camera-experience","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10105-create-a-more-responsive-camera-experience","title":"Create a more responsive camera experience","abstract":[{"text":"Discover how AVCapture and PhotoKit can help you create more responsive and delightful apps. Learn about the camera capture process and find out how deferred photo processing can help create the best quality photo. We’ll show you how zero shutter lag uses time travel to capture the perfect action photo, dive into building a responsive capture pipeline, and share how you can adopt the Video Effects API to recognize pre-defined gestures that trigger real-time video effects.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10203-Develop-your-first-immersive-app":{"url":"\/documentation\/wwdcnotes\/wwdc23-10203-develop-your-first-immersive-app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app","kind":"article","title":"Develop your first immersive app","type":"topic","role":"sampleCode","abstract":[{"text":"Find out how you can build immersive apps for visionOS using Xcode and Reality Composer Pro. We’ll show you how to get started with a new visionOS project, use Xcode Previews for your SwiftUI development, and take advantage of RealityKit and RealityView to render 3D content.","type":"text"}]},"WWDC23-10071-audiovisualMedia6":{"alt":"2D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-audiovisualMedia6.jpg"}],"identifier":"WWDC23-10071-audiovisualMedia6","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10188-Sync-to-iCloud-with-CKSyncEngine":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10188-sync-to-icloud-with-cksyncengine","kind":"article","abstract":[{"type":"text","text":"Discover how CKSyncEngine can help you sync people’s CloudKit data to iCloud. Learn how you can reduce the amount of code in your app when you let the system handle scheduling for your sync operations. We’ll share how you can automatically benefit from enhanced performance as CloudKit evolves, explore testing for your sync implementation, and more."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10188-Sync-to-iCloud-with-CKSyncEngine","title":"Sync to iCloud with CKSyncEngine"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10110-elevate-your-windowed-app-for-spatial-computing","abstract":[{"text":"Discover how you can bring your multiplatform SwiftUI app to visionOS and the Shared Space. We’ll show you how to add the visionOS destination to an existing app and view your app in the Simulator. Explore how your SwiftUI code automatically adapts to support the unique context and presentation of the visionOS platform. Learn how you can update custom views, improve your app’s UI, and add features and controls specific to this platform.","type":"text"}],"type":"topic","title":"Elevate your windowed app for spatial computing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10244-Create-rich-documentation-with-SwiftDocC":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10244-Create-rich-documentation-with-SwiftDocC","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10244-create-rich-documentation-with-swiftdocc","title":"Create rich documentation with Swift-DocC","abstract":[{"text":"Learn how you can take advantage of the latest features in Swift-DocC to create rich and detailed documentation for your app or framework. We’ll show you how to use the Xcode 15 Documentation Preview editor to efficiently iterate on your existing project’s documentation, and explore expanded authoring capabilities like grid-based layouts, video support, and custom themes.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10155-Discover-String-Catalogs":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10155-Discover-String-Catalogs","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10155-discover-string-catalogs","title":"Discover String Catalogs","abstract":[{"text":"Discover how Xcode 15 makes it easy to localize your app by managing all of your strings in one place. We’ll show you how to extract, edit, export, and build strings in your project using String Catalogs. We’ll also share how you can adopt String Catalogs in existing projects at your own pace by choosing which files to migrate.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10045-Detect-animal-poses-in-Vision":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10045-detect-animal-poses-in-vision","abstract":[{"text":"Go beyond detecting cats and dogs in images. We’ll show you how to use Vision to detect the individual joints and poses of these animals as well — all in real time — and share how you can enable exciting features like animal tracking for a camera app, creative embellishment on an animal photo, and more. We’ll also explore other important enhancements to Vision and share best practices.","type":"text"}],"type":"topic","title":"Detect animal poses in Vision"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10050-Optimize-machine-learning-for-Metal-apps":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10050-Optimize-machine-learning-for-Metal-apps","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10050-optimize-machine-learning-for-metal-apps","title":"Optimize machine learning for Metal apps","abstract":[{"text":"Discover the latest enhancements to accelerated ML training in Metal. Find out about updates to PyTorch and TensorFlow, and learn about Metal acceleration for JAX. We’ll show you how MPS Graph can support faster ML inference when you use both the GPU and Apple Neural Engine, and share how the same API can rapidly integrate your Core ML and ONNX models.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10162-The-SwiftUI-cookbook-for-focus":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10162-The-SwiftUI-cookbook-for-focus","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10162-the-swiftui-cookbook-for-focus","title":"The SwiftUI cookbook for focus","abstract":[{"type":"text","text":"The SwiftUI team is back in the coding “kitchen” with powerful tools to shape your app’s focus experience. Join us and learn about the staple ingredients that support focus-driven interactions in your app. Discover focus interactions for custom views, find out about key-press handlers for keyboard input, and learn how to support movement and hierarchy with focus sections. We’ll also go through some tasty recipes for common focus patterns in your app."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10192-Explore-enhancements-to-RoomPlan":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10192-Explore-enhancements-to-RoomPlan","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10192-explore-enhancements-to-roomplan","title":"Explore enhancements to RoomPlan","abstract":[{"type":"text","text":"Join us for an exciting update to RoomPlan as we explore MultiRoom support and enhancements to room representations. Learn how you can scan areas with more detail, capture multiple rooms, and merge individual scans into one larger structure. We’ll also share workflows and best practices when working with RoomPlan results that you want to combine into your existing 3D model library."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10056-Build-better-documentbased-apps":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10056-Build-better-documentbased-apps","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10056-build-better-documentbased-apps","title":"Build better document-based apps","abstract":[{"text":"Discover how you can use the latest features in iPadOS to improve your document-based apps. We’ll show you how to take advantage of UIDocument as well as existing desktop-class iPad and document-based APIs to add new features in your app. Find out how to convert data models to UIDocument, present documents with UIDocumentViewController, learn how to migrate your apps to the latest APIs, and explore best practices.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10060-Get-started-with-privacy-manifests":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10060-Get-started-with-privacy-manifests","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10060-get-started-with-privacy-manifests","title":"Get started with privacy manifests","abstract":[{"type":"text","text":"Meet privacy manifests: a new tool that helps you accurately identify the privacy practices of your app’s dependencies. Find out how third-party SDK developers can use these manifests to share privacy practices for their frameworks. We’ll also share how Xcode can produce a full privacy report to help you more easily represent the privacy practices of all the code in your app."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10081-enhance-your-spatial-computing-app-with-realitykit","title":"Enhance your spatial computing app with RealityKit","abstract":[{"text":"Go beyond the window and learn how you can bring engaging and immersive 3D content to your apps with RealityKit. Discover how SwiftUI scenes work in tandem with RealityView and how you can embed your content into an entity hierarchy. We’ll also explore how you can blend virtual content and the real world using anchors, bring particle effects into your apps, add video content, and create more immersive experiences with portals.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10023-Build-a-multidevice-workout-app":{"url":"\/documentation\/wwdcnotes\/wwdc23-10023-build-a-multidevice-workout-app","abstract":[{"text":"Learn how you can get iPhone involved in your Apple Watch-based workout apps with HealthKit. We’ll show you how to mirror workouts between devices and take a ride with cycling data types. Plus, get to know HealthKit for iPad.","type":"text"}],"title":"Build a multi-device workout app","type":"topic","kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10023-Build-a-multidevice-workout-app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10156-Explore-SwiftUI-animation":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10156-Explore-SwiftUI-animation","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10156-explore-swiftui-animation","title":"Explore SwiftUI animation","abstract":[{"text":"Explore SwiftUI’s powerful animation capabilities and find out how these features work together to produce impressive visual effects. Learn how SwiftUI refreshes the rendering of a view, determines what to animate, interpolates values over time, and propagates context for the current transaction.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10016-Build-custom-workouts-with-WorkoutKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10016-Build-custom-workouts-with-WorkoutKit","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10016-build-custom-workouts-with-workoutkit","title":"Build custom workouts with WorkoutKit","abstract":[{"text":"WorkoutKit makes it easy to create, preview, and schedule planned workouts for the Workout app on Apple Watch. Learn how to build custom intervals, create alerts, and use the built-in preview UI to send your own workout routines to Apple Watch.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10037-Explore-pie-charts-and-interactivity-in-Swift-Charts":{"kind":"article","abstract":[{"text":"Swift Charts has come full circle: Get ready to bake up pie and donut charts in your app with the latest improvements to the framework. Learn how to make your charts scrollable, explore the chart selection API for revealing additional details in your data, and find out how enabling additional interactivity can make your charts even more delightful.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10037-Explore-pie-charts-and-interactivity-in-Swift-Charts","type":"topic","title":"Explore pie charts and interactivity in Swift Charts","url":"\/documentation\/wwdcnotes\/wwdc23-10037-explore-pie-charts-and-interactivity-in-swift-charts","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10007-Create-seamless-experiences-with-Virtualization":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10007-Create-seamless-experiences-with-Virtualization","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10007-create-seamless-experiences-with-virtualization","title":"Create seamless experiences with Virtualization","abstract":[{"type":"text","text":"Discover the latest updates to the Virtualization framework. We’ll show you how to configure a virtual machine (VM) to automatically resize its display, take you through saving and restoring a running VM, and explore storage and performance options for Virtualization apps running on the desktop or in the data center."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10034-Create-accessible-spatial-experiences":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10034-Create-accessible-spatial-experiences","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10034-create-accessible-spatial-experiences","title":"Create accessible spatial experiences","abstract":[{"text":"Learn how you can make spatial computing apps that work well for everyone. Like all Apple platforms, visionOS is designed for accessibility: We’ll share how we’ve reimagined assistive technologies like VoiceOver and Pointer Control and designed features like Dwell Control to help people interact in the way that works best for them. Learn best practices for vision, motor, cognitive, and hearing accessibility and help everyone enjoy immersive experiences for visionOS.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10085-Discover-Quick-Look-for-spatial-computing":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10085-Discover-Quick-Look-for-spatial-computing","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10085-discover-quick-look-for-spatial-computing","title":"Discover Quick Look for spatial computing","abstract":[{"text":"Learn how to use Quick Look on visionOS to add powerful previews for 3D content, spatial images and videos, and much more. We’ll show you the different ways that the system presents these experiences, demonstrate how someone can drag and drop Quick Look content from an app or website to create a separate window with that content, and explore how you can present Quick Look directly within an app.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10051-Create-a-great-ShazamKit-experience":{"url":"\/documentation\/wwdcnotes\/wwdc23-10051-create-a-great-shazamkit-experience","kind":"article","role":"sampleCode","title":"Create a great ShazamKit experience","type":"topic","abstract":[{"text":"Discover how your app can offer a great audio matching experience with the latest updates to ShazamKit. We’ll take you through matching features, updates to audio recognition, and interactions with the Shazam library. Learn tips and best practices for using ShazamKit in your audio apps.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10051-Create-a-great-ShazamKit-experience"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10087-Build-spatial-SharePlay-experiences":{"url":"\/documentation\/wwdcnotes\/wwdc23-10087-build-spatial-shareplay-experiences","kind":"article","role":"sampleCode","title":"Build spatial SharePlay experiences","type":"topic","abstract":[{"text":"Discover how you can use the GroupActivities framework to build unique sharing and collaboration experiences for visionOS. We’ll introduce you to SharePlay on this platform, learn how to create experiences that make people feel present as if they were in the same space, and explore how immersive apps can respect shared context between participants.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10087-Build-spatial-SharePlay-experiences"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10127-Optimize-GPU-renderers-with-Metal":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10127-Optimize-GPU-renderers-with-Metal","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10127-optimize-gpu-renderers-with-metal","title":"Optimize GPU renderers with Metal","abstract":[{"type":"text","text":"Discover how to optimize your GPU renderer using the latest Metal features and best practices. We’ll show you how to use function specialization and parallel shader compilation to maintain responsive authoring workflows and the fastest rendering speeds, and help you tune your compute shaders for optimal performance."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","title":"Build spatial experiences with RealityKit","abstract":[{"text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio.","type":"text"}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences":{"url":"\/documentation\/wwdcnotes\/wwdc23-10091-evolve-your-arkit-app-for-spatial-experiences","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences","kind":"article","abstract":[{"text":"Discover how you can bring your app’s AR experience to visionOS. Learn how ARKit and RealityKit have evolved for spatial computing: We’ll highlight conceptual and API changes for those coming from iPadOS and iOS and guide you to sessions with more details to help you bring your AR experience to this platform.","type":"text"}],"type":"topic","title":"Evolve your ARKit app for spatial experiences"},"https://developer.apple.com/forums/tags/wwdc2023-10071":{"titleInlineContent":[{"type":"text","text":"Search the forums for tag wwdc2023-10071"}],"url":"https:\/\/developer.apple.com\/forums\/tags\/wwdc2023-10071","title":"Search the forums for tag wwdc2023-10071","identifier":"https:\/\/developer.apple.com\/forums\/tags\/wwdc2023-10071","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10153-Unlock-the-power-of-grammatical-agreement":{"url":"\/documentation\/wwdcnotes\/wwdc23-10153-unlock-the-power-of-grammatical-agreement","kind":"article","role":"sampleCode","title":"Unlock the power of grammatical agreement","type":"topic","abstract":[{"text":"Discover how you can use automatic grammatical agreement in your apps and games to create inclusive and more natural-sounding expressions. We’ll share best practices for working with Foundation, showcase examples in multiple languages, and demonstrate how to use these APIs to enhance the user experience for your apps.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10153-Unlock-the-power-of-grammatical-agreement"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10128-Your-guide-to-Metal-ray-tracing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10128-Your-guide-to-Metal-ray-tracing","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10128-your-guide-to-metal-ray-tracing","title":"Your guide to Metal ray tracing","abstract":[{"type":"text","text":"Discover how you can enhance the visual quality of your games and apps with Metal ray tracing. We’ll take you through the fundamentals of the Metal ray tracing API. Explore the latest enhancements and techniques that will enable you to create larger and more complex scenes, reduce memory usage and build times, and efficiently render visual content like hair and fur."}],"role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10028-Bring-widgets-to-life":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10028-Bring-widgets-to-life","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10028-bring-widgets-to-life","title":"Bring widgets to life","abstract":[{"text":"Learn how to make animated and interactive widgets for your apps and games. We’ll show you how to tweak animations for entry transitions and add interactivity using SwiftUI Button and Toggle so that you can create powerful moments right from the Home Screen and Lock Screen.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10076-Design-for-spatial-user-interfaces":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10076-design-for-spatial-user-interfaces","title":"Design for spatial user interfaces","abstract":[{"text":"Learn how to design great interfaces for spatial computing apps. We’ll share how your existing screen-based knowledge easily translates into creating great experiences for visionOS. Explore guidelines for UI components, materials, and typography and find out how you can design experiences that are familiar, legible, and easy to use.","type":"text"}],"role":"sampleCode","kind":"article"},"WWDC23-10071-audiovisualMedia7":{"alt":"2D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-audiovisualMedia7.jpg"}],"identifier":"WWDC23-10071-audiovisualMedia7","type":"image"},"WWDC23-10071-threeDAudiovisualMedia":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems":{"abstract":[{"text":"Discover how you can integrate CarPlay into modern vehicle systems. We’ll show you how to adjust CarPlay for any high-resolution display — regardless of configuration or size. Learn how you can use CarPlay-supplied metadata and video streams to show information on additional displays, and find out how advances in wireless connectivity, audio, and video encoding can help prepare your vehicle system for the next generation of CarPlay.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems","title":"Optimize CarPlay for vehicle systems","url":"\/documentation\/wwdcnotes\/wwdc23-10150-optimize-carplay-for-vehicle-systems","type":"topic","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","title":"WWDC Notes","role":"collection","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"url":"\/documentation\/wwdcnotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes"},"WWDC23-10071-threeDAudiovisualMedia7":{"alt":"3D audiovisual media","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10071-threeDAudiovisualMedia7.jpg"}],"identifier":"WWDC23-10071-threeDAudiovisualMedia7","type":"image"}}}