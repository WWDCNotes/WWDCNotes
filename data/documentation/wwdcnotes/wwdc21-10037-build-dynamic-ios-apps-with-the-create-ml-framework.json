{"sampleCodeDownload":{"kind":"sampleDownload","action":{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10037","overridingTitle":"Watch Video (16 min)"}},"abstract":[{"text":"Discover how your app can train Core ML models fully on device with the Create ML framework, enabling adaptive and customized app experiences, all while preserving data privacy. We‚Äôll explore the types of models that can be created on-the-fly for image-based tasks like Style Transfer and Image Classification, audio tasks like custom Sound Classification, or tasks that build on a rich set of Text Classification, Tabular Data Classification, and Tabular Regressors. And we‚Äôll take you through the many opportunities these models offer to make your app more personal and dynamic.","type":"text"}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc21-10037-build-dynamic-ios-apps-with-the-create-ml-framework"]}],"metadata":{"modules":[{"name":"WWDC Notes"}],"title":"Build dynamic iOS apps with the Create ML framework","role":"sampleCode","roleHeading":"WWDC21"},"kind":"article","identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10037-Build-dynamic-iOS-apps-with-the-Create-ML-framework"},"schemaVersion":{"major":0,"minor":3,"patch":0},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21"]]},"primaryContentSections":[{"kind":"content","content":[{"anchor":"overview","text":"Overview","type":"heading","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"isActive":true,"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference"}]},{"anchor":"Related-Sessions","text":"Related Sessions","type":"heading","level":2},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10019-Get-to-know-Create-ML-Components","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110332-Whats-new-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10156-Control-training-in-Create-ML-with-Swift"],"type":"links","style":"list"}]}],"sections":[],"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10156-Control-training-in-Create-ML-with-Swift":{"abstract":[{"type":"text","text":"With the Create ML framework you have more power than ever to easily develop models and automate workflows. We‚Äôll show you how to explore and interact with your machine learning models while you train them, helping you get a better model quickly. Discover how training control in Create ML can customize your training workflow with checkpointing APIs to pause, save, resume, and extend your training process. And find out how you can monitor your progress programmatically using Combine APIs."}],"url":"\/documentation\/wwdcnotes\/wwdc20-10156-control-training-in-create-ml-with-swift","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10156-Control-training-in-Create-ML-with-Swift","kind":"article","type":"topic","title":"Control training in Create ML with Swift"},"WWDC21.jpeg":{"alt":null,"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC21.jpeg"}],"identifier":"WWDC21.jpeg"},"WWDCNotes.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDCNotes.png"}],"alt":null,"identifier":"WWDCNotes.png","type":"image"},"https://developer.apple.com/videos/play/wwdc2021/10037":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10037","type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10037"},"WWDC21-Icon.png":{"alt":null,"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC21-Icon.png"}],"identifier":"WWDC21-Icon.png"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}],"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","title":"Learn More‚Ä¶","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"title":"WWDC Notes","type":"topic","kind":"symbol","role":"collection","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"url":"\/documentation\/wwdcnotes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110332-Whats-new-in-Create-ML":{"url":"\/documentation\/wwdcnotes\/wwdc22-110332-whats-new-in-create-ml","type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110332-Whats-new-in-Create-ML","abstract":[{"type":"text","text":"Discover the latest updates to Create ML. We‚Äôll share improvements to Create ML‚Äôs evaluation tools that can help you understand how your custom models will perform on real-world data. Learn how you can check model performance on each type of image in your test data and identify problems within individual images to help you troubleshoot mistaken classifications, poorly labeled data, and other errors. We‚Äôll also show you how to test your model with iPhone and iPad in live preview using Continuity Camera, and share how you can take Action Classification even further with the new Repetition Counting capabilities of the Create ML Components framework."}],"title":"What‚Äôs new in Create ML","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10019-Get-to-know-Create-ML-Components":{"title":"Get to know Create ML Components","kind":"article","role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Create ML makes it easy to build custom machine learning models for image classification, object detection, sound classification, hand pose classification, action classification, tabular data regression, and more. And with the Create ML Components framework, you can further customize underlying tasks and improve your model. We‚Äôll explore the feature extractors, transformers, and estimators that make up these tasks, and show you how you can combine them with other components and pre-processing steps to build custom tasks for concepts like image regression."}],"url":"\/documentation\/wwdcnotes\/wwdc22-10019-get-to-know-create-ml-components","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10019-Get-to-know-Create-ML-Components"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21":{"url":"\/documentation\/wwdcnotes\/wwdc21","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21","images":[{"type":"icon","identifier":"WWDC21-Icon.png"},{"type":"card","identifier":"WWDC21.jpeg"}],"kind":"article","role":"collectionGroup","title":"WWDC21","abstract":[{"text":"Xcode 13, Swift 5.5, iOS 15, macOS 12 (Monterey), tvOS 15, watchOS 8.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"code":"MusicKit","type":"codeVoice"},{"text":", ","type":"text"},{"code":"DocC","type":"codeVoice"},{"text":", ","type":"text"},{"code":"StoreKit 2","type":"codeVoice"},{"text":", and more.","type":"text"}]}}}