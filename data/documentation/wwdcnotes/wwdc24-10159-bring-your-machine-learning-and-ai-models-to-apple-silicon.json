{"metadata":{"title":"Bring your machine learning and AI models to Apple silicon","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC24","role":"sampleCode"},"sections":[],"primaryContentSections":[{"kind":"content","content":[{"anchor":"overview","type":"heading","level":2,"text":"Overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true,"type":"reference"}]},{"anchor":"Related-Sessions","type":"heading","level":2,"text":"Related Sessions"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10027-Optimize-your-Core-ML-usage","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10038-Tune-your-Core-ML-models","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10161-Deploy-machine-learning-and-AI-models-ondevice-with-Core-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10223-Explore-machine-learning-on-Apple-platforms"],"style":"list","type":"links"}]}],"abstract":[{"type":"text","text":"Learn how to optimize your machine learning and AI models to leverage the power of Apple silicon. Review model conversion workflows to prepare your models for on-device deployment. Understand model compression techniques that are compatible with Apple silicon, and at what stages in your model deployment workflow you can apply them. We‚Äôll also explore the tradeoffs between storage size, latency, power usage and accuracy."}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10159","overridingTitle":"Watch Video (30 min)"}},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10159-Bring-your-machine-learning-and-AI-models-to-Apple-silicon","interfaceLanguage":"swift"},"kind":"article","variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc24-10159-bring-your-machine-learning-and-ai-models-to-apple-silicon"]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24"]]},"references":{"WWDCNotes.png":{"alt":null,"identifier":"WWDCNotes.png","type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDCNotes.png"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU","title":"Support real-time ML inference on the CPU","abstract":[{"text":"Discover how you can use BNNSGraph to accelerate the execution of your machine learning model on the CPU. We will show you how to use BNNSGraph to compile and execute a machine learning model on the CPU and share how it provides real-time guarantees such as no runtime memory allocation and single-threaded running for audio or signal processing models.","type":"text"}],"role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10211-support-realtime-ml-inference-on-the-cpu","type":"topic"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}],"url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10223-Explore-machine-learning-on-Apple-platforms":{"type":"topic","title":"Explore machine learning on Apple platforms","url":"\/documentation\/wwdcnotes\/wwdc24-10223-explore-machine-learning-on-apple-platforms","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10223-Explore-machine-learning-on-Apple-platforms","kind":"article","abstract":[{"type":"text","text":"Get started with an overview of machine learning frameworks on Apple platforms. Whether you‚Äôre implementing your first ML model, or an ML expert, we‚Äôll offer guidance to help you select the right framework for your app‚Äôs needs."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression","role":"sampleCode","abstract":[{"text":"Discover how to reduce the footprint of machine learning models in your app with Core ML Tools. Learn how to use techniques like palettization, pruning, and quantization to dramatically reduce model size while still achieving great accuracy. Explore comparisons between compression during the training stages and on fully trained models, and learn how compressed models can run even faster when your app takes full advantage of the Apple Neural Engine.","type":"text"}],"title":"Use Core ML Tools for machine learning model compression","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10047-use-core-ml-tools-for-machine-learning-model-compression","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","type":"topic","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"role":"collection","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"title":"WWDC Notes","url":"\/documentation\/wwdcnotes","kind":"symbol"},"WWDC24-Icon.png":{"type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDC24-Icon.png","traits":["1x","light"]}],"alt":null,"identifier":"WWDC24-Icon.png"},"WWDC24.jpeg":{"alt":null,"identifier":"WWDC24.jpeg","type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC24.jpeg"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10027-Optimize-your-Core-ML-usage":{"kind":"article","type":"topic","title":"Optimize your Core ML usage","url":"\/documentation\/wwdcnotes\/wwdc22-10027-optimize-your-core-ml-usage","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10027-Optimize-your-Core-ML-usage","abstract":[{"type":"text","text":"Learn how Core ML works with the CPU, GPU, and Neural Engine to power on-device, privacy-preserving machine learning experiences for your apps. We‚Äôll explore the latest tools for understanding and maximizing the performance of your models. We‚Äôll also show you how to generate reports to easily understand your model performance characteristics, help you gain insight into your models with the Core ML Instrument, and take you through API enhancements to further optimize Core ML integration in your apps."}],"role":"sampleCode"},"https://developer.apple.com/videos/play/wwdc2024/10159":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10159","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2024\/10159","checksum":null,"type":"download"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","title":"Improve Core ML integration with async prediction","abstract":[{"type":"text","text":"Learn how to speed up machine learning features in your app with the latest Core ML execution engine improvements and find out how aggressive asset caching can help with inference and faster model loads. We‚Äôll show you some of the latest options for async prediction and discuss considerations for balancing performance with overall memory usage to help you create a highly responsive app. Discover APIs to help you understand and maximize hardware utilization for your models."}],"role":"sampleCode","type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10049-improve-core-ml-integration-with-async-prediction"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10038-Tune-your-Core-ML-models":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10038-Tune-your-Core-ML-models","role":"sampleCode","abstract":[{"type":"text","text":"Bring the power of machine learning directly to your apps with Core ML. Discover how you can take advantage of the CPU, GPU, and Neural Engine to provide maximum performance while remaining on device and protecting privacy. Explore MLShapedArray, which makes it easy to work with multi-dimensional data in Swift, and learn more about ML Package support in Core ML, which includes support for ML Programs. This modern, programmatic approach to machine learning provides typed execution and tremendous flexibility. We‚Äôll also show you how to analyze performance of your models and tune the execution of each operation in a model using ML Programs."}],"title":"Tune your Core ML models","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc21-10038-tune-your-core-ml-models","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24","type":"topic","abstract":[{"type":"text","text":"Xcode 16, Swift 6, iOS 18, macOS 15 (Sequoia), tvOS 18, visionOS 2, watchOS 11."},{"type":"text","text":" "},{"type":"text","text":"New APIs: Swift Testing, "},{"type":"codeVoice","code":"FinanceKit"},{"type":"text","text":", "},{"type":"codeVoice","code":"TabletopKit"},{"type":"text","text":", and more."}],"role":"collectionGroup","images":[{"type":"icon","identifier":"WWDC24-Icon.png"},{"type":"card","identifier":"WWDC24.jpeg"}],"title":"WWDC24","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10161-Deploy-machine-learning-and-AI-models-ondevice-with-Core-ML":{"abstract":[{"type":"text","text":"Learn new ways to optimize speed and memory performance when you convert and run machine learning and AI models through Core ML. We‚Äôll cover new options for model representations, performance insights, execution, and model stitching which can be used together to create compelling and private on-device experiences."}],"title":"Deploy machine learning and AI models on-device with Core ML","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10161-Deploy-machine-learning-and-AI-models-ondevice-with-Core-ML","url":"\/documentation\/wwdcnotes\/wwdc24-10161-deploy-machine-learning-and-ai-models-ondevice-with-core-ml","role":"sampleCode","type":"topic"}}}