{"kind":"article","sections":[],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-10070-create-a-great-spatial-playback-experience"]}],"primaryContentSections":[{"content":[{"type":"heading","level":1,"anchor":"how-to-create-a-great-spatial-experiences-for-video-playback","text":"how to create a great spatial experiences for video playback."},{"type":"paragraph","inlineContent":[{"text":"A great experience is optimized for the platform, takes advantage of its powerful media capabilities, and integrates with the whole system.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"First, we’ll explore the media experience with a minimal app. Next, I’ll go over some more advanced UI features. Then, I’ll go over some other methods of displaying video. Finally, I’ll compare the options. If you have used the media APIs on iOS or tvOS, then this may feel familiar. This platform builds on those same APIs and extends them for its unique capabilities.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"codeVoice","code":"AVFoundation"},{"type":"text","text":" handles all the work of playing movies: streaming, parsing, decoding, synchronizing. And "},{"type":"codeVoice","code":"AVKit"},{"type":"text","text":" builds on "},{"type":"codeVoice","code":"AVFoundation"},{"type":"text","text":" and UI Frameworks, to create a playback experience that’s customized and integrated for each platform."}]},{"type":"paragraph","inlineContent":[{"text":"On this platform, ","type":"text"},{"code":"AVFoundation","type":"codeVoice"},{"text":" has been enhanced to support new media formats that take advantage of its unique capabilities, such as 3D video.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Refer to this session for more details about these formats.","type":"text"},{"text":"\n","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10071\/"}]},{"type":"paragraph","inlineContent":[{"code":"AVFoundation","type":"codeVoice"},{"text":" has also been enhanced to render performantly and with high quality using ","type":"text"},{"code":"RealityKit","type":"codeVoice"},{"text":", so that video can be composited seamlessly into the world around you, and so that audio also responds to the world around you. And ","type":"text"},{"code":"AVKit","type":"codeVoice"},{"text":"’s ","type":"text"},{"code":"AVPlayerViewController","type":"codeVoice"},{"text":" has been extended to make use of the power of RealityKit and the unique capabilities of the platform to create a highly refined experience.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10070-Frameworks"}]},{"type":"paragraph","inlineContent":[{"text":"This includes all the playback controls you expect, but also has many unique capabilities. What’s required to take advantage of this in your app?","type":"text"}]},{"type":"heading","level":2,"anchor":"Requirements","text":"Requirements"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"First, the Xcode target must build with this platform’s SDK. Compatible iOS apps built with the iOS SDK will get an iOS compatible experience."}]}]},{"content":[{"inlineContent":[{"text":"Use ","type":"text"},{"code":"AVPlayerViewController","type":"codeVoice"},{"text":" just like you do on iOS or tvOS.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"And finally, present the view controller so it fills the window. Let’s demonstrate this with some code.","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"First, we’ll import "},{"type":"codeVoice","code":"AVFoundation"},{"type":"text","text":" and "},{"type":"codeVoice","code":"AVKit"},{"type":"text","text":". Next, create an "},{"type":"codeVoice","code":"AVPlayerViewController"},{"type":"text","text":" and connect an "},{"type":"codeVoice","code":"AVPlayer"},{"type":"text","text":" to it. Then, create a new player item with the content URL and set it on the player."}]},{"type":"codeListing","syntax":"swift","code":["import AVFoundation  ","import AVKit","","    let controller = AVPlayerViewController ()","    controller.player = AVPlayer ()","    controller.player?.replaceCurrentItem(with: AVPlayerItemurl: contentURL))"]},{"type":"paragraph","inlineContent":[{"text":"Adding the item after setting the player on the view controller can improve performance because the player will understand how it will be displayed before it starts loading the media. Then, to use it in SwiftUI, wrap that code in a ","type":"text"},{"code":"UIViewControllerRepresentable","type":"codeVoice"},{"text":". We’ll call this one ","type":"text"},{"code":"PlayerView","type":"codeVoice"},{"text":".","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["import SwiftUI ","import AVFoundation ","import AVKit","","struct PlayerView: UIViewControllerepresentable {","","    func makeUIViewController(context: Context) -> AVPlayerViewController {","        let controller = AVPlayerViewController()","        controller.player = AVPlayer()","        controller.player?.replaceCurrentItem(with: AVPlayerItem(url: itemURL))","    return controller","}","","func updateUIViewController(_ : AVPlayerViewController, context: Context) {","}"]},{"type":"paragraph","inlineContent":[{"text":"Then, we’ll create our app, which we’ll call MoviePlayingApp.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["import SwiftUI","@main","struct MoviePlayingApp: App {","    var body: some SwiftUI.Scene {","        WindowGroup {","            PlayerView()","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Add the view controller, which we just defined, so it fills the window. Just like that, you’ve got a movie playing app. If you’re thinking this code looks very similar to what you would write on other Apple platforms, that’s because it is."}]},{"type":"paragraph","inlineContent":[{"code":"AVPlayerViewController","type":"codeVoice"},{"text":" and ","type":"text"},{"code":"AVPlayer","type":"codeVoice"},{"text":" are doing a lot of the heavy lifting so you don’t have to. Let me show you the media experience a simple app like this has. Before the app is launched, just the room is visible. When the app launches, a large screen appears right in front and the room darkens, creating a nice ambiance.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10070-PlayerView"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"When moving, the screen stays in place, and the audio stays anchored to the screen. To show playback controls, look at the screen and tap. The controls float just in front of the video. While playing, do nothing and they will disappear on their own. Or make them disappear by looking at the screen and tapping again. Grab the window bar below the screen to reposition it."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Grab the corner of the screen to resize. Notice that as the screen resizes, it animates smoothly and matches the aspect ratio of the video. Adjust the volume by turning the Digital Crown. Or use the Digital Crown to open an environment, like this. I love watching movies this way. You’ve got to experience this for yourself."}]},{"type":"paragraph","inlineContent":[{"text":"Now, let’s examine the playback controls more closely to see the features they provide. Here is our player interface. At the top right is the volume control to make quick adjustments or to mute. As I mentioned, volume can also be adjusted with the Digital Crown. At the bottom left are the familiar play\/pause and back\/forward buttons. In the bottom middle is the scrubber to jump to a different time in the movie. And in the bottom right is this button with more options. Here are options to adjust the playback speed. When movies contain multiple audio tracks or caption tracks, use these options to choose the language for the audio track, or to enable captions in the preferred language.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This last option is Dimming Effect. I love watching movies in the dark to really focus on them, but sometimes a video isn’t my only focus. Here, I can turn off Dimming Effect to better see what’s around me."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10070-dimmingEffect","type":"image"}]},{"type":"heading","level":2,"anchor":"Advanced-features","text":"Advanced features."},{"type":"heading","level":3,"anchor":"Thumbnail-scrubbing-and-Trick-Play","text":"Thumbnail scrubbing and Trick Play"},{"type":"paragraph","inlineContent":[{"text":"Thumbnail scrubbing shows a small image of the video while scrubbing, allowing seamless navigation of the content. The controls will automatically display a thumbnail when scrubbing for HLS streams that have an I-frame only playlist, also known as a Trick Play track. Small Trick Play tracks with a width of 145 pixels are preferred.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10070-iframes","type":"image"}]},{"type":"heading","level":3,"anchor":"Interstitials-support","text":"Interstitials support"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Sometimes media needs to be inserted into the timeline for a logo, a recap, or an ad. Interstitials support enables this ability. When interstitials are present, the controls will automatically reflect them with an indicator in the timeline. These interstitials can be configured programmatically with an AVPlayerInterstital EventController, or they can be described within the HLS stream."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10070-interstitials"}]},{"type":"paragraph","inlineContent":[{"text":"Refer to this session for more details.","type":"text"},{"text":"\n","type":"text"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2022\/10145","isActive":true,"type":"reference"}]},{"type":"heading","level":3,"anchor":"Additional-UI","text":"Additional UI"},{"type":"paragraph","inlineContent":[{"type":"text","text":"There are some additional UI options commonly used by video playing apps. Contextual actions allow you to add buttons like Skip intro or Play next episode. They can have a title and an optional image."},{"type":"text","text":" "},{"type":"text","text":"Custom info view controllers can be used to show metadata about the content or to suggest related content. These APIs work the same as on other Apple platforms."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10070-AdditionalUI"}]},{"type":"paragraph","inlineContent":[{"text":"Refer to this session for more details.","type":"text"},{"text":"\n","type":"text"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10290","isActive":true,"type":"reference"}]},{"type":"heading","level":2,"anchor":"Immersive-Spaces","text":"Immersive Spaces"},{"type":"paragraph","inlineContent":[{"text":"Your app can also transport you to another place with a feature called Immersive Spaces. When your app creates an Immersive Space, you get to decide what that space looks like. And even better, your video screen will automatically move into that space and anchor itself at a predictable size and position to guarantee an excellent viewing angle every time. And the controls detach and move closer to make them easier to interact with.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10070-immersiveSpaces"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let’s check out some code. Here is our MoviePlayingApp from earlier."},{"type":"text","text":" "},{"type":"text","text":"First, we’ll add an Immersive Space. The 3D content will be described by RealityKit entities. Then we’ll use onAppear on our PlayerView to open the space. Make sure your Immersive Space is designed to accommodate the movie player when it’s docked."}]},{"type":"codeListing","syntax":"swift","code":["import SwiftUI","","@main","struct MoviePlayingApp: App {","    var body: some SwiftUI.Scene {","        WindowGroup {","            PlayerView()","            .onAppear() {","                Task {","                    await openImmersiveSpace(id: \"PlayerImmersiveSpace\")","                }","            }","        }","        ImmersiveSpace(id: \"PlayerImmersiveSpace\") {","            RealityView { content in","                let entity = \/\/ Create entities.","                content.add(entity)","            }","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"For more information about how to build and present spaces, refer to this session."},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10111","isActive":true}]},{"type":"paragraph","inlineContent":[{"text":"We recommend you use ","type":"text"},{"code":"AVPlayerViewController","type":"codeVoice"},{"text":". You can hide the controls and supply an overlay for your custom UI. This is preferred over using a lower-level API because, as we’ve demonstrated, ","type":"text"},{"code":"AVPlayerViewController","type":"codeVoice"},{"text":" provides a lot of system integration features beyond just playback controls.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["showsPlaybackControls = false"]},{"type":"heading","level":2,"anchor":"Otheer-Use-Cases","text":"Otheer Use Cases"},{"type":"paragraph","inlineContent":[{"text":"Sometimes you want a movie to play inline in a window. It could be part of a document or to play a preview. AVPlayerViewController inline is great for this situation too. How do you get the inline view? It will automatically use this mode whenever it’s displayed without filling the window. Its inline controls are also redesigned for the OS. Note, because video is composited within the window using AVPlayerLayer, it won’t be able to display 3D video.","type":"text"}]},{"type":"heading","level":3,"anchor":"RealityKit-entity-video","text":"RealityKit entity video"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Sometimes your app may want to play video as an entity of a 3D scene. It could be a splash screen or a video transition. In these cases, you don’t want playback controls and you also don’t want system integration like docking. For those cases, use RealityKit’s "},{"type":"codeVoice","code":"VideoPlayerComponent"},{"type":"text","text":".  "},{"type":"codeVoice","code":"VideoPlayerComponent"},{"type":"text","text":" connects a "},{"type":"codeVoice","code":"RealityKit"},{"type":"text","text":" "},{"type":"codeVoice","code":"Entity"},{"type":"text","text":" to an "},{"type":"codeVoice","code":"AVPlayer"},{"type":"text","text":".  You can position it in your "},{"type":"codeVoice","code":"RealityKit"},{"type":"text","text":" scene just like any other entity. It creates an aspect ratio correct mesh for the video, and it supports displaying captions."},{"type":"text","text":"\n"},{"type":"text","text":"Whenever possible, prefer it over "},{"type":"codeVoice","code":"AVPlayerLayer"},{"type":"text","text":"."},{"type":"text","text":"\n"},{"type":"text","text":"Because it takes advantage of RealityKit’s optimizations for video, it gets better performance than "},{"type":"codeVoice","code":"AVPlayerLayer"},{"type":"text","text":", and it supports new 3D video formats."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Refer to this session for more details."},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081","isActive":true}]},{"type":"heading","level":3,"anchor":"Video-Effects","text":"Video Effects"},{"type":"paragraph","inlineContent":[{"text":"Sometimes you may want to use video in a 3D scene where the video is used as an effect. In this case, you may want to create your own geometry and have more control over how the video is displayed. VideoMaterial is a lower-level API that will display video on arbitrary geometry. This means it can’t ensure the original aspect ratio and it doesn’t have the ability to display captions.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10070-videoEffects","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Check out this related talk for more details."},{"type":"text","text":"\n"},{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2020\/10612","type":"reference"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We’ve talked about some additional UI features and some other use cases. The DestinationVideo sample app demonstrates some of these features. It has a video browser for choosing videos and plays them in an Immersive Space. Here it is. Choose a video to show the info page and an Immersive Space opens. Notice the use of an inline player with custom UI controls for the preview. Then, play the movie. The player UI appears and immediately docks into the Immersive Space at a fixed size and location for optimal viewing. Another nice detail is that when the screen is docked in an Immersive Space like this, the playback controls detach and come a little closer to make them more convenient to interact with. Tap the list button. The app has supplied custom info view controllers to display more info about the content and related content while watching the video. Near the end of the video, a contextual action button labeled Play Next appears in the bottom-right corner."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We’ve covered the spatial experience for video playback. It has a large screen floating in space in front of you with beautiful visuals and great spatial audio. It includes playback controls for everything you need to do, and we’ve talked about some other playback use cases."}]},{"type":"paragraph","inlineContent":[{"text":"There are several ways to display video in your app. Let’s compare them. These are the APIs to show video. Each has different capabilities.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10070-comparing"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Spatial media capabilities represent an opportunity for people to experience video in a whole new way."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"To recap:"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10070-recap"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"To get started, check out DestinationVideo Sample Project."},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/documentation\/visionos\/destination-video"}]},{"type":"paragraph","inlineContent":[{"text":"It demonstrates many of the features discussed here.","type":"text"}]},{"type":"heading","level":1,"anchor":"Check-out-also","text":"Check out also"},{"type":"paragraph","inlineContent":[{"type":"reference","isActive":true,"overridingTitle":"Deliver video content for spatial experiences - WWDC23","overridingTitleInlineContent":[{"text":"Deliver video content for spatial experiences - WWDC23","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10071\/"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"overridingTitle":"What’s new in HLS interstitials - WWDC22","overridingTitleInlineContent":[{"type":"text","text":"What’s new in HLS interstitials - WWDC22"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2022\/10145"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"overridingTitle":"What’s new in AVKit - WWDC21","overridingTitleInlineContent":[{"text":"What’s new in AVKit - WWDC21","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10290"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"overridingTitle":"Enhance your Spatial Computing App with RealityKit - WWDC23","overridingTitleInlineContent":[{"text":"Enhance your Spatial Computing App with RealityKit - WWDC23","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"overridingTitle":"What’s new in RealityKit - WWDC20","overridingTitleInlineContent":[{"text":"What’s new in RealityKit - WWDC20","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2020\/10612"}]},{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/developer.apple.com\/documentation\/visionos\/destination-video","overridingTitleInlineContent":[{"text":"Sample Project: DestinationVideo","type":"text"}],"type":"reference","overridingTitle":"Sample Project: DestinationVideo","isActive":true}]},{"type":"heading","level":2,"anchor":"Written-By","text":"Written By"},{"type":"row","columns":[{"content":[{"inlineContent":[{"type":"image","identifier":"multitudes"}],"type":"paragraph"}],"size":1},{"content":[{"type":"heading","anchor":"laurent-b","level":3,"text":"laurent b"},{"inlineContent":[{"overridingTitle":"Contributed Notes","type":"reference","isActive":true,"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}]},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/github.com\/multitudes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/laurentbrusa.hashnode.dev\/"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/x.com\/wrmultitudes"}],"type":"paragraph"}],"size":4}],"numberOfColumns":5},{"type":"thematicBreak"},{"type":"paragraph","inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"isActive":true,"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference"}]},{"type":"heading","level":2,"anchor":"Related-Sessions","text":"Related Sessions"},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing"],"style":"list"},{"type":"small","inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2025 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"metadata":{"modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC23","role":"sampleCode","title":"Create a great spatial playback experience"},"sampleCodeDownload":{"kind":"sampleDownload","action":{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10070","overridingTitle":"Watch Video (13 min)"}},"abstract":[{"type":"text","text":"Get ready to support video in your visionOS app! Take a tour of the frameworks and APIs that power video playback and learn how you can update your app to play 3D content. We’ll also share tips for customizing playback to create a more immersive watching experience."}],"schemaVersion":{"major":0,"patch":0,"minor":3},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10070-Create-a-great-spatial-playback-experience","interfaceLanguage":"swift"},"references":{"WWDC23-10070-dimmingEffect":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10070-dimmingEffect.jpg"}],"alt":"Dimming Effect","identifier":"WWDC23-10070-dimmingEffect"},"https://developer.apple.com/videos/play/wwdc2023/10071/":{"title":"Deliver video content for spatial experiences - WWDC23","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10071\/","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10071\/","type":"link","titleInlineContent":[{"text":"Deliver video content for spatial experiences - WWDC23","type":"text"}]},"WWDC23-10070-AdditionalUI":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10070-AdditionalUI.jpg"}],"alt":"Additional UI","type":"image","identifier":"WWDC23-10070-AdditionalUI"},"WWDC23-10070-interstitials":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10070-interstitials.jpg"}],"alt":"Interstitials support","identifier":"WWDC23-10070-interstitials"},"WWDC23-10070-immersiveSpaces":{"alt":"Immersive Spaces","variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10070-immersiveSpaces.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10070-immersiveSpaces","type":"image"},"WWDC23-Icon.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-Icon.png"}],"alt":null,"type":"image","identifier":"WWDC23-Icon.png"},"WWDC23-10070-PlayerView":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10070-PlayerView.jpg"}],"alt":"PlayerView","identifier":"WWDC23-10070-PlayerView"},"multitudes.jpeg":{"alt":null,"variants":[{"url":"\/images\/WWDCNotes\/multitudes.jpeg","traits":["1x","light"]}],"identifier":"multitudes.jpeg","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/multitudes":{"url":"\/documentation\/wwdcnotes\/multitudes","kind":"article","abstract":[{"type":"text","text":"student at 42Berlin 🐬 | C & C++ | 🍎 Swift(UI) app dev  | speciality coffee ☕️ & cycling 🚴🏻‍♂️"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","title":"laurent b (33 notes)","images":[{"type":"card","identifier":"multitudes.jpeg"},{"type":"icon","identifier":"multitudes.jpeg"}],"role":"sampleCode","type":"topic"},"WWDC23-10070-Frameworks":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10070-Frameworks.jpg"}],"identifier":"WWDC23-10070-Frameworks","alt":"Frameworks"},"https://developer.apple.com/videos/play/wwdc2023/10081":{"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081","titleInlineContent":[{"text":"Enhance your Spatial Computing App with RealityKit - WWDC23","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081","title":"Enhance your Spatial Computing App with RealityKit - WWDC23"},"https://github.com/multitudes":{"title":"GitHub","url":"https:\/\/github.com\/multitudes","identifier":"https:\/\/github.com\/multitudes","type":"link","titleInlineContent":[{"type":"text","text":"GitHub"}]},"https://laurentbrusa.hashnode.dev/":{"url":"https:\/\/laurentbrusa.hashnode.dev\/","title":"Blog","type":"link","identifier":"https:\/\/laurentbrusa.hashnode.dev\/","titleInlineContent":[{"type":"text","text":"Blog"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10071-Deliver-video-content-for-spatial-experiences":{"kind":"article","title":"Deliver video content for spatial experiences","url":"\/documentation\/wwdcnotes\/wwdc23-10071-deliver-video-content-for-spatial-experiences","type":"topic","role":"sampleCode","abstract":[{"text":"Learn how to prepare and deliver video content for visionOS using HTTP Live Streaming (HLS). Discover the current HLS delivery process for media and explore how you can expand your delivery pipeline to support 3D content. Get up to speed with tips and techniques for spatial media streaming and adapting your existing caption production workflows for 3D. And find out how to share audio tracks across video variants and add spatial audio to make your video content more immersive.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences"},"WWDC23-10070-videoEffects":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10070-videoEffects.jpg"}],"identifier":"WWDC23-10070-videoEffects","alt":"Video Effects"},"https://developer.apple.com/videos/play/wwdc2020/10612":{"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2020\/10612","titleInlineContent":[{"text":"What’s new in RealityKit - WWDC20","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2020\/10612","title":"What’s new in RealityKit - WWDC20"},"WWDC23-10070-recap":{"alt":"Recap","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10070-recap.jpg"}],"identifier":"WWDC23-10070-recap","type":"image"},"https://developer.apple.com/documentation/visionos/destination-video":{"url":"https:\/\/developer.apple.com\/documentation\/visionos\/destination-video","title":"Sample Project: DestinationVideo","type":"link","identifier":"https:\/\/developer.apple.com\/documentation\/visionos\/destination-video","titleInlineContent":[{"type":"text","text":"Sample Project: DestinationVideo"}]},"WWDCNotes.png":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDCNotes.png"}],"alt":null,"identifier":"WWDCNotes.png"},"https://developer.apple.com/videos/play/wwdc2022/10145":{"title":"What’s new in HLS interstitials - WWDC22","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2022\/10145","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2022\/10145","type":"link","titleInlineContent":[{"type":"text","text":"What’s new in HLS interstitials - WWDC22"}]},"https://developer.apple.com/videos/play/wwdc2023/10111":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10111","title":"Go beyond the window with SwiftUI - WWDC23","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10111","titleInlineContent":[{"type":"text","text":"Go beyond the window with SwiftUI - WWDC23"}]},"multitudes":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/multitudes.jpeg"}],"alt":"Profile image of laurent b","identifier":"multitudes"},"https://x.com/wrmultitudes":{"title":"X\/Twitter","url":"https:\/\/x.com\/wrmultitudes","identifier":"https:\/\/x.com\/wrmultitudes","type":"link","titleInlineContent":[{"type":"text","text":"X\/Twitter"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"title":"WWDC23","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23","role":"collectionGroup","abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"SwiftData"},{"type":"text","text":", "},{"type":"codeVoice","code":"Observation"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit"},{"type":"text","text":" views, and more."}],"images":[{"type":"icon","identifier":"WWDC23-Icon.png"},{"type":"card","identifier":"WWDC23.jpeg"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes":{"url":"\/documentation\/wwdcnotes","kind":"symbol","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"role":"collection","type":"topic"},"WWDC23.jpeg":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23.jpeg"}],"identifier":"WWDC23.jpeg","alt":null},"WWDC23-10070-iframes":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10070-iframes.jpg"}],"alt":"iframes","identifier":"WWDC23-10070-iframes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing":{"title":"Optimize app power and performance for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-10100-optimize-app-power-and-performance-for-spatial-computing","kind":"article","abstract":[{"type":"text","text":"Learn how you can create powerful apps and games for visionOS by optimizing for performance and efficiency. We’ll cover the unique power characteristics of the platform, explore building a performance plan, and share some of the tools and strategies to test and optimize your apps."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing","type":"topic","role":"sampleCode"},"WWDC23-10070-comparing":{"alt":"Comparing","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10070-comparing.jpg"}],"identifier":"WWDC23-10070-comparing","type":"image"},"https://developer.apple.com/wwdc23/10070":{"type":"download","checksum":null,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10070","url":"https:\/\/developer.apple.com\/wwdc23\/10070"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!"},"https://developer.apple.com/videos/play/wwdc2021/10290":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10290","title":"What’s new in AVKit - WWDC21","type":"link","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10290","titleInlineContent":[{"text":"What’s new in AVKit - WWDC21","type":"text"}]}}}