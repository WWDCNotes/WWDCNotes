{"metadata":{"roleHeading":"WWDC23","title":"Explore the USD ecosystem","role":"sampleCode","modules":[{"name":"WWDC Notes"}]},"abstract":[{"type":"text","text":"Discover the latest updates to Universal Scene Description (USD) on Apple platforms and learn how you can deliver great 3D content for your apps, games, and websites. Get to know USD for visionOS, explore MaterialX shaders and color management, and find out about some of the other improvements to the USD ecosystem."}],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10086-explore-the-usd-ecosystem"],"traits":[{"interfaceLanguage":"swift"}]}],"primaryContentSections":[{"kind":"content","content":[{"type":"heading","anchor":"overview","level":2,"text":"Overview"},{"type":"paragraph","inlineContent":[{"text":"Apple has been building on the foundation based on the new key technologies that power the 3D creative industry worldwide.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10086-intro1"}]},{"type":"paragraph","inlineContent":[{"text":"The first of these technologies is Universal Scene Description, or USD for short.","type":"text"},{"text":"\n","type":"text"},{"text":"It allows for a standard form of representing 3D content to share between applications.","type":"text"},{"text":"\n","type":"text"},{"text":"Now introducing support for MaterialX on xrOS to portably represent the visual appearance of objects.","type":"text"}]},{"type":"heading","anchor":"OpenUSD","level":2,"text":"OpenUSD"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Created by Pixar. USD is an open source project, created by Pixar, recently renamed to OpenUSD."}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Production proven and scalable, `from creators making single assets to large studios working on AAA games and films."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Expressive composition. USD allows for expressing of complex and flexible relationships between asset data via composition."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"On Apple platforms since 2017. Apple was an early adopter of USD, adding it to our platforms in 2017 and growing support since."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Heart of 3D content on XrOS. Today, USD is at the heart of 3D Content on xrOS.","type":"text"}]}]}]},{"type":"heading","anchor":"MaterialX","level":2,"text":"MaterialX"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"MaterialX is also an open source project, created at Industrial Light & Magic for their work on Star Wars, now developed in conjunction with others like Autodesk and adopted by the Academy Software Foundation."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Code-free shaders. It allows artists to combine shader logic into a node graph within their 3D applications, all without needing to know how to code."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Embedded in USD. This graph can also be embedded inside USD, so it travels with the scene data.","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Supported on xrOS. Apple is supporting MaterialX first on xrOS with RealityKit, Apple’s real-time 3D rendering framework for building immersive spatial experiences.","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Four areas to cover:"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"3D content in Apple apps","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"MaterialX","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Color management"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"New in USD","type":"text"}],"type":"paragraph"}]}]},{"type":"heading","anchor":"3D-content-in-Apple-apps","level":1,"text":"3D content in Apple apps"},{"type":"paragraph","inlineContent":[{"text":"Now Quick Look is available to xrOS.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"There is a great talk on how to easily author content that will look great on xrOS."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10086-content1"}]},{"type":"paragraph","inlineContent":[{"text":"Freeform, introduced last year is a powerful and easy-to-use brainstorming app. Freeform now gives the ability to embed USDZ content, and now collaborate on 3D assets is possible across all supported platforms like macOS, iOS, iPadOS, and now xrOS.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10086-content2"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Safari also introduces new support for 3D Content with the Model element. The Model element is available on all Apple platforms with Safari and can be enabled under the Developer menu on macOS or Settings on other platforms."}]},{"type":"paragraph","inlineContent":[{"text":"The Model element is embedding a USDZ file into the web page with an interactive view, with the ability to rotate around objects.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This allows creation of more interactive websites, and apple is working with the W3C Immersive Web Working Group on standardization."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10086-content3"}]},{"type":"paragraph","inlineContent":[{"text":"We also have Reality Composer Pro, a new macOS application joining our suite of tools for creators and developers. Using USD’s composition features, it lets multiple people work in parallel, enabling each person to tackle a different aspect of the scene and see them combined together as each asset updates.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10086-content4","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Assets can be authored to USD in your own content creation applications, and Reality Composer Pro lets us prepare them for use in xrOS apps and experiences.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Check out the Reality Composer Pro sessions to learn more:"}]},{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10164","isActive":true,"type":"reference"}]},{"type":"heading","anchor":"MaterialX","level":1,"text":"MaterialX"},{"type":"paragraph","inlineContent":[{"text":"As important as the 3D models are the shaders and materials that give them the individual visual aesthetic.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"MaterialX allows to have bespoke visuals that can be transported inside the USD scenes into RealityKit applications on xrOS. Reality Composer Pro introduces a Shader Graph that authors MaterialX nodes embedded inside of USD files.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10086-content5"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This enables the creation of shaders using an interactive node graph to compose the shader logic. MaterialX shader graphs are how creators will be constructing custom shaders for xrOS content. In addition to many of the standard MaterialX nodes, Reality Composer Pro also has a few custom MaterialX nodes that enable a range of xrOS-specific platform features."}]},{"type":"heading","anchor":"Custom-Material-nodes","level":2,"text":"Custom Material nodes"},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10086-content6"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Some of these shader nodes are: RealityKit PBR, physically based rendering shader which enables realistic-looking 3D content; RealityKit Unlit, an unlit shader that do more stylized shading; Geometry Modifiers that allow to modify surface deformations; as well as several custom utility nodes."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"There is a great developer session on how to use the Shader Graph:"}]},{"type":"paragraph","inlineContent":[{"type":"reference","overridingTitle":"Explore materials in Reality Composer Pro - WWDC23","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10164","overridingTitleInlineContent":[{"text":"Explore materials in Reality Composer Pro - WWDC23","type":"text"}],"isActive":true}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Support for MaterialX with USD grows across established third-party 3D applications, like SideFX’s Houdini and LookdevX in Autodesk’s Maya, shown here."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10086-content7","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Reality Composer Pro then lets preview the shaders to see how they’ll look before deployment to device.","type":"text"}]},{"type":"heading","anchor":"Metal-in-MaterialX","level":2,"text":"Metal in MaterialX"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Open source tooling"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Metal shader code generation"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Available in Material 1.38.7","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Material in USD on macOS"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"text":"MaterialX is an open source project which enables creators and developers to make use of it in their own workflows and applications directly.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"The MaterialX project includes support for generating shader code from your MaterialX node graphs.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Apple has added support to the project for creating Metal shader code to make the most use of our powerful GPUs."}]},{"type":"paragraph","inlineContent":[{"text":"This is now available in the MaterialX 1.38.7 release.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"For developers who use USD, this also enables the future use of MaterialX within USD on macOS.","type":"text"}]},{"type":"heading","anchor":"What-is-a-color-space","level":2,"text":"What is a color space"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Range and properties of color","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Display P3"}]}]}]},{"type":"paragraph","inlineContent":[{"text":"Having confidence in how shaders behave is important, but so is having confidence in what the colors look like.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The handling of color space management for RealityKithas been expanded, to make accurate-looking 3D content capable of using a wide gamut color range."}]},{"type":"paragraph","inlineContent":[{"text":"Color spaces are how graphics programs understand how to represent colors from digital values, including the range of colors available. This allows multiple applications to reliably display and edit the same colors.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Apple displays primarily use Display P3 as their color space, whereas many other platforms may use the more commonplace sRGB. DisplayP3 marries the wider primary range of digital cinema with the sRGB gamma curves used by computer displays.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"In fact, it’s capable of displaying up to 25 percent more colors than traditional sRGB, shown here as the black line within the greater Display P3 color space.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10086-content8"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This allows for representing more of the colors we see in the real world. Most color and image workflows tend to use sRGB, which represents a standard range of colors used by many monitors for decades."}]},{"type":"codeListing","code":["\/\/ sRGB","asset inputs:file = @0\/texture.png@"],"syntax":"swift"},{"type":"paragraph","inlineContent":[{"text":"These are still capable of creating good-looking content, but can’t take full advantage of the beautiful, wider-range displays that Apple products ship with.","type":"text"}]},{"type":"codeListing","code":["\/\/ Display P3","asset inputs:file = 00\/texture.png@ (","colorSpace = \"srgb_displayp3\"",")"],"syntax":"swift"},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10086-content9","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Textures authored with Display P3 in mind, and appropriately tagged, are able to express a much larger range of colors, with deeper and more saturated tones. This effect may be subtle, but allows for the creation of more vibrant and authentic-looking assets."}]},{"type":"heading","anchor":"New-in-USD","level":1,"text":"New in USD"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Updated and more efficient USD version","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Increased renderer feature support","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Updated documentation"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"All apple’s first party applications, such as Motion and Quick Look, now benefit from an updated and more efficient USD version. USD supports a wide range of object types, also known as schemas."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This update also allows the Storm renderer in Preview on macOS to support rendering even more USD schemas and features."}]},{"type":"heading","anchor":"New-RealityKit-USD-schemas","level":2,"text":"New RealityKit USD schemas"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Component"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Custom component","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Structs and dictionaries"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Audio File, Audio File Group, and Mix Group","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"text":"USD also allows for custom schema types. And this year, RealityKit is introducing new Component schemas for its Entity Component System, or ECS for short, on xrOS.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"RealityKit’s ECS splits the systems that process data from the Component data itself, allowing it to live alongside 3D content. Thanks to these custom schemas, we can now use RealityKitComponent for built-in Components, and RealityKitCustomComponent for our own Swift custom components.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The Swift components structs and dictionaries can be represented by the equivalent RealityKit USD schemas. RealityKit also builds upon USD’s spatialAudio with RealityKit’s Audio File, Audio File Group, and MixGroup to create even more immersive audio."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let’s take a look at a USD file that represents some custom component data, as a USD prim, which is what USD calls objects in its hierarchy."}]},{"type":"codeListing","code":["\/\/ Character.usda","def RealityKitCustomComponent \"MyProject_PointsComponent\" {","\tint points = 75","\tuniform token info:id = \"MyProject.PointsComponent\"","}"],"syntax":"swift"},{"type":"paragraph","inlineContent":[{"type":"text","text":"This allows custom component data to live alongside other prims such as geometry. Since this is all in USD, we can use any app that lets you author USD prims directly to create them alongside the rest of your scene."}]},{"type":"codeListing","code":["\/\/ PointsComponent.swift","public struct PointsComponent: Component, Codable {","\tvar points: Int = 100","\t","\tpublic init() { }"],"syntax":"swift"},{"type":"paragraph","inlineContent":[{"type":"text","text":"This aligns with the corresponding Swift Component that can then be used to read these values from other USD components, such as here where different objects in the app may have specific Engagement Points associated with them."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Please check out the talks on building applications with Reality Composer Pro to learn more."}]},{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273\/","isActive":true}]},{"type":"heading","anchor":"Industry-support","level":2,"text":"Industry support"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Growing ecosystem"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Easy to build for iOS","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Reduced dependencies","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Metal support in Hydra Storm","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"text":"Apple worked with Pixar and the community to list many of the software packages that now support USD on the OpenUSD webpage. This allows creators to see how easily they can create USD-based content with their own existing workflows on a Mac. And it also been working to build USD for portable platforms like iOS, so that developers, can integrate USD into your their applications that can author immersive USD content.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"USD includes a technology called Hydra, an abstraction framework for renderers, and Storm, a real-time renderer that makes use of Hydra. Apple has worked with Pixar to add Metal support to Storm, making use of modern graphics API that enables developers to create high-performance, GPU-based applications on Apple platforms.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"The Animal Logic ALab scene is representative of many feature film-level assets. When set to full resolution, this scene can take over 26GB of graphics memory, previously requiring desktop workstation GPUs.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10086-content10","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Now, with Metal in Hydra Storm, and unified memory on Apple silicon, a MacBook Pro is enough to work on the go, even on demanding scenes like this, while retaining interactive performance. This high-performance rendering in Storm also enables Blackmagic Design to add fast viewport rendering of USD to Fusion in DaVinci Resolve."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10086-content11","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Building on the collaboration from previous years, Apple is working with Autodesk on their open source Maya USD plugin."}]},{"type":"heading","anchor":"Maya-USD-plug-in","level":2,"text":"Maya USD plug-in"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Enhanced asset export"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Better animation import"}]}]},{"content":[{"inlineContent":[{"text":"Easier rOS workflows","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Apple has made several contributions to the project, including enhancements to the export of geometry and materials. There are also improvements to animation import. All of this helps to have more seamless workflows to create spatial content for xrOS. (Some of these features may be released in later releases of Maya USD)"}]},{"type":"heading","anchor":"Blender","level":2,"text":"Blender"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Better USD import and export"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"USDZ support"}]}]},{"content":[{"inlineContent":[{"text":"Metal rendering","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"text":"Apple has been working with the Blender Foundation, many individuals and partners like AMD, NVIDIA, and Unity, to deliver updates to Blender, an open-source 3D application. This collaboration has enabled significantly improved USD import and export in Blender 3.5.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This includes USDZ support for the first time. Apple also worked with the Blender Foundation to introduce Metal support for their Eevee and Cycles renderer. Now with Blender 3.5, we can run Blender as a fully native Metal application, speeding up our UI, viewport, and final render. Final renders can make use of the GPU to complete in up to half the time when compared to CPU based renders, and the viewport can now render up to 4 times faster than OpenGL in certain scenes."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10086-content12"}]},{"type":"heading","anchor":"Resources","level":2,"text":"Resources"},{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/developer.apple.com\/forums\/create\/question?tag1=795030&tag2=724030&tag3=251","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/forums\/tags\/wwdc2023-10086","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/documentation\/RealityKit\/validating-usd-files","type":"reference","isActive":true}]},{"type":"heading","anchor":"Related-Videos","level":2,"text":"Related Videos"},{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10149","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10167","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10164","isActive":true,"overridingTitle":"Explore materials in Reality Composer Pro - WWDC23","overridingTitleInlineContent":[{"text":"Explore materials in Reality Composer Pro - WWDC23","type":"text"}]},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10165","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273\/","isActive":true,"overridingTitle":"Work with Reality Composer Pro content in Xcode","overridingTitleInlineContent":[{"text":"Work with Reality Composer Pro content in Xcode","type":"text"}]}]},{"type":"heading","anchor":"Written-By","level":2,"text":"Written By"},{"columns":[{"size":1,"content":[{"inlineContent":[{"type":"image","identifier":"multitudes"}],"type":"paragraph"}]},{"size":4,"content":[{"anchor":"laurent-b","text":"laurent b","level":3,"type":"heading"},{"inlineContent":[{"type":"reference","overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","isActive":true,"overridingTitle":"Contributed Notes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/github.com\/multitudes","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/x.com\/wrmultitudes","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/laurentbrusa.hashnode.dev\/","isActive":true}],"type":"paragraph"}]}],"type":"row","numberOfColumns":5},{"type":"paragraph","inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"type":"reference","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","isActive":true}]},{"type":"heading","anchor":"Related-Sessions","level":2,"text":"Related Sessions"},{"type":"links","style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro"]},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"type":"small","inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}]}]}],"schemaVersion":{"patch":0,"minor":3,"major":0},"kind":"article","hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem"},"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (14 min)","type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10086"}},"sections":[],"references":{"https://developer.apple.com/videos/play/wwdc2023/10165":{"type":"link","title":"Meet Reality Composer Pro - WWDC23","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10165","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10165","titleInlineContent":[{"type":"text","text":"Meet Reality Composer Pro - WWDC23"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"type":"topic","title":"WWDC Notes","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"kind":"symbol","url":"\/documentation\/wwdcnotes","role":"collection"},"WWDC23-10086-content7":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content7.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content7"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10083-Meet-Reality-Composer-Pro":{"abstract":[{"type":"text","text":"Discover how to easily compose, edit, and preview 3D content with Reality Composer Pro. Follow along as we explore this developer tool by setting up a new project, composing scenes, adding particle emitters and audio, and even previewing content on device."}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10083-meet-reality-composer-pro","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","role":"sampleCode","type":"topic","title":"Meet Reality Composer Pro"},"WWDC23-10086-content12":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content12.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content12"},"https://developer.apple.com/videos/play/wwdc2023/10167":{"type":"link","title":"Create 3D models for Quick Look spatial experiences - WWDC23","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10167","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10167","titleInlineContent":[{"type":"text","text":"Create 3D models for Quick Look spatial experiences - WWDC23"}]},"https://developer.apple.com/forums/create/question?tag1=795030&tag2=724030&tag3=251":{"type":"link","title":"Have a question? Ask with tag wwdc2023-10086","url":"https:\/\/developer.apple.com\/forums\/create\/question?tag1=795030&tag2=724030&tag3=251","identifier":"https:\/\/developer.apple.com\/forums\/create\/question?tag1=795030&tag2=724030&tag3=251","titleInlineContent":[{"type":"text","text":"Have a question? Ask with tag wwdc2023-10086"}]},"WWDC23-10086-content9":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content9.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content9"},"multitudes.jpeg":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/multitudes.jpeg"}],"alt":null,"identifier":"multitudes.jpeg"},"https://github.com/multitudes":{"type":"link","title":"GitHub","url":"https:\/\/github.com\/multitudes","identifier":"https:\/\/github.com\/multitudes","titleInlineContent":[{"type":"text","text":"GitHub"}]},"https://developer.apple.com/videos/play/wwdc2023/10273/":{"type":"link","title":"Work with Reality Composer Pro content in Xcode","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273\/","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273\/","titleInlineContent":[{"type":"text","text":"Work with Reality Composer Pro content in Xcode"}]},"https://x.com/wrmultitudes":{"type":"link","title":"X\/Twitter","url":"https:\/\/x.com\/wrmultitudes","identifier":"https:\/\/x.com\/wrmultitudes","titleInlineContent":[{"type":"text","text":"X\/Twitter"}]},"WWDC23-10086-content6":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content6.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content6"},"WWDC23-10086-content3":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content3.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content3"},"WWDC23-10086-content11":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content11.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content11"},"https://developer.apple.com/wwdc23/10086":{"checksum":null,"type":"download","url":"https:\/\/developer.apple.com\/wwdc23\/10086","identifier":"https:\/\/developer.apple.com\/wwdc23\/10086"},"WWDC23-10086-content5":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content5.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content5"},"WWDC23-10086-content10":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content10.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content10"},"WWDC23-10086-intro1":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-intro1.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-intro1"},"WWDC23-10086-content4":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content4.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content4"},"WWDC23-10086-content2":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content2.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content2"},"https://laurentbrusa.hashnode.dev/":{"type":"link","title":"Blog","url":"https:\/\/laurentbrusa.hashnode.dev\/","identifier":"https:\/\/laurentbrusa.hashnode.dev\/","titleInlineContent":[{"type":"text","text":"Blog"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"SwiftData","type":"codeVoice"},{"type":"text","text":", "},{"type":"codeVoice","code":"Observation"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit"},{"type":"text","text":" views, and more."}],"title":"WWDC23","images":[{"type":"icon","identifier":"WWDC23-Icon.png"},{"type":"card","identifier":"WWDC23.jpeg"}],"kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","url":"\/documentation\/wwdcnotes\/wwdc23","role":"collectionGroup"},"doc://WWDCNotes/documentation/WWDCNotes/multitudes":{"kind":"article","abstract":[{"type":"text","text":"student at 42Berlin 🐬 | 🍎 Swift(UI) app dev  | speciality coffee ☕️ & cycling 🚴🏻‍♂️"}],"url":"\/documentation\/wwdcnotes\/multitudes","title":"laurent b (33 notes)","images":[{"type":"card","identifier":"multitudes.jpeg"},{"identifier":"multitudes.jpeg","type":"icon"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","type":"topic","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"abstract":[{"type":"text","text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio."}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","role":"sampleCode","type":"topic","title":"Build spatial experiences with RealityKit"},"WWDC23-10086-content1":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content1.jpg"}],"alt":"3D content in Apple apps","identifier":"WWDC23-10086-content1"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"type":"link","title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}]},"https://developer.apple.com/videos/play/wwdc2023/10164":{"type":"link","title":"Explore materials in Reality Composer Pro - WWDC23","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10164","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10164","titleInlineContent":[{"type":"text","text":"Explore materials in Reality Composer Pro - WWDC23"}]},"https://developer.apple.com/documentation/RealityKit/validating-usd-files":{"type":"link","title":"Validating feature support for USD files","url":"https:\/\/developer.apple.com\/documentation\/RealityKit\/validating-usd-files","identifier":"https:\/\/developer.apple.com\/documentation\/RealityKit\/validating-usd-files","titleInlineContent":[{"type":"text","text":"Validating feature support for USD files"}]},"WWDC23-10086-content8":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10086-content8.jpg"}],"alt":"USD and MaterialX","identifier":"WWDC23-10086-content8"},"https://developer.apple.com/videos/play/wwdc2023/10149":{"type":"link","title":"Build spatial experiences with RealityKit - WWDC23","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10149","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10149","titleInlineContent":[{"type":"text","text":"Build spatial experiences with RealityKit - WWDC23"}]},"https://developer.apple.com/forums/tags/wwdc2023-10086":{"type":"link","title":"Search the forums for tag wwdc2023-10086","url":"https:\/\/developer.apple.com\/forums\/tags\/wwdc2023-10086","identifier":"https:\/\/developer.apple.com\/forums\/tags\/wwdc2023-10086","titleInlineContent":[{"type":"text","text":"Search the forums for tag wwdc2023-10086"}]},"WWDCNotes.png":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}],"alt":null,"identifier":"WWDCNotes.png"},"WWDC23.jpeg":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23.jpeg"}],"alt":null,"identifier":"WWDC23.jpeg"},"WWDC23-Icon.png":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-Icon.png"}],"alt":null,"identifier":"WWDC23-Icon.png"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro":{"type":"topic","title":"Explore materials in Reality Composer Pro","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10202-explore-materials-in-reality-composer-pro","role":"sampleCode","abstract":[{"type":"text","text":"Learn how Reality Composer Pro can help you alter the appearance of your 3D objects using RealityKit materials. We’ll introduce you to MaterialX and physically-based (PBR) shaders, show you how to design dynamic materials using the shader graph editor, and explore adding custom inputs to a material so that you can control it in your visionOS app."}]},"multitudes":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/multitudes.jpeg"}],"alt":"Profile image of laurent b","identifier":"multitudes"}}}