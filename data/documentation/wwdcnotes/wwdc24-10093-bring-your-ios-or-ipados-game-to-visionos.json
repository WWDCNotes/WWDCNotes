{"schemaVersion":{"patch":0,"minor":3,"major":0},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10093-Bring-your-iOS-or-iPadOS-game-to-visionOS","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"Discover how to transform your iOS or iPadOS game into a uniquely visionOS experience. Increase the immersion (and fun factor!) with a 3D frame or an immersive background. And invite players further into your world by adding depth to the window with stereoscopy or head tracking."}],"metadata":{"role":"sampleCode","roleHeading":"WWDC24","modules":[{"name":"WWDC Notes"}],"title":"Bring your iOS or iPadOS game to visionOS"},"sections":[],"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video","identifier":"https:\/\/developer.apple.com\/wwdc24\/10093","type":"reference","isActive":true}},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc24-10093-bring-your-ios-or-ipados-game-to-visionos"]}],"kind":"article","primaryContentSections":[{"kind":"content","content":[{"type":"heading","level":2,"anchor":"overview","text":"Overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Focus: how to bring your Metal game into a hybrid environment on visionOS."}]},{"type":"paragraph","inlineContent":[{"text":"Intro: compare Wylde Flowers iPad to Wylde Flowers visionOS.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Two main modes for Metal on visionOS:."}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"run your game as a compatible app in a window. App behaves very similarly to how it would on an iPad. Runs alongside other apps in Shared Space.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"use CompositorServices to run your game as a fully immersive app where the game’s camera is controlled by the player’s head. See “Render Metal with passthrough in visionOS”."}]}]}]},{"type":"paragraph","inlineContent":[{"text":"“In between” is focus of this video. Start with a compatible app and progressively add features to increase immersion, leverage Vision Pro capabilities.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Sample for case study: ","type":"text"},{"identifier":"https:\/\/developer.apple.com\/documentation\/metal\/metal_sample_code_library\/rendering_a_scene_with_deferred_lighting_in_swift","isActive":true,"type":"reference"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Start: compile  app with the iOS SDK and run it on visionOS as a compatible app. Runs in a window."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Go to build settings, select iOS target, add Apple Vision as supported destination.Let’s add Apple Vision as a supported destination, to compile the app with the visionOS SDK. Might have minor compile errors."}]},{"type":"paragraph","inlineContent":[{"text":"Recommended: move to a LowLevelTexture to get the most control.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"If you want to render to a CAMetalLayer, you can create a View that contains it. Can create a CADisplayLink to get a callback every frame."}]},{"type":"paragraph","inlineContent":[{"text":"Can use LowLevelTextures in a similar way. Create a LowLevelTexture, then  create a TextureResource from the LowLevelTexture, and use it anywhere in a RealityKit scene. Use CommandQueue to draw to the LowLevelTexture, through an MTLTexture. For more details about LowLevelTexture, see the video “Build a spatial drawing app with RealityKit”.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"After converting to native visionOS, can add visionOS specific features.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Example: add frame around the game view, add background in an ImmersiveSpace.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"“Cut The Rope 3” has a dynamic frame around its window. Frame rendered with RealityKit, game rendered with Metal. Code sample."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Add immersive background behind game. Example: Void-X."}]},{"type":"paragraph","inlineContent":[{"text":"Can create background with an ImmersiveSpace in SwiftUI. Can put iOS game in a WindowGroup. Can have shared @State between the window and ImmersiveSpace, by using a SwiftUI @State object.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Example: add stereoscopy to Deferred Lighting sample."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Explanation of stereoscopy and parallax."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"If you want objects to come out of the bounds of the rectangle, can render them with RealityKit and APIs such as the new portal-crossing API. See the “Discover RealityKit APIs for iOS, macOS and visionOS” for example of portal-crossing."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"“Build compelling spatial photo and video experiences” has details about creating stereoscopic content."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Caution: don’t render beyond infinity. Eyes should either converge or be parallel. Very uncomfortable."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Recommended: add slider to the settings of your game, for the player to adjust the intensity of the stereoscopy to their comfort. Implement by changing distance between the two virtual cameras. See game loop of Deferred Lighting sample."}]},{"type":"paragraph","inlineContent":[{"text":"Optimization: use Vertex Amplification to render both eyes with the same draw calls. Article about Vertex Amplification on the developer documentation website.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Example: adapting code of the Deferred Lighting Sample.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Example: Deferred Lighting sample with head tracking. The camera moves as viewer’s head moves.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Use ImmersiveSpace and ARKit. Get head position from ARKit every frame, pass to your renderer. Code sample shown."}]},{"type":"paragraph","inlineContent":[{"text":"Windows and ImmersiveSpaces have their own coordinate spaces on visionOS. The head transform from ARKit is in the coordinate space of the ImmersiveSpace. To use in window,  convert the position to the window’s coordinate space. Code sample shown. Can invert this matrix and convert the head position to the window space.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"For best results, predict the head position (because of render delay). ARKit will do the head prediction if you give it an estimated render time for your app. Sample uses 33 milliseconds for the estimated presentationTime, which corresponds to 3 frames at 90fps.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"To make game look like it is rendered through a physical window, need to build asymmetric projection matrix. A fixed projection matrix will not match the shape of the window. Camera frustum must go through the window. Code sample shown."}]},{"type":"paragraph","inlineContent":[{"text":"Stereoscopy increases immersion of your game but doubles the render cost. Offset some of this by using Variable Rasterization Rates (VRR).","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Use VRR to lower resolution at periphery and increase resolution at center. Sample code. Sample video showing changes in AdaptiveResolutionComponent. More details on VRR.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Sample: "},{"type":"reference","identifier":"https:\/\/developer.apple.com\/documentation\/RealityKit\/rendering-a-windowed-game-in-stereo","isActive":true}]},{"type":"heading","level":2,"anchor":"Written-By","text":"Written By"},{"type":"row","numberOfColumns":5,"columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"halmueller"}]}]},{"size":4,"content":[{"text":"Hal Mueller","type":"heading","anchor":"Hal-Mueller","level":3},{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/halmueller","overridingTitle":"Contributed Notes","isActive":true,"overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}]},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/github.com\/halmueller","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/","isActive":true}]}]}]},{"type":"thematicBreak"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}]},{"type":"heading","level":2,"anchor":"Related-Sessions","text":"Related Sessions"},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10094-Explore-game-input-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10092-Render-Metal-with-passthrough-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10104-Build-a-spatial-drawing-app-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10103-Discover-RealityKit-APIs-for-iOS-macOS-and-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10166-Build-compelling-spatial-photo-and-video-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit"],"style":"list"},{"type":"small","inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2025 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}]}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24"]]},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","abstract":[{"text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","kind":"article","role":"sampleCode","type":"topic","title":"Build spatial experiences with RealityKit"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!"},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"title":"WWDC Notes","role":"collection","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","type":"topic","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"url":"\/documentation\/wwdcnotes"},"WWDCNotes.png":{"alt":null,"type":"image","identifier":"WWDCNotes.png","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDCNotes.png"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10104-Build-a-spatial-drawing-app-with-RealityKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10104-Build-a-spatial-drawing-app-with-RealityKit","kind":"article","title":"Build a spatial drawing app with RealityKit","role":"sampleCode","abstract":[{"type":"text","text":"Harness the power of RealityKit through the process of building a spatial drawing app. As you create an eye-catching spatial experience that integrates RealityKit with ARKit and SwiftUI, you’ll explore how resources work in RealityKit and how to use features like low-level mesh and texture APIs to achieve fast updates of the users’ brush strokes."}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10104-build-a-spatial-drawing-app-with-realitykit"},"WWDC24-Icon.png":{"alt":null,"identifier":"WWDC24-Icon.png","type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC24-Icon.png"}]},"https://developer.apple.com/wwdc24/10093":{"url":"https:\/\/developer.apple.com\/wwdc24\/10093","checksum":null,"type":"download","identifier":"https:\/\/developer.apple.com\/wwdc24\/10093"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10094-Explore-game-input-in-visionOS":{"abstract":[{"text":"Discover how to design and implement great input for your game in visionOS. Learn how system gestures let you provide frictionless ways for players to interact with your games. And explore best practices for supporting custom gestures and game controllers.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc24-10094-explore-game-input-in-visionos","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10094-Explore-game-input-in-visionOS","kind":"article","role":"sampleCode","title":"Explore game input in visionOS","type":"topic"},"https://developer.apple.com/documentation/metal/metal_sample_code_library/rendering_a_scene_with_deferred_lighting_in_swift":{"type":"link","identifier":"https:\/\/developer.apple.com\/documentation\/metal\/metal_sample_code_library\/rendering_a_scene_with_deferred_lighting_in_swift","titleInlineContent":[{"type":"text","text":"Metal Deferred Lighting sample"}],"title":"Metal Deferred Lighting sample","url":"https:\/\/developer.apple.com\/documentation\/metal\/metal_sample_code_library\/rendering_a_scene_with_deferred_lighting_in_swift"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10103-Discover-RealityKit-APIs-for-iOS-macOS-and-visionOS":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10103-Discover-RealityKit-APIs-for-iOS-macOS-and-visionOS","abstract":[{"type":"text","text":"Learn how new cross-platform APIs in RealityKit can help you build immersive apps for iOS, macOS, and visionOS. Check out the new hover effects, lights and shadows, and portal crossing features, and view them in action through real examples."}],"title":"Discover RealityKit APIs for iOS, macOS and visionOS","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10103-discover-realitykit-apis-for-ios-macos-and-visionos","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24":{"images":[{"type":"icon","identifier":"WWDC24-Icon.png"},{"type":"card","identifier":"WWDC24.jpeg"}],"title":"WWDC24","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24","abstract":[{"text":"Xcode 16, Swift 6, iOS 18, macOS 15 (Sequoia), tvOS 18, visionOS 2, watchOS 11.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: Swift Testing, ","type":"text"},{"code":"FinanceKit","type":"codeVoice"},{"text":", ","type":"text"},{"code":"TabletopKit","type":"codeVoice"},{"text":", and more.","type":"text"}],"kind":"article","role":"collectionGroup","url":"\/documentation\/wwdcnotes\/wwdc24","type":"topic"},"WWDC24.jpeg":{"alt":null,"type":"image","identifier":"WWDC24.jpeg","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC24.jpeg"}]},"https://":{"title":"Blog","identifier":"https:\/\/","url":"https:\/\/","type":"link","titleInlineContent":[{"type":"text","text":"Blog"}]},"https://developer.apple.com/documentation/RealityKit/rendering-a-windowed-game-in-stereo":{"type":"link","identifier":"https:\/\/developer.apple.com\/documentation\/RealityKit\/rendering-a-windowed-game-in-stereo","titleInlineContent":[{"type":"text","text":"Rendering a windowed game in stereo"},{"type":"text","text":" "}],"title":"Rendering a windowed game in stereo ","url":"https:\/\/developer.apple.com\/documentation\/RealityKit\/rendering-a-windowed-game-in-stereo"},"doc://WWDCNotes/documentation/WWDCNotes/halmueller":{"type":"topic","kind":"article","title":"Hal Mueller (7 notes)","abstract":[{"type":"text","text":"Software developer, application architect, teacher, geodata hacker. Mostly Swift, Objective-C, Python. SwiftUI, UIKit, AppKit."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/halmueller","url":"\/documentation\/wwdcnotes\/halmueller","images":[{"identifier":"halmueller.jpeg","type":"card"},{"identifier":"halmueller.jpeg","type":"icon"}],"role":"sampleCode"},"halmueller":{"alt":"Profile image of Hal Mueller","type":"image","identifier":"halmueller","variants":[{"url":"\/images\/WWDCNotes\/halmueller.jpeg","traits":["1x","light"]}]},"halmueller.jpeg":{"alt":null,"type":"image","identifier":"halmueller.jpeg","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/halmueller.jpeg"}]},"https://github.com/halmueller":{"title":"GitHub","identifier":"https:\/\/github.com\/halmueller","url":"https:\/\/github.com\/halmueller","type":"link","titleInlineContent":[{"type":"text","text":"GitHub"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10166-Build-compelling-spatial-photo-and-video-experiences":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10166-Build-compelling-spatial-photo-and-video-experiences","type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10166-build-compelling-spatial-photo-and-video-experiences","title":"Build compelling spatial photo and video experiences","abstract":[{"type":"text","text":"Learn how to adopt spatial photos and videos in your apps. Explore the different types of stereoscopic media and find out how to capture spatial videos in your iOS app on iPhone 15 Pro. Discover the various ways to detect and present spatial media, including the new QuickLook Preview Application API in visionOS. And take a deep dive into the metadata and stereo concepts that make a photo or video spatial."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10092-Render-Metal-with-passthrough-in-visionOS":{"abstract":[{"text":"Get ready to extend your Metal experiences for visionOS. Learn best practices for integrating your rendered content with people’s physical environments with passthrough. Find out how to position rendered content to match the physical world, reduce latency with trackable anchor prediction, and more.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc24-10092-render-metal-with-passthrough-in-visionos","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10092-Render-Metal-with-passthrough-in-visionOS","role":"sampleCode","title":"Render Metal with passthrough in visionOS","kind":"article"}}}