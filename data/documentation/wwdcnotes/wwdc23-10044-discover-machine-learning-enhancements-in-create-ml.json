{"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (16 min)","identifier":"https:\/\/developer.apple.com\/wwdc23\/10044","type":"reference","isActive":true}},"sections":[],"kind":"article","metadata":{"role":"sampleCode","title":"Discover machine learning enhancements in Create ML","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC23"},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","interfaceLanguage":"swift"},"topicSections":[{"abstract":[{"text":"We’ve been working on some great improvements to the Create ML app and frameworks.","type":"text"},{"text":"\n","type":"text"},{"text":"Training a large-scale model from scratch can take thousands of hours, millions of annotated files, and expert domain knowledge. Our goal is to give you the tools to build great apps that use machine learning without all of the overhead. We’ve gone through the process of creating state-of-the-art models that power many features, like the Search experience in the Photos app and Custom Sound Recognition in Accessibility.","type":"text"}],"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10019-Get-to-know-Create-ML-Components","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10020-Compose-advanced-models-with-Create-ML-Components","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110332-Whats-new-in-Create-ML"],"anchor":"Topics"}],"schemaVersion":{"major":0,"patch":0,"minor":3},"abstract":[{"type":"text","text":"Find out how Create ML can help you do even more with machine learning models. Learn about the latest updates to image understanding and text-based tasks with multilingual BERT embeddings. Discover how easy it is to train models that can understand the content of images using multi-label classification. We’ll also share information about interactive model evaluation and the latest APIs for custom training data augmentations."}],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10044-discover-machine-learning-enhancements-in-create-ml"],"traits":[{"interfaceLanguage":"swift"}]}],"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10020-Compose-advanced-models-with-Create-ML-Components":{"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10020-compose-advanced-models-with-create-ml-components","role":"sampleCode","abstract":[{"text":"Take your custom machine learning models to the next level with Create ML Components. We’ll show you how to work with temporal data like video or audio and compose models that can count repetitive human actions or provide advanced sound classification. We’ll also share best practices on using incremental fitting to speed up model training with new data.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10020-Compose-advanced-models-with-Create-ML-Components","type":"topic","title":"Compose advanced models with Create ML Components"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10019-Get-to-know-Create-ML-Components":{"abstract":[{"text":"Create ML makes it easy to build custom machine learning models for image classification, object detection, sound classification, hand pose classification, action classification, tabular data regression, and more. And with the Create ML Components framework, you can further customize underlying tasks and improve your model. We’ll explore the feature extractors, transformers, and estimators that make up these tasks, and show you how you can combine them with other components and pre-processing steps to build custom tasks for concepts like image regression.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc22-10019-get-to-know-create-ml-components","title":"Get to know Create ML Components","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10019-Get-to-know-Create-ML-Components","role":"sampleCode","kind":"article"},"WWDCNotes.png":{"alt":null,"variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"type":"image","identifier":"WWDCNotes.png"},"WWDC23-Icon.png":{"alt":null,"type":"image","identifier":"WWDC23-Icon.png","variants":[{"url":"\/images\/WWDCNotes\/WWDC23-Icon.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"SwiftData","type":"codeVoice"},{"type":"text","text":", "},{"code":"Observation","type":"codeVoice"},{"type":"text","text":", "},{"code":"StoreKit","type":"codeVoice"},{"type":"text","text":" views, and more."}],"url":"\/documentation\/wwdcnotes\/wwdc23","title":"WWDC23","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","role":"collectionGroup","kind":"article","images":[{"identifier":"WWDC23-Icon.png","type":"icon"},{"identifier":"WWDC23.jpeg","type":"card"}]},"https://developer.apple.com/wwdc23/10044":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10044","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc23\/10044","type":"download"},"WWDC23.jpeg":{"alt":null,"variants":[{"url":"\/images\/WWDCNotes\/WWDC23.jpeg","traits":["1x","light"]}],"type":"image","identifier":"WWDC23.jpeg"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110332-Whats-new-in-Create-ML":{"kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc22-110332-whats-new-in-create-ml","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110332-Whats-new-in-Create-ML","title":"What’s new in Create ML","abstract":[{"type":"text","text":"Discover the latest updates to Create ML. We’ll share improvements to Create ML’s evaluation tools that can help you understand how your custom models will perform on real-world data. Learn how you can check model performance on each type of image in your test data and identify problems within individual images to help you troubleshoot mistaken classifications, poorly labeled data, and other errors. We’ll also show you how to test your model with iPhone and iPad in live preview using Continuity Camera, and share how you can take Action Classification even further with the new Repetition Counting capabilities of the Create ML Components framework."}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10042-Explore-Natural-Language-multilingual-models":{"type":"topic","title":"Explore Natural Language multilingual models","url":"\/documentation\/wwdcnotes\/wwdc23-10042-explore-natural-language-multilingual-models","abstract":[{"text":"Learn how to create custom Natural Language models for text classification and word tagging using multilingual, transformer-based embeddings. We’ll show you how to train with less data and support up to 27 different languages across three scripts. Find out how to use these embeddings to fine-tune complex models trained in PyTorch and TensorFlow.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"url":"\/documentation\/wwdcnotes","title":"WWDC Notes","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","kind":"symbol","images":[{"type":"icon","identifier":"WWDCNotes.png"}]}}}