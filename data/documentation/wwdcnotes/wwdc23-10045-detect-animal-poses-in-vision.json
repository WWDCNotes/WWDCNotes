{"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"metadata":{"title":"Detect animal poses in Vision","role":"sampleCode","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC23"},"kind":"article","primaryContentSections":[{"content":[{"type":"heading","anchor":"overview","level":2,"text":"Overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"isActive":true,"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference"}]},{"type":"heading","anchor":"Related-Sessions","level":2,"text":"Related Sessions"},{"style":"list","type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision"]},{"type":"small","inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright ¬© 2012 ‚Äì 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (13 min)","identifier":"https:\/\/developer.apple.com\/wwdc23\/10045","type":"reference","isActive":true}},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-10045-detect-animal-poses-in-vision"]}],"schemaVersion":{"patch":0,"minor":3,"major":0},"abstract":[{"type":"text","text":"Go beyond detecting cats and dogs in images. We‚Äôll show you how to use Vision to detect the individual joints and poses of these animals as well ‚Äî all in real time ‚Äî and share how you can enable exciting features like animal tracking for a camera app, creative embellishment on an animal photo, and more. We‚Äôll also explore other important enhancements to Vision and share best practices."}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision"},"sections":[],"references":{"WWDCNotes.png":{"alt":null,"type":"image","identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}]},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"title":"Learn More‚Ä¶","type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}]},"WWDC23.jpeg":{"alt":null,"type":"image","identifier":"WWDC23.jpeg","variants":[{"url":"\/images\/WWDC23.jpeg","traits":["1x","light"]}]},"WWDC23-Icon.png":{"alt":null,"type":"image","identifier":"WWDC23-Icon.png","variants":[{"url":"\/images\/WWDC23-Icon.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes":{"url":"\/documentation\/wwdcnotes","role":"collection","type":"topic","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","kind":"symbol","title":"WWDC Notes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"kind":"article","type":"topic","role":"collectionGroup","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","url":"\/documentation\/wwdcnotes\/wwdc23","abstract":[{"text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"type":"codeVoice","code":"SwiftData"},{"text":", ","type":"text"},{"type":"codeVoice","code":"Observation"},{"text":", ","type":"text"},{"type":"codeVoice","code":"StoreKit"},{"text":" views, and more.","type":"text"}],"title":"WWDC23","images":[{"type":"icon","identifier":"WWDC23-Icon.png"},{"type":"card","identifier":"WWDC23.jpeg"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision":{"abstract":[{"text":"Discover how to build person-centric features with Vision. Learn how to detect human body poses and measure individual joint locations in 3D space. We‚Äôll also show you how to take advantage of person segmentation APIs to distinguish and segment up to four individuals in an image.","type":"text"}],"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","url":"\/documentation\/wwdcnotes\/wwdc23-111241-explore-3d-body-pose-and-person-segmentation-in-vision","kind":"article","title":"Explore 3D body pose and person segmentation in Vision"},"https://developer.apple.com/wwdc23/10045":{"type":"download","identifier":"https:\/\/developer.apple.com\/wwdc23\/10045","url":"https:\/\/developer.apple.com\/wwdc23\/10045","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit":{"title":"Integrate with motorized iPhone stands using DockKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","url":"\/documentation\/wwdcnotes\/wwdc23-10304-integrate-with-motorized-iphone-stands-using-dockkit","type":"topic","kind":"article","role":"sampleCode","abstract":[{"text":"Discover how you can create incredible photo and video experiences in your camera app when integrating with DockKit-compatible motorized stands. We‚Äôll show how your app can automatically track subjects in live video across a 360-degree field of view, take direct control of the stand to customize framing, directly control the motors, and provide your own inference model for tracking other objects. Finally, we‚Äôll demonstrate how to create a sense of emotion through dynamic device animations.","type":"text"}]}}}