{"schemaVersion":{"major":0,"patch":0,"minor":3},"metadata":{"roleHeading":"WWDC23","title":"Detect animal poses in Vision","role":"sampleCode","modules":[{"name":"WWDC Notes"}]},"sampleCodeDownload":{"action":{"overridingTitle":"Watch Video","identifier":"https:\/\/developer.apple.com\/wwdc23\/10045","isActive":true,"type":"reference"},"kind":"sampleDownload"},"primaryContentSections":[{"content":[{"type":"heading","text":"Overview","anchor":"overview","level":2},{"type":"paragraph","inlineContent":[{"text":"To learn even more about what‚Äôs new in the Vision framework, watch ‚ÄúExplore 3D body pose and person segmentation in Vision‚Äù and ‚ÄúLift subjects from images in your app.‚Äù And to learn more about building live camera-tracking experiences, check out ‚ÄúIntegrate with motorized iPhone stands using DockKit‚Äù","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","isActive":true,"type":"reference"}]},{"type":"heading","text":"Written By","anchor":"Written-By","level":2},{"type":"row","numberOfColumns":5,"columns":[{"size":1,"content":[{"inlineContent":[{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4"}],"type":"paragraph"}]},{"size":4,"content":[{"type":"heading","anchor":"To-Do<doc<replace-this-with-your-GitHub-handle>>","level":3,"text":"[To Do](<doc:<replace this with your GitHub handle>>)"},{"type":"paragraph","inlineContent":[{"type":"text","text":"An amazing developer."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"[Contributed Notes](<doc:"},{"type":"text","text":">)"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/x.com\/Jeehut","isActive":true}]}]}]},{"type":"heading","text":"Related Sessions","anchor":"Related-Sessions","level":2},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision"],"style":"list"},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"type":"small","inlineContent":[{"text":"All content copyright ¬© 2012 ‚Äì 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}]}],"kind":"content"}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision","interfaceLanguage":"swift"},"kind":"article","hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes"]]},"sections":[],"abstract":[{"type":"text","text":"Go beyond detecting cats and dogs in images. We‚Äôll show you how to use Vision to detect the individual joints and poses of these animals as well ‚Äî all in real time ‚Äî and share how you can enable exciting features like animal tracking for a camera app, creative embellishment on an animal photo, and more. We‚Äôll also explore other important enhancements to Vision and share best practices."}],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10045-detect-animal-poses-in-vision"],"traits":[{"interfaceLanguage":"swift"}]}],"references":{"WWDCNotes.png":{"type":"image","identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-111241-explore-3d-body-pose-and-person-segmentation-in-vision","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","title":"Explore 3D body pose and person segmentation in Vision","abstract":[{"text":"Discover how to build person-centric features with Vision. Learn how to detect human body poses and measure individual joint locations in 3D space. We‚Äôll also show you how to take advantage of person segmentation APIs to distinguish and segment up to four individuals in an image.","type":"text"}],"kind":"article"},"https://avatars.githubusercontent.com/u/123?v=4":{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4","traits":["1x","light"]}],"alt":"Profile image of To Do"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","url":"\/documentation\/wwdcnotes\/wwdc23-10304-integrate-with-motorized-iphone-stands-using-dockkit","type":"topic","title":"Integrate with motorized iPhone stands using DockKit","abstract":[{"type":"text","text":"Discover how you can create incredible photo and video experiences in your camera app when integrating with DockKit-compatible motorized stands. We‚Äôll show how your app can automatically track subjects in live video across a 360-degree field of view, take direct control of the stand to customize framing, directly control the motors, and provide your own inference model for tracking other objects. Finally, we‚Äôll demonstrate how to create a sense of emotion through dynamic device animations."}],"role":"sampleCode","kind":"article"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"text":"Learn More‚Ä¶","type":"text"}],"type":"link","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"type":"topic","role":"collection","url":"\/documentation\/wwdcnotes","title":"WWDC Notes","kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}]},"https://x.com/Jeehut":{"titleInlineContent":[{"text":"X\/Twitter","type":"text"}],"type":"link","identifier":"https:\/\/x.com\/Jeehut","title":"X\/Twitter","url":"https:\/\/x.com\/Jeehut"},"https://developer.apple.com/wwdc23/10045":{"type":"download","identifier":"https:\/\/developer.apple.com\/wwdc23\/10045","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc23\/10045"}}}