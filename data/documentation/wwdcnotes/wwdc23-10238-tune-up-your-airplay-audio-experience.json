{"primaryContentSections":[{"content":[{"type":"heading","text":"Airplay Overview","level":2,"anchor":"Airplay-Overview"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"With AirPlay Audio you can stream your favorite music or podcast in perfect sync."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"With AirPlay Video, you can stream your favorite movies and shows.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"With mirroring, you can share photos, personal videos, games, web pages, or spreadsheets.","type":"text"}]}]}]},{"type":"heading","text":"Airplay Enhanced Audio Buffering","level":2,"anchor":"Airplay-Enhanced-Audio-Buffering"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Built with a new and improved protocol keeping Whole home audio in mind."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Audio streams faster than real-time playback speed in order to minimize playback interruptions."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Highly responsive on HomePod or iPhone as a remote control."}]}]},{"content":[{"inlineContent":[{"text":"Supports multi-channel audio formats, like Dolby ATMOS.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Intelligent use of Lossless playback for iOS.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Supports HLS Interstitials."}],"type":"paragraph"}]}]},{"type":"heading","text":"Add Support To Your App","level":2,"anchor":"Add-Support-To-Your-App"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"If playing media is central to your app, set your audio session’s category to ","type":"text"},{"code":".playback","type":"codeVoice"},{"text":". This will ensure your app’s media will continue playing when the app is in background.","type":"text"}]}]}]},{"code":["let audioSession = AVAudioSession.sharedInstance()","try audioSession.setCategory(. playback ,xmode: . default , policy:.longFormAudio ) "],"type":"codeListing","syntax":"swift"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"for spoken audio, like podcasts or audiobooks, to set the mode to ","type":"text"},{"code":".spokenAudio","type":"codeVoice"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"set the audio session’s routing policy to ","type":"text"},{"code":".longFormAudio","type":"codeVoice"},{"text":". Longform audio is anything other than system sounds, such as music or podcasts.","type":"text"}]}]}]},{"type":"heading","text":"Intelligent Airplay Support","level":2,"anchor":"Intelligent-Airplay-Support"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Add a new key\/value to ","type":"text"},{"type":"codeVoice","code":"info.plist"},{"text":" and set ","type":"text"},{"type":"codeVoice","code":"AVInitialRouteSharingPolicy = LongformAudio"}],"type":"paragraph"}]}]},{"type":"heading","text":"Supporting Airplay","level":3,"anchor":"Supporting-Airplay"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Identify the audio type: add ","type":"text"},{"code":"AVRoutePickerView","type":"codeVoice"},{"text":" to your view hierarchy to include an AirPlay picker in your app.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Add an Airplay picker: The picker provides people with a list of potential AirPlay devices that they can use with your app."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Add a media player: "},{"code":"MPNowPlayingInfoCenter","type":"codeVoice"},{"type":"text","text":" and "},{"code":"MPRemoteCommandCenter","type":"codeVoice"},{"type":"text","text":" to receive remote commands, like play, pause, or skip."}]}]}]},{"type":"heading","text":"Supporting Airplay Enhanced Audio Buffering","level":2,"anchor":"Supporting-Airplay-Enhanced-Audio-Buffering"},{"type":"paragraph","inlineContent":[{"type":"codeVoice","code":"AVPLayer"},{"text":" or ","type":"text"},{"type":"codeVoice","code":"AVQueuePlayer"},{"text":" is the simplest way to support enhanced audio buffering for your app where AVQueuePlayer is highly recommended.","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Create a queue player "},{"type":"codeVoice","code":"let player = AVQueuePlayer()"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Identify a URL that points to local or cloud content that you want to play."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Then create an AVAsset instance with the URL, and create an AVPlayerItem instance with that asset."}]}]},{"content":[{"inlineContent":[{"text":"Give the AVPlayerItem to the player and start playback.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Automatically gets enhanced audio buffering when it is routed to AirPlay.","type":"text"}],"type":"paragraph"}]}]},{"code":["let player = AVQueuePlayer()","","let url = URL(string: \"http:\/\/www.examplecontenturl.com\")","let asset = AVAsset(url: url)","let item = AVPlayItem(asset: asset)","","player.insert(item, after: nil)","player.play()",""],"type":"codeListing","syntax":"swift"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"If your app preprocess on the media data or have a DRM model AVPlayer use","type":"text"},{"code":"AVSampleBufferAudioRenderer and AVSampleBufferRenderSynchronizer","type":"codeVoice"},{"text":" to synchronize multiple queued sample buffers to a single timeline","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"create a serial queue to perform all playback operations on.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Create the audio renderer and the render synchronizer. The synchronizer is used to establish the media timeline.","type":"text"}],"type":"paragraph"}]}]},{"code":["let serializationQueue = DispatchQueue(label: \"sample.buffer.player.serialization.queue\")","let audioRenderer = AVSampleBufferAudioRenderer()","let renderSynchronizer = AVSampleBufferRenderSynchronizer()"],"type":"codeListing","syntax":"swift"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Add the audio renderer to the render synchronizer ","type":"text"},{"type":"codeVoice","code":"renderSynchronizer.addRenderer(audioRenderer)"},{"text":". This will tell the audio renderer to follow the media timeline.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"To enqueue audio data, install a callback that will let you know you need more data."}]}]}]},{"code":["serializationQueue.async { [weak self] in","    guard let self = self else { return }","    \/\/ Start processing audio data and stop when there's no more data.","    self.audioRenderer.requestMediaDataWhenReady(on: serializationQueue) { [weak self] in","        guard let self = self else { return }","        while self.audioRenderer.isReadyForMoreMediaData {","            let sampleBuffer = self.nextSampleBuffer() \/\/ Returns nil at end of data.","            if let sampleBuffer = sampleBuffer {","                self.audioRenderer.enqueue(sampleBuffer)","            } else {","                \/\/ Tell the renderer to stop requesting audio data.","                audioRenderer.stopRequestingMediaData()","            }","        }","    }","","    \/\/ Start playback at the natural rate of the media.","    self.renderSynchronizer.rate = 1.0","}"],"type":"codeListing","syntax":"swift"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Both APIs will work for non-AirPlay playback, including local or Bluetooth."}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Developers might want different APIs for AirPlay and non-AirPlay playback. In that case, your app can register to the routeChangeNotification and act accordingly depending on the current route."}],"type":"paragraph"}]}]},{"type":"heading","text":"CarPlay enhanced audio Buffering","level":2,"anchor":"CarPlay-enhanced-audio-Buffering"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"car manufacture support."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Wireless, robust and responsive playback."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Same APIs support CarPlay."}]}]}]},{"type":"heading","text":"Written By","level":2,"anchor":"Written-By"},{"numberOfColumns":5,"type":"row","columns":[{"size":1,"content":[{"inlineContent":[{"type":"image","identifier":"RamitSharma991"}],"type":"paragraph"}]},{"size":4,"content":[{"anchor":"Ramit-Sharma","text":"Ramit Sharma","type":"heading","level":3},{"inlineContent":[{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/RamitSharma991","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"isActive":true,"type":"reference","overridingTitle":"Contributed Notes"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/github.com\/RamitSharma991","isActive":true,"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/x.com\/iosDev_ramit","isActive":true,"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/","isActive":true,"type":"reference"}],"type":"paragraph"}]}]},{"type":"thematicBreak"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"isActive":true,"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference"}]},{"type":"heading","text":"Related Sessions","level":2,"anchor":"Related-Sessions"},{"type":"links","style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10104-Integrate-your-media-app-with-HomePod","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10275-Explore-AirPlay-with-interstitials"]},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2025 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10238-tune-up-your-airplay-audio-experience"],"traits":[{"interfaceLanguage":"swift"}]}],"metadata":{"role":"sampleCode","title":"Tune up your AirPlay audio experience","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC23"},"abstract":[{"type":"text","text":"Learn how you can upgrade your app’s AirPlay audio experience to be more robust and responsive. We’ll show you how to adopt enhanced audio buffering with AVQueuePlayer, explore alternatives when building a custom player in your app, and share best practices."}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10238","type":"reference","overridingTitle":"Watch Video (10 min)","isActive":true}},"sections":[],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10238-Tune-up-your-AirPlay-audio-experience","interfaceLanguage":"swift"},"schemaVersion":{"patch":0,"major":0,"minor":3},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"kind":"article","references":{"https://":{"title":"Blog","identifier":"https:\/\/","url":"https:\/\/","type":"link","titleInlineContent":[{"type":"text","text":"Blog"}]},"doc://WWDCNotes/documentation/WWDCNotes/RamitSharma991":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/RamitSharma991","title":"Ramit Sharma (15 notes)","url":"\/documentation\/wwdcnotes\/ramitsharma991","type":"topic","kind":"article","abstract":[{"type":"text","text":"Indie iOS Dev. Swift, SwiftUI, Obj-C, UX and related."}],"images":[{"type":"card","identifier":"RamitSharma991.jpeg"},{"type":"icon","identifier":"RamitSharma991.jpeg"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"url":"\/documentation\/wwdcnotes\/wwdc23","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","role":"collectionGroup","title":"WWDC23","type":"topic","abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"SwiftData"},{"type":"text","text":", "},{"type":"codeVoice","code":"Observation"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit"},{"type":"text","text":" views, and more."}],"images":[{"type":"icon","identifier":"WWDC23-Icon.png"},{"type":"card","identifier":"WWDC23.jpeg"}],"kind":"article"},"WWDC23.jpeg":{"type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23.jpeg"}],"identifier":"WWDC23.jpeg","alt":null},"RamitSharma991.jpeg":{"type":"image","identifier":"RamitSharma991.jpeg","variants":[{"url":"\/images\/WWDCNotes\/RamitSharma991.jpeg","traits":["1x","light"]}],"alt":null},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"title":"Contributions are welcome!","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems":{"type":"topic","abstract":[{"type":"text","text":"Discover how you can integrate CarPlay into modern vehicle systems. We’ll show you how to adjust CarPlay for any high-resolution display — regardless of configuration or size. Learn how you can use CarPlay-supplied metadata and video streams to show information on additional displays, and find out how advances in wireless connectivity, audio, and video encoding can help prepare your vehicle system for the next generation of CarPlay."}],"role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10150-optimize-carplay-for-vehicle-systems","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems","title":"Optimize CarPlay for vehicle systems"},"https://developer.apple.com/wwdc23/10238":{"type":"download","url":"https:\/\/developer.apple.com\/wwdc23\/10238","checksum":null,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10238"},"https://x.com/iosDev_ramit":{"type":"link","identifier":"https:\/\/x.com\/iosDev_ramit","title":"X\/Twitter","titleInlineContent":[{"type":"text","text":"X\/Twitter"}],"url":"https:\/\/x.com\/iosDev_ramit"},"https://github.com/RamitSharma991":{"type":"link","url":"https:\/\/github.com\/RamitSharma991","identifier":"https:\/\/github.com\/RamitSharma991","title":"GitHub","titleInlineContent":[{"text":"GitHub","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"url":"\/documentation\/wwdcnotes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","title":"WWDC Notes","type":"topic","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"kind":"symbol"},"WWDC23-Icon.png":{"alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-Icon.png"}],"identifier":"WWDC23-Icon.png","type":"image"},"WWDCNotes.png":{"type":"image","identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10104-Integrate-your-media-app-with-HomePod":{"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10104-Integrate-your-media-app-with-HomePod","url":"\/documentation\/wwdcnotes\/wwdc23-10104-integrate-your-media-app-with-homepod","abstract":[{"type":"text","text":"Learn how people can interact with your media app directly from HomePod. We’ll show you how to add a media intent to your iPhone or iPad app and help people stream your content to a HomePod speaker over AirPlay simply by using their voice. Explore implementation details and get tips and best practices on how to create a great experience for music, audiobooks, podcasts, meditations, or other media types."}],"kind":"article","title":"Integrate your media app with HomePod"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10275-Explore-AirPlay-with-interstitials":{"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10275-Explore-AirPlay-with-interstitials","url":"\/documentation\/wwdcnotes\/wwdc23-10275-explore-airplay-with-interstitials","abstract":[{"type":"text","text":"Learn how you can use HLS Interstitials with AirPlay to create seamless transitions for your video content between advertisements. We’ll share best practices and tips for creating a great experience when sharing content from Apple devices to popular smart TVs."}],"kind":"article","title":"Explore AirPlay with interstitials"},"RamitSharma991":{"type":"image","variants":[{"url":"\/images\/WWDCNotes\/RamitSharma991.jpeg","traits":["1x","light"]}],"identifier":"RamitSharma991","alt":"Profile image of Ramit Sharma"}}}