{"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC17"]]},"metadata":{"modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC17","role":"sampleCode","title":"SceneKit: What’s New"},"kind":"article","sections":[],"primaryContentSections":[{"content":[{"text":"Camera enhancements","anchor":"Camera-enhancements","level":2,"type":"heading"},{"inlineContent":[{"text":"Cameras follow objects with a smooth acceleration and deceleration. They also can adapt their behavior in different areas, such as moving up or down depending on the area, or remaining fixed in a certain orientation.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"SceneKit is transitioning to a physically based camera API. This API allows implementation of physically plausible depths of field, as well as motion blur and screen space ambient occlusion."}],"type":"paragraph"},{"text":"New API","anchor":"New-API","level":3,"type":"heading"},{"inlineContent":[{"text":"Rather than specifying ","type":"text"},{"code":"xFov","type":"codeVoice"},{"text":" and ","type":"text"},{"code":"yFov","type":"codeVoice"},{"text":" properties, now configure the ","type":"text"},{"code":"fieldOfView","type":"codeVoice"},{"text":" in degrees or specify the ","type":"text"},{"code":"focalLength","type":"codeVoice"},{"text":" and ","type":"text"},{"code":"sensorHeight","type":"codeVoice"},{"text":" of the camera (analogous to a physical camera).","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Setting ","type":"text"},{"type":"codeVoice","code":"fieldOfView"},{"text":" adjusts ","type":"text"},{"type":"codeVoice","code":"focalLength"},{"text":" and ","type":"text"},{"type":"codeVoice","code":"sensorHeight"},{"text":" and vice versa.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"You can also configure depth of field with ","type":"text"},{"code":"wantsDepthOfField","type":"codeVoice"},{"text":", ","type":"text"},{"code":"focusDistance","type":"codeVoice"},{"text":" and ","type":"text"},{"code":"fStop","type":"codeVoice"},{"text":".","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Depth of field also comes with automatic bokeh. Use of an HDR camera is recommended, done by setting "},{"code":"wantsHDR = true","type":"codeVoice"},{"type":"text","text":". Configure the bokeh with "},{"code":"apertureBladeCount","type":"codeVoice"},{"type":"text","text":"."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Set motion blur with "},{"type":"codeVoice","code":"motionBlurIntensity"},{"type":"text","text":". Works per object."}],"type":"paragraph"},{"inlineContent":[{"inlineContent":[{"type":"text","text":"Ambient occlusion"}],"type":"strong"},{"type":"text","text":" affects how light reflects off of objects with depth where not all parts of the surface get the same amount of light. You’ll see shading and shadows on the object. Set by the "},{"type":"codeVoice","code":"screenSpaceAmbientOcclusion..."},{"type":"text","text":" family of properties."}],"type":"paragraph"},{"text":"Camera control","anchor":"Camera-control","level":3,"type":"heading"},{"inlineContent":[{"type":"codeVoice","code":"SCNCameraController"},{"type":"text","text":" allows you to manipulate the camera. Usually accessed with "},{"type":"codeVoice","code":"SCNView.defaultCameraController"},{"type":"text","text":", but you can instantiate your own."}],"type":"paragraph"},{"inlineContent":[{"text":"Use an ","type":"text"},{"code":"SCNCameraController","type":"codeVoice"},{"text":" to allow users to manipulate the camera with tap gestures. There are different camera modes. Some focus on an object and allow rotation, others allow you to fly throughout the scene, and more.","type":"text"}],"type":"paragraph"},{"text":"Camera behavior","anchor":"Camera-behavior","level":4,"type":"heading"},{"inlineContent":[{"type":"text","text":"Use "},{"type":"codeVoice","code":"SCNConstraints"},{"type":"text","text":" to define camera behavior if you need something more complicated for certain games or apps. Some examples of constraints:"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"codeVoice","code":"SCNLookAtConstraint"},{"type":"text","text":" will keep focus on an object as it moves."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"codeVoice","code":"SCNReplicatorConstraint"},{"text":" replicates the behavior of an object. For example, the default camera behavior, it’ll follow the object.","type":"text"}]}]},{"content":[{"inlineContent":[{"code":"SCNDistanceConstraint","type":"codeVoice"},{"type":"text","text":" will keep you within a min\/max distance of an object."}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Tessellation and subdivision surfaces","anchor":"Tessellation-and-subdivision-surfaces","level":2,"type":"heading"},{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Tessellation","type":"text"}]},{"type":"text","text":" lets you provide the GPU with low-resolution models which then generates models in memory that are much higher detail. SceneKit does tessellation with "},{"type":"codeVoice","code":"SCNGeometryTessellator"},{"type":"text","text":"."}],"type":"paragraph"},{"text":"Shader modifiers","anchor":"Shader-modifiers","level":3,"type":"heading"},{"inlineContent":[{"type":"text","text":"Shader modifiers create custom effects during tessellation. You can use it to create waves in a body of water, for example."}],"type":"paragraph"},{"text":"Displacement mapping","anchor":"Displacement-mapping","level":3,"type":"heading"},{"inlineContent":[{"type":"text","text":"Modifies a surface."}],"type":"paragraph"},{"inlineContent":[{"text":"Height maps modify a surface with changes in the height of its vertexes. Imagine starting with a perfectly smooth surface representing land on an alien planet and then applying a height map to add hills and valleys.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Vector displacement maps are an extension of height maps that also let you modify vectors in all three dimensions. Create a 3D rock from a flat surface and add texture, for example","type":"text"}],"type":"paragraph"},{"text":"Subdivision surfaces","anchor":"Subdivision-surfaces","level":3,"type":"heading"},{"inlineContent":[{"text":"You can use SceneKit to start with a coarse model and refine it smoother. Like, a cube into a sphere. But not objects are uniformly smooth. Subdivision surfaces can create different angles of the surfaces in different parts of the model.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"This has been available in SceneKit but is now moving to the GPU for increased performance."}],"type":"paragraph"},{"inlineContent":[{"text":"Feature-adaptive subdivision is now supported. Using creases, you can make certain parts of a model smooth, and others more blocky.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Keep two things in mind if you’ll be using subdivision surfaces:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"When loading "},{"type":"codeVoice","code":"SCNScene"},{"type":"text","text":" from files, make sure to specify the "},{"type":"codeVoice","code":".preserveOriginalTopology: true"},{"type":"text","text":" option."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"When creating "},{"type":"codeVoice","code":"SCNGeometryElement"},{"type":"text","text":" objects programmatically, use the "},{"type":"codeVoice","code":".polygon"},{"type":"text","text":" primitive type. This is to use quads, not triangles."}]}]}],"type":"orderedList"},{"text":"Animation improvements","anchor":"Animation-improvements","level":2,"type":"heading"},{"inlineContent":[{"text":"New ","type":"text"},{"code":"SCNAnimation","type":"codeVoice"},{"text":" protocol and ","type":"text"},{"code":"SCNAnimationPlayer","type":"codeVoice"},{"text":" class that make it easy to start animations and mutate them live.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"You can blend animations together, too.","type":"text"}],"type":"paragraph"},{"text":"Developer tools","anchor":"Developer-tools","level":2,"type":"heading"},{"inlineContent":[{"text":"A new SceneKit Instrument helps with:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Understanding performance issues"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Recording a trace of SceneKit’s behavior","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Providing accurate per-frame performance analysis"}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"text":"SceneKit’s Scene Editor also has new features, including a new Shader Modifier Editor.","type":"text"}],"type":"paragraph"},{"text":"Related technologies","anchor":"Related-technologies","level":2,"type":"heading"},{"text":"ARKit","anchor":"ARKit","level":3,"type":"heading"},{"inlineContent":[{"type":"text","text":"Support for ARKit using "},{"type":"codeVoice","code":"ARSCNView"},{"type":"text","text":", a subclass of "},{"type":"codeVoice","code":"SCNView"},{"type":"text","text":". Very easy to set a texture or SceneView’s background to the output of an "},{"type":"codeVoice","code":"AVCaptureDevice"},{"type":"text","text":"."}],"type":"paragraph"},{"inlineContent":[{"text":"You can have objects in an AR scene cast shadows too.","type":"text"}],"type":"paragraph"},{"text":"GameplayKit","anchor":"GameplayKit","level":3,"type":"heading"},{"inlineContent":[{"text":"GameplayKit components can drive SceneKit objects.","type":"text"}],"type":"paragraph"},{"text":"Model I\/O","anchor":"Model-IO","level":3,"type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Improved support for USD","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Better material bridging"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Support for animations"}]}]}],"type":"unorderedList"},{"text":"UIFocus","anchor":"UIFocus","level":3,"type":"heading"},{"inlineContent":[{"type":"codeVoice","code":"SCNNode"},{"type":"text","text":" conforms to "},{"type":"codeVoice","code":"UIFocusItem"},{"type":"text","text":" to let you select and focus on objects on the Apple TV using your remote."}],"type":"paragraph"},{"text":"Rendering Additions","anchor":"Rendering-Additions","level":2,"type":"heading"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Support for point cloud rendering"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"New transparency modes"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Support for cascaded shadow maps"}]}]}],"type":"unorderedList"},{"text":"Written By","anchor":"Written-By","level":2,"type":"heading"},{"numberOfColumns":5,"columns":[{"content":[{"inlineContent":[{"type":"image","identifier":"thecodedself"}],"type":"paragraph"}],"size":1},{"content":[{"type":"heading","level":3,"text":"Keegan Rush","anchor":"Keegan-Rush"},{"type":"paragraph","inlineContent":[{"overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"isActive":true,"type":"reference","overridingTitle":"Contributed Notes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/thecodedself"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"isActive":true,"type":"reference","identifier":"https:\/\/github.com\/thecodedself"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"isActive":true,"type":"reference","identifier":"https:\/\/www.thecodedself.com"}]}],"size":4}],"type":"row"},{"type":"thematicBreak"},{"inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"isActive":true,"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference"}],"type":"paragraph"},{"text":"Related Sessions","anchor":"Related-Sessions","level":2,"type":"heading"},{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}],"type":"small"},{"inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2025 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}],"kind":"content"}],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc17-604-scenekit-whats-new"],"traits":[{"interfaceLanguage":"swift"}]}],"schemaVersion":{"patch":0,"minor":3,"major":0},"abstract":[{"text":"SceneKit is a fast and fully featured high-level 3D graphics framework that enables your apps and games to create immersive scenes and effects. See the latest advances in camera control and effects for simulating real camera optics including bokeh and motion blur. Learn about surface subdivision and tessellation to create smooth-looking surfaces right on the GPU starting from a coarser mesh. Check out new integration with ARKit and workflow improvements enabled by the Xcode Scene Editor.","type":"text"}],"sampleCodeDownload":{"action":{"identifier":"https:\/\/developer.apple.com\/wwdc17\/604","type":"reference","isActive":true,"overridingTitle":"Watch Video (53 min)"},"kind":"sampleDownload"},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC17-604-SceneKit-Whats-New"},"references":{"https://developer.apple.com/wwdc17/604":{"identifier":"https:\/\/developer.apple.com\/wwdc17\/604","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc17\/604","type":"download"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!"},"doc://WWDCNotes/documentation/WWDCNotes/thecodedself":{"abstract":[{"type":"text","text":"No Bio on GitHub"}],"kind":"article","type":"topic","images":[{"type":"card","identifier":"thecodedself.jpeg"},{"type":"icon","identifier":"thecodedself.jpeg"}],"title":"Keegan Rush (2 notes)","role":"sampleCode","url":"\/documentation\/wwdcnotes\/thecodedself","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/thecodedself"},"thecodedself.jpeg":{"identifier":"thecodedself.jpeg","alt":null,"variants":[{"url":"\/images\/WWDCNotes\/thecodedself.jpeg","traits":["1x","light"]}],"type":"image"},"WWDCNotes.png":{"alt":null,"type":"image","identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}]},"WWDC17.jpeg":{"type":"image","identifier":"WWDC17.jpeg","alt":null,"variants":[{"url":"\/images\/WWDCNotes\/WWDC17.jpeg","traits":["1x","light"]}]},"https://www.thecodedself.com":{"identifier":"https:\/\/www.thecodedself.com","url":"https:\/\/www.thecodedself.com","titleInlineContent":[{"type":"text","text":"Blog"}],"title":"Blog","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"type":"topic","title":"WWDC Notes","kind":"symbol","url":"\/documentation\/wwdcnotes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"role":"collection"},"WWDC17-Icon.png":{"alt":null,"type":"image","identifier":"WWDC17-Icon.png","variants":[{"url":"\/images\/WWDCNotes\/WWDC17-Icon.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC17":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC17","abstract":[{"type":"text","text":"Xcode 9, Swift 4.0, iOS 11, macOS 10.13 (High Sierra), tvOS 11, watchOS 4."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"Core NFC"},{"type":"text","text":" and more."}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc17","title":"WWDC17","type":"topic","role":"collectionGroup","images":[{"type":"icon","identifier":"WWDC17-Icon.png"},{"type":"card","identifier":"WWDC17.jpeg"}]},"thecodedself":{"type":"image","identifier":"thecodedself","alt":"Profile image of Keegan Rush","variants":[{"url":"\/images\/WWDCNotes\/thecodedself.jpeg","traits":["1x","light"]}]},"https://github.com/thecodedself":{"identifier":"https:\/\/github.com\/thecodedself","url":"https:\/\/github.com\/thecodedself","titleInlineContent":[{"type":"text","text":"GitHub"}],"title":"GitHub","type":"link"}}}