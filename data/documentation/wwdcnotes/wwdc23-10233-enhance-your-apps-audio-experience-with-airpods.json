{"kind":"article","sections":[],"schemaVersion":{"patch":0,"minor":3,"major":0},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"primaryContentSections":[{"kind":"content","content":[{"type":"heading","level":2,"text":"Chapters:","anchor":"Chapters"},{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10233?time=260","isActive":true,"type":"reference"},{"text":" AirPods Automatic Switching for macOS","type":"text"},{"text":"\n","type":"text"},{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10233?time=401","isActive":true,"type":"reference"},{"text":" Press to Mute and Unmute","type":"text"},{"text":"\n","type":"text"},{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10233?time=722","isActive":true,"type":"reference"},{"text":" Spatial Audio with AirPods","type":"text"}]},{"type":"heading","level":2,"text":"Intro","anchor":"Intro"},{"type":"paragraph","inlineContent":[{"text":"In this session, we will explore how you can enhance your app’s audio experience with AirPods. We will introduce you to some of the AirPods features we announced for iOS 17 and macOS 14.","type":"text"}]},{"type":"heading","level":2,"text":"One of the most common use cases","anchor":"One-of-the-most-common-use-cases"},{"type":"paragraph","inlineContent":[{"text":"You are enjoying music on AirPods in Personalized Spatial Audio with iPhone and receive a notification to join a work meeting. As you unlock your Mac to join the call, you are greeted by an AirPods Connected banner, letting you know that the AirPods are now ready and connected to the Mac.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10233-connected","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Next, as you join the meeting, audio will be played from Mac through your AirPods as you would expect, and the music you were listening to on iPhone pauses. In the middle of your work call, someone in office comes over to talk, or with remote work, someone rings your doorbell at home for a delivery."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Now, you can press the AirPods stem to mute yourself on the call, and when you do so, you will be notified by a friendly microphone status banner and an audio chime as well."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10233-off","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Then, as you would expect, you can press the AirPods stem again to unmute yourself and continue on with the meeting. And of course, you will see the banner and hear a chime on unmute."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10233-on"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Finally, you are finished with your work meeting and it’s time to unwind. You pick up your iPhone, press play on your favorite Apple Music playlist, and audio switches back to your AirPods from iPhone seamlessly, so you can continue on with your day without missing a beat."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"So do you want to unlock the magical AirPods experience for your application and people with AirPods be able to use your app with a breeze across platforms? In this session, we will go through how you can optimize your app to take advantage of these features and deliver exactly that."}]},{"type":"heading","level":2,"text":"AirPods automatic switching for macOS.","anchor":"AirPods-automatic-switching-for-macOS"},{"items":[{"content":[{"inlineContent":[{"text":"Automatically switch your macOS audio to AirPods based on the audio activity","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Uses indicators like “Now Playing” registration and input audio activity"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Automatic participation for Apps without sandbox restrictions or those using App Sandbox"}],"type":"paragraph"}]}],"type":"unorderedList"},{"type":"paragraph","inlineContent":[{"text":"macOS 14 supports AirPods automatic switching, between devices based on the user’s intended activity. Automatic switching algorithm uses indicators like “Now Playing” registration and input audio activity to make those decisions. The good news is that all App Store apps, as well as apps outside the App Store which uses App Sandbox or opt not to have a sandbox, do not have to do anything to adopt it. They will be able to fully participate in this feature without any change needed from the developer.","type":"text"},{"text":"\n","type":"text"},{"text":"Now, let’s talk through best practices for an optimal AirPods experience for people with these feature. With registering for Now Playing on macOS, the automatic routing algorithm can now know when a long-form audio is playing, for example, and allows us to make the right routing decisions.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"If your app is a media or streaming app, we recommend you register for Now Playing to help us prioritize your audio accordingly."},{"type":"text","text":"\n"},{"type":"text","text":"If you are a conference or a gaming app, we do not recommend registering for Now Playing."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We also recommend using Audio Services API to play notifications and app-specific chimes.  This would help differentiate notifications from media contents and avoid unexpected behaviors."},{"type":"text","text":"\n"},{"type":"text","text":"If you are a conferencing app, we recommend using input mic only when conference or voice session starts and keep it open only for the duration of the live meeting or voice session."},{"type":"text","text":"\n"},{"type":"text","text":"For media apps, we recommend you use the default route selected by the user to play audio."},{"type":"text","text":"\n"},{"type":"text","text":"Also, avoid playing silence after the user pauses audio. If you have to play silence, we would recommend to keep it less than two seconds."}]},{"type":"heading","level":2,"text":"Press to Mute and Unmute with AirPods","anchor":"Press-to-Mute-and-Unmute-with-AirPods"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"(New!) Gesture on AirPods to control application’s mic"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"CallKit based apps will automatically get support"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"(New!) API for communication apps not using CallKit"}],"type":"paragraph"}]}],"type":"unorderedList"},{"type":"paragraph","inlineContent":[{"type":"text","text":"With iOS 17 and macOS 14, People can now mute or unmute an application’s mic during calls by simply pressing AirPods stem. Starting in iOS 17, all CallKit apps will get Press to Mute and Unmute support with absolutely no additional adoption necessary."},{"type":"text","text":"\n"},{"type":"text","text":"For communications app not using CallKit, we have introduced new API that I will detail shortly. In all cases, iOS 17 will respond to the mute gesture by muting the uplink audio, playing a tone… And notifying the application that it has been muted. Then, when someone triggers the same gesture again, iOS 17 will unmute the uplink audio, play the tone… And notify the application that it has been unmuted."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10233-onOff","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This features adds significant convenience for people. Let me show you how quickly you can add it on iOS17."}]},{"type":"heading","level":3,"text":"introducing AVAudioApplication","anchor":"introducing-AVAudioApplication"},{"type":"paragraph","inlineContent":[{"type":"text","text":"AVAudioApplication is a new sibling in the AVAudioSession family."},{"type":"text","text":"\n"},{"type":"text","text":"It is a way to configure application-wide audio behaviors for your app."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let me show you how quickly you can incorporate Press to Mute and Unmute using AVAudioApplication. First, we need to import AVFAudio. Next, get the shared instance of AVAudioApplication. Then we will need to register for mute gesture change notifications with Notification Center. This opts your application into Press to Mute and Unmute."},{"type":"text","text":"\n"},{"type":"text","text":"These notifications will inform you when your mute state has changed by a mute gesture. From there, you introspect the AVAudioApplication input muteStateKey of the user info to determine the new state."},{"type":"text","text":"\n"},{"type":"text","text":"After receiving this notification, you can update any internal state and UI as a result of this notification firing. Additionally, it is necessary that AVAudioApplication is updated when someone takes a mute action within your application."},{"type":"text","text":" "},{"type":"text","text":"As you would expect, we provide both setters and getters."}]},{"code":["\/\/ Adopting AVAudioApplication into your App","import AVFAudio","","\/\/ Get the started instance ","let instance = AVAudioApplication.shared","","\/\/ Register for mute gesture notifications on Notification Center ","AVAudioApplication.inputMuteStateChangeNotification","","\/\/ Key for mute state","AVAudioApplication.muteStateKey","","\/\/ Updating AVAudioApplication’s mute state","instance.setInputMuted(...)","","\/\/ Reading AVAudioApplication’s mute state","instance.isInputMuted"],"type":"codeListing","syntax":"swift"},{"type":"paragraph","inlineContent":[{"text":"It is that simple to incorporate, Press to Mute and Unmute into your app on iOS 17 Moving over to the Mac.","type":"text"},{"text":"\n","type":"text"},{"text":"It is important to note that in macOS 14, Press to Mute and Unmute works a little bit differently. Just like iOS, your app will be notified when the mute state changes. However, on macOS, your application is responsible for muting any uplink audio when a gesture has been performed.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"There is some additional API required to opt in, which I will detail in a moment."}]},{"type":"paragraph","inlineContent":[{"text":"Lastly, do note, for applications looking to detect muted talkers, please refer to “What’s new in voice processing APIs” session for details on new API to support that.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let’s take a look at what adoption is needed on the Mac. Remember, on macOS 14, it is your application’s responsibility to mute uplink audio as a result of a mute gesture."}]},{"type":"paragraph","inlineContent":[{"text":"On the shared instance of AVAudioApplication, you will need to set a Mute State Change handler. This handler will be called when someone performs a mute gesture. Here, you mute any uplink audio and update any internal state. It also gives you an opportunity to reject if the mute action is not appropriate for your application’s current usage. It is recommended that this handler should not be used for UI updates, since you will continue to receive Input Mute State Change notification when mute state changes. In addition, we have provided a new property within the CoreAudio framework to help you quickly mute any input audio to your process.","type":"text"}]},{"code":["\/\/ Configure the Input Mute State Change handler (macOS only)","instance.setInputMuteStateChangeHandler { isMuted in","    \/\/...","    return didSucceed","}","","\/\/ Optional: let CoreAudio mute your input for you (macOS only)","\/\/ Define the Core Audio property","var inputeMutePropertyAddress = AudioObjectPropertyAddress(","    mSelector: kAudioHardwarePropertyProcessInputMute,","    mScope: kAudioObjectPropertyScopeInput,","    mElement:kAudioObjectPropertyElementMain)","","\/\/ Enable this property when you want to mute your input","UInt32 isMuted = 1; \/\/ 1 = muted, 0 = unmuted","AudioObjectSetPropertyData(kAudioObjectSystemObject,","                           &inputeMutePropertyAddress,","                           0,","                           nil,","                           UInt32(MemoryLayout.size(ofValue: isMuted),","                           &isMuted)"],"type":"codeListing","syntax":"swift"},{"type":"paragraph","inlineContent":[{"type":"text","text":"This property, when enabled, will silence any input audio to your process while continuing to perform IO as usual."}]},{"type":"heading","level":2,"text":"Spatial Audio with AirPods","anchor":"Spatial-Audio-with-AirPods"},{"type":"paragraph","inlineContent":[{"type":"text","text":"With the launch of iOS 16, we took this to the next level with Personalized Spatial Audio, because the way we all perceive sound is unique, based on the size and shape of our head and ears. And this push towards increased personalization has been well-received by people. With macOS 14, iOS 17 and tvOS 17, we are glad to announce continued Spatial Audio support for all three platforms."}]},{"type":"paragraph","inlineContent":[{"text":"For macOS, we support Spatial Audio for AVPlayer as well as AVSampleBufferAudioRenderer API. iOS and tvOS support Spatial Audio for AURemoteIO as well as AudioQueue API along with the above mentioned APIs.","type":"text"}]},{"type":"heading","level":2,"text":"Spatial Audio API support","anchor":"Spatial-Audio-API-support"},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10233-spatialAudio"}]},{"type":"paragraph","inlineContent":[{"text":"Do note that Spatial Audio for AudioQueue and AURemoteIO does not have an API interface. Instead, it is automatically enabled for apps that register for Now Playing.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This would present the user with an option to configure the feature via the Control Center."}]},{"type":"heading","level":2,"text":"Wrap Up","anchor":"Wrap-Up"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Transform your app behavior for AirPods Automatic Switching"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Press to Mute and Unmute and associated API","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Spatial Audio across platforms","type":"text"}]}]}],"type":"unorderedList"},{"type":"heading","level":1,"text":"Check out also","anchor":"Check-out-also"},{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10265\/","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc19\/501\/","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/documentation\/mediaplayer\/becoming_a_now_playable_app","isActive":true}]},{"type":"heading","level":2,"text":"Written By","anchor":"Written-By"},{"type":"row","columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"multitudes"}]}]},{"size":4,"content":[{"type":"heading","level":3,"anchor":"laurent-b","text":"laurent b"},{"type":"paragraph","inlineContent":[{"isActive":true,"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","overridingTitle":"Contributed Notes","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}]},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"isActive":true,"type":"reference","identifier":"https:\/\/github.com\/multitudes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"isActive":true,"type":"reference","identifier":"https:\/\/laurentbrusa.hashnode.dev\/"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"isActive":true,"type":"reference","identifier":"https:\/\/x.com\/wrmultitudes"}]}]}],"numberOfColumns":5},{"type":"thematicBreak"},{"type":"paragraph","inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}]},{"type":"heading","level":2,"text":"Related Sessions","anchor":"Related-Sessions"},{"style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10235-Whats-new-in-voice-processing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10265-Immerse-your-app-in-Spatial-Audio"],"type":"links"},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"type":"small","inlineContent":[{"text":"All content copyright © 2012 – 2025 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}]}]}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods","interfaceLanguage":"swift"},"metadata":{"title":"Enhance your app’s audio experience with AirPods","roleHeading":"WWDC23","role":"sampleCode","modules":[{"name":"WWDC Notes"}]},"abstract":[{"type":"text","text":"Discover how you can create transformative audio experiences in your app using AirPods. Learn how to incorporate AirPods Automatic Switching, use AVAudioApplication to support Mute Control, and take advantage of Spatial Audio to create immersive soundscapes in your app or game."}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"type":"reference","overridingTitle":"Watch Video (14 min)","identifier":"https:\/\/developer.apple.com\/wwdc23\/10233"}},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10233-enhance-your-apps-audio-experience-with-airpods"],"traits":[{"interfaceLanguage":"swift"}]}],"references":{"doc://WWDCNotes/documentation/WWDCNotes/multitudes":{"abstract":[{"type":"text","text":"student at 42Berlin 🐬 | C & C++ | 🍎 Swift(UI) app dev  | speciality coffee ☕️ & cycling 🚴🏻‍♂️"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","url":"\/documentation\/wwdcnotes\/multitudes","type":"topic","kind":"article","title":"laurent b (33 notes)","images":[{"identifier":"multitudes.jpeg","type":"card"},{"identifier":"multitudes.jpeg","type":"icon"}]},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","title":"Contributions are welcome!","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"WWDC23-Icon.png":{"alt":null,"identifier":"WWDC23-Icon.png","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-Icon.png"}],"type":"image"},"WWDC23-10233-connected":{"identifier":"WWDC23-10233-connected","type":"image","alt":"connected banner","variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10233-connected.jpg","traits":["1x","light"]}]},"multitudes.jpeg":{"type":"image","alt":null,"identifier":"multitudes.jpeg","variants":[{"url":"\/images\/WWDCNotes\/multitudes.jpeg","traits":["1x","light"]}]},"https://developer.apple.com/wwdc23/10233":{"url":"https:\/\/developer.apple.com\/wwdc23\/10233","identifier":"https:\/\/developer.apple.com\/wwdc23\/10233","checksum":null,"type":"download"},"https://developer.apple.com/wwdc23/10233?time=401":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10233?time=401","type":"link","titleInlineContent":[{"text":"06:41","type":"text"}],"title":"06:41","url":"https:\/\/developer.apple.com\/wwdc23\/10233?time=401"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"type":"topic","role":"collectionGroup","images":[{"identifier":"WWDC23-Icon.png","type":"icon"},{"identifier":"WWDC23.jpeg","type":"card"}],"abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"SwiftData","type":"codeVoice"},{"type":"text","text":", "},{"code":"Observation","type":"codeVoice"},{"type":"text","text":", "},{"code":"StoreKit","type":"codeVoice"},{"type":"text","text":" views, and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23","title":"WWDC23"},"https://developer.apple.com/wwdc23/10233?time=722":{"titleInlineContent":[{"type":"text","text":"12:02"}],"identifier":"https:\/\/developer.apple.com\/wwdc23\/10233?time=722","title":"12:02","url":"https:\/\/developer.apple.com\/wwdc23\/10233?time=722","type":"link"},"https://laurentbrusa.hashnode.dev/":{"titleInlineContent":[{"type":"text","text":"Blog"}],"url":"https:\/\/laurentbrusa.hashnode.dev\/","type":"link","title":"Blog","identifier":"https:\/\/laurentbrusa.hashnode.dev\/"},"https://developer.apple.com/videos/play/wwdc2021/10265/":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10265\/","type":"link","titleInlineContent":[{"text":"Immerse your app in Spatial Audio - WWDC21","type":"text"}],"title":"Immerse your app in Spatial Audio - WWDC21","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10265\/"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10235-Whats-new-in-voice-processing":{"role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10235-whats-new-in-voice-processing","type":"topic","title":"What’s new in voice processing","abstract":[{"text":"Learn how to use the Apple voice processing APIs to achieve the best possible audio experience in your VoIP apps. We’ll show you how to detect when someone is talking while muted, adjust ducking behavior of other audio, and more.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10235-Whats-new-in-voice-processing"},"WWDC23.jpeg":{"alt":null,"identifier":"WWDC23.jpeg","variants":[{"url":"\/images\/WWDCNotes\/WWDC23.jpeg","traits":["1x","light"]}],"type":"image"},"WWDC23-10233-on":{"type":"image","alt":"unmuted banner","identifier":"WWDC23-10233-on","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10233-on.jpg"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"kind":"symbol","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"url":"\/documentation\/wwdcnotes","role":"collection"},"WWDC23-10233-spatialAudio":{"identifier":"WWDC23-10233-spatialAudio","type":"image","alt":"Spatial Audio Support","variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10233-spatialAudio.jpg","traits":["1x","light"]}]},"https://developer.apple.com/wwdc23/10233?time=260":{"titleInlineContent":[{"type":"text","text":"04:20"}],"identifier":"https:\/\/developer.apple.com\/wwdc23\/10233?time=260","title":"04:20","url":"https:\/\/developer.apple.com\/wwdc23\/10233?time=260","type":"link"},"https://developer.apple.com/videos/play/wwdc19/501/":{"titleInlineContent":[{"type":"text","text":"Reaching the Big Screen with AirPlay 2. - WWDC19"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc19\/501\/","type":"link","title":"Reaching the Big Screen with AirPlay 2. - WWDC19","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc19\/501\/"},"https://x.com/wrmultitudes":{"identifier":"https:\/\/x.com\/wrmultitudes","type":"link","titleInlineContent":[{"text":"X\/Twitter","type":"text"}],"title":"X\/Twitter","url":"https:\/\/x.com\/wrmultitudes"},"WWDC23-10233-onOff":{"alt":"unmuted - muted banner","identifier":"WWDC23-10233-onOff","variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10233-onOff.jpg","traits":["1x","light"]}],"type":"image"},"https://github.com/multitudes":{"titleInlineContent":[{"type":"text","text":"GitHub"}],"url":"https:\/\/github.com\/multitudes","type":"link","title":"GitHub","identifier":"https:\/\/github.com\/multitudes"},"https://developer.apple.com/documentation/mediaplayer/becoming_a_now_playable_app":{"identifier":"https:\/\/developer.apple.com\/documentation\/mediaplayer\/becoming_a_now_playable_app","type":"link","titleInlineContent":[{"text":"Becoming a now playable app (Sample Code) -  WWDC19","type":"text"}],"title":"Becoming a now playable app (Sample Code) -  WWDC19","url":"https:\/\/developer.apple.com\/documentation\/mediaplayer\/becoming_a_now_playable_app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10265-Immerse-your-app-in-Spatial-Audio":{"role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10265-Immerse-your-app-in-Spatial-Audio","abstract":[{"text":"Discover how spatial audio can help you provide a theater-like experience for media in your apps and on the web. We’ll show you how you can easily bring immersive audio to those listening with compatible hardware, and how to automatically deliver different listening experiences depending on someone’s bandwidth or connection — all with little to no change to your code. And gain recommendations on how you can tailor the experience in your app and use spatial audio to tell stories in new, exciting ways.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc21-10265-immerse-your-app-in-spatial-audio","type":"topic","title":"Immerse your app in Spatial Audio"},"WWDCNotes.png":{"alt":null,"identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"type":"image"},"WWDC23-10233-off":{"type":"image","alt":"muted banner","identifier":"WWDC23-10233-off","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10233-off.jpg"}]},"multitudes":{"identifier":"multitudes","type":"image","alt":"Profile image of laurent b","variants":[{"url":"\/images\/WWDCNotes\/multitudes.jpeg","traits":["1x","light"]}]}}}