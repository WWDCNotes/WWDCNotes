{"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-10042-explore-natural-language-multilingual-models"]}],"metadata":{"modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC23","role":"sampleCode","title":"Explore Natural Language multilingual models"},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"Learn how to create custom Natural Language models for text classification and word tagging using multilingual, transformer-based embeddings. We’ll show you how to train with less data and support up to 27 different languages across three scripts. Find out how to use these embeddings to fine-tune complex models trained in PyTorch and TensorFlow."}],"schemaVersion":{"minor":3,"major":0,"patch":0},"sampleCodeDownload":{"action":{"isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10042","type":"reference","overridingTitle":"Watch Video (14 min)"},"kind":"sampleDownload"},"topicSections":[{"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10657-Make-apps-smarter-with-Natural-Language","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-232-Advances-in-Natural-Language-Framework"],"discussion":{"content":[{"text":"Discussion","anchor":"discussion","level":2,"type":"heading"},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10042-advancedApplications3"}]},{"type":"paragraph","inlineContent":[{"text":"Here are some examples of output from the model. If I pass in some English text, for example, “A path through a garden full of pink flowers,” the model leads us down a path into a garden full of pink flowers.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10042-advancedApplications4","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"But also, if I translate the same sentence into French, Spanish, Italian, and German, the model produces images of paths and gardens full of pink flowers for each one."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10042-advancedApplications5"}]},{"type":"paragraph","inlineContent":[{"text":"Let me take a slightly more complicated example. “A road in front of trees and mountains under a cloudy sky.” Here’s some output from the model, with road, trees, mountains, and clouds. But likewise, I can translate the same sentence into French, Spanish, Italian, and German, or any of a number of other languages, and for each one get an image of road, trees, mountains, and clouds.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10042-advancedApplications6","type":"image"}]},{"text":"Wrap Up","anchor":"Wrap-Up","level":2,"type":"heading"}],"kind":"content"},"abstract":[{"type":"text","text":"Now, to give you just a taste of what’s possible with this, we prepared a simple example model. We started with an existing English-language Stable Diffusion model, then used some multilingual data to fine-tune it to use the new BERT embeddings as an input layer, taking those as fixed, and also training a simple linear projection layer to convert dimensionalities. The result then is a Stable Diffusion model that takes multilingual input."}],"title":"Adapting a model"}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"],["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML"]]},"sections":[],"kind":"article","references":{"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"type":"topic","kind":"symbol","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"title":"WWDC Notes","role":"collection","url":"\/documentation\/wwdcnotes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10657-Make-apps-smarter-with-Natural-Language":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10657-Make-apps-smarter-with-Natural-Language","kind":"article","abstract":[{"type":"text","text":"Explore how you can leverage the Natural Language framework to better analyze and understand text. Learn how to draw meaning from text using the framework’s built-in word and sentence embeddings, and how to create your own custom embeddings for specific needs."}],"url":"\/documentation\/wwdcnotes\/wwdc20-10657-make-apps-smarter-with-natural-language","title":"Make apps smarter with Natural Language","type":"topic","role":"sampleCode"},"WWDC23-10042-advancedApplications5":{"variants":[{"url":"\/images\/WWDC23-10042-advancedApplications5.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10042-advancedApplications5","type":"image","alt":"Advanced Applications"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","url":"\/documentation\/wwdcnotes\/wwdc23-10044-discover-machine-learning-enhancements-in-create-ml","title":"Discover machine learning enhancements in Create ML","kind":"article","role":"sampleCode","abstract":[{"type":"text","text":"Find out how Create ML can help you do even more with machine learning models. Learn about the latest updates to image understanding and text-based tasks with multilingual BERT embeddings. Discover how easy it is to train models that can understand the content of images using multi-label classification. We’ll also share information about interactive model evaluation and the latest APIs for custom training data augmentations."}],"type":"topic"},"WWDC23.jpeg":{"variants":[{"url":"\/images\/WWDC23.jpeg","traits":["1x","light"]}],"identifier":"WWDC23.jpeg","type":"image","alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-232-Advances-in-Natural-Language-Framework":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-232-Advances-in-Natural-Language-Framework","abstract":[{"type":"text","text":"Natural Language is a framework designed to provide high-performance, on-device APIs for natural language processing tasks across all Apple platforms. Learn about the addition of Sentiment Analysis and Text Catalog support in the framework. Gain a deeper understanding of transfer learning for text-based models and the new support for Word Embeddings which can power great search experiences in your app."}],"type":"topic","title":"Advances in Natural Language Framework","url":"\/documentation\/wwdcnotes\/wwdc19-232-advances-in-natural-language-framework","role":"sampleCode","kind":"article"},"WWDC23-10042-advancedApplications3":{"variants":[{"url":"\/images\/WWDC23-10042-advancedApplications3.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10042-advancedApplications3","type":"image","alt":"Advanced Applications"},"WWDC23-10042-advancedApplications4":{"variants":[{"url":"\/images\/WWDC23-10042-advancedApplications4.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10042-advancedApplications4","type":"image","alt":"Advanced Applications"},"WWDCNotes.png":{"variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"identifier":"WWDCNotes.png","type":"image","alt":null},"WWDC23-10042-advancedApplications6":{"variants":[{"url":"\/images\/WWDC23-10042-advancedApplications6.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10042-advancedApplications6","type":"image","alt":"Advanced Applications"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"kind":"article","images":[{"identifier":"WWDC23-Icon.png","type":"icon"},{"identifier":"WWDC23.jpeg","type":"card"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","role":"collectionGroup","abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"SwiftData"},{"type":"text","text":", "},{"type":"codeVoice","code":"Observation"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit"},{"type":"text","text":" views, and more."}],"type":"topic","title":"WWDC23","url":"\/documentation\/wwdcnotes\/wwdc23"},"WWDC23-Icon.png":{"variants":[{"url":"\/images\/WWDC23-Icon.png","traits":["1x","light"]}],"identifier":"WWDC23-Icon.png","type":"image","alt":null},"https://developer.apple.com/wwdc23/10042":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10042","type":"download","url":"https:\/\/developer.apple.com\/wwdc23\/10042","checksum":null}}}