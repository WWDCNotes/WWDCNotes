{"sections":[],"topicSections":[{"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10657-Make-apps-smarter-with-Natural-Language","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-232-Advances-in-Natural-Language-Framework"],"title":"Adapting a model","abstract":[{"type":"text","text":"Now, to give you just a taste of what’s possible with this, we prepared a simple example model. We started with an existing English-language Stable Diffusion model, then used some multilingual data to fine-tune it to use the new BERT embeddings as an input layer, taking those as fixed, and also training a simple linear projection layer to convert dimensionalities. The result then is a Stable Diffusion model that takes multilingual input."}],"anchor":"Adapting-a-model","discussion":{"kind":"content","content":[{"anchor":"discussion","type":"heading","text":"Discussion","level":2},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10042-advancedApplications3","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Here are some examples of output from the model. If I pass in some English text, for example, “A path through a garden full of pink flowers,” the model leads us down a path into a garden full of pink flowers.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10042-advancedApplications4"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"But also, if I translate the same sentence into French, Spanish, Italian, and German, the model produces images of paths and gardens full of pink flowers for each one."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10042-advancedApplications5","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let me take a slightly more complicated example. “A road in front of trees and mountains under a cloudy sky.” Here’s some output from the model, with road, trees, mountains, and clouds. But likewise, I can translate the same sentence into French, Spanish, Italian, and German, or any of a number of other languages, and for each one get an image of road, trees, mountains, and clouds."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10042-advancedApplications6"}]},{"anchor":"Wrap-Up","type":"heading","text":"Wrap Up","level":2}]}}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"],["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML"]]},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-10042-explore-natural-language-multilingual-models"]}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (14 min)","type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc23\/10042","isActive":true}},"kind":"article","metadata":{"roleHeading":"WWDC23","title":"Explore Natural Language multilingual models","role":"sampleCode","modules":[{"name":"WWDC Notes"}]},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"Learn how to create custom Natural Language models for text classification and word tagging using multilingual, transformer-based embeddings. We’ll show you how to train with less data and support up to 27 different languages across three scripts. Find out how to use these embeddings to fine-tune complex models trained in PyTorch and TensorFlow."}],"schemaVersion":{"major":0,"patch":0,"minor":3},"references":{"https://developer.apple.com/wwdc23/10042":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10042","url":"https:\/\/developer.apple.com\/wwdc23\/10042","checksum":null,"type":"download"},"WWDC23-10042-advancedApplications3":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10042-advancedApplications3.jpg","traits":["1x","light"]}],"type":"image","identifier":"WWDC23-10042-advancedApplications3","alt":"Advanced Applications"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-232-Advances-in-Natural-Language-Framework":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-232-Advances-in-Natural-Language-Framework","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-232-advances-in-natural-language-framework","title":"Advances in Natural Language Framework","type":"topic","abstract":[{"text":"Natural Language is a framework designed to provide high-performance, on-device APIs for natural language processing tasks across all Apple platforms. Learn about the addition of Sentiment Analysis and Text Catalog support in the framework. Gain a deeper understanding of transfer learning for text-based models and the new support for Word Embeddings which can power great search experiences in your app.","type":"text"}]},"WWDC23-10042-advancedApplications4":{"identifier":"WWDC23-10042-advancedApplications4","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23-10042-advancedApplications4.jpg"}],"alt":"Advanced Applications","type":"image"},"WWDC23-Icon.png":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC23-Icon.png","traits":["1x","light"]}],"identifier":"WWDC23-Icon.png","alt":null,"type":"image"},"WWDC23-10042-advancedApplications6":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10042-advancedApplications6.jpg","traits":["1x","light"]}],"type":"image","identifier":"WWDC23-10042-advancedApplications6","alt":"Advanced Applications"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10657-Make-apps-smarter-with-Natural-Language":{"title":"Make apps smarter with Natural Language","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10657-Make-apps-smarter-with-Natural-Language","role":"sampleCode","type":"topic","abstract":[{"text":"Explore how you can leverage the Natural Language framework to better analyze and understand text. Learn how to draw meaning from text using the framework’s built-in word and sentence embeddings, and how to create your own custom embeddings for specific needs.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc20-10657-make-apps-smarter-with-natural-language","kind":"article"},"WWDCNotes.png":{"variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"type":"image","identifier":"WWDCNotes.png","alt":null},"doc://WWDCNotes/documentation/WWDCNotes":{"type":"topic","url":"\/documentation\/wwdcnotes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"role":"collection","kind":"symbol","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","abstract":[{"text":"Find out how Create ML can help you do even more with machine learning models. Learn about the latest updates to image understanding and text-based tasks with multilingual BERT embeddings. Discover how easy it is to train models that can understand the content of images using multi-label classification. We’ll also share information about interactive model evaluation and the latest APIs for custom training data augmentations.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10044-discover-machine-learning-enhancements-in-create-ml","title":"Discover machine learning enhancements in Create ML","kind":"article","type":"topic"},"WWDC23.jpeg":{"identifier":"WWDC23.jpeg","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC23.jpeg"}],"alt":null,"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"title":"WWDC23","type":"topic","role":"collectionGroup","url":"\/documentation\/wwdcnotes\/wwdc23","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","images":[{"type":"icon","identifier":"WWDC23-Icon.png"},{"type":"card","identifier":"WWDC23.jpeg"}],"abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"SwiftData"},{"type":"text","text":", "},{"type":"codeVoice","code":"Observation"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit"},{"type":"text","text":" views, and more."}],"kind":"article"},"WWDC23-10042-advancedApplications5":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10042-advancedApplications5.jpg","traits":["1x","light"]}],"identifier":"WWDC23-10042-advancedApplications5","alt":"Advanced Applications","type":"image"}}}