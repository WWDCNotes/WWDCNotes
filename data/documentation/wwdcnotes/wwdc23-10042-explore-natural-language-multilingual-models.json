{"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10042-explore-natural-language-multilingual-models"],"traits":[{"interfaceLanguage":"swift"}]}],"topicSections":[{"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10657-Make-apps-smarter-with-Natural-Language","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-232-Advances-in-Natural-Language-Framework"],"discussion":{"kind":"content","content":[{"type":"heading","text":"Discussion","level":2,"anchor":"discussion"},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10042-advancedApplications3"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Here are some examples of output from the model. If I pass in some English text, for example, “A path through a garden full of pink flowers,” the model leads us down a path into a garden full of pink flowers."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10042-advancedApplications4"}]},{"type":"paragraph","inlineContent":[{"text":"But also, if I translate the same sentence into French, Spanish, Italian, and German, the model produces images of paths and gardens full of pink flowers for each one.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC23-10042-advancedApplications5","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Let me take a slightly more complicated example. “A road in front of trees and mountains under a cloudy sky.” Here’s some output from the model, with road, trees, mountains, and clouds. But likewise, I can translate the same sentence into French, Spanish, Italian, and German, or any of a number of other languages, and for each one get an image of road, trees, mountains, and clouds.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC23-10042-advancedApplications6"}]},{"type":"heading","text":"Wrap Up","level":2,"anchor":"Wrap-Up"}]},"title":"Adapting a model","abstract":[{"text":"Now, to give you just a taste of what’s possible with this, we prepared a simple example model. We started with an existing English-language Stable Diffusion model, then used some multilingual data to fine-tune it to use the new BERT embeddings as an input layer, taking those as fixed, and also training a simple linear projection layer to convert dimensionalities. The result then is a Stable Diffusion model that takes multilingual input.","type":"text"}]}],"schemaVersion":{"patch":0,"minor":3,"major":0},"kind":"article","sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"],["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML"]]},"metadata":{"title":"Explore Natural Language multilingual models","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC23","role":"sampleCode"},"abstract":[{"text":"Learn how to create custom Natural Language models for text classification and word tagging using multilingual, transformer-based embeddings. We’ll show you how to train with less data and support up to 27 different languages across three scripts. Find out how to use these embeddings to fine-tune complex models trained in PyTorch and TensorFlow.","type":"text"}],"sampleCodeDownload":{"action":{"type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc23\/10042","overridingTitle":"Watch Video (14 min)","isActive":true},"kind":"sampleDownload"},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models"},"references":{"WWDC23-10042-advancedApplications6":{"identifier":"WWDC23-10042-advancedApplications6","type":"image","alt":"Advanced Applications","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10042-advancedApplications6.jpg"}]},"WWDC23-10042-advancedApplications3":{"identifier":"WWDC23-10042-advancedApplications3","type":"image","alt":"Advanced Applications","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10042-advancedApplications3.jpg"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-232-Advances-in-Natural-Language-Framework":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-232-Advances-in-Natural-Language-Framework","type":"topic","role":"sampleCode","abstract":[{"text":"Natural Language is a framework designed to provide high-performance, on-device APIs for natural language processing tasks across all Apple platforms. Learn about the addition of Sentiment Analysis and Text Catalog support in the framework. Gain a deeper understanding of transfer learning for text-based models and the new support for Word Embeddings which can power great search experiences in your app.","type":"text"}],"title":"Advances in Natural Language Framework","url":"\/documentation\/wwdcnotes\/wwdc19-232-advances-in-natural-language-framework"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML":{"type":"topic","kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","url":"\/documentation\/wwdcnotes\/wwdc23-10044-discover-machine-learning-enhancements-in-create-ml","title":"Discover machine learning enhancements in Create ML","abstract":[{"type":"text","text":"Find out how Create ML can help you do even more with machine learning models. Learn about the latest updates to image understanding and text-based tasks with multilingual BERT embeddings. Discover how easy it is to train models that can understand the content of images using multi-label classification. We’ll also share information about interactive model evaluation and the latest APIs for custom training data augmentations."}]},"WWDC23.jpeg":{"identifier":"WWDC23.jpeg","type":"image","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23.jpeg"}]},"WWDC23-Icon.png":{"identifier":"WWDC23-Icon.png","type":"image","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-Icon.png"}]},"WWDC23-10042-advancedApplications5":{"identifier":"WWDC23-10042-advancedApplications5","type":"image","alt":"Advanced Applications","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10042-advancedApplications5.jpg"}]},"WWDC23-10042-advancedApplications4":{"identifier":"WWDC23-10042-advancedApplications4","type":"image","alt":"Advanced Applications","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10042-advancedApplications4.jpg"}]},"https://developer.apple.com/wwdc23/10042":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10042","type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc23\/10042"},"WWDCNotes.png":{"identifier":"WWDCNotes.png","type":"image","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes","kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"title":"WWDC Notes","role":"collection"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10657-Make-apps-smarter-with-Natural-Language":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10657-Make-apps-smarter-with-Natural-Language","url":"\/documentation\/wwdcnotes\/wwdc20-10657-make-apps-smarter-with-natural-language","kind":"article","title":"Make apps smarter with Natural Language","type":"topic","role":"sampleCode","abstract":[{"type":"text","text":"Explore how you can leverage the Natural Language framework to better analyze and understand text. Learn how to draw meaning from text using the framework’s built-in word and sentence embeddings, and how to create your own custom embeddings for specific needs."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"images":[{"type":"icon","identifier":"WWDC23-Icon.png"},{"type":"card","identifier":"WWDC23.jpeg"}],"role":"collectionGroup","url":"\/documentation\/wwdcnotes\/wwdc23","type":"topic","title":"WWDC23","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","kind":"article","abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"SwiftData","type":"codeVoice"},{"text":", ","type":"text"},{"code":"Observation","type":"codeVoice"},{"text":", ","type":"text"},{"code":"StoreKit","type":"codeVoice"},{"type":"text","text":" views, and more."}]}}}