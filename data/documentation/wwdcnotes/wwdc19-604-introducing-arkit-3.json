{"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc19-604-introducing-arkit-3"]}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-604-Introducing-ARKit-3","interfaceLanguage":"swift"},"sampleCodeDownload":{"kind":"sampleDownload","action":{"type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc19\/604","isActive":true,"overridingTitle":"Watch Video (51 min)"}},"metadata":{"role":"sampleCode","title":"Introducing ARKit 3","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC19"},"schemaVersion":{"patch":0,"minor":3,"major":0},"kind":"article","abstract":[{"text":"ARKit is the groundbreaking augmented reality (AR) platform for iOS that can transform how people connect with the world around them. Explore the state-of-the-art capabilities of ARKit 3 and discover the innovative foundation it provides for RealityKit. Learn how ARKit makes AR even more immersive through understanding of body position and movement for motion capture and people occlusion. Check out additions for multiple face tracking, collaborative session building, a coaching UI for on-boarding, and much more.","type":"text"}],"primaryContentSections":[{"kind":"content","content":[{"level":2,"anchor":"New-Features-in-ARKit-3","text":"New Features in ARKit 3","type":"heading"},{"items":[{"content":[{"inlineContent":[{"text":"Visual Coherence","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Positional Tracking","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Simultaneous Front and Back Camera"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Record and Replay of Sequences"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"More Robust 3D Object Detection","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Multiple-face Tracking","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"HDR Environment Textures","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Faster Reference Image Loading"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Motion Capture","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Detect up to 100 Images","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Face Tracking Enhancements","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"People Occlusion","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Raycasting","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Collaborative Session","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"ML Based Plane Detection"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"New Plane Classes"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"RealityKit Integration","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"AR QuickLook Additions"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Auto-detect Image Size"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"AR Coaching UI","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"level":2,"anchor":"Whats-New","text":"What’s New","type":"heading"},{"level":3,"anchor":"People-Occlusion","text":"People Occlusion","type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Available on A12 and later","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Two ways:"}],"type":"paragraph"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"people fragmentation (AR experience will always be occluded by people, regardless of the distance of AR objects and people)","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"people fragmentation + depth (ARKit estimate the people distance and occluded objects\/people based on that)","type":"text"}],"type":"paragraph"}]}]}]}],"type":"unorderedList"},{"level":3,"anchor":"Motion-Capture","text":"Motion Capture","type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Tracks Human Body"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Two ways: 2D and 3D"}],"type":"paragraph"}]}],"type":"unorderedList"},{"level":3,"anchor":"Collaborative-Session","text":"Collaborative Session","type":"heading"},{"items":[{"content":[{"inlineContent":[{"text":"Multiple devices can be used to merge POI together and create a big AR world","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Uses the ","type":"text"},{"identifier":"https:\/\/developer.apple.com\/documentation\/multipeerconnectivity","type":"reference","isActive":true},{"text":" framework for sharing AR World data or other wireless way to do so.","type":"text"}]}]}],"type":"unorderedList"},{"level":3,"anchor":"AR-Coaching-UI","text":"AR Coaching UI","type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"To be used when telling the user to move the phone in the horizontal\/vertical plane to start the AR experience","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Automatically hides\/updates itself based on the AR state","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"level":3,"anchor":"New-Plane-Classes","text":"New Plane Classes","type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Wall floor ceiling table seat door window (last two are new)","type":"text"}]}]}],"type":"unorderedList"},{"level":3,"anchor":"Visual-Coherence","text":"Visual Coherence","type":"heading"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Motion blur"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Bokeh"}]}]}],"type":"unorderedList"},{"level":2,"anchor":"Written-By","text":"Written By","type":"heading"},{"columns":[{"content":[{"type":"paragraph","inlineContent":[{"identifier":"zntfdr","type":"image"}]}],"size":1},{"content":[{"type":"heading","text":"Federico Zanetello","level":3,"anchor":"Federico-Zanetello"},{"type":"paragraph","inlineContent":[{"overridingTitle":"Contributed Notes","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"isActive":true,"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"isActive":true,"identifier":"https:\/\/github.com\/zntfdr","type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"isActive":true,"identifier":"https:\/\/zntfdr.dev","type":"reference"}]}],"size":4}],"numberOfColumns":5,"type":"row"},{"type":"thematicBreak"},{"inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true}],"type":"paragraph"},{"level":2,"anchor":"Related-Sessions","text":"Related Sessions","type":"heading"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10611-Explore-ARKit-4","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-103-Platforms-State-of-the-Union","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-603-Introducing-RealityKit-and-Reality-Composer","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-605-Building-Apps-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-607-Bringing-People-into-AR","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-610-Building-Collaborative-AR-Experiences"],"style":"list","type":"links"},{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}],"type":"small"},{"inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}]}],"sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19"]]},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC19":{"title":"WWDC19","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19","role":"collectionGroup","images":[{"type":"icon","identifier":"WWDC19-Icon.png"},{"type":"card","identifier":"WWDC19.jpeg"}],"abstract":[{"type":"text","text":"Xcode 11, Swift 5.1, iOS 13, macOS 10.15 (Catalina), tvOS 13, watchOS 6."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"Combine","type":"codeVoice"},{"type":"text","text":", "},{"code":"Core Haptics","type":"codeVoice"},{"type":"text","text":", "},{"type":"codeVoice","code":"Create ML"},{"type":"text","text":", and more."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19"},"https://zntfdr.dev":{"identifier":"https:\/\/zntfdr.dev","title":"Blog","titleInlineContent":[{"type":"text","text":"Blog"}],"url":"https:\/\/zntfdr.dev","type":"link"},"zntfdr.jpeg":{"alt":null,"type":"image","identifier":"zntfdr.jpeg","variants":[{"url":"\/images\/WWDCNotes\/zntfdr.jpeg","traits":["1x","light"]}]},"WWDC19-Icon.png":{"type":"image","alt":null,"variants":[{"url":"\/images\/WWDCNotes\/WWDC19-Icon.png","traits":["1x","light"]}],"identifier":"WWDC19-Icon.png"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link"},"https://developer.apple.com/wwdc19/604":{"url":"https:\/\/developer.apple.com\/wwdc19\/604","type":"download","identifier":"https:\/\/developer.apple.com\/wwdc19\/604","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-607-Bringing-People-into-AR":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-607-bringing-people-into-ar","title":"Bringing People into AR","abstract":[{"type":"text","text":"ARKit 3 enables a revolutionary capability for robust integration of real people into AR scenes. Learn how apps can use live motion capture to animate virtual characters or be applied to 2D and 3D simulation. See how People Occlusion enables even more immersive AR experiences by enabling virtual content to pass behind people in the real world."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-607-Bringing-People-into-AR","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-605-Building-Apps-with-RealityKit":{"role":"sampleCode","abstract":[{"text":"Gain a practical understanding of RealityKit capabilities by developing a game using its easy-to-learn API. Learn the recommended approach for loading assets, building a scene, applying animations, and handling game input. See how entities and components express the powerful elements of RealityKit while providing flexibility for customization. Find out how to take advantage of built-in networking and get details about extending the game into an immersive muliti-player experience.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc19-605-building-apps-with-realitykit","kind":"article","title":"Building Apps with RealityKit","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-605-Building-Apps-with-RealityKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10611-Explore-ARKit-4":{"type":"topic","kind":"article","title":"Explore ARKit 4","abstract":[{"type":"text","text":"ARKit 4 enables you to build the next generation of augmented reality apps to transform how people connect with the world around them. We’ll walk you through the latest improvements to Apple’s augmented reality platform, including how to use Location Anchors to connect virtual objects with a real-world longitude, latitude, and altitude. Discover how to harness the LiDAR Scanner on iPad Pro and obtain a depth map of your environment. And learn how to track faces in AR on more devices, including the iPad Air (3rd generation), iPad mini (5th generation), and all devices with the A12 Bionic chip or later that have a front-facing camera."}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10611-Explore-ARKit-4","url":"\/documentation\/wwdcnotes\/wwdc20-10611-explore-arkit-4"},"https://github.com/zntfdr":{"type":"link","url":"https:\/\/github.com\/zntfdr","identifier":"https:\/\/github.com\/zntfdr","titleInlineContent":[{"type":"text","text":"GitHub"}],"title":"GitHub"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-610-Building-Collaborative-AR-Experiences":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-610-Building-Collaborative-AR-Experiences","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-610-building-collaborative-ar-experiences","kind":"article","title":"Building Collaborative AR Experiences","type":"topic","abstract":[{"type":"text","text":"With iOS 13, ARKit and RealityKit enable apps to establish shared AR experiences faster and easier than ever. Understand how collaborative sessions allow multiple devices to build a combined world map and share AR anchors and updates in real-time. Learn how to incorporate collaborative sessions into ARKit-based apps, then roll into SwiftStrike, an engaging and immersive multiplayer AR game built using RealityKit and Swift."}]},"https://developer.apple.com/documentation/multipeerconnectivity":{"url":"https:\/\/developer.apple.com\/documentation\/multipeerconnectivity","type":"link","identifier":"https:\/\/developer.apple.com\/documentation\/multipeerconnectivity","title":"MultipeerConnectivity","titleInlineContent":[{"text":"MultipeerConnectivity","type":"text"}]},"WWDC19.jpeg":{"identifier":"WWDC19.jpeg","variants":[{"url":"\/images\/WWDCNotes\/WWDC19.jpeg","traits":["1x","light"]}],"alt":null,"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","url":"\/documentation\/wwdcnotes","type":"topic","title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}]},"zntfdr":{"type":"image","alt":"Profile image of Federico Zanetello","variants":[{"url":"\/images\/WWDCNotes\/zntfdr.jpeg","traits":["1x","light"]}],"identifier":"zntfdr"},"WWDCNotes.png":{"alt":null,"type":"image","identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-103-Platforms-State-of-the-Union":{"type":"topic","role":"sampleCode","title":"Platforms State of the Union","abstract":[{"text":"WWDC 2019 Platforms State of the Union","type":"text"}],"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19-103-platforms-state-of-the-union","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-103-Platforms-State-of-the-Union"},"doc://WWDCNotes/documentation/WWDCNotes/zntfdr":{"title":"Federico Zanetello (332 notes)","kind":"article","url":"\/documentation\/wwdcnotes\/zntfdr","role":"sampleCode","images":[{"type":"card","identifier":"zntfdr.jpeg"},{"type":"icon","identifier":"zntfdr.jpeg"}],"abstract":[{"type":"text","text":"Software engineer with a strong passion for well-written code, thought-out composable architectures, automation, tests, and more."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-603-Introducing-RealityKit-and-Reality-Composer":{"type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-603-introducing-realitykit-and-reality-composer","title":"Introducing RealityKit and Reality Composer","abstract":[{"text":"Architected for AR, RealityKit provides developers access to world-class capabilities for rendering, animation, physics, and spatial audio. See how RealityKit reimagines the traditional 3D engine to make AR development faster and easier for developers than ever before. Understand the building blocks of developing RealityKit based apps and games, and learn about prototyping and producing content for AR experiences with Reality Composer.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-603-Introducing-RealityKit-and-Reality-Composer","kind":"article"}}}