{"sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20"]]},"kind":"article","primaryContentSections":[{"kind":"content","content":[{"text":"Overview","type":"heading","level":2,"anchor":"overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true}]},{"text":"Related Sessions","type":"heading","level":2,"anchor":"Related-Sessions"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10041-Extract-document-data-using-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10099-Explore-the-Action-and-Vision-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10653-Detect-Body-and-Hand-Pose-with-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-222-Understanding-Images-in-Vision-Framework","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-234-Text-Recognition-in-Vision-Framework"],"type":"links","style":"list"},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright ¬© 2012 ‚Äì 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}]}],"schemaVersion":{"minor":3,"major":0,"patch":0},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10673-Explore-Computer-Vision-APIs","interfaceLanguage":"swift"},"metadata":{"roleHeading":"WWDC20","modules":[{"name":"WWDC Notes"}],"title":"Explore Computer Vision APIs","role":"sampleCode"},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc20-10673-explore-computer-vision-apis"],"traits":[{"interfaceLanguage":"swift"}]}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"type":"reference","overridingTitle":"Watch Video (24 min)","identifier":"https:\/\/developer.apple.com\/wwdc20\/10673","isActive":true}},"abstract":[{"text":"Learn how to bring Computer Vision intelligence to your app when you combine the power of Core Image, Vision, and Core ML. Go beyond machine learning alone and gain a deeper understanding of images and video. Discover new APIs in Core Image and Vision to bring Computer Vision to your application like new thresholding filters as well as Contour Detection and Optical Flow. And consider ways to use Core Image for preprocessing and visualization of these results.","type":"text"}],"references":{"doc://WWDCNotes/documentation/WWDCNotes":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","type":"topic","url":"\/documentation\/wwdcnotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"kind":"symbol","title":"WWDC Notes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}]},"https://developer.apple.com/wwdc20/10673":{"checksum":null,"url":"https:\/\/developer.apple.com\/wwdc20\/10673","type":"download","identifier":"https:\/\/developer.apple.com\/wwdc20\/10673"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-234-Text-Recognition-in-Vision-Framework":{"title":"Text Recognition in Vision Framework","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-234-Text-Recognition-in-Vision-Framework","url":"\/documentation\/wwdcnotes\/wwdc19-234-text-recognition-in-vision-framework","kind":"article","abstract":[{"text":"Document Camera and Text Recognition features in Vision Framework enable you to extract text data from images. Learn how to leverage this built-in machine learning technology in your app. Gain a deeper understanding of the differences between fast versus accurate processing as well as character-based versus language-based recognition.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-222-Understanding-Images-in-Vision-Framework":{"title":"Understanding Images in Vision Framework","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-222-Understanding-Images-in-Vision-Framework","type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19-222-understanding-images-in-vision-framework","abstract":[{"type":"text","text":"Learn all about the many advances in the Vision Framework including effortless image classification, image saliency, determining image similarity, and improvements in facial feature detection, and face capture quality scoring. This packed session will show you how easy it is to bring powerful computer vision techniques to your apps."}],"role":"sampleCode"},"WWDCNotes.png":{"type":"image","identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10099-Explore-the-Action-and-Vision-app":{"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc20-10099-explore-the-action-and-vision-app","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10099-Explore-the-Action-and-Vision-app","abstract":[{"type":"text","text":"It‚Äôs now easy to create an app for fitness or sports coaching that takes advantage of machine learning¬†‚Äî¬†and to prove it, we built our own. Learn how we designed the Action & Vision app using Object Detection and Action Classification in Create ML along with the new Body Pose Estimation, Trajectory Detection, and Contour Detection features in the Vision framework. Explore how you can create an immersive application for gameplay or training from setup to analysis and feedback. And follow along in Xcode with a full sample project."}],"role":"sampleCode","title":"Explore the Action & Vision app"},"WWDC20-Icon.png":{"type":"image","identifier":"WWDC20-Icon.png","variants":[{"url":"\/images\/WWDC20-Icon.png","traits":["1x","light"]}],"alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10041-Extract-document-data-using-Vision":{"kind":"article","abstract":[{"text":"Discover how Vision can provide expert image recognition and analysis in your app to extract information from documents, recognize text in multiple languages, and identify barcodes. We‚Äôll explore the latest updates to Text Recognition and Barcode Detection, show you how to bring all these tools together with Core ML, and help your app make greater sense of the world through images or the live camera.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc21-10041-extract-document-data-using-vision","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10041-Extract-document-data-using-Vision","title":"Extract document data using Vision","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10653-Detect-Body-and-Hand-Pose-with-Vision":{"title":"Detect Body and Hand Pose with Vision","kind":"article","abstract":[{"type":"text","text":"Explore how the Vision framework can help your app detect body and hand poses in photos and video. With pose detection, your app can analyze the poses, movements, and gestures of people to offer new video editing possibilities, or to perform action classification when paired with an action classifier built in Create ML. And we‚Äôll show you how you can bring gesture recognition into your app through hand pose, delivering a whole new form of interaction."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10653-Detect-Body-and-Hand-Pose-with-Vision","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc20-10653-detect-body-and-hand-pose-with-vision","role":"sampleCode"},"WWDC20.jpeg":{"type":"image","identifier":"WWDC20.jpeg","variants":[{"url":"\/images\/WWDC20.jpeg","traits":["1x","light"]}],"alt":null},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"title":"Learn More‚Ä¶","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20":{"url":"\/documentation\/wwdcnotes\/wwdc20","title":"WWDC20","images":[{"type":"icon","identifier":"WWDC20-Icon.png"},{"type":"card","identifier":"WWDC20.jpeg"}],"abstract":[{"text":"Xcode 12, Swift 5.3, iOS 14, macOS 11 (Big Sur), tvOS 14, watchOS 7.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"type":"codeVoice","code":"WidgetKit"},{"text":", ","type":"text"},{"type":"codeVoice","code":"StoreKit Testing"},{"text":", and more.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20","kind":"article","type":"topic","role":"collectionGroup"}}}