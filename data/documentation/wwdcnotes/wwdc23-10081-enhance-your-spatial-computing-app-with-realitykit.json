{"kind":"article","schemaVersion":{"major":0,"minor":3,"patch":0},"metadata":{"roleHeading":"WWDC23","role":"sampleCode","title":"Enhance your spatial computing app with RealityKit","modules":[{"name":"WWDC Notes"}]},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit"},"primaryContentSections":[{"kind":"content","content":[{"level":2,"text":"Overview","type":"heading","anchor":"overview"},{"inlineContent":[{"type":"text","text":"Speakers: Yujin Ariza, RealityKit Engineer"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Refresher:"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"inlineContent":[{"text":"Entities","type":"text"}],"type":"strong"},{"text":" are container objects.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"text":"Components","type":"text"}]},{"type":"text","text":" define specific behavior on entities."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Systems"}]},{"type":"text","text":" act on both entities and components to add functionality."}]}]},{"content":[{"inlineContent":[{"inlineContent":[{"text":"RealityView","type":"text"}],"type":"strong"},{"text":" is an API that acts as a bridge between SwiftUI and RealityKit","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"level":2,"text":"How to embed SwiftUI views into RealityKit content using attachments in RealityView 02:05","type":"heading","anchor":"How-to-embed-SwiftUI-views-into-RealityKit-content-using-attachments-in-RealityView-0205"},{"style":"note","type":"aside","name":"Note","content":[{"inlineContent":[{"text":"Attachments are a useful way to embed SwiftUI content into your RealityKit scene.","type":"text"}],"type":"paragraph"}]},{"inlineContent":[{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081?time=147"},{"type":"text","text":"."}],"type":"paragraph"},{"inlineContent":[{"inlineContent":[{"text":"2 parts to settings up attachments","type":"text"}],"type":"strong"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Add the parameter in the make closure of your RealityView"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Include the attachments view builder to your RealityView","type":"text"}],"type":"paragraph"}]}],"type":"orderedList"},{"inlineContent":[{"text":"The ","type":"text"},{"type":"strong","inlineContent":[{"type":"text","text":"attachments view builder"}]},{"text":" is where you can provide SwiftUI views that you want to add to your RealityKit content. You can then tag those views and call them as entities ","type":"text"},{"type":"strong","inlineContent":[{"text":"inside your make closure","type":"text"}]},{"text":" using the call ","type":"text"},{"code":"entity(for:)","type":"codeVoice"},{"text":".","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"How to use multiple attachments inside of a make closure "},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081?time=272","type":"reference","isActive":true}]}]}],"type":"unorderedList"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10081-attachments"}],"type":"paragraph"},{"inlineContent":[{"text":"You can also update entities inside of the update closure whenever there are changes to SwiftUI view state.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10081-attachments-update"}],"type":"paragraph"},{"level":2,"text":"How to add Video Playback in RealityKit scenes 06:17","type":"heading","anchor":"How-to-add-Video-Playback-in-RealityKit-scenes-0617"},{"inlineContent":[{"type":"codeVoice","code":"VideoPlayerComponent"},{"text":" is a new component type in RealityKit used for embedding video content inside a 3D scene.","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"type":"text","text":"Reminder: components define behavior that you attach to entities"}],"type":"emphasis"},{"text":".","type":"text"}]}]}],"type":"unorderedList"},{"inlineContent":[{"inlineContent":[{"type":"text","text":"To play a video using "},{"type":"codeVoice","code":"VideoPlayerComponent"}],"type":"strong"},{"text":":","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Load a video file from resources bundle"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Create an ","type":"text"},{"code":"AVPlayer","type":"codeVoice"},{"text":" instance","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Create a "},{"type":"codeVoice","code":"VideoPlayerComponent"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Attach component to an entity","type":"text"}]}]}],"type":"orderedList"},{"inlineContent":[{"identifier":"WWDC23-10081-videoplayercomponent","type":"image"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Since RealityKit is a 3D framework, video is represented as an entity with a mesh so that you can move and position it in 3D space.","type":"text"}]}]},{"content":[{"inlineContent":[{"code":"VideoPlayerComponent","type":"codeVoice"},{"text":" also supports ","type":"text"},{"inlineContent":[{"type":"text","text":"Passthrough Tinting"}],"type":"strong"},{"text":" by setting the ","type":"text"},{"code":"isPassthroughTintingEnabled","type":"codeVoice"},{"text":" property to true.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"You can also subscribe to "},{"type":"codeVoice","code":"VideoPlayerEvents"},{"type":"text","text":" by calling the subscribe function inside RealityViews content, and specifying the event type and entity "},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081?time=639","isActive":true},{"type":"text","text":"."}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"type":"text","text":"Learn more about video content including 3D videos in "},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10071"},{"type":"text","text":"."}],"type":"paragraph"},{"level":2,"text":"How to use Portals 11:06","type":"heading","anchor":"How-to-use-Portals-1106"},{"inlineContent":[{"inlineContent":[{"text":"Portals","type":"text"}],"type":"strong"},{"text":" create openings to other worlds that are visible through mesh surfaces. Entities inside of these worlds use separate lighting, and are masked by portal geometry.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"To make a portal, you must first create a ","type":"text"},{"inlineContent":[{"type":"text","text":"World"}],"type":"strong"},{"text":". You doing this by adding a ","type":"text"},{"code":"World","type":"codeVoice"},{"text":" component to an entity. Add content to the world by attaching entities as children of the world entity.","type":"text"},{"text":" ","type":"text"},{"inlineContent":[{"text":"Note: entities in a world are only visible through a portal surface","type":"text"}],"type":"emphasis"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Once you have your World entity, you create a mesh with a portal material, then add a portal component targeted to the world entity. "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081\/?time=791"},{"type":"text","text":"."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10081-portals"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"text":"Basically there’s a separate component called ","type":"text"},{"code":"World","type":"codeVoice"},{"text":" which is what you use in portals and I think is the only way to render portals","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Lighting is unique and can learn more in another session","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Show schematics for how Portals are built","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Link example he creates","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"level":2,"text":"How to use the Particle Emitters API 15:04","type":"heading","anchor":"How-to-use-the-Particle-Emitters-API-1504"},{"inlineContent":[{"type":"codeVoice","code":"ParticleEmitterComponent"},{"type":"text","text":" provided in RealityKit can be created either Reality Composer Pro or via RealityKit at runtime."}],"type":"paragraph"},{"style":"note","type":"aside","name":"Note","content":[{"type":"paragraph","inlineContent":[{"type":"emphasis","inlineContent":[{"text":"The ParticleEmitterComponent contains many properties that control various aspects of particle look and behavior.","type":"text"}]}]}]},{"inlineContent":[{"type":"text","text":"Code walkthrough of building a particle system "},{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081\/?time=949"},{"type":"text","text":"."}],"type":"paragraph"},{"level":2,"text":"How to use Anchors in RealityKit 17:10","type":"heading","anchor":"How-to-use-Anchors-in-RealityKit-1710"},{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Anchors","type":"text"}]},{"type":"text","text":" in RealityKit can be used to place content on surfaces, such as walls, floors, or locations relative to head and hands."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Anchors support 2 tracking modes:"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"code":".continuous","type":"codeVoice"}]}]}],"type":"orderedList"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"anchor entity moves along with the anchor over time, such as when your head moves."}],"type":"paragraph"}]}],"type":"unorderedList"},{"start":2,"items":[{"content":[{"inlineContent":[{"code":".once","type":"codeVoice"}],"type":"paragraph"}]}],"type":"orderedList"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"anchor entity will not move after being positioned once."}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"type":"text","text":"You can listen to when an entity becomes anchored by subscribing to the "},{"type":"codeVoice","code":"AnchoredStateChanged"},{"type":"text","text":" event in RealityKit."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Anchor transforms are "},{"inlineContent":[{"type":"text","text":"not"}],"type":"strong"},{"type":"text","text":" accessible to the app. In order to get access to anchor transforms, you will need to use ARKit."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Code walkthrough of setting an anchor in your app "},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081\/?time=1098","isActive":true},{"type":"text","text":"."}],"type":"paragraph"},{"level":2,"text":"Written By","type":"heading","anchor":"Written-By"},{"numberOfColumns":5,"columns":[{"size":1,"content":[{"inlineContent":[{"identifier":"stevenpaulhoward","type":"image"}],"type":"paragraph"}]},{"size":4,"content":[{"level":3,"anchor":"stevenpaulhoward","text":"stevenpaulhoward","type":"heading"},{"inlineContent":[{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/stevenpaulhoward","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"isActive":true,"type":"reference","overridingTitle":"Contributed Notes"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/github.com\/stevenpaulhoward","isActive":true,"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/x.com\/stevnhoward","isActive":true,"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/","isActive":true,"type":"reference"}],"type":"paragraph"}]}],"type":"row"},{"type":"thematicBreak"},{"inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}],"type":"paragraph"},{"level":2,"text":"Related Sessions","type":"heading","anchor":"Related-Sessions"},{"style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10095-Explore-rendering-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode"],"type":"links"},{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}],"type":"small"},{"inlineContent":[{"text":"All content copyright © 2012 – 2025 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}],"type":"small"}]}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"abstract":[{"text":"Go beyond the window and learn how you can bring engaging and immersive 3D content to your apps with RealityKit. Discover how SwiftUI scenes work in tandem with RealityView and how you can embed your content into an entity hierarchy. We’ll also explore how you can blend virtual content and the real world using anchors, bring particle effects into your apps, add video content, and create more immersive experiences with portals.","type":"text"}],"sampleCodeDownload":{"action":{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10081","overridingTitle":"Watch Video (20 min)"},"kind":"sampleDownload"},"sections":[],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-10081-enhance-your-spatial-computing-app-with-realitykit"]}],"references":{"https://developer.apple.com/videos/play/wwdc2023/10081/?time=1098":{"titleInlineContent":[{"text":"18:18","type":"text"}],"type":"link","title":"18:18","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081\/?time=1098","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081\/?time=1098"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10083-Meet-Reality-Composer-Pro":{"type":"topic","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","abstract":[{"type":"text","text":"Discover how to easily compose, edit, and preview 3D content with Reality Composer Pro. Follow along as we explore this developer tool by setting up a new project, composing scenes, adding particle emitters and audio, and even previewing content on device."}],"title":"Meet Reality Composer Pro","url":"\/documentation\/wwdcnotes\/wwdc23-10083-meet-reality-composer-pro"},"WWDC23-10081-portals":{"identifier":"WWDC23-10081-portals","variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10081-portals.png","traits":["1x","light"]}],"alt":"Schematic of portals.","type":"image"},"stevenpaulhoward":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/stevenpaulhoward.jpeg"}],"alt":"Profile image of stevenpaulhoward","identifier":"stevenpaulhoward","type":"image"},"WWDC23-Icon.png":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC23-Icon.png","traits":["1x","light"]}],"type":"image","alt":null,"identifier":"WWDC23-Icon.png"},"WWDC23-10081-attachments":{"identifier":"WWDC23-10081-attachments","variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10081-attachments.png","traits":["1x","light"]}],"alt":"Structure of attachments.","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode":{"title":"Work with Reality Composer Pro content in Xcode","abstract":[{"text":"Learn how to bring content from Reality Composer Pro to life in Xcode. We’ll show you how to load 3D scenes into Xcode, integrate your content with your code, and add interactivity to your app. We’ll also share best practices and tips for using these tools together in your development workflow.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10273-work-with-reality-composer-pro-content-in-xcode","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"kind":"article","abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"SwiftData"},{"type":"text","text":", "},{"type":"codeVoice","code":"Observation"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit"},{"type":"text","text":" views, and more."}],"title":"WWDC23","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23","role":"collectionGroup","images":[{"identifier":"WWDC23-Icon.png","type":"icon"},{"identifier":"WWDC23.jpeg","type":"card"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"},"https://developer.apple.com/videos/play/wwdc2023/10081?time=272":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081?time=272","title":"04:32","titleInlineContent":[{"text":"04:32","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081?time=272","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10082-Meet-ARKit-for-spatial-computing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","kind":"article","type":"topic","title":"Meet ARKit for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-10082-meet-arkit-for-spatial-computing","role":"sampleCode","abstract":[{"type":"text","text":"Discover how you can use ARKit’s tracking and scene understanding features to develop a whole new universe of immersive apps and games. Learn how visionOS and ARKit work together to help you create apps that understand a person’s surroundings — all while preserving privacy. Explore the latest updates to the ARKit API and follow along as we demonstrate how to take advantage of hand tracking and scene geometry in your apps."}]},"WWDC23.jpeg":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC23.jpeg","traits":["1x","light"]}],"type":"image","alt":null,"identifier":"WWDC23.jpeg"},"stevenpaulhoward.jpeg":{"identifier":"stevenpaulhoward.jpeg","variants":[{"url":"\/images\/WWDCNotes\/stevenpaulhoward.jpeg","traits":["1x","light"]}],"alt":null,"type":"image"},"https://developer.apple.com/wwdc23/10081":{"url":"https:\/\/developer.apple.com\/wwdc23\/10081","identifier":"https:\/\/developer.apple.com\/wwdc23\/10081","type":"download","checksum":null},"https://developer.apple.com/videos/play/wwdc2023/10081/?time=791":{"titleInlineContent":[{"text":"Example code walkthrough here","type":"text"}],"type":"link","title":"Example code walkthrough here","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081\/?time=791","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081\/?time=791"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"type":"topic","title":"Build spatial experiences with RealityKit","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","abstract":[{"type":"text","text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio."}],"role":"sampleCode"},"WWDC23-10081-videoplayercomponent":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10081-videoplayercomponent.png","traits":["1x","light"]}],"alt":"Video Player Component Flow.","identifier":"WWDC23-10081-videoplayercomponent","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","role":"collection","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes","kind":"symbol","images":[{"identifier":"WWDCNotes.png","type":"icon"}]},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"link"},"https://developer.apple.com/videos/play/wwdc2023/10081/?time=949":{"titleInlineContent":[{"text":"15:49","type":"text"}],"type":"link","title":"15:49","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081\/?time=949","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081\/?time=949"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10113-Take-SwiftUI-to-the-next-dimension":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","type":"topic","abstract":[{"text":"Get ready to add depth and dimension to your visionOS apps. Find out how to bring three-dimensional objects to your app using volumes, get to know the Model 3D API, and learn how to position and animate content. We’ll also show you how to use UI attachments in RealityView and support gestures in your content.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10113-take-swiftui-to-the-next-dimension","role":"sampleCode","title":"Take SwiftUI to the next dimension"},"WWDC23-10081-attachments-update":{"variants":[{"url":"\/images\/WWDCNotes\/WWDC23-10081-attachments-update.png","traits":["1x","light"]}],"alt":"Attachments with update closure.","identifier":"WWDC23-10081-attachments-update","type":"image"},"https://developer.apple.com/videos/play/wwdc2023/10081?time=639":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081?time=639","titleInlineContent":[{"text":"10:39","type":"text"}],"title":"10:39","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081?time=639","type":"link"},"https://developer.apple.com/videos/play/wwdc2023/10071":{"titleInlineContent":[{"text":"Deliver video content for spatial experiences","type":"text"}],"type":"link","title":"Deliver video content for spatial experiences","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10071","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10071"},"WWDCNotes.png":{"variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"alt":null,"identifier":"WWDCNotes.png","type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/stevenpaulhoward":{"url":"\/documentation\/wwdcnotes\/stevenpaulhoward","title":"stevenpaulhoward (4 notes)","abstract":[{"text":"3D connoisseur","type":"text"}],"images":[{"identifier":"stevenpaulhoward.jpeg","type":"card"},{"identifier":"stevenpaulhoward.jpeg","type":"icon"}],"kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/stevenpaulhoward","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10095-Explore-rendering-for-spatial-computing":{"url":"\/documentation\/wwdcnotes\/wwdc23-10095-explore-rendering-for-spatial-computing","abstract":[{"text":"Find out how you can take control of RealityKit rendering to improve the look and feel of your apps and games on visionOS. Discover how you can customize lighting, add grounding shadows, and control tone mapping for your content. We’ll also go over best practices for two key treatments on the platform: rasterization rate maps and dynamic content scaling.","type":"text"}],"title":"Explore rendering for spatial computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10095-Explore-rendering-for-spatial-computing","role":"sampleCode","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10071-Deliver-video-content-for-spatial-experiences":{"abstract":[{"text":"Learn how to prepare and deliver video content for visionOS using HTTP Live Streaming (HLS). Discover the current HLS delivery process for media and explore how you can expand your delivery pipeline to support 3D content. Get up to speed with tips and techniques for spatial media streaming and adapting your existing caption production workflows for 3D. And find out how to share audio tracks across video variants and add spatial audio to make your video content more immersive.","type":"text"}],"type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences","title":"Deliver video content for spatial experiences","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10071-deliver-video-content-for-spatial-experiences"},"https://github.com/stevenpaulhoward":{"titleInlineContent":[{"text":"GitHub","type":"text"}],"type":"link","title":"GitHub","url":"https:\/\/github.com\/stevenpaulhoward","identifier":"https:\/\/github.com\/stevenpaulhoward"},"https://":{"url":"https:\/\/","title":"Blog","titleInlineContent":[{"text":"Blog","type":"text"}],"identifier":"https:\/\/","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10111-Go-beyond-the-window-with-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","kind":"article","type":"topic","title":"Go beyond the window with SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10111-go-beyond-the-window-with-swiftui","role":"sampleCode","abstract":[{"text":"Get ready to launch into space — a new SwiftUI scene type that can help you make great immersive experiences for visionOS. We’ll show you how to create a new scene with ImmersiveSpace, place 3D content, and integrate RealityView. Explore how you can use the immersionStyle scene modifier to increase the level of immersion in an app and learn best practices for managing spaces, adding virtual hands with ARKit, adding support for SharePlay, and building an “out of this world” experience!","type":"text"}]},"https://developer.apple.com/videos/play/wwdc2023/10081?time=147":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081?time=147","titleInlineContent":[{"text":"Example app that demonstrates how to put text labels and views alongside 3D content using attachment views","type":"text"}],"title":"Example app that demonstrates how to put text labels and views alongside 3D content using attachment views","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10081?time=147","type":"link"},"https://x.com/stevnhoward":{"titleInlineContent":[{"text":"X\/Twitter","type":"text"}],"type":"link","title":"X\/Twitter","url":"https:\/\/x.com\/stevnhoward","identifier":"https:\/\/x.com\/stevnhoward"}}}