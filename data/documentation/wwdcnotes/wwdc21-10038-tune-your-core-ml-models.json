{"abstract":[{"text":"Bring the power of machine learning directly to your apps with Core ML. Discover how you can take advantage of the CPU, GPU, and Neural Engine to provide maximum performance while remaining on device and protecting privacy. Explore MLShapedArray, which makes it easy to work with multi-dimensional data in Swift, and learn more about ML Package support in Core ML, which includes support for ML Programs. This modern, programmatic approach to machine learning provides typed execution and tremendous flexibility. We‚Äôll also show you how to analyze performance of your models and tune the execution of each operation in a model using ML Programs.","type":"text"}],"schemaVersion":{"patch":0,"major":0,"minor":3},"sampleCodeDownload":{"kind":"sampleDownload","action":{"identifier":"https:\/\/developer.apple.com\/wwdc21\/10038","isActive":true,"type":"reference","overridingTitle":"Watch Video (24 min)"}},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10038-Tune-your-Core-ML-models","interfaceLanguage":"swift"},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21"]]},"primaryContentSections":[{"kind":"content","content":[{"anchor":"overview","text":"Overview","level":2,"type":"heading"},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:"},{"type":"text","text":" "},{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","type":"reference","isActive":true}]},{"type":"heading","text":"Related Sessions","anchor":"Related-Sessions","level":2},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10153-Get-models-on-device-using-Core-ML-Converters"],"style":"list"},{"type":"small","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Legal Notice"}]}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright ¬© 2012 ‚Äì 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}]}],"sections":[],"kind":"article","variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc21-10038-tune-your-core-ml-models"]}],"metadata":{"roleHeading":"WWDC21","title":"Tune your Core ML models","modules":[{"name":"WWDC Notes"}],"role":"sampleCode"},"references":{"https://developer.apple.com/wwdc21/10038":{"url":"https:\/\/developer.apple.com\/wwdc21\/10038","type":"download","identifier":"https:\/\/developer.apple.com\/wwdc21\/10038","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction":{"abstract":[{"type":"text","text":"Learn how to speed up machine learning features in your app with the latest Core ML execution engine improvements and find out how aggressive asset caching can help with inference and faster model loads. We‚Äôll show you some of the latest options for async prediction and discuss considerations for balancing performance with overall memory usage to help you create a highly responsive app. Discover APIs to help you understand and maximize hardware utilization for your models."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","title":"Improve Core ML integration with async prediction","url":"\/documentation\/wwdcnotes\/wwdc23-10049-improve-core-ml-integration-with-async-prediction","role":"sampleCode","kind":"article","type":"topic"},"WWDCNotes.png":{"type":"image","identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"alt":null},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","titleInlineContent":[{"text":"Learn More‚Ä¶","type":"text"}],"type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"WWDC21.jpeg":{"type":"image","identifier":"WWDC21.jpeg","variants":[{"url":"\/images\/WWDC21.jpeg","traits":["1x","light"]}],"alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10153-Get-models-on-device-using-Core-ML-Converters":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10153-Get-models-on-device-using-Core-ML-Converters","url":"\/documentation\/wwdcnotes\/wwdc20-10153-get-models-on-device-using-core-ml-converters","title":"Get models on device using Core ML Converters","abstract":[{"type":"text","text":"With Core ML you can bring incredible machine learning models to your app and run them entirely on-device. And when you use Core ML Converters, you can incorporate almost any trained model from TensorFlow or PyTorch and take full advantage of the GPU, CPU, and Neural Engine. Discover everything you need to begin converting existing models from other ML platforms and explore how to create custom operations that extend the capabilities of your models."}],"kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","role":"collection","title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","url":"\/documentation\/wwdcnotes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21":{"title":"WWDC21","url":"\/documentation\/wwdcnotes\/wwdc21","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21","role":"collectionGroup","kind":"article","images":[{"identifier":"WWDC21-Icon.png","type":"icon"},{"identifier":"WWDC21.jpeg","type":"card"}],"type":"topic","abstract":[{"text":"Xcode 13, Swift 5.5, iOS 15, macOS 12 (Monterey), tvOS 15, watchOS 8.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"code":"MusicKit","type":"codeVoice"},{"text":", ","type":"text"},{"code":"DocC","type":"codeVoice"},{"text":", ","type":"text"},{"code":"StoreKit 2","type":"codeVoice"},{"text":", and more.","type":"text"}]},"WWDC21-Icon.png":{"type":"image","identifier":"WWDC21-Icon.png","variants":[{"url":"\/images\/WWDC21-Icon.png","traits":["1x","light"]}],"alt":null}}}