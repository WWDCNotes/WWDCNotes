{"metadata":{"role":"sampleCode","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC19","title":"Introducing Accelerate for Swift"},"kind":"article","sampleCodeDownload":{"kind":"sampleDownload","action":{"type":"reference","overridingTitle":"Watch Video (20 min)","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc19\/718"}},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-718-Introducing-Accelerate-for-Swift","interfaceLanguage":"swift"},"sections":[],"seeAlsoSections":[{"generated":true,"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-722-Introducing-Combine","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-520-Introducing-Core-Haptics","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-249-Introducing-MultiCamera-Capture-for-iOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-260-Introducing-Photo-Segmentation-Mattes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-430-Introducing-the-Create-ML-App","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-245-Introducing-the-Indoor-Maps-Program"],"title":"New Tools & Frameworks"}],"schemaVersion":{"major":0,"minor":3,"patch":0},"primaryContentSections":[{"kind":"content","content":[{"type":"heading","text":"What is Accelerate?","anchor":"What-is-Accelerate","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"The primary purpose of Accelerate is to provide thousands of low-level math primitives that run on a CPU and support image and signal processing, vector arithmetic, linear algebra, and machine learning. Most of these primitives are hand tuned to the microarchitecture of the processor."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This improves performances and battery usage."}]},{"type":"heading","text":"Swift","anchor":"Swift","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"Until now the Accelerate APIs were not really Swift-friendly, this year Apple has changed that particular in four libraries:"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"inlineContent":[{"type":"text","text":"vDSP"}],"type":"strong"},{"text":" (Digital Signal Processing): provides digital signal processing routines including arithmetic on large vectors, Fourier transforms, biquadratic filtering, and powerful type conversion.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"vForce"}]},{"text":" (Basically vDSP with more geometry like ","type":"text"},{"code":"sin","type":"codeVoice"},{"text":"\/","type":"text"},{"code":"cos","type":"codeVoice"},{"text":"\/","type":"text"},{"code":"log","type":"codeVoice"},{"text":"\/","type":"text"},{"code":"sqrt","type":"codeVoice"},{"text":"): provides arithmetic and transcendental functions including trig and logarithmic routines.","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Quadrature","type":"text"}]},{"type":"text","text":" (historic name, it meant compute the area beneath a curve in a interval): dedicated to the numerical integration of functions."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"vImage"}]},{"text":" (Rich collection of editing tools. Used along with CoreGraphics\/CoreVideo): provides a huge selection of image processing functions and integrates easily with core graphics and core video.","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"text":"Now using any of these libraries requires much less code in Swift, and it is also safer (in some APIs).","type":"text"}]},{"type":"heading","text":"Behind the Scenes","anchor":"Behind-the-Scenes","level":2},{"type":"paragraph","inlineContent":[{"text":"Accelerate gets its performance benefits by using vectorization.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let’s make an example of multiplying two arrays:"}]},{"type":"codeListing","code":["let a: [Float] = [10, 20, 30, 40] ","let b: [Float] = [1, 2, 3, 4] ","var c: [Float] = [0, 0, 0, 0] ","","for i in 0 ..< c.count {","  c[i] = a[i] * b[i] ","}"],"syntax":"swift"},{"type":"paragraph","inlineContent":[{"text":"By doing so, each pair of elements are separately loaded, multiplied together, and the results stored.","type":"text"},{"text":" ","type":"text"},{"text":"With Accelerate:","type":"text"}]},{"type":"codeListing","code":["let a: [Float] = [10, 20, 30, 40] ","let b: [Float] = [1, 2, 3, 4] ","var c: [Float] = [0, 0, 0, 0] ","","vDSP.multiply(a, b, result: &c) "],"syntax":"swift"},{"type":"paragraph","inlineContent":[{"text":"When using Accelerate, the calculation is performed on single instruction multiple data, or SIMD registers.","type":"text"},{"text":" ","type":"text"},{"text":"These registers can perform the same instruction on multiple items of data by packing those multiple items into a single register. For example, a single 128-bit register can actually store four 32-bit floating point values. So, a vectorized multiply operation can simultaneously multiply four pairs of elements at a time.","type":"text"},{"text":" ","type":"text"},{"text":"This means that not only will the task be quicker, it will also be significantly more energy efficient.","type":"text"}]},{"type":"heading","text":"Real Examples","anchor":"Real-Examples","level":2},{"type":"paragraph","inlineContent":[{"text":"Basically anything that operates on arrays (or matrices) with a ","type":"text"},{"code":"map","type":"codeVoice"},{"text":"\/","type":"text"},{"code":"for-each","type":"codeVoice"},{"text":" can use Accelerate to improve performances by at least x3\/4.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Even by computing a sum, a conversion, etc.","type":"text"}]},{"type":"heading","text":"Written By","anchor":"Written-By","level":2},{"type":"row","columns":[{"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/5277837?v=4"}]}],"size":1},{"content":[{"text":"Federico Zanetello","type":"heading","anchor":"Federico-Zanetello","level":3},{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","overridingTitle":"Contributed Notes","overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"https:\/\/github.com\/zntfdr","isActive":true},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"type":"reference","identifier":"zntfdr.dev","isActive":true}]}],"size":4}],"numberOfColumns":5},{"type":"heading","text":"Related Sessions","anchor":"Related-Sessions","level":2},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10233-Use-Accelerate-to-improve-performance-and-incorporate-encrypted-archives"],"style":"list"},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"type":"small","inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}]}]}],"abstract":[{"type":"text","text":"Accelerate framework provides hundreds of computational functions that are highly optimized to the system architecture your device is running on. Learn how to access all of these powerful functions directly in Swift. Understand how the power of vector programming can deliver incredible performance to your iOS, macOS, tvOS, and watchOS apps."}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19"]]},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc19-718-introducing-accelerate-for-swift"],"traits":[{"interfaceLanguage":"swift"}]}],"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC19":{"url":"\/documentation\/wwdcnotes\/wwdc19","kind":"article","role":"collectionGroup","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"abstract":[{"type":"text","text":"Xcode 11, Swift 5.1, iOS 12, macOS 10.15, tvOS 13, watchOS 6."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"Combine"},{"type":"text","text":", "},{"type":"codeVoice","code":"Core Haptics"},{"type":"text","text":", "},{"type":"codeVoice","code":"Create ML"},{"type":"text","text":", and more."}],"type":"topic","title":"WWDC19","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19"},"doc://WWDCNotes/documentation/WWDCNotes/zntfdr":{"title":"Federico Zanetello (214 notes)","abstract":[{"type":"text","text":"Software engineer with a strong passion for well-written code, thought-out composable architectures, automation, tests, and more."}],"kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","role":"sampleCode","url":"\/documentation\/wwdcnotes\/zntfdr"},"WWDCNotes.png":{"type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"identifier":"WWDCNotes.png","alt":null},"zntfdr.dev":{"type":"link","identifier":"zntfdr.dev","titleInlineContent":[{"text":"Blog","type":"text"}],"url":"zntfdr.dev","title":"Blog"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-520-Introducing-Core-Haptics":{"type":"topic","kind":"article","role":"sampleCode","abstract":[{"type":"text","text":"Core Haptics lets you design fully customized haptic patterns with synchronized audio. See examples of how haptics and audio enables you to create a greater sense of immersion in your app or game. Learn how to create, play back, and share content, and where Core Haptics fits in with other audio and vibration APIs."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-520-Introducing-Core-Haptics","url":"\/documentation\/wwdcnotes\/wwdc19-520-introducing-core-haptics","title":"Introducing Core Haptics"},"doc://WWDCNotes/documentation/WWDCNotes":{"title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"kind":"symbol","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","url":"\/documentation\/wwdcnotes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10233-Use-Accelerate-to-improve-performance-and-incorporate-encrypted-archives":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10233-Use-Accelerate-to-improve-performance-and-incorporate-encrypted-archives","url":"\/documentation\/wwdcnotes\/wwdc21-10233-use-accelerate-to-improve-performance-and-incorporate-encrypted-archives","role":"sampleCode","kind":"article","title":"Use Accelerate to improve performance and incorporate encrypted archives","abstract":[{"type":"text","text":"The Accelerate framework helps you make large-scale mathematical computations and image calculations that are optimized for high-performance, low-energy consumption. Explore the latest updates to Accelerate and its Basic Neural Network Subroutines library, including additional layers, activation functions, and improved optimizer support. Check out improvements to simd.h that include better support for C++ templates. Discover support for Apple Encrypted Archive, an extension to Apple Archive that combines compression with powerful encryption and a digital signature. And learn how you can keep data your safe and secure without compromising on performance."}],"type":"topic"},"https://avatars.githubusercontent.com/u/5277837?v=4":{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/5277837?v=4","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/5277837?v=4","traits":["1x","light"]}],"alt":"Profile image of Federico Zanetello"},"https://developer.apple.com/wwdc19/718":{"checksum":null,"url":"https:\/\/developer.apple.com\/wwdc19\/718","identifier":"https:\/\/developer.apple.com\/wwdc19\/718","type":"download"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-245-Introducing-the-Indoor-Maps-Program":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-245-Introducing-the-Indoor-Maps-Program","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-245-introducing-the-indoor-maps-program","role":"sampleCode","kind":"article","abstract":[{"type":"text","text":"The Indoor Maps Program enables organizations with large public or private spaces to deliver user experiences that leverage precise location information and present stunning indoor maps. Learn the entire enablement workflow including, creation of a standards-based map definition, map validation, testing and calibration, and details on how to use MapKit and MapKit JS to integrate it all into your app or website."}],"title":"Introducing the Indoor Maps Program"},"https://github.com/zntfdr":{"type":"link","identifier":"https:\/\/github.com\/zntfdr","titleInlineContent":[{"text":"GitHub","type":"text"}],"url":"https:\/\/github.com\/zntfdr","title":"GitHub"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-430-Introducing-the-Create-ML-App":{"type":"topic","title":"Introducing the Create ML App","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc19-430-introducing-the-create-ml-app","kind":"article","abstract":[{"text":"Bringing the power of Core ML to your app begins with one challenge. How do you create your model? The new Create ML app provides an intuitive workflow for model creation. See how to train, evaluate, test, and preview your models quickly in this easy-to-use tool. Get started with one of the many available templates handling a number of powerful machine learning tasks. Learn more about the many features for continuous model improvement and experimentation.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-430-Introducing-the-Create-ML-App"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-722-Introducing-Combine":{"type":"topic","kind":"article","role":"sampleCode","abstract":[{"type":"text","text":"Combine is a unified declarative framework for processing values over time. Learn how it can simplify asynchronous code like networking, key value observing, notifications and callbacks."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-722-Introducing-Combine","url":"\/documentation\/wwdcnotes\/wwdc19-722-introducing-combine","title":"Introducing Combine"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-260-Introducing-Photo-Segmentation-Mattes":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-260-Introducing-Photo-Segmentation-Mattes","role":"sampleCode","abstract":[{"text":"Photos captured in Portrait Mode on iOS 12 contain an embedded person segmentation matte that made it easy to create creative visual effects like background replacement. iOS 13 leverages on-device machine learning to provide new segmentation mattes for any captured photo. Learn about the new semantic segmentation mattes available to you from both AVCapture and Core Image to isolate a person’s hair, skin, and teeth. Using any of these individual mattes or combining all of them, your app can now offer a tremendous amount of photo editing control.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-260-introducing-photo-segmentation-mattes","title":"Introducing Photo Segmentation Mattes","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-249-Introducing-MultiCamera-Capture-for-iOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-249-Introducing-MultiCamera-Capture-for-iOS","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc19-249-introducing-multicamera-capture-for-ios","role":"sampleCode","kind":"article","abstract":[{"type":"text","text":"In AVCapture on iOS 13 it is now possible to simultaneously capture photos and video from multiple cameras on iPhone XS, iPhone XS Max, iPhone XR, and the latest iPad Pro. It is also possible to configure the multiple microphones on the device to shape the sound that is captured. Learn how to leverage these powerful capabilities to bring creative new features like picture-in-picture and spatial audio to your camera apps. Gain a deeper understanding of the performance considerations that may influence your app design."}],"title":"Introducing Multi-Camera Capture for iOS"}}}