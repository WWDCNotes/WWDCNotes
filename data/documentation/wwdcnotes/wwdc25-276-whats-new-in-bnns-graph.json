{"kind":"article","sampleCodeDownload":{"action":{"overridingTitle":"Watch Video (23 min)","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/276","type":"reference","isActive":true},"kind":"sampleDownload"},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25"]]},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc25-276-whats-new-in-bnns-graph"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-276-Whats-new-in-BNNS-Graph","interfaceLanguage":"swift"},"sections":[],"metadata":{"role":"sampleCode","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC25","title":"What‚Äôs new in BNNS Graph"},"abstract":[{"type":"text","text":"The BNNS Graph Builder API now enables developers to write graphs of operations using the familiar Swift language to generate pre- and post-processing routines and small machine-learning models. BNNS compiles graphs ahead of execution and supports real-time and latency-sensitive use cases such as audio processing. In this session, we revisit last year‚Äôs bit-crusher example and simplify the Swift component by removing the reliance on a separate Python file and instead implement the audio effect entirely in Swift. The BNNS Graph Builder API is also suited to pre-processing image data before passing that data to a machine learning model. The session also includes a demonstration of clipping the transparent pixels from an image with an alpha channel."}],"schemaVersion":{"minor":3,"patch":0,"major":0},"primaryContentSections":[{"kind":"content","content":[{"level":2,"type":"heading","anchor":"overview","text":"Overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}]},{"level":2,"type":"heading","anchor":"Related-Sessions","text":"Related Sessions"},{"type":"links","style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-360-Discover-machine-learning-and-AI-frameworks-on-Apple-platforms"]}]}],"references":{"WWDC25-Icon.png":{"identifier":"WWDC25-Icon.png","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC25-Icon.png"}],"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU":{"kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10211-support-realtime-ml-inference-on-the-cpu","abstract":[{"type":"text","text":"Discover how you can use BNNSGraph to accelerate the execution of your machine learning model on the CPU. We will show you how to use BNNSGraph to compile and execute a machine learning model on the CPU and share how it provides real-time guarantees such as no runtime memory allocation and single-threaded running for audio or signal processing models."}],"role":"sampleCode","title":"Support real-time ML inference on the CPU","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU"},"doc://WWDCNotes/documentation/WWDCNotes":{"url":"\/documentation\/wwdcnotes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","type":"topic","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"role":"collection","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"kind":"symbol","title":"WWDC Notes"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}]},"https://developer.apple.com/videos/play/wwdc2025/276":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/276","type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/276"},"WWDC25.jpg":{"identifier":"WWDC25.jpg","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC25.jpg"}],"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25":{"abstract":[{"type":"text","text":"Xcode 26, Swift 6.2, iOS\/macOS\/tvOS\/visionOS 26."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"Foundation Models","type":"codeVoice"},{"type":"text","text":", "},{"code":"AlarmKit","type":"codeVoice"},{"type":"text","text":", "},{"code":"PermissionKit","type":"codeVoice"},{"type":"text","text":", and more."}],"images":[{"type":"icon","identifier":"WWDC25-Icon.png"},{"type":"card","identifier":"WWDC25.jpg"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25","title":"WWDC25","role":"collectionGroup","url":"\/documentation\/wwdcnotes\/wwdc25","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-360-Discover-machine-learning-and-AI-frameworks-on-Apple-platforms":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-360-Discover-machine-learning-and-AI-frameworks-on-Apple-platforms","role":"sampleCode","title":"Discover machine learning & AI frameworks on Apple platforms","kind":"article","abstract":[{"text":"Tour the latest updates to machine learning and AI frameworks available on Apple platforms. Whether you are an app developer ready to tap into Apple Intelligence, an ML engineer optimizing models for on-device deployment, or an AI enthusiast exploring the frontier of what is possible, we‚Äôll offer guidance to help select the right tools for your needs.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc25-360-discover-machine-learning-and-ai-frameworks-on-apple-platforms","type":"topic"},"WWDCNotes.png":{"identifier":"WWDCNotes.png","type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDCNotes.png"}],"alt":null}}}