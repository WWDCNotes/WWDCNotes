{"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc21-10041-extract-document-data-using-vision"]}],"schemaVersion":{"patch":0,"minor":3,"major":0},"primaryContentSections":[{"kind":"content","content":[{"text":"Overview","type":"heading","anchor":"overview","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}]},{"text":"Related Sessions","type":"heading","anchor":"Related-Sessions","level":2},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10673-Explore-Computer-Vision-APIs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-234-Text-Recognition-in-Vision-Framework"],"type":"links","style":"list"}]}],"metadata":{"title":"Extract document data using Vision","role":"sampleCode","modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC21"},"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10041","overridingTitle":"Watch Video (19 min)","type":"reference"}},"sections":[],"kind":"article","abstract":[{"text":"Discover how Vision can provide expert image recognition and analysis in your app to extract information from documents, recognize text in multiple languages, and identify barcodes. We‚Äôll explore the latest updates to Text Recognition and Barcode Detection, show you how to bring all these tools together with Core ML, and help your app make greater sense of the world through images or the live camera.","type":"text"}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21"]]},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10041-Extract-document-data-using-Vision","interfaceLanguage":"swift"},"references":{"WWDC21.jpeg":{"identifier":"WWDC21.jpeg","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC21.jpeg"}],"type":"image"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}],"title":"Learn More‚Ä¶","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"https://developer.apple.com/videos/play/wwdc2021/10041":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10041","type":"download","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10041","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes":{"url":"\/documentation\/wwdcnotes","kind":"symbol","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"role":"collection","type":"topic"},"WWDC21-Icon.png":{"identifier":"WWDC21-Icon.png","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC21-Icon.png"}],"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10673-Explore-Computer-Vision-APIs":{"kind":"article","title":"Explore Computer Vision APIs","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10673-Explore-Computer-Vision-APIs","url":"\/documentation\/wwdcnotes\/wwdc20-10673-explore-computer-vision-apis","type":"topic","abstract":[{"type":"text","text":"Learn how to bring Computer Vision intelligence to your app when you combine the power of Core Image, Vision, and Core ML. Go beyond machine learning alone and gain a deeper understanding of images and video. Discover new APIs in Core Image and Vision to bring Computer Vision to your application like new thresholding filters as well as Contour Detection and Optical Flow. And consider ways to use Core Image for preprocessing and visualization of these results."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-234-Text-Recognition-in-Vision-Framework":{"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19-234-text-recognition-in-vision-framework","abstract":[{"type":"text","text":"Document Camera and Text Recognition features in Vision Framework enable you to extract text data from images. Learn how to leverage this built-in machine learning technology in your app. Gain a deeper understanding of the differences between fast versus accurate processing as well as character-based versus language-based recognition."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-234-Text-Recognition-in-Vision-Framework","title":"Text Recognition in Vision Framework","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21":{"abstract":[{"type":"text","text":"Xcode 13, Swift 5.5, iOS 15, macOS 12 (Monterey), tvOS 15, watchOS 8."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"MusicKit"},{"type":"text","text":", "},{"type":"codeVoice","code":"DocC"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit 2"},{"type":"text","text":", and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21","url":"\/documentation\/wwdcnotes\/wwdc21","kind":"article","title":"WWDC21","type":"topic","images":[{"type":"icon","identifier":"WWDC21-Icon.png"},{"type":"card","identifier":"WWDC21.jpeg"}],"role":"collectionGroup"},"WWDCNotes.png":{"alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDCNotes.png"}],"type":"image","identifier":"WWDCNotes.png"}}}