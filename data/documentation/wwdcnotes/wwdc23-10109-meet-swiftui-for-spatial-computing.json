{"seeAlsoSections":[{"generated":true,"title":"New Tools & Frameworks","identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10184-Meet-ActivityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10032-Meet-Assistive-Access","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10147-Meet-Core-Location-Monitor","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10146-Meet-Core-Location-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10043-Meet-MapKit-for-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10191-Meet-Object-Capture-for-iOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10025-Meet-Push-Notifications-Console","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10099-Meet-RealityKit-Trace","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10279-Meet-Safari-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10013-Meet-StoreKit-for-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10171-Meet-Swift-OpenAPI-Generator","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10187-Meet-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111215-Meet-UIKit-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10039-Meet-device-management-for-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10268-Meet-mergeable-libraries","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10026-Meet-watchOS-10"]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10109-Meet-SwiftUI-for-spatial-computing"},"kind":"article","hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"abstract":[{"type":"text","text":"Take a tour of the solar system with us and explore SwiftUI for visionOS! Discover how you can build an entirely new universe of apps with windows, volumes, and spaces. We’ll show you how to get started with SwiftUI on this platform as we build an astronomy app, add 3D content, and create a fully immersive experience to transport people to the stars."}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-10109-meet-swiftui-for-spatial-computing"]}],"sections":[],"metadata":{"role":"sampleCode","modules":[{"name":"WWDC Notes"}],"title":"Meet SwiftUI for spatial computing","roleHeading":"WWDC23"},"primaryContentSections":[{"content":[{"type":"heading","anchor":"Introduction","text":"Introduction","level":2},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"When building an app for spatial computing: the best way to build it is with SwiftUI.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"New capabiltes such as Volumes and new 3D gestures, effects and layouts only exist in SwiftUI."}]}]},{"content":[{"inlineContent":[{"type":"text","text":"The visionOS system has been built from the ground up with SwiftUI (e.g. buttons, toggles, Home View, Control Centre)"}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"identifier":"WWDC23-10109-ui-components","type":"image"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"SwiftUI elements adapt to the idioms of visionOS:"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"bordered buttons use a vibrant material background."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"all buttons gain a rich hover effect that react to your eyes, hands and to pointer input.","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"buttons can automatically display a tooltip when you look at them.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"TabView hangs by the side of your app."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"TabView expands to display more detail just by looking at it."}]}]}],"type":"unorderedList"}]}],"type":"unorderedList"},{"text":"Scenes","anchor":"Scenes","level":2,"type":"heading"},{"inlineContent":[{"identifier":"WWDC23-10109-spatial-scenes","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"With spatial computing, there are 3 types of scenes that make up an app:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"text":"Windows","type":"text"}]},{"type":"text","text":": great for building traditional and familiar interfaces (e.g. Safari, Freeform), and menus that lead into more immersive experiences (e.g. Mindfulness)"}]}]},{"content":[{"inlineContent":[{"inlineContent":[{"type":"text","text":"Volumes"}],"type":"strong"},{"text":": a new 3D window style: for displaying objects and experiences in a bounded space.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Full Spaces","type":"text"}]},{"type":"text","text":": app gets complete control, hiding windows from other apps."}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Window","anchor":"Window","level":2,"type":"heading"},{"text":"Ornaments","anchor":"Ornaments","level":4,"type":"heading"},{"inlineContent":[{"text":"New concept added to SwiftUI: Ornaments.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Ornaments allow you to add accessory views relative to your app’s window. They can even extend outside the window’s bounds."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Create your own ornament using the "},{"type":"codeVoice","code":".ornament"},{"type":"text","text":" modifier."}],"type":"paragraph"},{"text":"Materials","anchor":"Materials","level":4,"type":"heading"},{"inlineContent":[{"text":"No dark or light appearance on visionOS. Materials do the hard work for you.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Secondary foreground style ("},{"type":"codeVoice","code":".foregroundStyle(.secondary)"},{"type":"text","text":") automatically uses a new vibrant treatment within its background material to increase visual weight."}],"type":"paragraph"},{"text":"Interaction","anchor":"Interaction","level":3,"type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"type":"text","text":"Eyes"}],"type":"strong"},{"type":"text","text":": Look at an element and use an indirect pinch gesture."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Hands"}]},{"text":": reaching out and touching apps.","type":"text"}]}]},{"content":[{"inlineContent":[{"inlineContent":[{"text":"Pointer","type":"text"}],"type":"strong"},{"text":": trackpad, hand gesture or hardware keyboard.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"inlineContent":[{"type":"text","text":"Accessibility"}],"type":"strong"},{"text":": e.g. VoiceOver, Switch Control.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"type":"text","text":"New gestures added to SwiftUI, like "},{"type":"codeVoice","code":"RotateGesture3D"},{"type":"text","text":"."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10109-spacial-swiftui-gestures"}],"type":"paragraph"},{"text":"Hover effects","anchor":"Hover-effects","level":4,"type":"heading"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Critical to making your app responsive."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Run outside of your app’s process."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Added automatically to most controls."}]}]},{"content":[{"inlineContent":[{"type":"text","text":"If you’re using a custom control style, make sure to add hover effects to make them responsive and easy to use."}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Volumes","anchor":"Volumes","level":2,"type":"heading"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"To add a volume, specify "},{"code":".windowStyle(.volumetric)","type":"codeVoice"},{"type":"text","text":" on your "},{"code":"WindowGroup","type":"codeVoice"},{"type":"text","text":"."}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Model3D","anchor":"Model3D","level":3,"type":"heading"},{"inlineContent":[{"identifier":"WWDC23-10109-model3d","type":"image"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"text":"To display a 3D model, use the new ","type":"text"},{"type":"codeVoice","code":"Model3D"},{"text":" API from RealityKit.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"A ","type":"text"},{"type":"codeVoice","code":"Model3D"},{"text":" always loads asynchornously. Similar to ","type":"text"},{"type":"codeVoice","code":"AsyncImageView"},{"text":", a ","type":"text"},{"type":"codeVoice","code":"Model3D"},{"text":" can display a placeholder view.","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Layouts like "},{"type":"codeVoice","code":"ZStack"},{"type":"text","text":" are automatically aware of the depth of your content."}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"RealityView","anchor":"RealityView","level":3,"type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"code":"RealityView","type":"codeVoice"},{"type":"text","text":" provides easy access to the full power of RealityKit Pro."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"code":"SpatialTapGesture","type":"codeVoice"},{"type":"text","text":" gives the full 3D location of the tap."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"the ","type":"text"},{"code":"tagetedToAnyEntity","type":"codeVoice"},{"text":" view modifier provides context like the entity you tapped on and the location relative to that entity.","type":"text"}]}]},{"content":[{"inlineContent":[{"code":"RealityView","type":"codeVoice"},{"text":" attachments allow mixing custom SwiftUI views together, inline with RealityKit entities.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Full Spaces","anchor":"Full-Spaces","level":2,"type":"heading"},{"text":"ImmersiveSpace","anchor":"ImmersiveSpace","level":3,"type":"heading"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Add an ","type":"text"},{"code":"ImmersiveSpace","type":"codeVoice"},{"text":" scene.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Provide an id to the space so you can programmatically open it from your main window.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"To open the space, use the new ","type":"text"},{"type":"codeVoice","code":"openImmersiveSpace"},{"text":" environment action.","type":"text"}]}]}],"type":"unorderedList"},{"text":"Immersion styles","anchor":"Immersion-styles","level":3,"type":"heading"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10109-immersion-styles"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"text":"Mixed, Progressive and Full immersion are supported.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"With Progressive immersion, you can use the digital dial to dial in how much immersion feels right to you."}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Use the "},{"code":"immersionStyle","type":"codeVoice"},{"type":"text","text":" view modifier."}],"type":"paragraph"}]}],"type":"unorderedList"},{"text":"Written By","anchor":"Written-By","level":2,"type":"heading"},{"columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/329601?v=4"}]}]},{"size":4,"content":[{"anchor":"Rony-Fadel","type":"heading","text":"Rony Fadel","level":3},{"type":"paragraph","inlineContent":[{"overridingTitle":"Contributed Notes","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/ronyfadel","isActive":true},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/fadel.io\/","isActive":true}]}]}],"numberOfColumns":5,"type":"row"},{"text":"Related Sessions","anchor":"Related-Sessions","level":2,"type":"heading"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10034-Create-accessible-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10148-Whats-new-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111215-Meet-UIKit-for-spatial-computing"],"style":"list","type":"links"},{"inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}],"type":"small"},{"inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}],"type":"small"}],"kind":"content"}],"sampleCodeDownload":{"action":{"isActive":true,"overridingTitle":"Watch Video (25 min)","type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc23\/10109"},"kind":"sampleDownload"},"schemaVersion":{"patch":0,"minor":3,"major":0},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10034-Create-accessible-spatial-experiences":{"url":"\/documentation\/wwdcnotes\/wwdc23-10034-create-accessible-spatial-experiences","abstract":[{"text":"Learn how you can make spatial computing apps that work well for everyone. Like all Apple platforms, visionOS is designed for accessibility: We’ll share how we’ve reimagined assistive technologies like VoiceOver and Pointer Control and designed features like Dwell Control to help people interact in the way that works best for them. Learn best practices for vision, motor, cognitive, and hearing accessibility and help everyone enjoy immersive experiences for visionOS.","type":"text"}],"title":"Create accessible spatial experiences","type":"topic","kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10034-Create-accessible-spatial-experiences"},"WWDC23-10109-ui-components":{"identifier":"WWDC23-10109-ui-components","type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10109-ui-components.png"}],"alt":"Overview of SwiftUI view components optimized for visionOS"},"doc://WWDCNotes/documentation/WWDCNotes/ronyfadel":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/ronyfadel","type":"topic","title":"Rony Fadel (2 notes)","role":"sampleCode","url":"\/documentation\/wwdcnotes\/ronyfadel","abstract":[{"type":"text","text":"Former Apple engineer turned indie developer."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","type":"topic","kind":"article","title":"Build spatial experiences with RealityKit","abstract":[{"text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10082-Meet-ARKit-for-spatial-computing":{"role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can use ARKit’s tracking and scene understanding features to develop a whole new universe of immersive apps and games. Learn how visionOS and ARKit work together to help you create apps that understand a person’s surroundings — all while preserving privacy. Explore the latest updates to the ARKit API and follow along as we demonstrate how to take advantage of hand tracking and scene geometry in your apps.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10082-meet-arkit-for-spatial-computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","title":"Meet ARKit for spatial computing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","abstract":[{"text":"Discover how you can run your existing iPad and iPhone apps on Vision Pro. Learn how iPadOS and iOS apps operate on this platform, find out about the Designed for iPad experience, and explore the paths available for enhancing your app experience on visionOS.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10090-run-your-ipad-and-iphone-apps-in-the-shared-space","kind":"article","type":"topic","title":"Run your iPad and iPhone apps in the Shared Space"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10111-Go-beyond-the-window-with-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10111-go-beyond-the-window-with-swiftui","abstract":[{"text":"Get ready to launch into space — a new SwiftUI scene type that can help you make great immersive experiences for visionOS. We’ll show you how to create a new scene with ImmersiveSpace, place 3D content, and integrate RealityView. Explore how you can use the immersionStyle scene modifier to increase the level of immersion in an app and learn best practices for managing spaces, adding virtual hands with ARKit, adding support for SharePlay, and building an “out of this world” experience!","type":"text"}],"kind":"article","type":"topic","title":"Go beyond the window with SwiftUI"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10171-Meet-Swift-OpenAPI-Generator":{"role":"sampleCode","kind":"article","abstract":[{"text":"Discover how Swift OpenAPI Generator can help you work with HTTP server APIs whether you’re extending an iOS app or writing a server in Swift. We’ll show you how this package plugin can streamline your workflow and simplify your codebase by generating code from an OpenAPI document.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10171-meet-swift-openapi-generator","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10171-Meet-Swift-OpenAPI-Generator","title":"Meet Swift OpenAPI Generator"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10013-Meet-StoreKit-for-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10013-Meet-StoreKit-for-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10013-meet-storekit-for-swiftui","type":"topic","role":"sampleCode","title":"Meet StoreKit for SwiftUI","abstract":[{"type":"text","text":"Discover how you can use App Store product metadata and Xcode Previews to add in-app purchases to your app with just a few lines of code. Explore a new collection of UI components in StoreKit and learn how you can easily merchandise your products, present subscriptions in a way that helps users make informed decisions, and more."}],"kind":"article"},"https://fadel.io/":{"identifier":"https:\/\/fadel.io\/","type":"link","title":"Blog","url":"https:\/\/fadel.io\/","titleInlineContent":[{"text":"Blog","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10279-Meet-Safari-for-spatial-computing":{"abstract":[{"text":"Discover the web for visionOS and learn how people can experience your web content in a whole new way. Explore the unique input model powering this platform and learn how you can optimize your website for spatial computing. We’ll also share how emerging standards are helping shape 3D experiences for the web.","type":"text"}],"title":"Meet Safari for spatial computing","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10279-Meet-Safari-for-spatial-computing","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10279-meet-safari-for-spatial-computing","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10147-Meet-Core-Location-Monitor":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10147-meet-core-location-monitor","role":"sampleCode","title":"Meet Core Location Monitor","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10147-Meet-Core-Location-Monitor","abstract":[{"type":"text","text":"Discover how Core Location Monitor can help you better understand location and beacon events in your app. Learn how to use Core Location Conditions to describe and track the state of events in your app, and find out how you can better respond to transitions in your apps through Swift semantics and improved reliability."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10026-Meet-watchOS-10":{"role":"sampleCode","kind":"article","abstract":[{"text":"Discover some of the most significant changes to Apple Watch since its introduction as we tour the redesigned user interface and the new Smart Stack. Learn how Apple designers approached the design of watchOS 10 as we explore layout, navigation, and visual style, and find out how you can apply them to create a great app for Apple Watch.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10026-meet-watchos-10","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10026-Meet-watchOS-10","title":"Meet watchOS 10"},"WWDC23-10109-spatial-scenes":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10109-spatial-scenes.png"}],"identifier":"WWDC23-10109-spatial-scenes","type":"image","alt":"Kinds of Scenes on visionOS: Window, Volume, or Full Space"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10146-Meet-Core-Location-for-spatial-computing":{"role":"sampleCode","kind":"article","abstract":[{"text":"Discover how Core Location helps your app find its place in the world — literally. We’ll share how you can build a spatial computing app that uses a person’s location while respecting their privacy. You’ll also learn how your app can request location access and how Core Location adapts requests from compatible iPad and iPhone apps.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10146-meet-core-location-for-spatial-computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10146-Meet-Core-Location-for-spatial-computing","title":"Meet Core Location for spatial computing"},"WWDCNotes.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}],"identifier":"WWDCNotes.png","type":"image","alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10268-Meet-mergeable-libraries":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10268-Meet-mergeable-libraries","url":"\/documentation\/wwdcnotes\/wwdc23-10268-meet-mergeable-libraries","type":"topic","role":"sampleCode","title":"Meet mergeable libraries","abstract":[{"type":"text","text":"Discover how mergeable libraries combine the best parts of static and dynamic libraries to help improve your app’s productivity and runtime performance. Learn how you can enable faster development while shipping the smallest app. We’ll show you how to adopt mergeable libraries in Xcode 15 and share best practices for working with your code."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing":{"kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10110-elevate-your-windowed-app-for-spatial-computing","abstract":[{"type":"text","text":"Discover how you can bring your multiplatform SwiftUI app to visionOS and the Shared Space. We’ll show you how to add the visionOS destination to an existing app and view your app in the Simulator. Explore how your SwiftUI code automatically adapts to support the unique context and presentation of the visionOS platform. Learn how you can update custom views, improve your app’s UI, and add features and controls specific to this platform."}],"title":"Elevate your windowed app for spatial computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing":{"title":"Get started with building apps for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-10260-get-started-with-building-apps-for-spatial-computing","abstract":[{"type":"text","text":"Get ready to develop apps and games for visionOS! Discover the fundamental building blocks that make up spatial computing — windows, volumes, and spaces — and find out how you can use these elements to build engaging and immersive experiences."}],"kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","url":"\/documentation\/wwdcnotes\/wwdc23","title":"WWDC23","kind":"article","role":"collectionGroup","type":"topic","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14, tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"SwiftData"},{"type":"text","text":", "},{"type":"codeVoice","code":"Observation"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit"},{"type":"text","text":" views, and more."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10032-Meet-Assistive-Access":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10032-meet-assistive-access","role":"sampleCode","title":"Meet Assistive Access","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10032-Meet-Assistive-Access","abstract":[{"type":"text","text":"Learn how Assistive Access can help people with cognitive disabilities more easily use iPhone and iPad. Discover the design principles that guide Assistive Access and find out how the system experience adapts to lighten cognitive load. We’ll show you how Assistive Access works and what you can do to support this experience in your app."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-111215-Meet-UIKit-for-spatial-computing":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-111215-meet-uikit-for-spatial-computing","role":"sampleCode","title":"Meet UIKit for spatial computing","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111215-Meet-UIKit-for-spatial-computing","abstract":[{"type":"text","text":"Learn how to bring your UIKit app to visionOS. We’ll show you how to build for a new destination, explore APIs and best practices for spatial computing, and take your content into the third dimension when you use SwiftUI with UIKit in visionOS."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10043-Meet-MapKit-for-SwiftUI":{"role":"sampleCode","title":"Meet MapKit for SwiftUI","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10043-Meet-MapKit-for-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10043-meet-mapkit-for-swiftui","abstract":[{"type":"text","text":"Discover how expanded SwiftUI support for MapKit has made it easier than ever for you to integrate Maps into your app. We’ll show you how to use SwiftUI to add annotations and overlays to a map, control the camera, and more."}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10072-Principles-of-spatial-design":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","type":"topic","title":"Principles of spatial design","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10072-principles-of-spatial-design","abstract":[{"type":"text","text":"Discover the fundamentals of spatial design. Learn how to design with depth, scale, windows, and immersion, and apply best practices for creating comfortable, human-centered experiences that transform reality. Find out how you can use these spatial design principles to extend your existing app or bring a new idea to life."}]},"WWDC23-10109-spacial-swiftui-gestures":{"identifier":"WWDC23-10109-spacial-swiftui-gestures","type":"image","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10109-spacial-swiftui-gestures.png"}],"alt":"New SwiftUI gestures: RotateGesture3D, targetedToEntity, SpatialEventGesture, preferredHandAction, 3D properties on spatial gestures"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10184-Meet-ActivityKit":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10184-meet-activitykit","role":"sampleCode","title":"Meet ActivityKit","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10184-Meet-ActivityKit","abstract":[{"type":"text","text":"Live Activities are a glanceable way for someone to keep track of the progress of a task within your app. We’ll teach you how you can create helpful experiences for the Lock Screen, the Dynamic Island, and StandBy. Learn how to update your app’s Live Activities, monitor activity state, and take advantage of WidgetKit and SwiftUI to build richer experiences."}]},"https://developer.apple.com/wwdc23/10109":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10109","type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc23\/10109"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10187-Meet-SwiftData":{"role":"sampleCode","kind":"article","abstract":[{"text":"SwiftData is a powerful and expressive persistence framework built for Swift. We’ll show you how you can model your data directly from Swift code, use SwiftData to work with your models, and integrate with SwiftUI.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10187-meet-swiftdata","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10187-Meet-SwiftData","title":"Meet SwiftData"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10083-Meet-Reality-Composer-Pro":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10083-meet-reality-composer-pro","role":"sampleCode","title":"Meet Reality Composer Pro","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","abstract":[{"type":"text","text":"Discover how to easily compose, edit, and preview 3D content with Reality Composer Pro. Follow along as we explore this developer tool by setting up a new project, composing scenes, adding particle emitters and audio, and even previewing content on device."}]},"WWDC23-10109-immersion-styles":{"identifier":"WWDC23-10109-immersion-styles","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10109-immersion-styles.png"}],"type":"image","alt":"Styles of Immersion on visionOS: Mixed, Progressive, or Full"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10076-Design-for-spatial-user-interfaces":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10076-design-for-spatial-user-interfaces","abstract":[{"text":"Learn how to design great interfaces for spatial computing apps. We’ll share how your existing screen-based knowledge easily translates into creating great experiences for visionOS. Explore guidelines for UI components, materials, and typography and find out how you can design experiences that are familiar, legible, and easy to use.","type":"text"}],"kind":"article","type":"topic","title":"Design for spatial user interfaces"},"WWDC23-10109-model3d":{"identifier":"WWDC23-10109-model3d","variants":[{"traits":["1x","light"],"url":"\/images\/WWDC23-10109-model3d.png"}],"type":"image","alt":"Use Model3D in SwiftUI like an AsyncImage"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10025-Meet-Push-Notifications-Console":{"role":"sampleCode","kind":"article","abstract":[{"text":"The Push Notifications Console is the best way to quickly test user notifications in your app. Learn how you can iterate on new ideas quickly by sending notifications directly from the console and analyze delivery logs to learn more about your pushes. We’ll also show you how to generate and validate tokens to successfully authenticate with Apple Push Notification service (APNs).","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10025-meet-push-notifications-console","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10025-Meet-Push-Notifications-Console","title":"Meet Push Notifications Console"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10099-Meet-RealityKit-Trace":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10099-meet-realitykit-trace","role":"sampleCode","title":"Meet RealityKit Trace","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10099-Meet-RealityKit-Trace","abstract":[{"type":"text","text":"Discover how you can use RealityKit Trace to improve the performance of your spatial computing apps. Explore performance profiling guidelines for this platform and learn how the RealityKit Trace template can help you optimize rendering for your apps. We’ll also provide guidance on profiling various types of content in your app to help pinpoint performance issues."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10191-Meet-Object-Capture-for-iOS":{"role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can offer an end-to-end Object Capture experience directly in your iOS apps to help people turn their objects into ready-to-use 3D models. Learn how you can create a fully automated Object Capture scan flow with our sample app and how you can assist people in automatically capturing the best content for their model. We’ll also discuss LiDAR data and provide best practices for scanning objects.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10191-meet-object-capture-for-ios","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10191-Meet-Object-Capture-for-iOS","title":"Meet Object Capture for iOS"},"doc://WWDCNotes/documentation/WWDCNotes":{"title":"WWDC Notes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","url":"\/documentation\/wwdcnotes","type":"topic","role":"collection","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"kind":"symbol"},"https://avatars.githubusercontent.com/u/329601?v=4":{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/329601?v=4","variants":[{"traits":["1x","light"],"url":"https:\/\/avatars.githubusercontent.com\/u\/329601?v=4"}],"type":"image","alt":"Profile image of Rony Fadel"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10148-Whats-new-in-SwiftUI":{"abstract":[{"type":"text","text":"Learn how you can use SwiftUI to build great apps for all Apple platforms. Explore the latest updates to SwiftUI and discover new scene types for visionOS. Simplify your data models with the latest data flow options and learn about the Inspector view. We’ll also take you through enhanced animation APIs, powerful ScrollView improvements, and a host of refinements to help you make tidier tables, improve focus and keyboard input, and so much more."}],"kind":"article","role":"sampleCode","title":"What’s new in SwiftUI","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10148-Whats-new-in-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10148-whats-new-in-swiftui"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10039-Meet-device-management-for-Apple-Watch":{"role":"sampleCode","kind":"article","abstract":[{"text":"Organizations can now deploy and configure Apple Watch in addition to other Apple devices. Learn how to implement device management for watchOS to help organizations improve productivity, support wellness, and provide additional support for their employees.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10039-meet-device-management-for-apple-watch","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10039-Meet-device-management-for-Apple-Watch","title":"Meet device management for Apple Watch"}}}