{"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"schemaVersion":{"minor":3,"patch":0,"major":0},"kind":"article","seeAlsoSections":[{"title":"New Tools & Frameworks","generated":true,"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10184-Meet-ActivityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10032-Meet-Assistive-Access","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10147-Meet-Core-Location-Monitor","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10146-Meet-Core-Location-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10043-Meet-MapKit-for-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10191-Meet-Object-Capture-for-iOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10025-Meet-Push-Notifications-Console","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10099-Meet-RealityKit-Trace","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10279-Meet-Safari-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10013-Meet-StoreKit-for-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10171-Meet-Swift-OpenAPI-Generator","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10187-Meet-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10109-Meet-SwiftUI-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10039-Meet-device-management-for-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10268-Meet-mergeable-libraries","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10026-Meet-watchOS-10"]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111215-Meet-UIKit-for-spatial-computing"},"abstract":[{"type":"text","text":"Learn how to bring your UIKit app to visionOS. We’ll show you how to build for a new destination, explore APIs and best practices for spatial computing, and take your content into the third dimension when you use SwiftUI with UIKit in visionOS."}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-111215-meet-uikit-for-spatial-computing"]}],"sections":[],"sampleCodeDownload":{"kind":"sampleDownload","action":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/111215","isActive":true,"type":"reference","overridingTitle":"Watch Video (25 min)"}},"primaryContentSections":[{"content":[{"level":2,"anchor":"Getting-Started","type":"heading","text":"Getting Started"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"General tab > Add run destination > visionOS"}]}]},{"content":[{"inlineContent":[{"text":"Asset Catalog > New app icon","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"visionOS app icons have 3 layers that respond dynamically","type":"text"}]}]}],"type":"unorderedList"}]}],"type":"unorderedList"},{"level":2,"anchor":"Platform-Differences","type":"heading","text":"Platform Differences"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Cannot use APIs that were deprecated prior to iOS 14","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Cannot use APIs that don’t translate well to visionOS. Examples (not an exhaustive list, check the docs):","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"UIDeviceOrientation","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"UIScreen"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"UITabBar leading and trailing accessory views","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Tab bar is vertical"}],"type":"paragraph"}]}],"type":"unorderedList"}]},{"content":[{"inlineContent":[{"text":"Apple Pencil","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"}]},{"content":[{"inlineContent":[{"type":"text","text":"Use "},{"type":"codeVoice","code":"#if !os(visionOS)"},{"type":"text","text":" to exclude code that can’t run on visionOS."}],"type":"paragraph"}]}]},{"level":2,"anchor":"Polishing-Your-App","type":"heading","text":"Polishing Your App"},{"level":4,"anchor":"Simulator","type":"heading","text":"Simulator"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"In the simulator, clicking simulates looking at a spot and pinching your fingers."}]}]}]},{"level":4,"anchor":"Colors","type":"heading","text":"Colors"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Semantic colors are especially important for this platform.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use semantic colors, fonts, and materials."}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"codeVoice","code":"UIColor.label"},{"type":"text","text":", "},{"code":"UIColor.secondaryLabel","type":"codeVoice"},{"text":", etc.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Labels using semantic colors get vibrancy by default","type":"text"}]}]}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"In their case they wanted to update a text field to use "},{"code":"borderStyle = .roundedRect","type":"codeVoice"},{"type":"text","text":" to give a style that matched the visionOS search bar"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"No distinction between dark and light mode on visionOS."}]}]}]},{"level":4,"anchor":"Vibrancy-and-Materials","type":"heading","text":"Vibrancy and Materials"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"codeVoice","code":"UINavigationController"},{"type":"text","text":" and "},{"type":"codeVoice","code":"UISplitViewController"},{"type":"text","text":" get the glass background by default"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Can override background with the new "},{"type":"codeVoice","code":"preferredContainerBackgroundStyle"},{"type":"text","text":" property on "},{"type":"codeVoice","code":"UIViewController"},{"type":"text","text":" ("},{"type":"codeVoice","code":"automatic"},{"type":"text","text":", "},{"type":"codeVoice","code":"glass"},{"type":"text","text":" or "},{"type":"codeVoice","code":"hidden"},{"type":"text","text":")"}]}]}]},{"level":4,"anchor":"Hover","type":"heading","text":"Hover"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Makes app feel responsive","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Hover effects indicate interactivity","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Exactly where someone is looking is never delivered to your process","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"UIView"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"New property ","type":"text"},{"code":"hoverStyle","type":"codeVoice"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"code":"UIHoverStyle","type":"codeVoice"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"code":"highlight","type":"codeVoice"},{"text":" or ","type":"text"},{"code":"lift","type":"codeVoice"},{"text":", or remove by setting to ","type":"text"},{"code":"nil","type":"codeVoice"}]}]}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use "},{"code":"UIShape","type":"codeVoice"},{"type":"text","text":" to set shape of hover"}]}]}]}]}]},{"level":4,"anchor":"Input","type":"heading","text":"Input"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Looking at something and pinching is like a tap"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Looking at something, pinching, moving your hand, then releasing is like a pan gesture","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"If you’re close to the app you can also reach out and touch it"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"You can also use a trackpad","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Accessibility has voiceover and switch control","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"System gesture recognizers just work"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Maximum of two inputs on this platform (one for each hand). Gesture recognizers that look for more than 2 touches won’t work.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Can use ","type":"text"},{"code":"traitCollection.userInterfaceIdiom == .reality","type":"codeVoice"},{"text":" to check whether we’re running in a spatial computing environment, and then don’t use more than 2 touches","type":"text"}]}]}]},{"level":2,"anchor":"Outside-the-bounds","type":"heading","text":"Outside the bounds"},{"level":3,"anchor":"Presentations","type":"heading","text":"Presentations"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Sheets"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Pushes the presenting view controller back and dims it","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Won’t dismiss based on touches outside the bounds or other gestures, regardless of ","type":"text"},{"code":"isModalInPresentation","type":"codeVoice"},{"text":", unlike iPadOS","type":"text"}]}]}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Alerts"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"2D representation of the app icon is placed at the top of an alert"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Make sure to always present an alert from the view controller that should be pushed back","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Popovers"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"On iPad, popovers are constrained to the scene, but not in visionOS (similar to macOS)"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"May want to update "},{"type":"codeVoice","code":"permittedArrowDirections"},{"type":"text","text":" to "},{"type":"codeVoice","code":".any"},{"type":"text","text":" on popovers to handle cases where it would now be more natural for the popover to go beyond the bounds of the window."}],"type":"paragraph"}]}]}]}]},{"level":3,"anchor":"Ornaments","type":"heading","text":"Ornaments"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Views that are separate from but anchored to the scene."}]}]},{"content":[{"inlineContent":[{"text":"Requires SwiftUI","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Take advantage of the extra space the spatial platform provides","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Scene-relative placement","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Examples in the system","type":"text"}]},{"items":[{"content":[{"inlineContent":[{"text":"Tab View goes on leading side of scene","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Safari puts the address bar above page content"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Freeform puts a toolbar at the bottom"}]}]}],"type":"unorderedList"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Ornaments are placed forward from the main content, and outside the scene bounds","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Require SwiftUI","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Ornament Alignment"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Scene alignment and content alignment (add screenshots)","type":"text"}]}]}],"type":"unorderedList"}]},{"content":[{"inlineContent":[{"type":"text","text":"Create an array of "},{"type":"codeVoice","code":"UIHostingOrnament"},{"type":"text","text":" objects and set to "},{"type":"codeVoice","code":"self.ornaments"},{"type":"text","text":"."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Build SwiftUI content inside initializer ","type":"text"},{"code":"UIHostingOrnament(sceneAlignment: contentAlignment:)","type":"codeVoice"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Ornaments share controller lifecycle"}]}]}]},{"level":3,"anchor":"RealityKit","type":"heading","text":"RealityKit"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"There’s a new SwiftUI view, "},{"code":"RealityView","type":"codeVoice"},{"type":"text","text":", used to host RealityKit content (see talk “Build spatial experiences with RealityKit”)"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Use "},{"type":"codeVoice","code":"UIHostingController"},{"type":"text","text":" to use "},{"type":"codeVoice","code":"RealityView"},{"type":"text","text":" (show example code)"}],"type":"paragraph"}]}]},{"level":2,"anchor":"Written-By","type":"heading","text":"Written By"},{"numberOfColumns":5,"type":"row","columns":[{"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/227043?v=4"}]}],"size":1},{"content":[{"type":"heading","anchor":"Chris-Vasselli","level":3,"text":"Chris Vasselli"},{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/chrisvasselli","overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"isActive":true,"overridingTitle":"Contributed Notes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/github.com\/chrisvasselli","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/x.com\/chrisvasselli","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/","isActive":true}]}],"size":4}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"reference","isActive":true}]},{"level":2,"anchor":"Related-Sessions","type":"heading","text":"Related Sessions"},{"type":"links","style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10109-Meet-SwiftUI-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app"]},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"metadata":{"roleHeading":"WWDC23","role":"sampleCode","title":"Meet UIKit for spatial computing","modules":[{"name":"WWDC Notes"}]},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10279-Meet-Safari-for-spatial-computing":{"title":"Meet Safari for spatial computing","kind":"article","abstract":[{"text":"Discover the web for visionOS and learn how people can experience your web content in a whole new way. Explore the unique input model powering this platform and learn how you can optimize your website for spatial computing. We’ll also share how emerging standards are helping shape 3D experiences for the web.","type":"text"}],"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10279-meet-safari-for-spatial-computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10279-Meet-Safari-for-spatial-computing","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10147-Meet-Core-Location-Monitor":{"abstract":[{"type":"text","text":"Discover how Core Location Monitor can help you better understand location and beacon events in your app. Learn how to use Core Location Conditions to describe and track the state of events in your app, and find out how you can better respond to transitions in your apps through Swift semantics and improved reliability."}],"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10147-meet-core-location-monitor","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10147-Meet-Core-Location-Monitor","title":"Meet Core Location Monitor"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"kind":"article","role":"collectionGroup","title":"WWDC23","type":"topic","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","url":"\/documentation\/wwdcnotes\/wwdc23","abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14, tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"SwiftData","type":"codeVoice"},{"type":"text","text":", "},{"code":"Observation","type":"codeVoice"},{"type":"text","text":", "},{"code":"StoreKit","type":"codeVoice"},{"type":"text","text":" views, and more."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10203-Develop-your-first-immersive-app":{"kind":"article","role":"sampleCode","title":"Develop your first immersive app","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app","url":"\/documentation\/wwdcnotes\/wwdc23-10203-develop-your-first-immersive-app","abstract":[{"type":"text","text":"Find out how you can build immersive apps for visionOS using Xcode and Reality Composer Pro. We’ll show you how to get started with a new visionOS project, use Xcode Previews for your SwiftUI development, and take advantage of RealityKit and RealityView to render 3D content."}]},"doc://WWDCNotes/documentation/WWDCNotes/chrisvasselli":{"abstract":[{"text":"Indie app developer, dad, creator of","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/chrisvasselli","title":"Chris Vasselli (1 note)","url":"\/documentation\/wwdcnotes\/chrisvasselli","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","url":"\/documentation\/wwdcnotes","type":"topic","title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"kind":"symbol"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10013-Meet-StoreKit-for-SwiftUI":{"type":"topic","title":"Meet StoreKit for SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10013-meet-storekit-for-swiftui","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10013-Meet-StoreKit-for-SwiftUI","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can use App Store product metadata and Xcode Previews to add in-app purchases to your app with just a few lines of code. Explore a new collection of UI components in StoreKit and learn how you can easily merchandise your products, present subscriptions in a way that helps users make informed decisions, and more.","type":"text"}]},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"type":"link","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10191-Meet-Object-Capture-for-iOS":{"type":"topic","title":"Meet Object Capture for iOS","url":"\/documentation\/wwdcnotes\/wwdc23-10191-meet-object-capture-for-ios","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10191-Meet-Object-Capture-for-iOS","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can offer an end-to-end Object Capture experience directly in your iOS apps to help people turn their objects into ready-to-use 3D models. Learn how you can create a fully automated Object Capture scan flow with our sample app and how you can assist people in automatically capturing the best content for their model. We’ll also discuss LiDAR data and provide best practices for scanning objects.","type":"text"}]},"https://x.com/chrisvasselli":{"url":"https:\/\/x.com\/chrisvasselli","identifier":"https:\/\/x.com\/chrisvasselli","type":"link","title":"X\/Twitter","titleInlineContent":[{"type":"text","text":"X\/Twitter"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10268-Meet-mergeable-libraries":{"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10268-Meet-mergeable-libraries","role":"sampleCode","kind":"article","title":"Meet mergeable libraries","abstract":[{"text":"Discover how mergeable libraries combine the best parts of static and dynamic libraries to help improve your app’s productivity and runtime performance. Learn how you can enable faster development while shipping the smallest app. We’ll show you how to adopt mergeable libraries in Xcode 15 and share best practices for working with your code.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10268-meet-mergeable-libraries"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10184-Meet-ActivityKit":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10184-meet-activitykit","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10184-Meet-ActivityKit","title":"Meet ActivityKit","role":"sampleCode","abstract":[{"type":"text","text":"Live Activities are a glanceable way for someone to keep track of the progress of a task within your app. We’ll teach you how you can create helpful experiences for the Lock Screen, the Dynamic Island, and StandBy. Learn how to update your app’s Live Activities, monitor activity state, and take advantage of WidgetKit and SwiftUI to build richer experiences."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10025-Meet-Push-Notifications-Console":{"type":"topic","title":"Meet Push Notifications Console","url":"\/documentation\/wwdcnotes\/wwdc23-10025-meet-push-notifications-console","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10025-Meet-Push-Notifications-Console","role":"sampleCode","kind":"article","abstract":[{"text":"The Push Notifications Console is the best way to quickly test user notifications in your app. Learn how you can iterate on new ideas quickly by sending notifications directly from the console and analyze delivery logs to learn more about your pushes. We’ll also show you how to generate and validate tokens to successfully authenticate with Apple Push Notification service (APNs).","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10072-Principles-of-spatial-design":{"kind":"article","role":"sampleCode","title":"Principles of spatial design","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","url":"\/documentation\/wwdcnotes\/wwdc23-10072-principles-of-spatial-design","abstract":[{"type":"text","text":"Discover the fundamentals of spatial design. Learn how to design with depth, scale, windows, and immersion, and apply best practices for creating comfortable, human-centered experiences that transform reality. Find out how you can use these spatial design principles to extend your existing app or bring a new idea to life."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing":{"kind":"article","role":"sampleCode","title":"Elevate your windowed app for spatial computing","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc23-10110-elevate-your-windowed-app-for-spatial-computing","abstract":[{"type":"text","text":"Discover how you can bring your multiplatform SwiftUI app to visionOS and the Shared Space. We’ll show you how to add the visionOS destination to an existing app and view your app in the Simulator. Explore how your SwiftUI code automatically adapts to support the unique context and presentation of the visionOS platform. Learn how you can update custom views, improve your app’s UI, and add features and controls specific to this platform."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10032-Meet-Assistive-Access":{"abstract":[{"text":"Learn how Assistive Access can help people with cognitive disabilities more easily use iPhone and iPad. Discover the design principles that guide Assistive Access and find out how the system experience adapts to lighten cognitive load. We’ll show you how Assistive Access works and what you can do to support this experience in your app.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10032-meet-assistive-access","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10032-Meet-Assistive-Access","role":"sampleCode","title":"Meet Assistive Access","kind":"article"},"https://avatars.githubusercontent.com/u/227043?v=4":{"type":"image","alt":"Profile image of Chris Vasselli","identifier":"https:\/\/avatars.githubusercontent.com\/u\/227043?v=4","variants":[{"traits":["1x","light"],"url":"https:\/\/avatars.githubusercontent.com\/u\/227043?v=4"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10109-Meet-SwiftUI-for-spatial-computing":{"title":"Meet SwiftUI for spatial computing","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10109-Meet-SwiftUI-for-spatial-computing","abstract":[{"text":"Take a tour of the solar system with us and explore SwiftUI for visionOS! Discover how you can build an entirely new universe of apps with windows, volumes, and spaces. We’ll show you how to get started with SwiftUI on this platform as we build an astronomy app, add 3D content, and create a fully immersive experience to transport people to the stars.","type":"text"}],"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10109-meet-swiftui-for-spatial-computing","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10026-Meet-watchOS-10":{"url":"\/documentation\/wwdcnotes\/wwdc23-10026-meet-watchos-10","abstract":[{"type":"text","text":"Discover some of the most significant changes to Apple Watch since its introduction as we tour the redesigned user interface and the new Smart Stack. Learn how Apple designers approached the design of watchOS 10 as we explore layout, navigation, and visual style, and find out how you can apply them to create a great app for Apple Watch."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10026-Meet-watchOS-10","role":"sampleCode","title":"Meet watchOS 10","kind":"article","type":"topic"},"WWDCNotes.png":{"alt":null,"identifier":"WWDCNotes.png","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}],"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"kind":"article","role":"sampleCode","title":"Build spatial experiences with RealityKit","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","abstract":[{"type":"text","text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio."}]},"https://":{"type":"link","identifier":"https:\/\/","titleInlineContent":[{"text":"Blog","type":"text"}],"title":"Blog","url":"https:\/\/"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10171-Meet-Swift-OpenAPI-Generator":{"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10171-meet-swift-openapi-generator","title":"Meet Swift OpenAPI Generator","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10171-Meet-Swift-OpenAPI-Generator","abstract":[{"text":"Discover how Swift OpenAPI Generator can help you work with HTTP server APIs whether you’re extending an iOS app or writing a server in Swift. We’ll show you how this package plugin can streamline your workflow and simplify your codebase by generating code from an OpenAPI document.","type":"text"}],"role":"sampleCode","type":"topic"},"https://developer.apple.com/wwdc23/111215":{"url":"https:\/\/developer.apple.com\/wwdc23\/111215","identifier":"https:\/\/developer.apple.com\/wwdc23\/111215","type":"download","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10146-Meet-Core-Location-for-spatial-computing":{"url":"\/documentation\/wwdcnotes\/wwdc23-10146-meet-core-location-for-spatial-computing","abstract":[{"type":"text","text":"Discover how Core Location helps your app find its place in the world — literally. We’ll share how you can build a spatial computing app that uses a person’s location while respecting their privacy. You’ll also learn how your app can request location access and how Core Location adapts requests from compatible iPad and iPhone apps."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10146-Meet-Core-Location-for-spatial-computing","role":"sampleCode","title":"Meet Core Location for spatial computing","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10082-Meet-ARKit-for-spatial-computing":{"abstract":[{"type":"text","text":"Discover how you can use ARKit’s tracking and scene understanding features to develop a whole new universe of immersive apps and games. Learn how visionOS and ARKit work together to help you create apps that understand a person’s surroundings — all while preserving privacy. Explore the latest updates to the ARKit API and follow along as we demonstrate how to take advantage of hand tracking and scene geometry in your apps."}],"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10082-meet-arkit-for-spatial-computing","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","title":"Meet ARKit for spatial computing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10083-Meet-Reality-Composer-Pro":{"type":"topic","title":"Meet Reality Composer Pro","url":"\/documentation\/wwdcnotes\/wwdc23-10083-meet-reality-composer-pro","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how to easily compose, edit, and preview 3D content with Reality Composer Pro. Follow along as we explore this developer tool by setting up a new project, composing scenes, adding particle emitters and audio, and even previewing content on device.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10039-Meet-device-management-for-Apple-Watch":{"abstract":[{"type":"text","text":"Organizations can now deploy and configure Apple Watch in addition to other Apple devices. Learn how to implement device management for watchOS to help organizations improve productivity, support wellness, and provide additional support for their employees."}],"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10039-meet-device-management-for-apple-watch","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10039-Meet-device-management-for-Apple-Watch","title":"Meet device management for Apple Watch"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10043-Meet-MapKit-for-SwiftUI":{"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10043-meet-mapkit-for-swiftui","abstract":[{"text":"Discover how expanded SwiftUI support for MapKit has made it easier than ever for you to integrate Maps into your app. We’ll show you how to use SwiftUI to add annotations and overlays to a map, control the camera, and more.","type":"text"}],"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10043-Meet-MapKit-for-SwiftUI","title":"Meet MapKit for SwiftUI"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10187-Meet-SwiftData":{"type":"topic","abstract":[{"text":"SwiftData is a powerful and expressive persistence framework built for Swift. We’ll show you how you can model your data directly from Swift code, use SwiftData to work with your models, and integrate with SwiftUI.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10187-Meet-SwiftData","title":"Meet SwiftData","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10187-meet-swiftdata"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space":{"url":"\/documentation\/wwdcnotes\/wwdc23-10090-run-your-ipad-and-iphone-apps-in-the-shared-space","role":"sampleCode","abstract":[{"type":"text","text":"Discover how you can run your existing iPad and iPhone apps on Vision Pro. Learn how iPadOS and iOS apps operate on this platform, find out about the Designed for iPad experience, and explore the paths available for enhancing your app experience on visionOS."}],"title":"Run your iPad and iPhone apps in the Shared Space","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10099-Meet-RealityKit-Trace":{"type":"topic","title":"Meet RealityKit Trace","url":"\/documentation\/wwdcnotes\/wwdc23-10099-meet-realitykit-trace","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10099-Meet-RealityKit-Trace","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can use RealityKit Trace to improve the performance of your spatial computing apps. Explore performance profiling guidelines for this platform and learn how the RealityKit Trace template can help you optimize rendering for your apps. We’ll also provide guidance on profiling various types of content in your app to help pinpoint performance issues.","type":"text"}]},"https://github.com/chrisvasselli":{"type":"link","identifier":"https:\/\/github.com\/chrisvasselli","titleInlineContent":[{"text":"GitHub","type":"text"}],"title":"GitHub","url":"https:\/\/github.com\/chrisvasselli"}}}