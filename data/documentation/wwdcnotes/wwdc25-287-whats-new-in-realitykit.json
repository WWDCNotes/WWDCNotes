{"sections":[],"metadata":{"modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC25","role":"sampleCode","title":"What‚Äôs new in RealityKit"},"schemaVersion":{"patch":0,"major":0,"minor":3},"primaryContentSections":[{"kind":"content","content":[{"type":"heading","level":2,"text":"Overview","anchor":"overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true}]},{"type":"heading","level":2,"text":"Related Sessions","anchor":"Related-Sessions"},{"type":"links","style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-274-Better-together-SwiftUI-and-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-296-Support-immersive-video-playback-in-visionOS-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-289-Explore-spatial-accessory-input-on-visionOS"]}]}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-287-Whats-new-in-RealityKit","interfaceLanguage":"swift"},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc25-287-whats-new-in-realitykit"],"traits":[{"interfaceLanguage":"swift"}]}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"overridingTitle":"Watch Video (26 min)","type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/287"}},"kind":"article","hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25"]]},"abstract":[{"type":"text","text":"Unleash your creativity with new RealityKit features that can help you build rich 3D content for iOS, iPadOS, macOS, tvOS and visionOS. Learn how you can access ARKit data directly through RealityKit. Explore how you can interact with your 3D content more naturally using the object manipulation feature. Discover some new APIs for scene understanding, environment blending, instancing and much more, all using an interactive sample."}],"references":{"WWDCNotes.png":{"identifier":"WWDCNotes.png","type":"image","alt":null,"variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","role":"collection","title":"WWDC Notes","type":"topic","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"url":"\/documentation\/wwdcnotes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-274-Better-together-SwiftUI-and-RealityKit":{"title":"Better together: SwiftUI and RealityKit","url":"\/documentation\/wwdcnotes\/wwdc25-274-better-together-swiftui-and-realitykit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-274-Better-together-SwiftUI-and-RealityKit","type":"topic","kind":"article","abstract":[{"text":"Discover how to seamlessly blend SwiftUI and RealityKit in visionOS 26. We‚Äôll explore enhancements to Model3D, including animation and ConfigurationCatalog support, and demonstrate smooth transitions to RealityView. You‚Äôll learn how to leverage SwiftUI animations to drive RealityKit component changes, implement interactive manipulation, use new SwiftUI components for richer interactions, and observe RealityKit changes from your SwiftUI code. We‚Äôll also cover how to use unified coordinate conversion for cross-framework coordinate transformations.","type":"text"}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25":{"kind":"article","images":[{"type":"icon","identifier":"WWDC25-Icon.png"},{"type":"card","identifier":"WWDC25.jpg"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25","url":"\/documentation\/wwdcnotes\/wwdc25","title":"WWDC25","abstract":[{"text":"Xcode 26, Swift 6.2, iOS\/macOS\/tvOS\/visionOS 26.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"code":"Foundation Models","type":"codeVoice"},{"text":", ","type":"text"},{"code":"AlarmKit","type":"codeVoice"},{"text":", ","type":"text"},{"code":"PermissionKit","type":"codeVoice"},{"text":", and more.","type":"text"}],"role":"collectionGroup","type":"topic"},"https://developer.apple.com/videos/play/wwdc2025/287":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/287","type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/287"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-296-Support-immersive-video-playback-in-visionOS-apps":{"type":"topic","title":"Support immersive video playback in visionOS apps","url":"\/documentation\/wwdcnotes\/wwdc25-296-support-immersive-video-playback-in-visionos-apps","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-296-Support-immersive-video-playback-in-visionOS-apps","kind":"article","abstract":[{"type":"text","text":"Discover how to play immersive videos in visionOS apps. We‚Äôll cover various immersive rendering modes, review the frameworks that support them, and walk through how to render immersive video in your app. To get the most out of this video, we recommend first watching ‚ÄúExplore video experiences for visionOS‚Äù from WWDC25."}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25-289-Explore-spatial-accessory-input-on-visionOS":{"role":"sampleCode","title":"Explore spatial accessory input on visionOS","abstract":[{"text":"Learn how you can integrate spatial accessories into your app. Display virtual content, interact with your app, track them in space, and get information on interactions for enhanced virtual experiences on visionOS.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-289-Explore-spatial-accessory-input-on-visionOS","url":"\/documentation\/wwdcnotes\/wwdc25-289-explore-spatial-accessory-input-on-visionos","kind":"article"},"WWDC25-Icon.png":{"identifier":"WWDC25-Icon.png","alt":null,"variants":[{"url":"\/images\/WWDCNotes\/WWDC25-Icon.png","traits":["1x","light"]}],"type":"image"},"WWDC25.jpg":{"identifier":"WWDC25.jpg","type":"image","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDC25.jpg"}]},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","type":"link","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"text":"Learn More‚Ä¶","type":"text"}]}}}