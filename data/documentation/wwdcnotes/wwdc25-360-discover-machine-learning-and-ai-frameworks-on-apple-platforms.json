{"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc25-360-discover-machine-learning-and-ai-frameworks-on-apple-platforms"],"traits":[{"interfaceLanguage":"swift"}]}],"sections":[],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-360-Discover-machine-learning-and-AI-frameworks-on-Apple-platforms","interfaceLanguage":"swift"},"kind":"article","hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25"]]},"primaryContentSections":[{"kind":"content","content":[{"type":"heading","text":"Key Takeaways","level":2,"anchor":"Key-Takeaways"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"üì± Foundation Models framework provides access to the on-device language model"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"üìå ML-Powered APIs assist in complex tasks for specific use-cases","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"üç∫ You can bring your own model to device"}]}]},{"content":[{"inlineContent":[{"text":"üíª MLX helps you tune and train models on Apple Silicon","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC25-360-Summary"}]},{"type":"heading","text":"Presenters","level":2,"anchor":"Presenters"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Jaimin Upadhyay, Core ML"}]}]}],"type":"unorderedList"},{"type":"heading","text":"Platform Intelligence","level":2,"anchor":"Platform-Intelligence"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"ML and AI are used through the platform to provide powerful features and experiences"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"A wide range of ML-powered APis are available to provide functionality in your app"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Foundation Models framework allows apps to access the on-device language model"}],"type":"paragraph"}]}],"type":"unorderedList"},{"type":"heading","text":"ML-Powered APIs","level":2,"anchor":"ML-Powered-APIs"},{"type":"table","header":"row","rows":[[[{"inlineContent":[{"type":"text","text":"Framework"}],"type":"paragraph"}],[{"inlineContent":[{"type":"text","text":"Use"}],"type":"paragraph"}]],[[{"inlineContent":[{"text":"Vision","type":"text"}],"type":"paragraph"}],[{"inlineContent":[{"type":"text","text":"Understand the content of images and videos"}],"type":"paragraph"}]],[[{"inlineContent":[{"type":"text","text":"Natural Language"}],"type":"paragraph"}],[{"inlineContent":[{"text":"Identify language, parts of speech, and named entities in natural language text","type":"text"}],"type":"paragraph"}]],[[{"inlineContent":[{"text":"Translation","type":"text"}],"type":"paragraph"}],[{"inlineContent":[{"text":"Perform text translations between multiple languages.","type":"text"}],"type":"paragraph"}]],[[{"inlineContent":[{"text":"Sound Analysis","type":"text"}],"type":"paragraph"}],[{"inlineContent":[{"type":"text","text":"Recognize many categories of sound"}],"type":"paragraph"}]],[[{"inlineContent":[{"type":"text","text":"Speech"}],"type":"paragraph"}],[{"inlineContent":[{"type":"text","text":"Identify and transcribe spoken words in audio"}],"type":"paragraph"}]],[[{"inlineContent":[{"type":"text","text":"Foundation Models"}],"type":"paragraph"}],[{"inlineContent":[{"type":"text","text":"Access to an on-device language model specialized for everyday tasks"}],"type":"paragraph"}]]]},{"type":"heading","text":"Image Generation","level":3,"anchor":"Image-Generation"},{"items":[{"content":[{"inlineContent":[{"text":"Image Playground Framework provides SwiftUI extensions to bring up the ","type":"text"},{"type":"codeVoice","code":"imagePlaygroundSheet"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"codeVoice","code":"ImageCreator"},{"type":"text","text":" allows you to create images programmatically"}]}]}],"type":"unorderedList"},{"code":["import ImagePlayground","","let creator = try await ImageCreator()","","let images = creator.images(","   for: [.text(\"A cat wearing mittens.\")],","   style: selectedStyle,","   limit: 4",")","","for try await image in images {","   doStuff(with: image.cgImage)","}"],"type":"codeListing","syntax":"swift"},{"type":"heading","text":"Smart Reply","level":3,"anchor":"Smart-Reply"},{"items":[{"content":[{"inlineContent":[{"text":"Allows users to choose generated smart replies for messages and emails.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"The context must be donated to the keyboard to use Smart Reply","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"code":["let context = UIMailConversationContext()","context.entries = ...","","...","","entryField.conversationContext = context","","...","","func textField(_ :UITextField, insertInputSuggestion inputSuggestion: UIInputSuggestion) {","   ...","","   entryField.text = generateLongForm(from: inputSuggestion)","}"],"type":"codeListing","syntax":"swift"},{"type":"heading","text":"Foundation Models Framework","level":2,"anchor":"Foundation-Models-Framework"},{"items":[{"content":[{"inlineContent":[{"text":"Provides programmatic access to a highly optimized on-device language model specialized for everyday tasks","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"User‚Äôs data stays private and doesn‚Äôt need to be sent anywhere","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"No cost to developers or users","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Features work offline","type":"text"}]}]}],"type":"unorderedList"},{"code":["import FoundationModels","","let session - LanguageModelSession()","","let response = try a wait session.respond(to: \"Tell a joke\")",""],"type":"codeListing","syntax":"swift"},{"type":"heading","text":"Structured Responses","level":4,"anchor":"Structured-Responses"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Foundation Models framework can provide structured responses within your app"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Mark types as ","type":"text"},{"code":"@Generable","type":"codeVoice"},{"text":" to allow Foundation Models framework to generate the type","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Use "},{"type":"codeVoice","code":"@Guide"},{"type":"text","text":" to provide natural language guides for properties"}],"type":"paragraph"}]}]}]}],"type":"unorderedList"},{"code":["let prompt = \"Generate a list of suggested search terms for an app about visiting famous landmarks.\"","","let response = try await session.respond(","   to: prompt,","   generating: SearchSuggestions.self",")","","@Generable","private struct SearchSuggestions {","   @Guide(description: \"A list of suggested search terms\", .count(4))","   var searchTerms: [SearchTerm]","}","","@Generable","struct SearchTerm: Identifiable, Equatable {","   @Guide(description: \"A unique id\", .pattern(\\search-term-\\(d\/))","   var id: String","","   @Guide(description: \"A 2-3 word search term, like 'Beautiful sunsets'\")","   var content: String","}"],"type":"codeListing","syntax":"swift"},{"type":"heading","text":"Tool Calling","level":4,"anchor":"Tool-Calling"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"The foundation model data is fixed in time and does not contain recent events","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Tool calling let you provide additional data to the model","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Tools can take real actions, in your app, on the system, or in real world.","type":"text"}]}]}],"type":"unorderedList"},{"type":"heading","text":"Vision","level":2,"anchor":"Vision"},{"items":[{"content":[{"inlineContent":[{"text":"Includes 30 APIs for different types of image analysis","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"type":"heading","text":"New APIs","level":3,"anchor":"New-APIs"},{"items":[{"content":[{"inlineContent":[{"type":"text","text":"Document Recognition can group document structures making it easier to process and understand documents"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Lens Smudge Detection helps identify smudges on a camera lens"}],"type":"paragraph"}]}],"type":"unorderedList"},{"type":"heading","text":"Speech","level":2,"anchor":"Speech"},{"items":[{"content":[{"inlineContent":[{"type":"codeVoice","code":"SFSpeechRecognizer"},{"type":"text","text":" works well for short-form dictation"}],"type":"paragraph"}]}],"type":"unorderedList"},{"type":"heading","text":"New APIs","level":3,"anchor":"New-APIs"},{"items":[{"content":[{"inlineContent":[{"type":"codeVoice","code":"SpeechAnalyzer"},{"type":"text","text":" supports many more use cases and is run completely on device"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"A new speech-to-text model that is faster and more flexible"}]}]}],"type":"unorderedList"},{"type":"heading","text":"ML Models","level":2,"anchor":"ML-Models"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"All previously mentioned APIs access models built into the system","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Any model can be brought to the device in a Core ML format."}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"A collection of open models in the Core ML format is available on "},{"type":"reference","identifier":"https:\/\/developer.apple.com\/machine-learning\/models\/","isActive":true}]}]}],"type":"unorderedList"}]},{"content":[{"inlineContent":[{"text":"MLX provides access to state-of-the-art models and the ability to fine tuning and train on Apple Silicon machines.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"type":"heading","text":"Written By","level":2,"anchor":"Written-By"},{"type":"row","numberOfColumns":5,"columns":[{"size":1,"content":[{"inlineContent":[{"type":"image","identifier":"harrison-heinig"}],"type":"paragraph"}]},{"size":4,"content":[{"level":3,"anchor":"Harrison-Heinig","type":"heading","text":"Harrison Heinig"},{"type":"paragraph","inlineContent":[{"overridingTitle":"Contributed Notes","type":"reference","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/harrison-heinig","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/github.com\/harrison-heinig","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/","isActive":true}]}]}]},{"type":"thematicBreak"},{"type":"paragraph","inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true}]},{"type":"heading","text":"Related Sessions","level":2,"anchor":"Related-Sessions"},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"type":"small","inlineContent":[{"text":"All content copyright ¬© 2012 ‚Äì 2025 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}]}]}],"abstract":[{"text":"Tour the latest updates to machine learning and AI frameworks available on Apple platforms. Whether you are an app developer ready to tap into Apple Intelligence, an ML engineer optimizing models for on-device deployment, or an AI enthusiast exploring the frontier of what is possible, we‚Äôll offer guidance to help select the right tools for your needs.","type":"text"}],"metadata":{"title":"Discover machine learning & AI frameworks on Apple platforms","modules":[{"name":"WWDC Notes"}],"role":"sampleCode","roleHeading":"WWDC25"},"schemaVersion":{"minor":3,"patch":0,"major":0},"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (19 min)","type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/360","isActive":true}},"references":{"WWDCNotes.png":{"alt":null,"identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"type":"image"},"harrison-heinig":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/harrison-heinig.jpeg"}],"type":"image","identifier":"harrison-heinig","alt":"Profile image of Harrison Heinig"},"WWDC25-360-Summary":{"type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDC25-360-Summary.jpeg","traits":["1x","light"]}],"alt":null,"identifier":"WWDC25-360-Summary"},"https://developer.apple.com/machine-learning/models/":{"titleInlineContent":[{"text":"developer.apple.com","type":"text"}],"identifier":"https:\/\/developer.apple.com\/machine-learning\/models\/","url":"https:\/\/developer.apple.com\/machine-learning\/models\/","type":"link","title":"developer.apple.com"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"title":"Contributions are welcome!","type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"WWDC25.jpg":{"type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDC25.jpg","traits":["1x","light"]}],"alt":null,"identifier":"WWDC25.jpg"},"https://github.com/harrison-heinig":{"titleInlineContent":[{"text":"GitHub","type":"text"}],"identifier":"https:\/\/github.com\/harrison-heinig","url":"https:\/\/github.com\/harrison-heinig","type":"link","title":"GitHub"},"doc://WWDCNotes/documentation/WWDCNotes/harrison-heinig":{"kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/harrison-heinig","type":"topic","title":"Harrison Heinig (5 notes)","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/harrison-heinig","images":[{"type":"card","identifier":"harrison-heinig.jpeg"},{"type":"icon","identifier":"harrison-heinig.jpeg"}],"abstract":[{"type":"text","text":"No Bio on GitHub"}]},"harrison-heinig.jpeg":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/harrison-heinig.jpeg"}],"type":"image","identifier":"harrison-heinig.jpeg","alt":null},"WWDC25-Icon.png":{"type":"image","variants":[{"url":"\/images\/WWDCNotes\/WWDC25-Icon.png","traits":["1x","light"]}],"alt":null,"identifier":"WWDC25-Icon.png"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC25":{"type":"topic","role":"collectionGroup","images":[{"identifier":"WWDC25-Icon.png","type":"icon"},{"identifier":"WWDC25.jpg","type":"card"}],"abstract":[{"type":"text","text":"Xcode 26, Swift 6.2, iOS\/macOS\/tvOS\/visionOS 26."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"Foundation Models"},{"type":"text","text":", "},{"type":"codeVoice","code":"AlarmKit"},{"type":"text","text":", "},{"type":"codeVoice","code":"PermissionKit"},{"type":"text","text":", and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25","title":"WWDC25","url":"\/documentation\/wwdcnotes\/wwdc25","kind":"article"},"https://developer.apple.com/videos/play/wwdc2025/360":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/360","checksum":null,"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/360","type":"download"},"https://":{"titleInlineContent":[{"text":"Blog","type":"text"}],"title":"Blog","type":"link","identifier":"https:\/\/","url":"https:\/\/"},"doc://WWDCNotes/documentation/WWDCNotes":{"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"kind":"symbol","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"url":"\/documentation\/wwdcnotes","role":"collection"}}}