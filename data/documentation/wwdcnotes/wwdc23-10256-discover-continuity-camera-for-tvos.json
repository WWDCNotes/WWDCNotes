{"metadata":{"role":"sampleCode","roleHeading":"WWDC23","title":"Discover Continuity Camera for tvOS","modules":[{"name":"WWDC Notes"}]},"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video","type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10256"}},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes"]]},"sections":[],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10256-discover-continuity-camera-for-tvos"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10256-Discover-Continuity-Camera-for-tvOS","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"Discover how you can bring AVFoundation, AVFAudio, and AudioToolbox to your apps on tvOS and create camera and microphone experiences for the living room. Find out how to support tvOS in your existing iOS camera experience with the Device Discovery API, build apps that use iPhone as a webcam or FaceTime source, and explore special considerations when developing for tvOS. We‚Äôll also show you how to enable audio recording for tvOS, and how to use echo cancellation to create great voice-driven experiences."}],"schemaVersion":{"patch":0,"major":0,"minor":3},"kind":"article","primaryContentSections":[{"kind":"content","content":[{"level":2,"type":"heading","anchor":"overview","text":"Overview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","isActive":true}]},{"level":2,"type":"heading","anchor":"Written-By","text":"Written By"},{"type":"row","columns":[{"content":[{"type":"paragraph","inlineContent":[{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4"}]}],"size":1},{"content":[{"type":"heading","level":3,"text":"[To Do](<doc:<replace this with your GitHub handle>>)","anchor":"To-Do<doc<replace-this-with-your-GitHub-handle>>"},{"type":"paragraph","inlineContent":[{"type":"text","text":"An amazing developer."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"[Contributed Notes](<doc:"},{"type":"text","text":">)"},{"type":"text","text":" "},{"identifier":"https:\/\/x.com\/Jeehut","type":"reference","isActive":true}]}],"size":4}],"numberOfColumns":5},{"level":2,"type":"heading","anchor":"Related-Sessions","text":"Related Sessions"},{"style":"list","type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10235-Whats-new-in-voice-processing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10018-Bring-Continuity-Camera-to-your-macOS-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110429-Discover-advancements-in-iOS-camera-capture-Depth-focus-and-multitasking"]},{"type":"small","inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright ¬© 2012 ‚Äì 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}]}],"references":{"WWDCNotes.png":{"alt":null,"type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"identifier":"WWDCNotes.png"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110429-Discover-advancements-in-iOS-camera-capture-Depth-focus-and-multitasking":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110429-Discover-advancements-in-iOS-camera-capture-Depth-focus-and-multitasking","role":"sampleCode","title":"Discover advancements in iOS camera capture: Depth, focus, and multitasking","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc22-110429-discover-advancements-in-ios-camera-capture-depth-focus-and-multitasking","abstract":[{"type":"text","text":"Discover how you can take advantage of advanced camera capture features in your app. We‚Äôll show you how to use the LiDAR scanner to create photo and video effects and perform accurate depth measurement. Learn how your app can use the camera for picture-in-picture or multitasking, control face-driven autofocus and autoexposure during camera capture, and more. We‚Äôll also share strategies for using multiple video outputs so that you can optimize live preview while capturing high-quality video output."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10018-Bring-Continuity-Camera-to-your-macOS-app":{"role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10018-Bring-Continuity-Camera-to-your-macOS-app","title":"Bring Continuity Camera to your macOS app","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10018-bring-continuity-camera-to-your-macos-app","abstract":[{"text":"Discover how you can use iPhone as an external camera in any Mac app with Continuity Camera. Whether you‚Äôre building video conferencing software or an experience that makes creative use of cameras, we‚Äôll show you how you can enhance your app with automatic camera switching. We‚Äôll also explore how to recognize user-preferred and system-preferred cameras, take you through APIs for high-resolution and high-quality photo capture from iPhone‚Äôs video stream, and more.","type":"text"}]},"https://avatars.githubusercontent.com/u/123?v=4":{"alt":"Profile image of To Do","type":"image","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4","traits":["1x","light"]}],"identifier":"https:\/\/avatars.githubusercontent.com\/u\/123?v=4"},"https://x.com/Jeehut":{"title":"X\/Twitter","titleInlineContent":[{"text":"X\/Twitter","type":"text"}],"type":"link","url":"https:\/\/x.com\/Jeehut","identifier":"https:\/\/x.com\/Jeehut"},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"type":"topic","role":"collection","url":"\/documentation\/wwdcnotes","title":"WWDC Notes","kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10235-Whats-new-in-voice-processing":{"type":"topic","kind":"article","title":"What‚Äôs new in voice processing","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10235-Whats-new-in-voice-processing","abstract":[{"type":"text","text":"Learn how to use the Apple voice processing APIs to achieve the best possible audio experience in your VoIP apps. We‚Äôll show you how to detect when someone is talking while muted, adjust ducking behavior of other audio, and more."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10235-whats-new-in-voice-processing"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"title":"Learn More‚Ä¶","titleInlineContent":[{"text":"Learn More‚Ä¶","type":"text"}],"type":"link","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"},"https://developer.apple.com/wwdc23/10256":{"type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc23\/10256","identifier":"https:\/\/developer.apple.com\/wwdc23\/10256"}}}