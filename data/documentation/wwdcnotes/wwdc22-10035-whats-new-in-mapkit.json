{"sampleCodeDownload":{"action":{"isActive":true,"type":"reference","overridingTitle":"Watch Video (41 min)","identifier":"https:\/\/developer.apple.com\/wwdc22\/10035"},"kind":"sampleDownload"},"schemaVersion":{"major":0,"patch":0,"minor":3},"sections":[],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc22-10035-whats-new-in-mapkit"],"traits":[{"interfaceLanguage":"swift"}]}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22"]]},"abstract":[{"type":"text","text":"Come along with us as MapKit enters a new dimension. We’ll show you how you can upgrade your app to use the latest map and support the highly-detailed 3D City Experience. Learn how you can visualize data using overlays while ensuring they integrate smoothly into the 3D map. We’ll also cover how to create interactive and immersive experiences with Selectable Map Features and Look Around APIs."}],"kind":"article","primaryContentSections":[{"content":[{"type":"heading","anchor":"overview","text":"Overview","level":2},{"type":"paragraph","inlineContent":[{"text":"Originally launched with U.S. support, the all-new map and Look Around coverage has been expanding since and now includes Canada, many European countries, Japan, and more.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-maps1"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Last year, Apple Maps introduced the 3D City Experiences, featuring turn lanes, crosswalks, bike lanes, and handcrafted 3D landmarks like the Ferry Building."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-ferryBuilding"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The additional detail of the map allows to provide context and precision and a high level of realism."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-london","type":"image"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-goldenGate","type":"image"}]},{"type":"heading","anchor":"New-MapKit-features","text":"New MapKit features.","level":1},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"The Map Configuration API."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Improvements to the overlay APIs"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"New blend modes support","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"brand-new Selectable Map Features API.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Integrating the immersive Look Around experience","type":"text"}]}]}]},{"type":"heading","anchor":"Map-Configuration-API","text":"Map Configuration API.","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"To adopt the all-new map is easy and we just need to recompile our app with the new SDK; it will be automatically opted in to the all-new Apple map, including the 3D City Experience, where available."}]},{"type":"paragraph","inlineContent":[{"text":"In iOS 15, the way to configure the map is through various properties on MKMapView. In iOS 16, however, those properties are being softly deprecated.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-DeprecatedAPI"}]},{"type":"paragraph","inlineContent":[{"text":"and a new Map Configuration API is being introduced as a replacement.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["\/\/ Configuring your map view","class MKMapView {","    ...","    var preferredConfiguration: MKMapConfiguration","}"]},{"type":"paragraph","inlineContent":[{"code":"MKMapConfiguration","type":"codeVoice"},{"text":" is the central class of the new Map Configuration API. ","type":"text"},{"code":"MKMapConfiguration","type":"codeVoice"},{"text":" is an abstract base class with three concrete subclasses.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKMapConfiguration {","}","","class MKImageryMapConfiguration : MKMapConfiguration {","}","","class MKHybridMapConfiguration : MKMapConfiguration {","}","","class MKStandardMapConfiguration : MKMapConfiguration {","}"]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The imagery map configuration is used to present satellite-style imagery."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"The hybrid map configuration is used to present an imagery-based map with added map features such as road labels and points of interest.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The standard map configuration is used to present a fully graphics-based map."}]}]}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-mapsImagery"}]},{"type":"heading","anchor":"The-elevation-style-property","text":"The elevation style property.","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"The base map configuration class supports an "},{"type":"codeVoice","code":"elevationStyle"},{"type":"text","text":" property, which can be either flat or realistic. A flat elevation style means that the ground appears flat. Roads, including bridges and overpasses, also appear flat."}]},{"type":"paragraph","inlineContent":[{"text":"Flat is the default elevation style. A realistic elevation style means that the ground terrain reproduces the real-world elevation such as hills and mountains. Roads are depicted with realistic elevation details.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKMapConfiguration {","    var elevationStyle: ElevationStyle","}","","extension MKMapConfiguration {","    enum ElevationStyle {","        case flat ","        case realistic","    }","}"]},{"type":"heading","anchor":"The-map-configuration-subclasses","text":"The map configuration subclasses.","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"The imagery map configuration only shows satellite imagery with no additional map features, so it doesn’t have any other properties."}]},{"type":"codeListing","syntax":"swift","code":["class MKImageryMapConfiguration : MKMapConfiguration {","    ","}"]},{"type":"paragraph","inlineContent":[{"text":"The hybrid map configuration has additional properties to control filtering of point of interest categories and whether to show traffic or not.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKHybridMapConfiguration : MKMapConfiguration {","    var point0fInterestFilter: MKPointOfInterestFilter?","    var showsTraffic: Bool","}"]},{"type":"paragraph","inlineContent":[{"text":"The standard map configuration supports an ","type":"text"},{"type":"codeVoice","code":"emphasisStyle"},{"text":" property which can be either default or muted.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"class MKStandardMapConfiguration : MKMapConfiguration {","type":"text"},{"text":" ","type":"text"},{"text":"var emphasisStyle: EmphasisStyle","type":"text"},{"text":" ","type":"text"},{"text":"}","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"As the name implies, this is the default emphasis style unless otherwise stated. The muted emphasis style softens the contrasts of the map details.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-standardMapConfig"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The standard map configuration also has additional properties to control filtering of point of interest categories and whether to show traffic or not."}]},{"type":"codeListing","syntax":"swift","code":["class MKStandardMapConfiguration : MKMapConfiguration {","    var emphasisStyle: EmphasisStyle ","    var pointOfInterestFilter: MKPoint0fInterestFilter?","    var showsTraffic: Bool","}"]},{"type":"heading","anchor":"Map-type-mapping","text":"Map type mapping","level":2},{"type":"paragraph","inlineContent":[{"text":"Here’s a table that shows the correspondence between the new map configuration classes and the ","type":"text"},{"type":"codeVoice","code":"MKMapType"},{"text":" property.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-mapTypeMapping","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"The all-new map with the 3D City Experience requires compatible hardware. On iOS, the new map support requires A12-based iPhones and iPads or later. On macOS, the new map support requires any M1-based computer or later.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-deviceSupport"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"In areas where the 3D City Experience is not available, the map will automatically fall back to present the all-new map with a flat elevation. On all other devices, the all-new map will be presented with a flat elevation."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"On M1 Macs, Xcode allows you to simulate both experiences simply by changing the OS version."}]},{"type":"heading","anchor":"3D-City-Experience","text":"3D City Experience","level":2},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"San Francisco Bay Area"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Los Angeles","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"New York","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"London"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Washington, DC"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"San Diego"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Philadelphia","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Toronto","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Montreal","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Vancouver"}]}]}]},{"type":"heading","anchor":"Overlays","text":"Overlays","level":1},{"type":"paragraph","inlineContent":[{"text":"MapKit has supported overlays with several styling options for years. In iOS 16, there are some additions.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Overlays can be rendered at two different levels: above roads and above labels. You can specify the rendering level at insertion time using one of MapKit’s many overlay insertion functions."}]},{"type":"codeListing","syntax":"swift","code":["\/\/ Overlay levels","class MKMapView {","    func addOverlay(_: MKOverlay, level: MKOverlayLevel)","    \/\/ ...","}","","public enum MKOverlayLevel {","    case aboveLabels ","    case aboveRoads","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Above labels renders the overlay above everything, including labels. Since labels provide important context information, only use above labels in those rare cases where we don’t want the data to interact with the map at all. Consider using the muted map emphasis or the blend modes."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Above roads means the overlay will be shown on top of the terrain, including roads, land cover, or bodies of water. It will, however, be shown below labels and, to some degree, trees and buildings. See the screenshot on the right below."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Above roads will be the new default mode in iOS 16."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-aboveLevels"}]},{"type":"heading","anchor":"Transparent-buildings","text":"Transparent buildings","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"There is a new feature in iOS 16 called transparent buildings."}]},{"type":"paragraph","inlineContent":[{"text":"Regardless of whether the overlay level is above roads or above labels, it will always be rendered on top of buildings when viewed top-down with no pitch.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-aboveLevels2","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Ground objects such as trees and buildings are now automatically rendered with transparency when appearing above overlays, so as not to fully obscure them. The alpha value varies with the map’s pitch angle. Reverting to showing the map top-down with a 0º pitch angle, colliding ground objects effectively disappear from view, leaving the overlays fully visible.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Transparent buildings also work for semi-transparent overlays. The alpha value of the overlay will be added to combine with the alpha value of the transparent buildings."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-aboveLevels3"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"There’s one more change to overlays. When adding an overlay to a map with realistic terrain,"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-aboveLevels4"}]},{"type":"paragraph","inlineContent":[{"text":"MapKit will automatically transition the map to a flat representation.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-aboveLevels5"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The map will automatically go back to realistic when removing the last overlay. One notable exception to this rule are overlays sourced through MapKit’s directions API. Those overlays automatically follow the terrain."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-aboveLevels6"}]},{"type":"heading","anchor":"Adding-Polygon-Overlays","text":"Adding Polygon Overlays","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"Using the sample app, which helps users rent scooters to tour San Francisco."}]},{"type":"paragraph","inlineContent":[{"text":"The app offers a number of features, as shown by the rows in this table view. “Operating Area” allows the user to see where they can take our scooters. “Ride” takes the user on a tour across the Golden Gate Bridge. “Explore” gives the user an interactive map of downtown San Francisco, which they can use to explore attractions near the waterfront. “Highlights” offers a closer look at must-see places. We will implement or upgrade these features throughout this session.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"We are going to use the Operating Area feature.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-sampleApp1","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"let’s add a polygon overlay to visualize the operating area. When the view is loaded, we’ll first set the region and the camera boundary."}]},{"type":"codeListing","syntax":"swift","code":["import MapKit","","\/\/ This class displays elevated route line overlay loaded from MapKit server on a map view.","","class PolygonOverlayViewController: UIViewController, MKMapViewDelegate {","","    @IBOutlet var mapView: MKMapView!","    ","    private let dataSource: OverlayDataSource","","    required init? (coder: NSCoder) {","        dataSource = OverlavDataSource()","        super.init (coder: coder)","    }","        ","    override func viewDidLoad() {","        super.viewDidLoad ()","        mapView.region = .overlay","        ","        mapView.cameraBoundary = MKMapView.CameraBoundary(coordinateRegion: .overlayCameraBoundary)","        ","        mapView.addOverlays(dataSource.overlays, level: .aboveRoads)","    }","","    \/\/ MARK: - MKMapViewDelegate","    func mapView(_ mapView: MKMapView, rendererFor overlay: MKOverlay) -> MKOverlayRenderer {","        let renderer: MKOverlayPathRenderer","        ","        if let multiPolygon = overlay as? MKMultiPolygon {","            renderer = MKMultiPolygonRenderer(multiPolygon: multiPolygon)","            renderer.fillColor = UIColor(red: 1, green: 0.59, blue: 0.7, alpha: 1.0)","            renderer.strokeColor = UIColor(red: 0.63, green: 0.27, blue: 0.63, alpha: 1.0)","            renderer.linewidth = 3.0","        else {","            renderer = MKOverlayPathRenderer(overlay: overlay)","        return renderer","        }","    }","    \/\/...","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The polygon overlay is opaque when viewed straight down. As we zoom in and pitch, the buildings begin to show, with the transparency increasing as we pitch further. This effect is only available when using the overlay level AboveRoads."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-sampleApp2","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"To want to leverage transparent buildings and trees, choose the correct overlay level.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Let’s go back to the code and make the overlay semi-transparent with alpha to 0.8.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Now we have a transparent overlay and we can see roads and buildings even when not pitched."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-sampleApp3"}]},{"type":"heading","anchor":"Integrate-realistic-terrain-and-show-adding-an-elevated-route-line","text":"Integrate realistic terrain and show adding an elevated route line","level":2},{"type":"paragraph","inlineContent":[{"text":"We will integrate realistic terrain and add an elevated route line. This will complete our “Ride” feature of the app, a tour across the Golden Gate Bridge.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Start by configuring the map view. We can change the elevation style in code, or we can just open the Interface Builder inspector on the right-hand side."}]},{"type":"paragraph","inlineContent":[{"text":"Here are the available map view configuration settings. Let’s select “elevation: realistic”.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-sampleApp4"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Next, let’s work on the route."}]},{"type":"paragraph","inlineContent":[{"text":"For this feature, we want to show a route when the user toggles the Show Route switch. We will also animate the camera to focus on the route.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Since we want to show a route across the Golden Gate Bridge, we’ll use the Presidio Park entry as the start point and the Battery Spencer as the end point."}]},{"type":"codeListing","syntax":"swift","code":["imроrt UIKit","import MapKit","","","\/\/This class displays elevated route line overlay loaded from MapKit server on a map view.","","class Polyline0verlayViewController: UIViewController, MKMapViewDelegate {","    @IBOutlet private var mapView: MKMapView!","    ","    let presidioEntry = CLLocationCoordinate2D(latitude: 37.79190, longitude: -122.44776)","    let batterySpencer = CLLocationCoordinate2D(latitude: 37.82798, longitude: -122.48201)","","    \/\/..."]},{"type":"paragraph","inlineContent":[{"text":"When the map view is loaded, we’ll create annotations to mark the start and destination points.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["","override func viewDidLoad() {","    super.viewDidLoad()","    configureCamera()","    \/\/ Create annotations","    addAnnotationsAtStartAndEnd()"]},{"type":"paragraph","inlineContent":[{"text":"Set coordinates and title, append it to the annotation array, then add them to the map view.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["func addAnnotationsAtStartAndEnd() {","    \/\/ Create annotations for start location and destination.","    var annotations = [MKAnnotation]()","    ","    let startAnnotation = MKPointAnnotation()","    startAnnotation.coordinate = presidioEntry","    startAnnotation.title = \"Presidio Gate\"","    annotations.append(startAnnotation)","    ","    let endAnnotation = MKPointAnnotation( )","    endAnnotation.coordinate = batterySpencer","    endAnnotation.title = \"Battery Spencer\"","    annotations.append(endAnnotation)","    ","    \/\/ Add annotations to map view. ","    mapView.addAnnotations (annotations)","    }"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"While normal overlays will flatten the map, the polyline returned by MapKit’s Directions API will preserve the realistic terrain."}]},{"type":"paragraph","inlineContent":[{"text":"In this action function, once the switch is turned on, it will create place marks with the coordinates defined above.","type":"text"},{"text":" ","type":"text"},{"text":"Then create a direction request, with source and destination. Finally, we request the directions.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"If the fetch operation succeeds, we add the route polyline as an overlay.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["@IBAction func routeSwitchToggled(_ sender: UISwitch) {","    if sender.isOn {","","        \/\/ Create MKPlaceMark for start position and destination","        let origin = MKPlacemark(coordinate: presidioEntry)","        let destination = MKPlacemark(coordinate: batterySpencer)","    ","        \/\/ Create MDirections request with locations defined above.","        let request = MKDirections.Request()","        request. source = MKMapItem(placemark: origin)","        request.destination = MKMapItem(placemark: destination)","    ","        Task {","    ","            \/\/ Make direction request.","            let direction = MDirections(request: request)","            do {","                guard let response = try await direction.calculate() else { return }","    ","                \/\/ Add route polyline","                for route in response.routes {","                    self.mapView.addOverlay(route.polyline, level: .aboveRoads)","                }","        ","                \/\/ Animate map camera for a closer look at elevated route polyline ","                animateCamera()","        ","            } catch {","            \/\/ ...","            }","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The annotations are automatically upgraded to the new gradient look.. Once we toggle show route, the camera will pitch. Then, you can get a better view of them."}]},{"type":"paragraph","inlineContent":[{"text":"The route line follows the elevated terrain. It also follows the road across the bridge. Also, the route subtly shows through the bridge pillars.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-sampleApp5"}]},{"type":"paragraph","inlineContent":[{"text":"Finally, we can see the route show through the trees that stand in front of it.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-sampleApp6","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Here a part of the route goes through a tunnel, so we get transparency for it. ElevationRealisticStyle and the elevated route line feature are supported on A12-based iOS devices. The same app on an older iOS device, will automatically get a 2D route on a 2D map…"}]},{"type":"heading","anchor":"Blend-modes","text":"Blend modes","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"This new API gives you more control over the look and feel of overlays. During a blend operation, two graphical layers are combined following a set of equations specified by the blend mode."}]},{"type":"paragraph","inlineContent":[{"text":"In this scenario, we want to highlight the area of the Presidio National Park in San Francisco in the center of this map. First, we create an overlay covering the entire map area, with a cutout in the shape of the Presidio.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-blendModes","type":"image"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-blendModes2","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"We are not using any blend modes yet. This is just a plain overlay, in the shape of a big square doughnut. Next, we assign a hue blend mode to the overlay, with a gray fill. This desaturates the map outside of the Presidio.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-blendModes3","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Next, we are going to duplicate that overlay and assign it a hard light blend mode, with a dark gray fill.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This has the effect of darkening the area around the Presidio. This already looks nice, but lets add another overlay. This time, we’ll add an overlay in the shape of the Presidio and assign a saturation blend mode, with a yellow fill. But the colors are way too bright. We’ll apply a color burn blend mode with a gray fill."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-blendModes4","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We added a property to MKOverlayRenderer, called blendMode. All we need to do is set the desired CoreGraphics blend mode on the overlay renderer."}]},{"type":"codeListing","syntax":"swift","code":["class MKOverlayRenderer {","    ","    var blendMode: CGBlendMode","}","","class MKMapView {","    func insertOverlay(_ overlay: MKOverlay, at index: Int, level: MKOverlayLevel) ","    func insertOverlay(_ overlay: MKOverlay, above sibling: MKOverlay) ","    func insertOverlay(_ overlay: MKOverlay, below sibling: MKOverlay)","    \/\/...","}"]},{"type":"paragraph","inlineContent":[{"text":"Blend modes are order dependent. The overlay at the bottom of the stack is blended with the map, the second-to-last overlay is then blended with the result of the previous blend operation, and so on.","type":"text"},{"text":"\n","type":"text"},{"text":"In MapKit, the order of overlays is determined at insertion time. we can use either absolute or relative positioning using one of MKMapView’s many overlay insertion functions.","type":"text"}]},{"type":"heading","anchor":"Blend-modes","text":"Blend modes:","level":2},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Multiply","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Screen"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Overlay"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Darken","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Lighten"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"ColorDodge","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"ColorBurn","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"LinearBurn"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"SoftLight"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"HardLight"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Difference"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Exclusion"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Hue","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Saturation","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Color"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Luminosity"}],"type":"paragraph"}]}]},{"type":"heading","anchor":"Selectable-Map-Features","text":"Selectable Map Features","level":1},{"type":"paragraph","inlineContent":[{"text":"Using MapKit we leverage annotations to show the location of cities, points of interest, or physical objects. Unless using POI filtering, we are placing those annotations on a map which already contains a number of similar annotations provided by Apple. Up until now, users could only interact with the annotations we provided.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"In iOS 16, using the new Selectable Map Features API, we’ll have the option to let our users select features on the map.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-selectableMapFeatures"}]},{"type":"paragraph","inlineContent":[{"text":"Selectable map features include points of interest, such as stores, restaurants, and landmarks; territories, such as cities and states; and physical features, such as mountain ranges and lakes.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-selectableMapFeatures2"}]},{"type":"paragraph","inlineContent":[{"text":"To adopt Selectable Map Features in your app:","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"First, configure which feature types should be selectable. There are three main feature types, and it might not make sense for all of them to be interactive. For points-of-interest features, we can also use existing filter API to further restrict which points-of-interest categories can appear and therefore be selectable.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Second, implement the ","type":"text"},{"code":"MKMapView","type":"codeVoice"},{"text":" delegate callbacks to handle selection events. We might want to control how selected features appear, or might want to show some additional UI in response to the selection events.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Third, to request and display additional place information in the application’s user interface. To give users more context about the place they selected, we’ll need to request additional information.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"We’ll start with configuring which map features should be selectable using the new ","type":"text"},{"code":"selectableMapFeatures","type":"codeVoice"},{"text":" property.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKMapView {","    var selectableMapFeatures: MKMapFeatureOptions","}","","struct MKMapFeature0ptions: OptionSet {","    static var points0fInterest ","    static var territories ","    static var physicalFeatures","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We can choose any combination of points of interest, territories, and physical features. Once we have configured the selectable map features and the user taps one of those features, we’ll start receiving some new delegate callbacks allowing to customize the selection behavior."}]},{"type":"codeListing","syntax":"swift","code":["protocol MKMapViewDelegate {","    optional func mapView(_: MKMapView, didSelect annotation: MKAnnotation) ","    optional func mapView(_: MKMapView, didDeselect annotation: MKAnnotation) ","    ","    \/\/ existing","    optional func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView?","}"]},{"type":"paragraph","inlineContent":[{"text":"The first callback is the new didSelect annotation. This callback is a great opportunity to request additional data about the map item using the new request API.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The second callback is the existing viewFor annotation. This is where we can customize the view which will be shown for the selected state."}]},{"type":"paragraph","inlineContent":[{"text":"While this is existing API, there is a new type of annotation class called ","type":"text"},{"type":"codeVoice","code":"MapFeatureAnnotation"},{"text":".","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKMapFeatureAnnotation: MKAnnotation {","    var featureType: FeatureType ","    var point0fInterestCategory: MKPoint0fInterestCategory?","    var iconStyle: MKIconStyle?","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This class will be passed to “view for annotation” when the user selects a map feature. "},{"type":"codeVoice","code":"MapFeatureAnnotation"},{"type":"text","text":" has a number of properties. We can inspect the "},{"type":"codeVoice","code":"FeatureType"},{"type":"text","text":" property to determine whether the map feature is a point of interest, a territory, or a physical feature. If the map feature is a point of interest, the "},{"type":"codeVoice","code":"pointOfInterestCategory"},{"type":"text","text":" property will let us know what its category is, and the "},{"type":"codeVoice","code":"iconStyle"},{"type":"text","text":" property will let us obtain additional information about the icon, such as its background color and the icon image itself."}]},{"type":"codeListing","syntax":"swift","code":["class MKIconStyle {","    var backgroundColor: UIColor ","    var image: UIImage","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"How to customize the annotation view using the viewFor annotation callback. To achieve the same selection style as the Maps app, return nil."}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView? {","    return nil","}"]},{"type":"paragraph","inlineContent":[{"text":"To customize the selection style, we can return an annotationView, the same way we would for our own annotations.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView? {","    ","    if let feature = annotation as MKMapFeatureAnnotation? {","        var annotationView: MKMarkerAnnotationView =","        \/\/ dequeue or create","        annotationView.image = feature.iconStyle?.image","        annotationView.color = \/\/ application tint color","        return annotationView","    }","    \/\/ else","    return nil","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The "},{"type":"codeVoice","code":"markerAnnotationView"},{"type":"text","text":" is a great option. It will give us the same balloon-style shape as the Maps app, a gradient treatment, and it allows to choose our own color or icon. To go fully custom, we can provide any annotation view subclass that we create."}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView?","{","    return MyUnicornAnnotationView()","}"]},{"type":"paragraph","inlineContent":[{"text":"We can use the feature annotation to retrieve visual information about the selected feature. By passing the feature annotation on to our new ","type":"text"},{"type":"codeVoice","code":"MKMapItemRequest"},{"text":" API, we can also retrieve a map item for the selected feature.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKMapItemRequest : NSObject {","","    init(featureAnnotation: MKMapFeatureAnnotation) {}","    ","    func getMapItem(completionHandler: @escaping (MKMapItem?, Error?) -> Void) {}","    var mapItem: MKMapItem { get async throws }","}"]},{"type":"paragraph","inlineContent":[{"text":"This map item contains additional metadata about the place, such as an address, a name, a phone number, and a URL.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The map item also provides a function to punch out to the Maps app if the users want to see additional metadata which isn’t available through MapKit."}]},{"type":"codeListing","syntax":"swift","code":["\/\/ Existing API","","open class MKMapItem : NSObject {","    open var placemark: MKPlacemark { get }","    open var name: String?","    open var phoneNumber: String?","    open var url: URL?","    ","    \/\/ ...","    ","    func openInMaps (launchOptions: [String : Any]? = nil, ","        from scene: UIScene?) async -> Bool {}"]},{"type":"heading","anchor":"The-explore-feature-of-the-sample-app","text":"The explore feature of the sample app","level":1},{"type":"paragraph","inlineContent":[{"text":"The users should be able to explore some interesting places near the waterfront. If they tap on POIs, annotations should show up. We will perform a camera animation to the tapped location, and show an info card from the bottom.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"First, let’s filter points of interest on the map and remove the categories which are irrelevant to the tour."},{"type":"text","text":" "},{"type":"text","text":"Aside from applying the filter in code, we can also apply it in Interface Builder inspector. Let’s select the map view, and go to inspector on the right-hand side and do an exclusion filter."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"lets select the categories that we don’t want, for example: airport, car rental, hospital, and laundry."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-exploreMapFeatures","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"It’s very simple to enable Selectable Map Features. All we need to do is to specify an option set of desired selectable features.","type":"text"},{"text":"\n","type":"text"},{"text":"In the scope of this sample app, we’ll just use points of interest, but we also can support selectable physical features and territories.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["override func viewDidLoad() {","    super.viewDidLoad()","    ","    mapView.region = .annotation","    ","    mapView.cameraBoundary = MKMapView.CameraBoundary(coordinateRegion: .annotationCameraBoundary)","    ","    \/\/ Enable selectable map","    mapView.selectableMapFeatures = [.pointsOfInterest]"]},{"type":"paragraph","inlineContent":[{"text":"We can use the existing delegate method mapView viewForAnnotation to create a view for the feature annotation.","type":"text"},{"text":" ","type":"text"},{"text":"Here, we’ll just return nil… To use the default gradient annotation offered by MapKit.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_ mapView: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView? {","    return nil","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"If an annotation is on Selected state, we will be informed through the new delegate method mapView didSelectAnnotation."},{"type":"text","text":"\n"},{"type":"text","text":"We use this function to perform a camera animation and zoom in on the selected feature."},{"type":"text","text":" "},{"type":"text","text":"First, we cast the annotation to featureAnnotation, then create a map item request with it."},{"type":"text","text":" "},{"type":"text","text":"This is a new API to fetch additional place informations with feature annotations."},{"type":"text","text":" "},{"type":"text","text":"We issue the request. Once the fetch operation succeeds, we will animate to the map item. When the camera animation has completed, we will get details from the feature item and show them on an info card."}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_ mapView: MKMapView, didSelect annotation: MKAnnotation) {","    guard let featureAnnotation = annotation as? MKMapFeatureAnnotation else { return }","    let featureRequest = MKMapItemRequest(mapFeatureAnnotation: featureAnnotation)","","    Task {","    ","        \/\/ Issue request.","        do {","            guard let featureItem = try await featureRequest.mapItem else { return }","        ","            UIView.animate(withDuration: 4) {","            ","                \/\/ Update map camera","                self.animateCamera(featureItem)","            ","            } completion: { _ in","                \/\/ Concatenate info string from map item - name, category, url and address","                self.showInfoCardView(featureItem)","            }","        } catch {","    ","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The gradient annotations show up. The camera animates to the tab location. Then the info card shows up."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-exploreMapFeatures2","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Now let’s customize our annotation for the selection state.","type":"text"},{"text":"\n","type":"text"},{"text":"Instead of nil, let’s create a ","type":"text"},{"code":"MarkerAnnotationView","type":"codeVoice"},{"text":". We’ll cast the annotation to ","type":"text"},{"code":"featureAnnotation","type":"codeVoice"},{"text":" first, so we can use specific data from it to customize the view. Let’s tint the annotation with a purple-ish color so it’s in line with our corporate identity.","type":"text"},{"text":" ","type":"text"},{"text":"We can also customize the annotation glyph. ","type":"text"},{"code":"SelectedGlyphImage","type":"codeVoice"},{"text":" is for annotations on Selected state. GlyphImage is smaller. It is the glyph for annotations on Unselected state. Assigning them the same glyph is recommended for a smooth transition from the Unselected to Selected state.","type":"text"},{"text":"\n","type":"text"},{"text":"Let’s use the icon style image we got from the featureAnnotation.","type":"text"},{"text":"\n","type":"text"},{"code":"MKIconStyle","type":"codeVoice"},{"text":" is a new class in iOS16. It has the iconography and color info of the selected POI.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView? {","    ","    if let featureAnnotation = annotation as? MKMapFeatureAnnotation {","        ","        let customView = MKMarkerAnnotationView(annotation: featureAnnotation, reuseIdentifier: nil)","        ","        customView.markerTintColor = UIColor(red: 0.63, green: 0.27, blue: 0.63, alpha: 1.0)","        ","        customView.selectedGlyphImage = featureAnnotation.iconStyle?.image","        customView.glyphImage = featureAnnotation.iconStyle?.image","        ","        return customView","    }","    ","    let annotationView = MKMarkerAnnotationView(annotation: annotation, reuseIdentifier: nil)","    return annotationView","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Now we have an annotation that matches our corporate colors, but still uses Apple iconography."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-exploreMapFeatures3"}]},{"type":"heading","anchor":"Look-Around","text":"Look Around!","level":1},{"type":"paragraph","inlineContent":[{"type":"text","text":"The Maps app introduced Look Around in iOS 13"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-lookAround"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Look Around is available in many places around the world, including these cities, and entire countries."}]},{"type":"heading","anchor":"Cities","text":"Cities:","level":2},{"type":"paragraph","inlineContent":[{"text":"Atlanta, GA \/ Boston, MA \/ Chicago, IL \/ Denver, CO \/ Detroit, MI \/ Dublin, Ireland \/ Edinburgh, Scotland \/ Fukuoka, Japan \/ Hiroshima, Japan \/ Houston, TX \/ Kanazawa, Japan \/ Las Vegas, NV \/ London, United Kingdom \/ Los Angeles, CA \/ Miami, FL \/ Nagoya, Japan \/ New York, NY \/ Oahu, HI \/ Osaka, Japan \/ Philadelphia, PA \/ Phoenix, AZ \/ Portland, OR \/ Sagamihara, Japan \/ San Diego, CA \/ San Francisco Bay Area \/ Santa Cruz, CA \/ Seattle, WA \/ Sendai, Japan \/ Takamatsu, Japan \/ Tokyo, Japan \/ Washington, DC \/ Yokohama, Japan","type":"text"}]},{"type":"heading","anchor":"Countries-and-territories","text":"Countries and territories:","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"Andorra \/ Australia \/ Canada \/ Gibraltar \/ Italy \/ Portugal \/ San Marino \/ Spain"}]},{"type":"paragraph","inlineContent":[{"text":"With iOS 16, Look Around is coming to MapKit, and adopting it only requires three steps.","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Check for data availability."},{"type":"text","text":"\n"},{"type":"text","text":"Check whether data is available for the desired location. Even if Look Around is available in the target region, not every location can be seen from a street, and therefore, Look Around imagery might not always be available."}]}]},{"content":[{"inlineContent":[{"text":"Pass data to the Look Around UI.","type":"text"},{"text":" ","type":"text"},{"text":"Once we’ve determined whether Look Around data is available, we’ll need to pass that data on to either the Look Around View Controller or the Look Around Snapshotter.","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Conditionally show Look Around UI.","type":"text"},{"text":"\n","type":"text"},{"text":"And finally, if Look Around data is available, we’ll want to update your app UI to show the Look Around preview.","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We create a "},{"type":"codeVoice","code":"LookAroundSceneRequest"},{"type":"text","text":", which is a new class introduced in iOS 16. we can initialize a new instance with either a coordinate or a map item."},{"type":"text","text":"\n"},{"type":"text","text":"we’ll retrieve its scene property. This is an optional async property. If data is available, we will get back a scene instance. If data is not available, we will get back a nil instead. And if there was a problem with the request, an error will be thrown."}]},{"type":"codeListing","syntax":"swift","code":["class MKLookAroundSceneRequest {","    init (coordinate: CLLocationCoordinate2D)","    init (mapItem: MKMapItem)","    var scene: MKLookAroundScene? { get async throws }","}"]},{"type":"paragraph","inlineContent":[{"text":"The Look Around Scene is an opaque object with no properties. It acts as a token that ensures the availability of Look Around imagery for a requested location.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKLookAroundScene {","","}"]},{"type":"paragraph","inlineContent":[{"text":"To show an interactive preview of the Look Around scene, we pass the scene on to a new Look Around View Controller instance as an init parameter or assign it to the read write scene property of an existing instance.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKLookAroundViewController : UIViewController {","    init (scene: MKLookAroundScene)","    var scene: MKLookAroundScene?","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Alternatively, we can also pass the scene on to a new Look Around View Snapshotter instance as an init parameter and subsequently retrieve its snapshot async property."}]},{"type":"codeListing","syntax":"swift","code":["class MKLookAroundSnapshotter {","    init (scene: MKLookAroundScene, options: MKLookAroundSnapshotter.Options) ","    var snapshot: MKLookAroundSnapshotter.Snapshot { get async throws }"]},{"type":"paragraph","inlineContent":[{"text":"The Look Around view controller is designed to embed a smaller static preview of a Look Around image, which the user can tap on to enter a full-screen Look Around interactive session.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-lookAround2","type":"image"}]},{"type":"heading","anchor":"Highlights-feature-of-the-sample-app","text":"Highlights feature of the sample app","level":1},{"type":"paragraph","inlineContent":[{"text":"The last sample app feature, Highlights. Users can get a realistic view of must-see places.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We already have a couple of San Francisco landmark names in the segment control bar on top of the screen. When users tap on one of them, we want to perform a camera animation to the tapped location. We also want to show a Look around preview at bottom left, which users can expand to full screen. Let’s do it! First we need to add a container view for the Look Around preview."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-highlights","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let’s go to the size inspector. Let’s give it a position and size."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-highlights2","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"We want to hide this preview at the beginning, so let’s open the attributes inspector and check Hidden.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Next, we need to create a Look Around view controller…"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-highlights3","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"And embed it to the container view."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-highlights4"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Same as any other segue, we need to give it an identifier."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-highlights5","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Let’s call it ","type":"text"},{"type":"codeVoice","code":"presentLookAroundEmbedded"},{"text":". And import it to code so we can update its visibility later.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let’s name it “preview.” Here, we already have a LookAroundViewController declared. We just need to grab the instance in the prepare function."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-highlights6"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Make sure the segue identifier is matched."}]},{"type":"codeListing","syntax":"swift","code":["override func prepare(for segue: UIStoryboardSegue, sender: Any?) {","    \/\/ Grab lookAroundViewController instance.","    if segue.identifier == \"presentLookAroundEmbedded\" {","        if let lookAroundViewController = segue.destination as? MKLookAroundViewController {","            self.lookAroundViewController = lookAroundViewController","            }","        }","    }"]},{"type":"paragraph","inlineContent":[{"text":"Then, in the segment control function, we’ll create a local search with the landmark name.","type":"text"},{"text":" ","type":"text"},{"text":"If the request succeeds, we will get a map item which will be used in the following camera animation and Look Around scene retrieval.","type":"text"},{"text":"\n","type":"text"},{"text":"For camera animation, we first need to create a camera with the new API. MapCamera looking at map item. Let’s use map view frame size for the view size, and set allow pitch to true. This will give us a pitch view to landmarks and a top-down view to other places. Assign the new camera. That’s it.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["@IBAction func landmark(_ sender: UISegmentedControl) {","    cleanUpPreview()","    ","    let request = MKLocalSearch.Request()","    if sender.selectedSegmentIndex == 0 {","        request.naturalLanguageQuery = \"Ferry Building\"","    } else if sender. selectedSegmentIndex == 1 {","        request.naturalLanquageQuery = \"Coit Tower\"","    } else if sender.selectedSegmentIndex == 2 {","        request.naturalLanguageQuery = \"Dragon Gate\"","    }","","    let search = MKLocalSearch (request: request)","    search.start { response, error in","        guard let response = response else { return }","    ","        if let item = response.mapItems.first {","        ","            UIView.animate(withDuration: 6) {","        ","            \/\/ Camera animation","            let camera = MKMapCamera(lookingAt: item, forViewsize: self.mapView.frame.size, allowPitch: true)","            self.mapView.camera = camera","            ) completion: { _ in","        ","                \/\/ Prepare LookAround preview.","                self.configureLookAroundScene(item)","                }","            }","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"text":"Once the camera animation is completed, we’ll show its Look Around preview.","type":"text"},{"text":"\n","type":"text"},{"text":"First, we need to determine if the Look Around data is available for this map item. To do that, we need to use the new LookAroundSceneRequest class. Let’s create our request and pass in the map item. Then perform the request.","type":"text"},{"text":"\n","type":"text"},{"text":"If get scene request succeeds, then we assign the scene to our LookAroundViewController.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["func configureLookAroundScene(_ item: MKMapItem) {","    guard let lookAroundViewController = self.lookAroundViewController else { return }","    let lookAroundRequest = MKLookAroundSceneRequest(mapItem: item)","","    Task {","        \/\/ Create LookAround scene request.","        do {","            \/\/ Issue request.","            guard let lookAroundScene = try await lookAroundRequest.scene else { return }","            lookAroundViewController.scene = lookAroundScene","            ","            \/\/ Show lookAround preview.","            self.preview.isHidden = false","        } catch {","        ","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"text":"If there is no error but we get nil for the scene, it means Look Around data is not available at the request location.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-last","type":"image"}]},{"type":"heading","anchor":"Check-out-also","text":"Check out also","level":1},{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"https:\/\/developer.apple.com\/wwdc22\/10006","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/tech-talks\/110356","isActive":true}]},{"type":"heading","anchor":"Written-By","text":"Written By","level":2},{"type":"row","numberOfColumns":5,"columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"identifier":"multitudes","type":"image"}]}]},{"size":4,"content":[{"level":3,"anchor":"laurent-b","type":"heading","text":"laurent b"},{"inlineContent":[{"overridingTitle":"Contributed Notes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","isActive":true,"overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/github.com\/multitudes","isActive":true,"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/laurentbrusa.hashnode.dev\/","isActive":true,"type":"reference"},{"text":" ","type":"text"},{"text":"|","type":"text"},{"text":" ","type":"text"},{"identifier":"https:\/\/x.com\/wrmultitudes","isActive":true,"type":"reference"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","isActive":true,"type":"reference"}]},{"type":"heading","anchor":"Related-Sessions","text":"Related Sessions","level":2},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10006-Meet-Apple-Maps-Server-APIs"],"style":"list"},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"type":"small","inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}]}],"kind":"content"}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10035-Whats-new-in-MapKit"},"metadata":{"modules":[{"name":"WWDC Notes"}],"roleHeading":"WWDC22","role":"sampleCode","title":"What’s new in MapKit"},"references":{"WWDC22-10035-aboveLevels3":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels3.jpg","traits":["1x","light"]}],"alt":"Above Levels","identifier":"WWDC22-10035-aboveLevels3"},"WWDC22-10035-blendModes2":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-blendModes2.jpg","traits":["1x","light"]}],"alt":"Blend modes","identifier":"WWDC22-10035-blendModes2"},"WWDC22-10035-blendModes4":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-blendModes4.jpg","traits":["1x","light"]}],"alt":"Blend modes","identifier":"WWDC22-10035-blendModes4"},"WWDC22-10035-standardMapConfig":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-standardMapConfig.jpg","traits":["1x","light"]}],"alt":"Standard Map Config","identifier":"WWDC22-10035-standardMapConfig"},"WWDC22-10035-aboveLevels":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels.jpg","traits":["1x","light"]}],"alt":"Above Levels","identifier":"WWDC22-10035-aboveLevels"},"WWDCNotes.png":{"type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"alt":null,"identifier":"WWDCNotes.png"},"https://github.com/multitudes":{"type":"link","url":"https:\/\/github.com\/multitudes","titleInlineContent":[{"type":"text","text":"GitHub"}],"title":"GitHub","identifier":"https:\/\/github.com\/multitudes"},"WWDC22-10035-highlights4":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights4.jpg","traits":["1x","light"]}],"alt":"highlights","identifier":"WWDC22-10035-highlights4"},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","type":"topic","title":"WWDC Notes","url":"\/documentation\/wwdcnotes","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"role":"collection"},"https://x.com/wrmultitudes":{"type":"link","url":"https:\/\/x.com\/wrmultitudes","titleInlineContent":[{"type":"text","text":"X\/Twitter"}],"title":"X\/Twitter","identifier":"https:\/\/x.com\/wrmultitudes"},"multitudes.jpeg":{"type":"image","variants":[{"url":"\/images\/multitudes.jpeg","traits":["1x","light"]}],"alt":null,"identifier":"multitudes.jpeg"},"WWDC22-10035-sampleApp6":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp6.jpg","traits":["1x","light"]}],"alt":"Sample App Levels","identifier":"WWDC22-10035-sampleApp6"},"WWDC22-10035-selectableMapFeatures2":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-selectableMapFeatures2.jpg","traits":["1x","light"]}],"alt":"Selectable Map Features","identifier":"WWDC22-10035-selectableMapFeatures2"},"WWDC22-10035-london":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-london.jpg","traits":["1x","light"]}],"alt":"London St Paul","identifier":"WWDC22-10035-london"},"WWDC22-10035-mapsImagery":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-mapsImagery.jpg","traits":["1x","light"]}],"alt":"Maps Imagery","identifier":"WWDC22-10035-mapsImagery"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10006-Meet-Apple-Maps-Server-APIs":{"title":"Meet Apple Maps Server APIs","url":"\/documentation\/wwdcnotes\/wwdc22-10006-meet-apple-maps-server-apis","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10006-Meet-Apple-Maps-Server-APIs","abstract":[{"type":"text","text":"Simplify your app’s mapping architecture by implementing the Apple Maps stack across MapKit, MapKit JS, and Apple Maps Server APIs. Learn how these APIs can reduce network calls and increase power efficiency, which can help improve the overall performance of your app. We’ll show you how to use geocoding and estimated time of arrival APIs to build functionality for a simple store locator, and explore the API authentication flow."}],"role":"sampleCode","kind":"article","type":"topic"},"WWDC22-10035-highlights":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights.jpg","traits":["1x","light"]}],"alt":"highlights","identifier":"WWDC22-10035-highlights"},"WWDC22-10035-blendModes":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-blendModes.jpg","traits":["1x","light"]}],"alt":"Blend modes","identifier":"WWDC22-10035-blendModes"},"WWDC22-10035-exploreMapFeatures":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-exploreMapFeatures.jpg","traits":["1x","light"]}],"alt":"Explore Map Features","identifier":"WWDC22-10035-exploreMapFeatures"},"WWDC22-10035-lookAround2":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-lookAround2.jpg","traits":["1x","light"]}],"alt":"Look Around","identifier":"WWDC22-10035-lookAround2"},"doc://WWDCNotes/documentation/WWDCNotes/multitudes":{"title":"laurent b (33 notes)","abstract":[{"text":"student at 42Berlin 🐬 | 🍎 Swift(UI) app dev  | speciality coffee ☕️ & cycling 🚴🏻‍♂️","type":"text"}],"images":[{"type":"card","identifier":"multitudes.jpeg"},{"type":"icon","identifier":"multitudes.jpeg"}],"url":"\/documentation\/wwdcnotes\/multitudes","type":"topic","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes"},"WWDC22-10035-deviceSupport":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-deviceSupport.jpg","traits":["1x","light"]}],"alt":"Device Support","identifier":"WWDC22-10035-deviceSupport"},"WWDC22-10035-aboveLevels6":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels6.jpg","traits":["1x","light"]}],"alt":"Above Levels","identifier":"WWDC22-10035-aboveLevels6"},"WWDC22-10035-sampleApp1":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp1.jpg","traits":["1x","light"]}],"alt":"Sample App Levels","identifier":"WWDC22-10035-sampleApp1"},"https://laurentbrusa.hashnode.dev/":{"type":"link","url":"https:\/\/laurentbrusa.hashnode.dev\/","titleInlineContent":[{"type":"text","text":"Blog"}],"title":"Blog","identifier":"https:\/\/laurentbrusa.hashnode.dev\/"},"WWDC22-10035-sampleApp2":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp2.jpg","traits":["1x","light"]}],"alt":"Sample App Levels","identifier":"WWDC22-10035-sampleApp2"},"WWDC22-10035-highlights3":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights3.jpg","traits":["1x","light"]}],"alt":"highlights","identifier":"WWDC22-10035-highlights3"},"WWDC22-10035-lookAround":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-lookAround.jpg","traits":["1x","light"]}],"alt":"Look Around","identifier":"WWDC22-10035-lookAround"},"WWDC22-10035-highlights6":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights6.jpg","traits":["1x","light"]}],"alt":"highlights","identifier":"WWDC22-10035-highlights6"},"WWDC22-10035-ferryBuilding":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-ferryBuilding.jpg","traits":["1x","light"]}],"alt":"Ferry Building","identifier":"WWDC22-10035-ferryBuilding"},"https://developer.apple.com/videos/play/tech-talks/110356":{"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/tech-talks\/110356","titleInlineContent":[{"type":"text","text":"Whats new for enterprise developer (Tech Talk) -  WWDC22"}],"title":"Whats new for enterprise developer (Tech Talk) -  WWDC22","identifier":"https:\/\/developer.apple.com\/videos\/play\/tech-talks\/110356"},"https://developer.apple.com/wwdc22/10006":{"type":"link","url":"https:\/\/developer.apple.com\/wwdc22\/10006","titleInlineContent":[{"type":"text","text":"Meet Apple Map Server APIs - WWDC22"}],"title":"Meet Apple Map Server APIs - WWDC22","identifier":"https:\/\/developer.apple.com\/wwdc22\/10006"},"WWDC22-10035-last":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-last.jpg","traits":["1x","light"]}],"alt":"look around preview","identifier":"WWDC22-10035-last"},"WWDC22-10035-highlights5":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights5.jpg","traits":["1x","light"]}],"alt":"highlights","identifier":"WWDC22-10035-highlights5"},"WWDC22-10035-highlights2":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights2.jpg","traits":["1x","light"]}],"alt":"highlights","identifier":"WWDC22-10035-highlights2"},"WWDC22-10035-sampleApp5":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp5.jpg","traits":["1x","light"]}],"alt":"Sample App Levels","identifier":"WWDC22-10035-sampleApp5"},"https://developer.apple.com/wwdc22/10035":{"type":"download","url":"https:\/\/developer.apple.com\/wwdc22\/10035","checksum":null,"identifier":"https:\/\/developer.apple.com\/wwdc22\/10035"},"WWDC22-10035-sampleApp4":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp4.jpg","traits":["1x","light"]}],"alt":"Sample App Levels","identifier":"WWDC22-10035-sampleApp4"},"WWDC22-10035-aboveLevels2":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels2.jpg","traits":["1x","light"]}],"alt":"Above Levels","identifier":"WWDC22-10035-aboveLevels2"},"WWDC22-10035-sampleApp3":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp3.jpg","traits":["1x","light"]}],"alt":"Sample App","identifier":"WWDC22-10035-sampleApp3"},"WWDC22-10035-exploreMapFeatures3":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-exploreMapFeatures3.jpg","traits":["1x","light"]}],"alt":"Explore Map Features","identifier":"WWDC22-10035-exploreMapFeatures3"},"WWDC22-10035-aboveLevels4":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels4.jpg","traits":["1x","light"]}],"alt":"Above Levels","identifier":"WWDC22-10035-aboveLevels4"},"WWDC22-10035-exploreMapFeatures2":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-exploreMapFeatures2.jpg","traits":["1x","light"]}],"alt":"Explore Map Features","identifier":"WWDC22-10035-exploreMapFeatures2"},"multitudes":{"type":"image","variants":[{"url":"\/images\/multitudes.jpeg","traits":["1x","light"]}],"alt":"Profile image of laurent b","identifier":"multitudes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22","role":"collectionGroup","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc22","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"kind":"article","title":"WWDC22","abstract":[{"type":"text","text":"Xcode 14, Swift 5.7, iOS 16, macOS 13 (Ventura), tvOS 16, watchOS 9."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"WeatherKit"},{"type":"text","text":", "},{"type":"codeVoice","code":"ScreenCaptureKit"},{"type":"text","text":", "},{"type":"codeVoice","code":"Swift Regex"},{"type":"text","text":", and more."}]},"WWDC22-10035-mapTypeMapping":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-mapTypeMapping.jpg","traits":["1x","light"]}],"alt":"Map type mapping","identifier":"WWDC22-10035-mapTypeMapping"},"WWDC22-10035-DeprecatedAPI":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-DeprecatedAPI.jpg","traits":["1x","light"]}],"alt":"Deprecated API","identifier":"WWDC22-10035-DeprecatedAPI"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"type":"link","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"title":"Contributions are welcome!","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"},"WWDC22-10035-maps1":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-maps1.jpg","traits":["1x","light"]}],"alt":"maps","identifier":"WWDC22-10035-maps1"},"WWDC22-10035-goldenGate":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-goldenGate.jpg","traits":["1x","light"]}],"alt":"Golden Gate","identifier":"WWDC22-10035-goldenGate"},"WWDC22-10035-blendModes3":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-blendModes3.jpg","traits":["1x","light"]}],"alt":"Blend modes","identifier":"WWDC22-10035-blendModes3"},"WWDC22-10035-aboveLevels5":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels5.jpg","traits":["1x","light"]}],"alt":"Above Levels","identifier":"WWDC22-10035-aboveLevels5"},"WWDC22-10035-selectableMapFeatures":{"type":"image","variants":[{"url":"\/images\/WWDC22-10035-selectableMapFeatures.jpg","traits":["1x","light"]}],"alt":"Selectable Map Features","identifier":"WWDC22-10035-selectableMapFeatures"}}}