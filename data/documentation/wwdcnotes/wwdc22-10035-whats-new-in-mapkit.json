{"seeAlsoSections":[{"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10097-Whats-new-in-App-Clips","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10043-Whats-new-in-App-Store-Connect","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10074-Whats-new-in-AppKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110332-Whats-new-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10005-Whats-new-in-HealthKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10008-Whats-new-in-Nearby-Interaction","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10089-Whats-new-in-PDFKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10157-Whats-new-in-SF-Symbols-4","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10048-Whats-new-in-Safari-and-WebKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110336-Whats-new-in-Screen-Time-API","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10140-Whats-new-in-SharePlay","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10039-Whats-new-in-StoreKit-testing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110354-Whats-new-in-Swift","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110368-Whats-new-in-SwiftDocC","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10052-Whats-new-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10090-Whats-new-in-TextKit-and-text-views","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10068-Whats-new-in-UIKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10024-Whats-new-in-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10049-Whats-new-in-WKWebView","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110427-Whats-new-in-Xcode","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10045-Whats-new-in-managing-Apple-devices","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10023-Whats-new-in-the-Photos-picker","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10153-Whats-new-in-web-accessibility","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10149-Whats-new-in-AVQT","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10115-Whats-new-in-CloudKit-Console","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110345-Whats-new-in-Endpoint-Security","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10145-Whats-new-in-HLS-Interstitials","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10099-Whats-new-in-Safari-Web-Extensions","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10041-Whats-new-in-Wallet-and-Apple-Pay","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10009-Whats-new-in-iPad-app-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10109-Whats-new-in-notarization-for-Mac-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10096-Whats-new-in-privacy"],"generated":true,"title":"Updated Tools & Frameworks"}],"primaryContentSections":[{"content":[{"text":"Overview","type":"heading","level":2,"anchor":"overview"},{"type":"paragraph","inlineContent":[{"text":"Originally launched with U.S. support, the all-new map and Look Around coverage has been expanding since and now includes Canada, many European countries, Japan, and more.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-maps1","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Last year, Apple Maps introduced the 3D City Experiences, featuring turn lanes, crosswalks, bike lanes, and handcrafted 3D landmarks like the Ferry Building."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-ferryBuilding"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The additional detail of the map allows to provide context and precision and a high level of realism."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-london"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-goldenGate","type":"image"}]},{"text":"New MapKit features.","type":"heading","level":1,"anchor":"New-MapKit-features"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The Map Configuration API."}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Improvements to the overlay APIs"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"New blend modes support","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"brand-new Selectable Map Features API."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Integrating the immersive Look Around experience"}],"type":"paragraph"}]}]},{"text":"Map Configuration API.","type":"heading","level":2,"anchor":"Map-Configuration-API"},{"type":"paragraph","inlineContent":[{"text":"To adopt the all-new map is easy and we just need to recompile our app with the new SDK; it will be automatically opted in to the all-new Apple map, including the 3D City Experience, where available.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"In iOS 15, the way to configure the map is through various properties on MKMapView. In iOS 16, however, those properties are being softly deprecated."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-DeprecatedAPI"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"and a new Map Configuration API is being introduced as a replacement."}]},{"type":"codeListing","syntax":"swift","code":["\/\/ Configuring your map view","class MKMapView {","    ...","    var preferredConfiguration: MKMapConfiguration","}"]},{"type":"paragraph","inlineContent":[{"type":"codeVoice","code":"MKMapConfiguration"},{"text":" is the central class of the new Map Configuration API. ","type":"text"},{"type":"codeVoice","code":"MKMapConfiguration"},{"text":" is an abstract base class with three concrete subclasses.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKMapConfiguration {","}","","class MKImageryMapConfiguration : MKMapConfiguration {","}","","class MKHybridMapConfiguration : MKMapConfiguration {","}","","class MKStandardMapConfiguration : MKMapConfiguration {","}"]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"The imagery map configuration is used to present satellite-style imagery.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The hybrid map configuration is used to present an imagery-based map with added map features such as road labels and points of interest."}]}]},{"content":[{"inlineContent":[{"text":"The standard map configuration is used to present a fully graphics-based map.","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-mapsImagery","type":"image"}]},{"text":"The elevation style property.","type":"heading","level":3,"anchor":"The-elevation-style-property"},{"type":"paragraph","inlineContent":[{"text":"The base map configuration class supports an ","type":"text"},{"code":"elevationStyle","type":"codeVoice"},{"text":" property, which can be either flat or realistic. A flat elevation style means that the ground appears flat. Roads, including bridges and overpasses, also appear flat.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Flat is the default elevation style. A realistic elevation style means that the ground terrain reproduces the real-world elevation such as hills and mountains. Roads are depicted with realistic elevation details.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKMapConfiguration {","    var elevationStyle: ElevationStyle","}","","extension MKMapConfiguration {","    enum ElevationStyle {","        case flat ","        case realistic","    }","}"]},{"text":"The map configuration subclasses.","type":"heading","level":3,"anchor":"The-map-configuration-subclasses"},{"type":"paragraph","inlineContent":[{"text":"The imagery map configuration only shows satellite imagery with no additional map features, so it doesn’t have any other properties.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKImageryMapConfiguration : MKMapConfiguration {","    ","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The hybrid map configuration has additional properties to control filtering of point of interest categories and whether to show traffic or not."}]},{"type":"codeListing","syntax":"swift","code":["class MKHybridMapConfiguration : MKMapConfiguration {","    var point0fInterestFilter: MKPointOfInterestFilter?","    var showsTraffic: Bool","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The standard map configuration supports an "},{"code":"emphasisStyle","type":"codeVoice"},{"type":"text","text":" property which can be either default or muted."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"class MKStandardMapConfiguration : MKMapConfiguration {"},{"type":"text","text":" "},{"type":"text","text":"var emphasisStyle: EmphasisStyle"},{"type":"text","text":" "},{"type":"text","text":"}"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"As the name implies, this is the default emphasis style unless otherwise stated. The muted emphasis style softens the contrasts of the map details."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-standardMapConfig"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The standard map configuration also has additional properties to control filtering of point of interest categories and whether to show traffic or not."}]},{"type":"codeListing","syntax":"swift","code":["class MKStandardMapConfiguration : MKMapConfiguration {","    var emphasisStyle: EmphasisStyle ","    var pointOfInterestFilter: MKPoint0fInterestFilter?","    var showsTraffic: Bool","}"]},{"text":"Map type mapping","type":"heading","level":2,"anchor":"Map-type-mapping"},{"type":"paragraph","inlineContent":[{"text":"Here’s a table that shows the correspondence between the new map configuration classes and the ","type":"text"},{"type":"codeVoice","code":"MKMapType"},{"text":" property.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-mapTypeMapping","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The all-new map with the 3D City Experience requires compatible hardware. On iOS, the new map support requires A12-based iPhones and iPads or later. On macOS, the new map support requires any M1-based computer or later."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-deviceSupport"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"In areas where the 3D City Experience is not available, the map will automatically fall back to present the all-new map with a flat elevation. On all other devices, the all-new map will be presented with a flat elevation."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"On M1 Macs, Xcode allows you to simulate both experiences simply by changing the OS version."}]},{"text":"3D City Experience","type":"heading","level":2,"anchor":"3D-City-Experience"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"San Francisco Bay Area","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Los Angeles","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"New York","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"London","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Washington, DC"}]}]},{"content":[{"inlineContent":[{"text":"San Diego","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Philadelphia"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Toronto"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Montreal","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Vancouver","type":"text"}]}]}]},{"text":"Overlays","type":"heading","level":1,"anchor":"Overlays"},{"type":"paragraph","inlineContent":[{"text":"MapKit has supported overlays with several styling options for years. In iOS 16, there are some additions.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Overlays can be rendered at two different levels: above roads and above labels. You can specify the rendering level at insertion time using one of MapKit’s many overlay insertion functions.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["\/\/ Overlay levels","class MKMapView {","    func addOverlay(_: MKOverlay, level: MKOverlayLevel)","    \/\/ ...","}","","public enum MKOverlayLevel {","    case aboveLabels ","    case aboveRoads","}"]},{"type":"paragraph","inlineContent":[{"text":"Above labels renders the overlay above everything, including labels. Since labels provide important context information, only use above labels in those rare cases where we don’t want the data to interact with the map at all. Consider using the muted map emphasis or the blend modes.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Above roads means the overlay will be shown on top of the terrain, including roads, land cover, or bodies of water. It will, however, be shown below labels and, to some degree, trees and buildings. See the screenshot on the right below."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Above roads will be the new default mode in iOS 16."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-aboveLevels","type":"image"}]},{"text":"Transparent buildings","type":"heading","level":1,"anchor":"Transparent-buildings"},{"type":"paragraph","inlineContent":[{"type":"text","text":"There is a new feature in iOS 16 called transparent buildings."}]},{"type":"paragraph","inlineContent":[{"text":"Regardless of whether the overlay level is above roads or above labels, it will always be rendered on top of buildings when viewed top-down with no pitch.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-aboveLevels2","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Ground objects such as trees and buildings are now automatically rendered with transparency when appearing above overlays, so as not to fully obscure them. The alpha value varies with the map’s pitch angle. Reverting to showing the map top-down with a 0º pitch angle, colliding ground objects effectively disappear from view, leaving the overlays fully visible."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Transparent buildings also work for semi-transparent overlays. The alpha value of the overlay will be added to combine with the alpha value of the transparent buildings."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-aboveLevels3"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"There’s one more change to overlays. When adding an overlay to a map with realistic terrain,"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-aboveLevels4","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"MapKit will automatically transition the map to a flat representation.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-aboveLevels5"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The map will automatically go back to realistic when removing the last overlay. One notable exception to this rule are overlays sourced through MapKit’s directions API. Those overlays automatically follow the terrain."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-aboveLevels6"}]},{"text":"Adding Polygon Overlays","type":"heading","level":2,"anchor":"Adding-Polygon-Overlays"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Using the sample app, which helps users rent scooters to tour San Francisco."}]},{"type":"paragraph","inlineContent":[{"text":"The app offers a number of features, as shown by the rows in this table view. “Operating Area” allows the user to see where they can take our scooters. “Ride” takes the user on a tour across the Golden Gate Bridge. “Explore” gives the user an interactive map of downtown San Francisco, which they can use to explore attractions near the waterfront. “Highlights” offers a closer look at must-see places. We will implement or upgrade these features throughout this session.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"We are going to use the Operating Area feature.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-sampleApp1"}]},{"type":"paragraph","inlineContent":[{"text":"let’s add a polygon overlay to visualize the operating area. When the view is loaded, we’ll first set the region and the camera boundary.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["import MapKit","","\/\/ This class displays elevated route line overlay loaded from MapKit server on a map view.","","class PolygonOverlayViewController: UIViewController, MKMapViewDelegate {","","    @IBOutlet var mapView: MKMapView!","    ","    private let dataSource: OverlayDataSource","","    required init? (coder: NSCoder) {","        dataSource = OverlavDataSource()","        super.init (coder: coder)","    }","        ","    override func viewDidLoad() {","        super.viewDidLoad ()","        mapView.region = .overlay","        ","        mapView.cameraBoundary = MKMapView.CameraBoundary(coordinateRegion: .overlayCameraBoundary)","        ","        mapView.addOverlays(dataSource.overlays, level: .aboveRoads)","    }","","    \/\/ MARK: - MKMapViewDelegate","    func mapView(_ mapView: MKMapView, rendererFor overlay: MKOverlay) -> MKOverlayRenderer {","        let renderer: MKOverlayPathRenderer","        ","        if let multiPolygon = overlay as? MKMultiPolygon {","            renderer = MKMultiPolygonRenderer(multiPolygon: multiPolygon)","            renderer.fillColor = UIColor(red: 1, green: 0.59, blue: 0.7, alpha: 1.0)","            renderer.strokeColor = UIColor(red: 0.63, green: 0.27, blue: 0.63, alpha: 1.0)","            renderer.linewidth = 3.0","        else {","            renderer = MKOverlayPathRenderer(overlay: overlay)","        return renderer","        }","    }","    \/\/...","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The polygon overlay is opaque when viewed straight down. As we zoom in and pitch, the buildings begin to show, with the transparency increasing as we pitch further. This effect is only available when using the overlay level AboveRoads."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-sampleApp2"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"To want to leverage transparent buildings and trees, choose the correct overlay level."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let’s go back to the code and make the overlay semi-transparent with alpha to 0.8."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Now we have a transparent overlay and we can see roads and buildings even when not pitched."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-sampleApp3","type":"image"}]},{"text":"Integrate realistic terrain and show adding an elevated route line","type":"heading","level":2,"anchor":"Integrate-realistic-terrain-and-show-adding-an-elevated-route-line"},{"type":"paragraph","inlineContent":[{"type":"text","text":"We will integrate realistic terrain and add an elevated route line. This will complete our “Ride” feature of the app, a tour across the Golden Gate Bridge."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Start by configuring the map view. We can change the elevation style in code, or we can just open the Interface Builder inspector on the right-hand side."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Here are the available map view configuration settings. Let’s select “elevation: realistic”."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-sampleApp4"}]},{"type":"paragraph","inlineContent":[{"text":"Next, let’s work on the route.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"For this feature, we want to show a route when the user toggles the Show Route switch. We will also animate the camera to focus on the route.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Since we want to show a route across the Golden Gate Bridge, we’ll use the Presidio Park entry as the start point and the Battery Spencer as the end point."}]},{"type":"codeListing","syntax":"swift","code":["imроrt UIKit","import MapKit","","","\/\/This class displays elevated route line overlay loaded from MapKit server on a map view.","","class Polyline0verlayViewController: UIViewController, MKMapViewDelegate {","    @IBOutlet private var mapView: MKMapView!","    ","    let presidioEntry = CLLocationCoordinate2D(latitude: 37.79190, longitude: -122.44776)","    let batterySpencer = CLLocationCoordinate2D(latitude: 37.82798, longitude: -122.48201)","","    \/\/..."]},{"type":"paragraph","inlineContent":[{"text":"When the map view is loaded, we’ll create annotations to mark the start and destination points.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["","override func viewDidLoad() {","    super.viewDidLoad()","    configureCamera()","    \/\/ Create annotations","    addAnnotationsAtStartAndEnd()"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Set coordinates and title, append it to the annotation array, then add them to the map view."}]},{"type":"codeListing","syntax":"swift","code":["func addAnnotationsAtStartAndEnd() {","    \/\/ Create annotations for start location and destination.","    var annotations = [MKAnnotation]()","    ","    let startAnnotation = MKPointAnnotation()","    startAnnotation.coordinate = presidioEntry","    startAnnotation.title = \"Presidio Gate\"","    annotations.append(startAnnotation)","    ","    let endAnnotation = MKPointAnnotation( )","    endAnnotation.coordinate = batterySpencer","    endAnnotation.title = \"Battery Spencer\"","    annotations.append(endAnnotation)","    ","    \/\/ Add annotations to map view. ","    mapView.addAnnotations (annotations)","    }"]},{"type":"paragraph","inlineContent":[{"text":"While normal overlays will flatten the map, the polyline returned by MapKit’s Directions API will preserve the realistic terrain.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"In this action function, once the switch is turned on, it will create place marks with the coordinates defined above.","type":"text"},{"text":" ","type":"text"},{"text":"Then create a direction request, with source and destination. Finally, we request the directions.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"If the fetch operation succeeds, we add the route polyline as an overlay.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["@IBAction func routeSwitchToggled(_ sender: UISwitch) {","    if sender.isOn {","","        \/\/ Create MKPlaceMark for start position and destination","        let origin = MKPlacemark(coordinate: presidioEntry)","        let destination = MKPlacemark(coordinate: batterySpencer)","    ","        \/\/ Create MDirections request with locations defined above.","        let request = MKDirections.Request()","        request. source = MKMapItem(placemark: origin)","        request.destination = MKMapItem(placemark: destination)","    ","        Task {","    ","            \/\/ Make direction request.","            let direction = MDirections(request: request)","            do {","                guard let response = try await direction.calculate() else { return }","    ","                \/\/ Add route polyline","                for route in response.routes {","                    self.mapView.addOverlay(route.polyline, level: .aboveRoads)","                }","        ","                \/\/ Animate map camera for a closer look at elevated route polyline ","                animateCamera()","        ","            } catch {","            \/\/ ...","            }","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"text":"The annotations are automatically upgraded to the new gradient look.. Once we toggle show route, the camera will pitch. Then, you can get a better view of them.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The route line follows the elevated terrain. It also follows the road across the bridge. Also, the route subtly shows through the bridge pillars."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-sampleApp5","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Finally, we can see the route show through the trees that stand in front of it."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-sampleApp6"}]},{"type":"paragraph","inlineContent":[{"text":"Here a part of the route goes through a tunnel, so we get transparency for it. ElevationRealisticStyle and the elevated route line feature are supported on A12-based iOS devices. The same app on an older iOS device, will automatically get a 2D route on a 2D map…","type":"text"}]},{"text":"Blend modes","type":"heading","level":1,"anchor":"Blend-modes"},{"type":"paragraph","inlineContent":[{"type":"text","text":"This new API gives you more control over the look and feel of overlays. During a blend operation, two graphical layers are combined following a set of equations specified by the blend mode."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"In this scenario, we want to highlight the area of the Presidio National Park in San Francisco in the center of this map. First, we create an overlay covering the entire map area, with a cutout in the shape of the Presidio."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-blendModes"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-blendModes2","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We are not using any blend modes yet. This is just a plain overlay, in the shape of a big square doughnut. Next, we assign a hue blend mode to the overlay, with a gray fill. This desaturates the map outside of the Presidio."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-blendModes3","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Next, we are going to duplicate that overlay and assign it a hard light blend mode, with a dark gray fill.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"This has the effect of darkening the area around the Presidio. This already looks nice, but lets add another overlay. This time, we’ll add an overlay in the shape of the Presidio and assign a saturation blend mode, with a yellow fill. But the colors are way too bright. We’ll apply a color burn blend mode with a gray fill.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-blendModes4","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We added a property to MKOverlayRenderer, called blendMode. All we need to do is set the desired CoreGraphics blend mode on the overlay renderer."}]},{"type":"codeListing","syntax":"swift","code":["class MKOverlayRenderer {","    ","    var blendMode: CGBlendMode","}","","class MKMapView {","    func insertOverlay(_ overlay: MKOverlay, at index: Int, level: MKOverlayLevel) ","    func insertOverlay(_ overlay: MKOverlay, above sibling: MKOverlay) ","    func insertOverlay(_ overlay: MKOverlay, below sibling: MKOverlay)","    \/\/...","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Blend modes are order dependent. The overlay at the bottom of the stack is blended with the map, the second-to-last overlay is then blended with the result of the previous blend operation, and so on."},{"type":"text","text":"\n"},{"type":"text","text":"In MapKit, the order of overlays is determined at insertion time. we can use either absolute or relative positioning using one of MKMapView’s many overlay insertion functions."}]},{"text":"Blend modes:","type":"heading","level":2,"anchor":"Blend-modes"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Multiply","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Screen","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Overlay","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Darken","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Lighten"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"ColorDodge"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"ColorBurn"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"LinearBurn","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"SoftLight"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"HardLight"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Difference","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Exclusion","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Hue"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Saturation"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Color"}]}]},{"content":[{"inlineContent":[{"text":"Luminosity","type":"text"}],"type":"paragraph"}]}]},{"text":"Selectable Map Features","type":"heading","level":1,"anchor":"Selectable-Map-Features"},{"type":"paragraph","inlineContent":[{"text":"Using MapKit we leverage annotations to show the location of cities, points of interest, or physical objects. Unless using POI filtering, we are placing those annotations on a map which already contains a number of similar annotations provided by Apple. Up until now, users could only interact with the annotations we provided.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"In iOS 16, using the new Selectable Map Features API, we’ll have the option to let our users select features on the map."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-selectableMapFeatures","type":"image"}]},{"type":"paragraph","inlineContent":[{"text":"Selectable map features include points of interest, such as stores, restaurants, and landmarks; territories, such as cities and states; and physical features, such as mountain ranges and lakes.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-selectableMapFeatures2"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"To adopt Selectable Map Features in your app:"}]},{"type":"paragraph","inlineContent":[{"text":"First, configure which feature types should be selectable. There are three main feature types, and it might not make sense for all of them to be interactive. For points-of-interest features, we can also use existing filter API to further restrict which points-of-interest categories can appear and therefore be selectable.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Second, implement the ","type":"text"},{"code":"MKMapView","type":"codeVoice"},{"text":" delegate callbacks to handle selection events. We might want to control how selected features appear, or might want to show some additional UI in response to the selection events.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Third, to request and display additional place information in the application’s user interface. To give users more context about the place they selected, we’ll need to request additional information."}]},{"type":"paragraph","inlineContent":[{"text":"We’ll start with configuring which map features should be selectable using the new ","type":"text"},{"type":"codeVoice","code":"selectableMapFeatures"},{"text":" property.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKMapView {","    var selectableMapFeatures: MKMapFeatureOptions","}","","struct MKMapFeature0ptions: OptionSet {","    static var points0fInterest ","    static var territories ","    static var physicalFeatures","}"]},{"type":"paragraph","inlineContent":[{"text":"We can choose any combination of points of interest, territories, and physical features. Once we have configured the selectable map features and the user taps one of those features, we’ll start receiving some new delegate callbacks allowing to customize the selection behavior.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["protocol MKMapViewDelegate {","    optional func mapView(_: MKMapView, didSelect annotation: MKAnnotation) ","    optional func mapView(_: MKMapView, didDeselect annotation: MKAnnotation) ","    ","    \/\/ existing","    optional func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView?","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The first callback is the new didSelect annotation. This callback is a great opportunity to request additional data about the map item using the new request API."}]},{"type":"paragraph","inlineContent":[{"text":"The second callback is the existing viewFor annotation. This is where we can customize the view which will be shown for the selected state.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"While this is existing API, there is a new type of annotation class called ","type":"text"},{"type":"codeVoice","code":"MapFeatureAnnotation"},{"text":".","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKMapFeatureAnnotation: MKAnnotation {","    var featureType: FeatureType ","    var point0fInterestCategory: MKPoint0fInterestCategory?","    var iconStyle: MKIconStyle?","}"]},{"type":"paragraph","inlineContent":[{"text":"This class will be passed to “view for annotation” when the user selects a map feature. ","type":"text"},{"code":"MapFeatureAnnotation","type":"codeVoice"},{"text":" has a number of properties. We can inspect the ","type":"text"},{"code":"FeatureType","type":"codeVoice"},{"text":" property to determine whether the map feature is a point of interest, a territory, or a physical feature. If the map feature is a point of interest, the ","type":"text"},{"code":"pointOfInterestCategory","type":"codeVoice"},{"text":" property will let us know what its category is, and the ","type":"text"},{"code":"iconStyle","type":"codeVoice"},{"text":" property will let us obtain additional information about the icon, such as its background color and the icon image itself.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKIconStyle {","    var backgroundColor: UIColor ","    var image: UIImage","}"]},{"type":"paragraph","inlineContent":[{"text":"How to customize the annotation view using the viewFor annotation callback. To achieve the same selection style as the Maps app, return nil.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView? {","    return nil","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"To customize the selection style, we can return an annotationView, the same way we would for our own annotations."}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView? {","    ","    if let feature = annotation as MKMapFeatureAnnotation? {","        var annotationView: MKMarkerAnnotationView =","        \/\/ dequeue or create","        annotationView.image = feature.iconStyle?.image","        annotationView.color = \/\/ application tint color","        return annotationView","    }","    \/\/ else","    return nil","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The "},{"type":"codeVoice","code":"markerAnnotationView"},{"type":"text","text":" is a great option. It will give us the same balloon-style shape as the Maps app, a gradient treatment, and it allows to choose our own color or icon. To go fully custom, we can provide any annotation view subclass that we create."}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView?","{","    return MyUnicornAnnotationView()","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We can use the feature annotation to retrieve visual information about the selected feature. By passing the feature annotation on to our new "},{"code":"MKMapItemRequest","type":"codeVoice"},{"type":"text","text":" API, we can also retrieve a map item for the selected feature."}]},{"type":"codeListing","syntax":"swift","code":["class MKMapItemRequest : NSObject {","","    init(featureAnnotation: MKMapFeatureAnnotation) {}","    ","    func getMapItem(completionHandler: @escaping (MKMapItem?, Error?) -> Void) {}","    var mapItem: MKMapItem { get async throws }","}"]},{"type":"paragraph","inlineContent":[{"text":"This map item contains additional metadata about the place, such as an address, a name, a phone number, and a URL.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"The map item also provides a function to punch out to the Maps app if the users want to see additional metadata which isn’t available through MapKit.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["\/\/ Existing API","","open class MKMapItem : NSObject {","    open var placemark: MKPlacemark { get }","    open var name: String?","    open var phoneNumber: String?","    open var url: URL?","    ","    \/\/ ...","    ","    func openInMaps (launchOptions: [String : Any]? = nil, ","        from scene: UIScene?) async -> Bool {}"]},{"text":"The explore feature of the sample app","type":"heading","level":1,"anchor":"The-explore-feature-of-the-sample-app"},{"type":"paragraph","inlineContent":[{"type":"text","text":"The users should be able to explore some interesting places near the waterfront. If they tap on POIs, annotations should show up. We will perform a camera animation to the tapped location, and show an info card from the bottom."}]},{"type":"paragraph","inlineContent":[{"text":"First, let’s filter points of interest on the map and remove the categories which are irrelevant to the tour.","type":"text"},{"text":" ","type":"text"},{"text":"Aside from applying the filter in code, we can also apply it in Interface Builder inspector. Let’s select the map view, and go to inspector on the right-hand side and do an exclusion filter.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"lets select the categories that we don’t want, for example: airport, car rental, hospital, and laundry."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-exploreMapFeatures"}]},{"type":"paragraph","inlineContent":[{"text":"It’s very simple to enable Selectable Map Features. All we need to do is to specify an option set of desired selectable features.","type":"text"},{"text":"\n","type":"text"},{"text":"In the scope of this sample app, we’ll just use points of interest, but we also can support selectable physical features and territories.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["override func viewDidLoad() {","    super.viewDidLoad()","    ","    mapView.region = .annotation","    ","    mapView.cameraBoundary = MKMapView.CameraBoundary(coordinateRegion: .annotationCameraBoundary)","    ","    \/\/ Enable selectable map","    mapView.selectableMapFeatures = [.pointsOfInterest]"]},{"type":"paragraph","inlineContent":[{"text":"We can use the existing delegate method mapView viewForAnnotation to create a view for the feature annotation.","type":"text"},{"text":" ","type":"text"},{"text":"Here, we’ll just return nil… To use the default gradient annotation offered by MapKit.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_ mapView: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView? {","    return nil","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"If an annotation is on Selected state, we will be informed through the new delegate method mapView didSelectAnnotation."},{"type":"text","text":"\n"},{"type":"text","text":"We use this function to perform a camera animation and zoom in on the selected feature."},{"type":"text","text":" "},{"type":"text","text":"First, we cast the annotation to featureAnnotation, then create a map item request with it."},{"type":"text","text":" "},{"type":"text","text":"This is a new API to fetch additional place informations with feature annotations."},{"type":"text","text":" "},{"type":"text","text":"We issue the request. Once the fetch operation succeeds, we will animate to the map item. When the camera animation has completed, we will get details from the feature item and show them on an info card."}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_ mapView: MKMapView, didSelect annotation: MKAnnotation) {","    guard let featureAnnotation = annotation as? MKMapFeatureAnnotation else { return }","    let featureRequest = MKMapItemRequest(mapFeatureAnnotation: featureAnnotation)","","    Task {","    ","        \/\/ Issue request.","        do {","            guard let featureItem = try await featureRequest.mapItem else { return }","        ","            UIView.animate(withDuration: 4) {","            ","                \/\/ Update map camera","                self.animateCamera(featureItem)","            ","            } completion: { _ in","                \/\/ Concatenate info string from map item - name, category, url and address","                self.showInfoCardView(featureItem)","            }","        } catch {","    ","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The gradient annotations show up. The camera animates to the tab location. Then the info card shows up."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-exploreMapFeatures2","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Now let’s customize our annotation for the selection state."},{"type":"text","text":"\n"},{"type":"text","text":"Instead of nil, let’s create a "},{"code":"MarkerAnnotationView","type":"codeVoice"},{"type":"text","text":". We’ll cast the annotation to "},{"code":"featureAnnotation","type":"codeVoice"},{"type":"text","text":" first, so we can use specific data from it to customize the view. Let’s tint the annotation with a purple-ish color so it’s in line with our corporate identity."},{"type":"text","text":" "},{"type":"text","text":"We can also customize the annotation glyph. "},{"code":"SelectedGlyphImage","type":"codeVoice"},{"type":"text","text":" is for annotations on Selected state. GlyphImage is smaller. It is the glyph for annotations on Unselected state. Assigning them the same glyph is recommended for a smooth transition from the Unselected to Selected state."},{"type":"text","text":"\n"},{"type":"text","text":"Let’s use the icon style image we got from the featureAnnotation."},{"type":"text","text":"\n"},{"code":"MKIconStyle","type":"codeVoice"},{"type":"text","text":" is a new class in iOS16. It has the iconography and color info of the selected POI."}]},{"type":"codeListing","syntax":"swift","code":["func mapView(_: MKMapView, viewFor annotation: MKAnnotation) -> MKAnnotationView? {","    ","    if let featureAnnotation = annotation as? MKMapFeatureAnnotation {","        ","        let customView = MKMarkerAnnotationView(annotation: featureAnnotation, reuseIdentifier: nil)","        ","        customView.markerTintColor = UIColor(red: 0.63, green: 0.27, blue: 0.63, alpha: 1.0)","        ","        customView.selectedGlyphImage = featureAnnotation.iconStyle?.image","        customView.glyphImage = featureAnnotation.iconStyle?.image","        ","        return customView","    }","    ","    let annotationView = MKMarkerAnnotationView(annotation: annotation, reuseIdentifier: nil)","    return annotationView","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Now we have an annotation that matches our corporate colors, but still uses Apple iconography."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-exploreMapFeatures3","type":"image"}]},{"text":"Look Around!","type":"heading","level":1,"anchor":"Look-Around"},{"type":"paragraph","inlineContent":[{"text":"The Maps app introduced Look Around in iOS 13","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-lookAround"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Look Around is available in many places around the world, including these cities, and entire countries."}]},{"text":"Cities:","type":"heading","level":2,"anchor":"Cities"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Atlanta, GA \/ Boston, MA \/ Chicago, IL \/ Denver, CO \/ Detroit, MI \/ Dublin, Ireland \/ Edinburgh, Scotland \/ Fukuoka, Japan \/ Hiroshima, Japan \/ Houston, TX \/ Kanazawa, Japan \/ Las Vegas, NV \/ London, United Kingdom \/ Los Angeles, CA \/ Miami, FL \/ Nagoya, Japan \/ New York, NY \/ Oahu, HI \/ Osaka, Japan \/ Philadelphia, PA \/ Phoenix, AZ \/ Portland, OR \/ Sagamihara, Japan \/ San Diego, CA \/ San Francisco Bay Area \/ Santa Cruz, CA \/ Seattle, WA \/ Sendai, Japan \/ Takamatsu, Japan \/ Tokyo, Japan \/ Washington, DC \/ Yokohama, Japan"}]},{"text":"Countries and territories:","type":"heading","level":2,"anchor":"Countries-and-territories"},{"type":"paragraph","inlineContent":[{"text":"Andorra \/ Australia \/ Canada \/ Gibraltar \/ Italy \/ Portugal \/ San Marino \/ Spain","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"With iOS 16, Look Around is coming to MapKit, and adopting it only requires three steps."}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Check for data availability."},{"type":"text","text":"\n"},{"type":"text","text":"Check whether data is available for the desired location. Even if Look Around is available in the target region, not every location can be seen from a street, and therefore, Look Around imagery might not always be available."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Pass data to the Look Around UI."},{"type":"text","text":" "},{"type":"text","text":"Once we’ve determined whether Look Around data is available, we’ll need to pass that data on to either the Look Around View Controller or the Look Around Snapshotter."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Conditionally show Look Around UI."},{"type":"text","text":"\n"},{"type":"text","text":"And finally, if Look Around data is available, we’ll want to update your app UI to show the Look Around preview."}]}]}]},{"type":"paragraph","inlineContent":[{"text":"We create a ","type":"text"},{"code":"LookAroundSceneRequest","type":"codeVoice"},{"text":", which is a new class introduced in iOS 16. we can initialize a new instance with either a coordinate or a map item.","type":"text"},{"text":"\n","type":"text"},{"text":"we’ll retrieve its scene property. This is an optional async property. If data is available, we will get back a scene instance. If data is not available, we will get back a nil instead. And if there was a problem with the request, an error will be thrown.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKLookAroundSceneRequest {","    init (coordinate: CLLocationCoordinate2D)","    init (mapItem: MKMapItem)","    var scene: MKLookAroundScene? { get async throws }","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The Look Around Scene is an opaque object with no properties. It acts as a token that ensures the availability of Look Around imagery for a requested location."}]},{"type":"codeListing","syntax":"swift","code":["class MKLookAroundScene {","","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"To show an interactive preview of the Look Around scene, we pass the scene on to a new Look Around View Controller instance as an init parameter or assign it to the read write scene property of an existing instance."}]},{"type":"codeListing","syntax":"swift","code":["class MKLookAroundViewController : UIViewController {","    init (scene: MKLookAroundScene)","    var scene: MKLookAroundScene?","}"]},{"type":"paragraph","inlineContent":[{"text":"Alternatively, we can also pass the scene on to a new Look Around View Snapshotter instance as an init parameter and subsequently retrieve its snapshot async property.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["class MKLookAroundSnapshotter {","    init (scene: MKLookAroundScene, options: MKLookAroundSnapshotter.Options) ","    var snapshot: MKLookAroundSnapshotter.Snapshot { get async throws }"]},{"type":"paragraph","inlineContent":[{"text":"The Look Around view controller is designed to embed a smaller static preview of a Look Around image, which the user can tap on to enter a full-screen Look Around interactive session.","type":"text"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-lookAround2","type":"image"}]},{"text":"Highlights feature of the sample app","type":"heading","level":1,"anchor":"Highlights-feature-of-the-sample-app"},{"type":"paragraph","inlineContent":[{"type":"text","text":"The last sample app feature, Highlights. Users can get a realistic view of must-see places."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We already have a couple of San Francisco landmark names in the segment control bar on top of the screen. When users tap on one of them, we want to perform a camera animation to the tapped location. We also want to show a Look around preview at bottom left, which users can expand to full screen. Let’s do it! First we need to add a container view for the Look Around preview."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-highlights"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let’s go to the size inspector. Let’s give it a position and size."}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-highlights2","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"We want to hide this preview at the beginning, so let’s open the attributes inspector and check Hidden."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Next, we need to create a Look Around view controller…"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC22-10035-highlights3","type":"image"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"And embed it to the container view."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-highlights4"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Same as any other segue, we need to give it an identifier."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-highlights5"}]},{"type":"paragraph","inlineContent":[{"text":"Let’s call it ","type":"text"},{"code":"presentLookAroundEmbedded","type":"codeVoice"},{"text":". And import it to code so we can update its visibility later.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Let’s name it “preview.” Here, we already have a LookAroundViewController declared. We just need to grab the instance in the prepare function."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-highlights6"}]},{"type":"paragraph","inlineContent":[{"text":"Make sure the segue identifier is matched.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["override func prepare(for segue: UIStoryboardSegue, sender: Any?) {","    \/\/ Grab lookAroundViewController instance.","    if segue.identifier == \"presentLookAroundEmbedded\" {","        if let lookAroundViewController = segue.destination as? MKLookAroundViewController {","            self.lookAroundViewController = lookAroundViewController","            }","        }","    }"]},{"type":"paragraph","inlineContent":[{"text":"Then, in the segment control function, we’ll create a local search with the landmark name.","type":"text"},{"text":" ","type":"text"},{"text":"If the request succeeds, we will get a map item which will be used in the following camera animation and Look Around scene retrieval.","type":"text"},{"text":"\n","type":"text"},{"text":"For camera animation, we first need to create a camera with the new API. MapCamera looking at map item. Let’s use map view frame size for the view size, and set allow pitch to true. This will give us a pitch view to landmarks and a top-down view to other places. Assign the new camera. That’s it.","type":"text"}]},{"type":"codeListing","syntax":"swift","code":["@IBAction func landmark(_ sender: UISegmentedControl) {","    cleanUpPreview()","    ","    let request = MKLocalSearch.Request()","    if sender.selectedSegmentIndex == 0 {","        request.naturalLanguageQuery = \"Ferry Building\"","    } else if sender. selectedSegmentIndex == 1 {","        request.naturalLanquageQuery = \"Coit Tower\"","    } else if sender.selectedSegmentIndex == 2 {","        request.naturalLanguageQuery = \"Dragon Gate\"","    }","","    let search = MKLocalSearch (request: request)","    search.start { response, error in","        guard let response = response else { return }","    ","        if let item = response.mapItems.first {","        ","            UIView.animate(withDuration: 6) {","        ","            \/\/ Camera animation","            let camera = MKMapCamera(lookingAt: item, forViewsize: self.mapView.frame.size, allowPitch: true)","            self.mapView.camera = camera","            ) completion: { _ in","        ","                \/\/ Prepare LookAround preview.","                self.configureLookAroundScene(item)","                }","            }","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Once the camera animation is completed, we’ll show its Look Around preview."},{"type":"text","text":"\n"},{"type":"text","text":"First, we need to determine if the Look Around data is available for this map item. To do that, we need to use the new LookAroundSceneRequest class. Let’s create our request and pass in the map item. Then perform the request."},{"type":"text","text":"\n"},{"type":"text","text":"If get scene request succeeds, then we assign the scene to our LookAroundViewController."}]},{"type":"codeListing","syntax":"swift","code":["func configureLookAroundScene(_ item: MKMapItem) {","    guard let lookAroundViewController = self.lookAroundViewController else { return }","    let lookAroundRequest = MKLookAroundSceneRequest(mapItem: item)","","    Task {","        \/\/ Create LookAround scene request.","        do {","            \/\/ Issue request.","            guard let lookAroundScene = try await lookAroundRequest.scene else { return }","            lookAroundViewController.scene = lookAroundScene","            ","            \/\/ Show lookAround preview.","            self.preview.isHidden = false","        } catch {","        ","        }","    }","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"If there is no error but we get nil for the scene, it means Look Around data is not available at the request location."}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC22-10035-last"}]},{"text":"Check out also","type":"heading","level":1,"anchor":"Check-out-also"},{"type":"paragraph","inlineContent":[{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc22\/10006"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/tech-talks\/110356"}]},{"text":"Written By","type":"heading","level":2,"anchor":"Written-By"},{"columns":[{"content":[{"inlineContent":[{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4","type":"image"}],"type":"paragraph"}],"size":1},{"content":[{"anchor":"laurent-b","text":"laurent b","level":3,"type":"heading"},{"type":"paragraph","inlineContent":[{"type":"reference","isActive":true,"overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"overridingTitle":"Contributed Notes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/github.com\/multitudes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/laurentbrusa.hashnode.dev\/"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/x.com\/wrmultitudes"}]}],"size":4}],"numberOfColumns":5,"type":"row"},{"type":"paragraph","inlineContent":[{"text":"Missing anything? Corrections? ","type":"text"},{"isActive":true,"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"reference"}]},{"text":"Related Sessions","type":"heading","level":2,"anchor":"Related-Sessions"},{"style":"list","type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10006-Meet-Apple-Maps-Server-APIs"]},{"type":"small","inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}]},{"type":"small","inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}]}],"kind":"content"}],"sections":[],"sampleCodeDownload":{"kind":"sampleDownload","action":{"overridingTitle":"Watch Video (41 min)","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc22\/10035","type":"reference"}},"schemaVersion":{"minor":3,"patch":0,"major":0},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc22-10035-whats-new-in-mapkit"]}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22"]]},"kind":"article","metadata":{"role":"sampleCode","modules":[{"name":"WWDC Notes"}],"title":"What’s new in MapKit","roleHeading":"WWDC22"},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10035-Whats-new-in-MapKit","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"Come along with us as MapKit enters a new dimension. We’ll show you how you can upgrade your app to use the latest map and support the highly-detailed 3D City Experience. Learn how you can visualize data using overlays while ensuring they integrate smoothly into the 3D map. We’ll also cover how to create interactive and immersive experiences with Selectable Map Features and Look Around APIs."}],"references":{"WWDC22-10035-aboveLevels4":{"identifier":"WWDC22-10035-aboveLevels4","alt":"Above Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels4.jpg","traits":["1x","light"]}]},"WWDC22-10035-exploreMapFeatures3":{"identifier":"WWDC22-10035-exploreMapFeatures3","alt":"Explore Map Features","type":"image","variants":[{"url":"\/images\/WWDC22-10035-exploreMapFeatures3.jpg","traits":["1x","light"]}]},"WWDC22-10035-deviceSupport":{"identifier":"WWDC22-10035-deviceSupport","alt":"Device Support","type":"image","variants":[{"url":"\/images\/WWDC22-10035-deviceSupport.jpg","traits":["1x","light"]}]},"WWDCNotes.png":{"identifier":"WWDCNotes.png","alt":null,"type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10043-Whats-new-in-App-Store-Connect":{"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10043-whats-new-in-app-store-connect","title":"What’s new in App Store Connect","abstract":[{"text":"Discover the latest updates to App Store Connect, your suite of tools to create, manage, and submit apps on the App Store. Learn about enhancements to the submission experience — including the ability to manage submissions in App Store Connect on iOS and iPadOS — as well as the newest updates to the App Store Connect API and much more.","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10043-Whats-new-in-App-Store-Connect"},"WWDC22-10035-exploreMapFeatures2":{"identifier":"WWDC22-10035-exploreMapFeatures2","alt":"Explore Map Features","type":"image","variants":[{"url":"\/images\/WWDC22-10035-exploreMapFeatures2.jpg","traits":["1x","light"]}]},"WWDC22-10035-aboveLevels2":{"identifier":"WWDC22-10035-aboveLevels2","alt":"Above Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels2.jpg","traits":["1x","light"]}]},"WWDC22-10035-lookAround2":{"identifier":"WWDC22-10035-lookAround2","alt":"Look Around","type":"image","variants":[{"url":"\/images\/WWDC22-10035-lookAround2.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10005-Whats-new-in-HealthKit":{"title":"What’s new in HealthKit","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc22-10005-whats-new-in-healthkit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10005-Whats-new-in-HealthKit","abstract":[{"text":"Bring the latest HealthKit features to your health & fitness app. We’ll show you how to capture more detailed sleep data through sleep stages, track swim-bike-run and interval workouts with the enhanced Workout API, and save vision prescriptions — including an image of the physical prescription — directly to HealthKit while preserving privacy.","type":"text"}],"role":"sampleCode"},"WWDC22-10035-aboveLevels3":{"identifier":"WWDC22-10035-aboveLevels3","alt":"Above Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels3.jpg","traits":["1x","light"]}]},"WWDC22-10035-highlights4":{"identifier":"WWDC22-10035-highlights4","alt":"highlights","type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights4.jpg","traits":["1x","light"]}]},"WWDC22-10035-standardMapConfig":{"identifier":"WWDC22-10035-standardMapConfig","alt":"Standard Map Config","type":"image","variants":[{"url":"\/images\/WWDC22-10035-standardMapConfig.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10097-Whats-new-in-App-Clips":{"url":"\/documentation\/wwdcnotes\/wwdc22-10097-whats-new-in-app-clips","type":"topic","title":"What’s new in App Clips","abstract":[{"type":"text","text":"Explore the latest updates to App Clips! Discover how we’ve made your App Clip even easier to build with improvements to the size limit as well as CloudKit and keychain usage. We’ll also show you how to use our validation tool to verify your App Clip and automate workflows for your advanced App Clip experiences using App Store Connect."}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10097-Whats-new-in-App-Clips","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10039-Whats-new-in-StoreKit-testing":{"title":"What’s new in StoreKit testing","url":"\/documentation\/wwdcnotes\/wwdc22-10039-whats-new-in-storekit-testing","role":"sampleCode","abstract":[{"text":"Discover the latest tools to help you test your in-app purchases and subscriptions. We’ll show you how to bring your products from App Store Connect into StoreKit Testing in Xcode, learn about improvements to the transaction manager, and explore your in-app purchase flow in Xcode Previews. We’ll also take you through best practices when setting up an Apple ID for the sandbox environment, and show you how to create tests for refund requests, price increase consent, billing retry, and much more.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10039-Whats-new-in-StoreKit-testing","kind":"article","type":"topic"},"https://x.com/wrmultitudes":{"identifier":"https:\/\/x.com\/wrmultitudes","type":"link","titleInlineContent":[{"text":"X\/Twitter","type":"text"}],"title":"X\/Twitter","url":"https:\/\/x.com\/wrmultitudes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10099-Whats-new-in-Safari-Web-Extensions":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10099-Whats-new-in-Safari-Web-Extensions","url":"\/documentation\/wwdcnotes\/wwdc22-10099-whats-new-in-safari-web-extensions","abstract":[{"text":"Learn how you can use the latest improvements to Safari Web Extensions to create even better experiences for people browsing the web. We’ll show you how to upgrade to manifest version 3, adopt the latest APIs for Web Extensions, and sync extensions across devices.","type":"text"}],"type":"topic","kind":"article","title":"What’s new in Safari Web Extensions"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110368-Whats-new-in-SwiftDocC":{"url":"\/documentation\/wwdcnotes\/wwdc22-110368-whats-new-in-swiftdocc","abstract":[{"text":"Join us for an exciting update on Swift-DocC and learn how you can write and share documentation for your own projects. We’ll explore improvements to Swift-DocC navigation and share how you can compile documentation for application targets and Objective-C code. We’ll also show you how to publish your content straight to hosting services like GitHub Pages.","type":"text"}],"type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110368-Whats-new-in-SwiftDocC","title":"What’s new in Swift-DocC","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10049-Whats-new-in-WKWebView":{"abstract":[{"type":"text","text":"Explore the latest updates to WKWebView, our framework for incorporating web content into your app’s interface. We’ll show you how to use the JavaScript fullscreen API, explore CSS viewport units, and learn more about find interactions. We’ll also take you through refinements to content blocking controls, embedding encrypted media, and using the Web Inspector."}],"kind":"article","role":"sampleCode","title":"What’s new in WKWebView","url":"\/documentation\/wwdcnotes\/wwdc22-10049-whats-new-in-wkwebview","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10049-Whats-new-in-WKWebView"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10008-Whats-new-in-Nearby-Interaction":{"url":"\/documentation\/wwdcnotes\/wwdc22-10008-whats-new-in-nearby-interaction","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10008-Whats-new-in-Nearby-Interaction","abstract":[{"text":"Discover how the Nearby Interaction framework can help you easily integrate Ultra Wideband (UWB) into your apps and hardware accessories. Learn how you can combine the visual-spatial power of ARKit with the radio sensitivity of the U1 chip to locate nearby stationary objects with precision. We’ll also show you how you can create background interactions using UWB accessories paired via Bluetooth.","type":"text"}],"type":"topic","role":"sampleCode","kind":"article","title":"What’s new in Nearby Interaction"},"WWDC22-10035-last":{"identifier":"WWDC22-10035-last","alt":"look around preview","type":"image","variants":[{"url":"\/images\/WWDC22-10035-last.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10089-Whats-new-in-PDFKit":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10089-Whats-new-in-PDFKit","url":"\/documentation\/wwdcnotes\/wwdc22-10089-whats-new-in-pdfkit","abstract":[{"text":"Discover PDFKit — a full-featured framework that helps your app view, edit, and save PDF documents. We’ll take you through the latest features in PDFKit, including support for live text and forms, creating PDFs from images, building interactive overlays, and saving annotations.","type":"text"}],"type":"topic","kind":"article","title":"What’s new in PDFKit"},"WWDC22-10035-sampleApp4":{"identifier":"WWDC22-10035-sampleApp4","alt":"Sample App Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp4.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110354-Whats-new-in-Swift":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110354-Whats-new-in-Swift","title":"What’s new in Swift","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-110354-whats-new-in-swift","abstract":[{"type":"text","text":"Join us for an update on Swift. We’ll take you through performance improvements, explore more secure and extensible Swift packages, and share advancements in Swift concurrency. We’ll also introduce you to Swift Regex, better generics, and other tools built into the language to help you write more flexible & expressive code."}],"type":"topic"},"WWDC22-10035-sampleApp6":{"identifier":"WWDC22-10035-sampleApp6","alt":"Sample App Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp6.jpg","traits":["1x","light"]}]},"WWDC22-10035-maps1":{"identifier":"WWDC22-10035-maps1","alt":"maps","type":"image","variants":[{"url":"\/images\/WWDC22-10035-maps1.jpg","traits":["1x","light"]}]},"WWDC22-10035-blendModes2":{"identifier":"WWDC22-10035-blendModes2","alt":"Blend modes","type":"image","variants":[{"url":"\/images\/WWDC22-10035-blendModes2.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10068-Whats-new-in-UIKit":{"title":"What’s new in UIKit","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10068-Whats-new-in-UIKit","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc22-10068-whats-new-in-uikit","abstract":[{"type":"text","text":"Discover the latest updates and improvements to UIKit and learn how to build better iPadOS, iOS, and Mac Catalyst apps. We’ll take you through UI refinements, productivity updates, API enhancements, and more. We’ll also help you explore improvements to performance, security, and privacy."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10024-Whats-new-in-Vision":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10024-Whats-new-in-Vision","title":"What’s new in Vision","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10024-whats-new-in-vision","abstract":[{"type":"text","text":"Learn about the latest updates to Vision APIs that help your apps recognize text, detect faces and face landmarks, and implement optical flow. We’ll take you through the capabilities of optical flow for video-based apps, show you how to update your apps with revisions to the machine learning models that drive these APIs, and explore how you can visualize your Vision tasks with Quick Look Preview support in Xcode."}],"type":"topic"},"WWDC22-10035-ferryBuilding":{"identifier":"WWDC22-10035-ferryBuilding","alt":"Ferry Building","type":"image","variants":[{"url":"\/images\/WWDC22-10035-ferryBuilding.jpg","traits":["1x","light"]}]},"WWDC22-10035-selectableMapFeatures2":{"identifier":"WWDC22-10035-selectableMapFeatures2","alt":"Selectable Map Features","type":"image","variants":[{"url":"\/images\/WWDC22-10035-selectableMapFeatures2.jpg","traits":["1x","light"]}]},"https://github.com/multitudes":{"identifier":"https:\/\/github.com\/multitudes","type":"link","titleInlineContent":[{"text":"GitHub","type":"text"}],"title":"GitHub","url":"https:\/\/github.com\/multitudes"},"https://developer.apple.com/wwdc22/10006":{"identifier":"https:\/\/developer.apple.com\/wwdc22\/10006","type":"link","titleInlineContent":[{"text":"Meet Apple Map Server APIs - WWDC22","type":"text"}],"title":"Meet Apple Map Server APIs - WWDC22","url":"https:\/\/developer.apple.com\/wwdc22\/10006"},"WWDC22-10035-highlights5":{"identifier":"WWDC22-10035-highlights5","alt":"highlights","type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights5.jpg","traits":["1x","light"]}]},"WWDC22-10035-london":{"identifier":"WWDC22-10035-london","alt":"London St Paul","type":"image","variants":[{"url":"\/images\/WWDC22-10035-london.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110427-Whats-new-in-Xcode":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110427-Whats-new-in-Xcode","title":"What’s new in Xcode","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-110427-whats-new-in-xcode","abstract":[{"type":"text","text":"Discover the latest productivity and performance advancements in Xcode 14. We’ll introduce you to the fully redesigned SwiftUI canvas experience, explore enhancements to code completion and navigation, and take you through performance improvements we’ve made throughout the entire development process. We’ll also show you how you can now read and respond to feedback on your TestFlight builds without ever leaving Xcode."}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10023-Whats-new-in-the-Photos-picker":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10023-Whats-new-in-the-Photos-picker","title":"What’s new in the Photos picker","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10023-whats-new-in-the-photos-picker","abstract":[{"type":"text","text":"PHPicker provides simple and secure integration between your app and the system Photos library. Learn how SwiftUI and Transferable can help you offer integration across iOS, iPadOS, macOS, and watchOS."}],"type":"topic"},"WWDC22-10035-blendModes":{"identifier":"WWDC22-10035-blendModes","alt":"Blend modes","type":"image","variants":[{"url":"\/images\/WWDC22-10035-blendModes.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10045-Whats-new-in-managing-Apple-devices":{"url":"\/documentation\/wwdcnotes\/wwdc22-10045-whats-new-in-managing-apple-devices","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10045-Whats-new-in-managing-Apple-devices","type":"topic","title":"What’s new in managing Apple devices","abstract":[{"text":"Explore enhancements to device management across Apple platforms. Improve device deployment workflows using the latest version of Apple Configurator for iPhone. Learn about identity technologies and MDM protocol updates for macOS, iOS and iPadOS. We’ll also share an exciting change in how we provide device management documentation.","type":"text"}]},"https://avatars.githubusercontent.com/u/29355828?v=4":{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4","alt":"Profile image of laurent b","type":"image","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4","traits":["1x","light"]}]},"WWDC22-10035-highlights2":{"identifier":"WWDC22-10035-highlights2","alt":"highlights","type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights2.jpg","traits":["1x","light"]}]},"https://developer.apple.com/wwdc22/10035":{"identifier":"https:\/\/developer.apple.com\/wwdc22\/10035","type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc22\/10035"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10109-Whats-new-in-notarization-for-Mac-apps":{"url":"\/documentation\/wwdcnotes\/wwdc22-10109-whats-new-in-notarization-for-mac-apps","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10109-Whats-new-in-notarization-for-Mac-apps","type":"topic","title":"What’s new in notarization for Mac apps","abstract":[{"text":"Notarization works in tandem with macOS to help people safely download software for their Mac outside of the App Store. Learn about the required transition from altool to notarytool and how the Xcode GUI can help you achieve better overall performance when notarizing your app. We’ll also share information about APIs for interacting with the Notary service from any internet-connected machine.","type":"text"}]},"WWDC22-10035-selectableMapFeatures":{"identifier":"WWDC22-10035-selectableMapFeatures","alt":"Selectable Map Features","type":"image","variants":[{"url":"\/images\/WWDC22-10035-selectableMapFeatures.jpg","traits":["1x","light"]}]},"WWDC22-10035-DeprecatedAPI":{"identifier":"WWDC22-10035-DeprecatedAPI","alt":"Deprecated API","type":"image","variants":[{"url":"\/images\/WWDC22-10035-DeprecatedAPI.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10149-Whats-new-in-AVQT":{"title":"What’s new in AVQT","url":"\/documentation\/wwdcnotes\/wwdc22-10149-whats-new-in-avqt","role":"sampleCode","abstract":[{"text":"Discover the latest updates and improvements to the Advanced Video Quality Tool (AVQT). We’ll take you through the interactive reports feature and help you learn how to identify video quality-related issues. We’ll also explore extended support for raw formats, show you how to evaluate specific scenes within a video, and explore how you can use AVQT for Linux to analyze videos on Linux servers and online in the cloud.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10149-Whats-new-in-AVQT","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10115-Whats-new-in-CloudKit-Console":{"type":"topic","kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10115-Whats-new-in-CloudKit-Console","abstract":[{"type":"text","text":"We’ll take you through the latest updates to CloudKit Console and discover how you can explore and debug your containers on the web like never before. Learn more about Act as iCloud, which helps you query records and view data from the perspective of another account. Discover how to share zones of records, and provide better collaboration between participants. And find out how to hide inactive containers. We’ll also share a few tips on getting the most out of CloudKit Console."}],"title":"What’s new in CloudKit Console","url":"\/documentation\/wwdcnotes\/wwdc22-10115-whats-new-in-cloudkit-console"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10145-Whats-new-in-HLS-Interstitials":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10145-Whats-new-in-HLS-Interstitials","title":"What’s new in HLS Interstitials","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10145-whats-new-in-hls-interstitials","abstract":[{"type":"text","text":"HLS Interstitials can help you create seamless transitions in video content between advertisements, other interstitials, and your HLS streams. Learn how you can optimize your ad inventory, fine-tune interstitial presentation with SNAP-IN\/OUT when using HLS, and more."}],"type":"topic"},"https://developer.apple.com/videos/play/tech-talks/110356":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/tech-talks\/110356","type":"link","titleInlineContent":[{"text":"Whats new for enterprise developer (Tech Talk) -  WWDC22","type":"text"}],"title":"Whats new for enterprise developer (Tech Talk) -  WWDC22","url":"https:\/\/developer.apple.com\/videos\/play\/tech-talks\/110356"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10096-Whats-new-in-privacy":{"kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10096-Whats-new-in-privacy","title":"What’s new in privacy","role":"sampleCode","abstract":[{"type":"text","text":"At Apple, we believe that privacy is a fundamental human right, and protecting people’s privacy is at the center of everything we do. Discover how our engineering teams build privacy into all of our products and developer frameworks, and learn about the technologies and patterns you can adopt in your apps to build trust and protect your customers."}],"url":"\/documentation\/wwdcnotes\/wwdc22-10096-whats-new-in-privacy"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110336-Whats-new-in-Screen-Time-API":{"url":"\/documentation\/wwdcnotes\/wwdc22-110336-whats-new-in-screen-time-api","kind":"article","abstract":[{"text":"Find out how you can build apps that help people manage their relationship with their device — all while putting privacy first. We’ll take you through the Screen Time API and share how you can use features like core restrictions and device activity reports to create great experiences while providing measurable control for the device’s owner, parents, and guardians.","type":"text"}],"type":"topic","title":"What’s new in Screen Time API","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110336-Whats-new-in-Screen-Time-API","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10052-Whats-new-in-SwiftUI":{"url":"\/documentation\/wwdcnotes\/wwdc22-10052-whats-new-in-swiftui","kind":"article","abstract":[{"text":"It’s a SwiftUI party — and you’re invited! Join us as we share the latest updates and a glimpse into the future of UI framework design. Discover deep levels of customization, advanced techniques for layout, elegant strategies for sharing, and rock-solid structural approaches for designing an app top-to-bottom in SwiftUI. We’ll also have some celebratory fun as we play with the latest graphical effects and explore APIs.","type":"text"}],"type":"topic","title":"What’s new in SwiftUI","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10052-Whats-new-in-SwiftUI","role":"sampleCode"},"WWDC22-10035-blendModes4":{"identifier":"WWDC22-10035-blendModes4","alt":"Blend modes","type":"image","variants":[{"url":"\/images\/WWDC22-10035-blendModes4.jpg","traits":["1x","light"]}]},"WWDC22-10035-aboveLevels6":{"identifier":"WWDC22-10035-aboveLevels6","alt":"Above Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels6.jpg","traits":["1x","light"]}]},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"link","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"},"WWDC22-10035-exploreMapFeatures":{"identifier":"WWDC22-10035-exploreMapFeatures","alt":"Explore Map Features","type":"image","variants":[{"url":"\/images\/WWDC22-10035-exploreMapFeatures.jpg","traits":["1x","light"]}]},"WWDC22-10035-aboveLevels5":{"identifier":"WWDC22-10035-aboveLevels5","alt":"Above Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels5.jpg","traits":["1x","light"]}]},"WWDC22-10035-blendModes3":{"identifier":"WWDC22-10035-blendModes3","alt":"Blend modes","type":"image","variants":[{"url":"\/images\/WWDC22-10035-blendModes3.jpg","traits":["1x","light"]}]},"WWDC22-10035-sampleApp1":{"identifier":"WWDC22-10035-sampleApp1","alt":"Sample App Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp1.jpg","traits":["1x","light"]}]},"WWDC22-10035-lookAround":{"identifier":"WWDC22-10035-lookAround","alt":"Look Around","type":"image","variants":[{"url":"\/images\/WWDC22-10035-lookAround.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10041-Whats-new-in-Wallet-and-Apple-Pay":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10041-Whats-new-in-Wallet-and-Apple-Pay","title":"What’s new in Wallet and Apple Pay","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10041-whats-new-in-wallet-and-apple-pay","abstract":[{"type":"text","text":"Discover the latest updates to Wallet & Apple Pay. We’ll show you how to support Orders in Wallet for your apps and websites and securely validate someone’s age and identity with the Identity Verification API. We’ll also explore PassKit support for SwiftUI, and discuss how you how you can improve your Apple Pay experience with Automatic Payments."}],"type":"topic"},"WWDC22-10035-sampleApp3":{"identifier":"WWDC22-10035-sampleApp3","alt":"Sample App","type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp3.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10048-Whats-new-in-Safari-and-WebKit":{"url":"\/documentation\/wwdcnotes\/wwdc22-10048-whats-new-in-safari-and-webkit","kind":"article","abstract":[{"text":"Explore the latest features in Safari and WebKit and learn how you can make better and more powerful websites. We’ll take you on a tour through the latest updates to HTML, CSS enhancements, Web Inspector tooling, Web APIs, and more.","type":"text"}],"type":"topic","title":"What’s new in Safari and WebKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10048-Whats-new-in-Safari-and-WebKit","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10009-Whats-new-in-iPad-app-design":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10009-Whats-new-in-iPad-app-design","title":"What’s new in iPad app design","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10009-whats-new-in-ipad-app-design","abstract":[{"type":"text","text":"Discover the latest updates in iPad app design. We’ll take you through improvements to search, navigation bars, edit menus, multi-selection, and more. Learn how you can make your app both more powerful and easier to use when you incorporate customizable toolbars, multi-column tables, and find and replace."}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10074-Whats-new-in-AppKit":{"title":"What’s new in AppKit","url":"\/documentation\/wwdcnotes\/wwdc22-10074-whats-new-in-appkit","role":"sampleCode","abstract":[{"text":"Discover the latest advances in Mac app development using AppKit. We’ll take you through the latest updates to SF Symbols, show you how you can elevate your interface with enhanced controls, and help you learn to coordinate your windows with Stage Manager. We’ll also explore the latest sharing and collaboration features for macOS.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10074-Whats-new-in-AppKit","kind":"article","type":"topic"},"WWDC22-10035-goldenGate":{"identifier":"WWDC22-10035-goldenGate","alt":"Golden Gate","type":"image","variants":[{"url":"\/images\/WWDC22-10035-goldenGate.jpg","traits":["1x","light"]}]},"WWDC22-10035-mapsImagery":{"identifier":"WWDC22-10035-mapsImagery","alt":"Maps Imagery","type":"image","variants":[{"url":"\/images\/WWDC22-10035-mapsImagery.jpg","traits":["1x","light"]}]},"WWDC22-10035-mapTypeMapping":{"identifier":"WWDC22-10035-mapTypeMapping","alt":"Map type mapping","type":"image","variants":[{"url":"\/images\/WWDC22-10035-mapTypeMapping.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10140-Whats-new-in-SharePlay":{"title":"What’s new in SharePlay","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc22-10140-whats-new-in-shareplay","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10140-Whats-new-in-SharePlay","abstract":[{"text":"Join us as we share the latest updates to SharePlay. We’ll show you how you can start SharePlay sessions right from your app, take you through improvements to APIs to create richer experiences, and check out enhancements to GroupSessionMessenger. We’ll also explore best practices for adding SharePlay to your app.","type":"text"}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110345-Whats-new-in-Endpoint-Security":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110345-Whats-new-in-Endpoint-Security","url":"\/documentation\/wwdcnotes\/wwdc22-110345-whats-new-in-endpoint-security","type":"topic","abstract":[{"text":"Learn how you can build reliable endpoint security products like anti-virus software, endpoint detection and response, and data leakage prevention solutions for macOS. We’ll take you through the latest enhancements to Endpoint Security APIs: Learn how you can support more security events and use advanced muting capabilities in your app. We’ll also explore a standalone tool to help you perform introspection from the command line.","type":"text"}],"title":"What’s new in Endpoint Security","kind":"article","role":"sampleCode"},"WWDC22-10035-highlights6":{"identifier":"WWDC22-10035-highlights6","alt":"highlights","type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights6.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"type":"topic","title":"WWDC Notes","url":"\/documentation\/wwdcnotes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"role":"collection","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes"},"WWDC22-10035-highlights":{"identifier":"WWDC22-10035-highlights","alt":"highlights","type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights.jpg","traits":["1x","light"]}]},"WWDC22-10035-highlights3":{"identifier":"WWDC22-10035-highlights3","alt":"highlights","type":"image","variants":[{"url":"\/images\/WWDC22-10035-highlights3.jpg","traits":["1x","light"]}]},"WWDC22-10035-aboveLevels":{"identifier":"WWDC22-10035-aboveLevels","alt":"Above Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-aboveLevels.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/multitudes":{"url":"\/documentation\/wwdcnotes\/multitudes","role":"sampleCode","type":"topic","title":"laurent b (32 notes)","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","abstract":[{"text":"student at 42Berlin 🐬 | 🍎 Swift(UI) app dev  | speciality coffee ☕️ & cycling 🚴🏻‍♂️","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22":{"kind":"article","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"type":"topic","title":"WWDC22","url":"\/documentation\/wwdcnotes\/wwdc22","abstract":[{"type":"text","text":"Xcode 14, Swift 5.7, iOS 16, macOS 13, tvOS 16, watchOS 9."},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"type":"codeVoice","code":"WeatherKit"},{"text":", ","type":"text"},{"type":"codeVoice","code":"ScreenCaptureKit"},{"text":", ","type":"text"},{"type":"codeVoice","code":"Swift Regex"},{"text":", and more.","type":"text"}],"role":"collectionGroup","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10157-Whats-new-in-SF-Symbols-4":{"kind":"article","title":"What’s new in SF Symbols 4","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10157-Whats-new-in-SF-Symbols-4","type":"topic","abstract":[{"text":"Explore the latest updates to SF Symbols, Apple’s extensive library of iconography designed to integrate seamlessly with San Francisco, the system font for all Apple platforms. Discover the latest additions to the SF Symbols library and new categories in the app. Learn about the new Automatic behavior, which chooses the rendering mode that best highlights what’s unique about the symbol’s characteristics. See how to use the new Variable Color feature to make a symbol more dynamic. We’ll also learn about a more efficient way of annotating symbols with the new unified approach.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc22-10157-whats-new-in-sf-symbols-4"},"WWDC22-10035-sampleApp2":{"identifier":"WWDC22-10035-sampleApp2","alt":"Sample App Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp2.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10090-Whats-new-in-TextKit-and-text-views":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10090-Whats-new-in-TextKit-and-text-views","url":"\/documentation\/wwdcnotes\/wwdc22-10090-whats-new-in-textkit-and-text-views","abstract":[{"text":"Discover the latest updates to TextKit and text views in UI frameworks. Explore layout refinements and API enhancements, learn how you can maintain compatibility across multiple OS versions, and find out how to modernize your app with TextKit 2.","type":"text"}],"type":"topic","kind":"article","title":"What’s new in TextKit and text views"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10006-Meet-Apple-Maps-Server-APIs":{"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10006-meet-apple-maps-server-apis","abstract":[{"text":"Simplify your app’s mapping architecture by implementing the Apple Maps stack across MapKit, MapKit JS, and Apple Maps Server APIs. Learn how these APIs can reduce network calls and increase power efficiency, which can help improve the overall performance of your app. We’ll show you how to use geocoding and estimated time of arrival APIs to build functionality for a simple store locator, and explore the API authentication flow.","type":"text"}],"role":"sampleCode","title":"Meet Apple Maps Server APIs","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10006-Meet-Apple-Maps-Server-APIs","type":"topic"},"WWDC22-10035-sampleApp5":{"identifier":"WWDC22-10035-sampleApp5","alt":"Sample App Levels","type":"image","variants":[{"url":"\/images\/WWDC22-10035-sampleApp5.jpg","traits":["1x","light"]}]},"https://laurentbrusa.hashnode.dev/":{"identifier":"https:\/\/laurentbrusa.hashnode.dev\/","type":"link","titleInlineContent":[{"text":"Blog","type":"text"}],"title":"Blog","url":"https:\/\/laurentbrusa.hashnode.dev\/"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110332-Whats-new-in-Create-ML":{"type":"topic","title":"What’s new in Create ML","abstract":[{"type":"text","text":"Discover the latest updates to Create ML. We’ll share improvements to Create ML’s evaluation tools that can help you understand how your custom models will perform on real-world data. Learn how you can check model performance on each type of image in your test data and identify problems within individual images to help you troubleshoot mistaken classifications, poorly labeled data, and other errors. We’ll also show you how to test your model with iPhone and iPad in live preview using Continuity Camera, and share how you can take Action Classification even further with the new Repetition Counting capabilities of the Create ML Components framework."}],"url":"\/documentation\/wwdcnotes\/wwdc22-110332-whats-new-in-create-ml","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110332-Whats-new-in-Create-ML","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10153-Whats-new-in-web-accessibility":{"kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10153-Whats-new-in-web-accessibility","title":"What’s new in web accessibility","role":"sampleCode","abstract":[{"type":"text","text":"Discover techniques for building rich, accessible web apps with custom controls, SSML, and the dialog element. We’ll discuss different assistive technologies and help you learn how to use them when testing the accessibility of your web apps."}],"url":"\/documentation\/wwdcnotes\/wwdc22-10153-whats-new-in-web-accessibility"}}}