{"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21"]]},"schemaVersion":{"patch":0,"major":0,"minor":3},"kind":"article","variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc21-10146-whats-new-in-avfoundation"]}],"abstract":[{"type":"text","text":"Discover the latest updates to AVFoundation, Apple‚Äôs framework for inspecting, playing, and authoring audiovisual presentations. We‚Äôll explore how you can use AVFoundation to query attributes of audiovisual assets, further customize your custom video compositions with timed metadata, and author caption files."}],"primaryContentSections":[{"kind":"content","content":[{"level":2,"anchor":"overview","type":"heading","text":"Overview"},{"inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}],"type":"paragraph"},{"inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}],"type":"paragraph"},{"level":2,"anchor":"Related-Sessions","type":"heading","text":"Related Sessions"},{"style":"list","type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110379-Create-a-more-responsive-media-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10132-Meet-asyncawait-in-Swift","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10140-Explore-dynamic-prerolls-and-midrolls-in-HLS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10143-Explore-HLS-variants-in-AVFoundation","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10158-Explore-lowlatency-video-encoding-with-VideoToolbox","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10265-Immerse-your-app-in-Spatial-Audio","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10290-Whats-new-in-AVKit"]}]}],"sections":[],"metadata":{"role":"sampleCode","roleHeading":"WWDC21","title":"What‚Äôs new in AVFoundation","modules":[{"name":"WWDC Notes"}]},"sampleCodeDownload":{"kind":"sampleDownload","action":{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10146","isActive":true,"overridingTitle":"Watch Video (16 min)"}},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10146-Whats-new-in-AVFoundation","interfaceLanguage":"swift"},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10265-Immerse-your-app-in-Spatial-Audio":{"abstract":[{"type":"text","text":"Discover how spatial audio can help you provide a theater-like experience for media in your apps and on the web. We‚Äôll show you how you can easily bring immersive audio to those listening with compatible hardware, and how to automatically deliver different listening experiences depending on someone‚Äôs bandwidth or connection ‚Äî all with little to no change to your code. And gain recommendations on how you can tailor the experience in your app and use spatial audio to tell stories in new, exciting ways."}],"url":"\/documentation\/wwdcnotes\/wwdc21-10265-immerse-your-app-in-spatial-audio","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10265-Immerse-your-app-in-Spatial-Audio","type":"topic","title":"Immerse your app in Spatial Audio","kind":"article","role":"sampleCode"},"WWDC21-Icon.png":{"identifier":"WWDC21-Icon.png","variants":[{"url":"\/images\/WWDCNotes\/WWDC21-Icon.png","traits":["1x","light"]}],"alt":null,"type":"image"},"WWDCNotes.png":{"alt":null,"type":"image","identifier":"WWDCNotes.png","variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes\/WWDCNotes.png"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"url":"\/documentation\/wwdcnotes","kind":"symbol","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"role":"collection","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"title":"WWDC Notes"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10290-Whats-new-in-AVKit":{"title":"What‚Äôs new in AVKit","url":"\/documentation\/wwdcnotes\/wwdc21-10290-whats-new-in-avkit","kind":"article","role":"sampleCode","type":"topic","abstract":[{"text":"Learn about enhancements to Picture in Picture and full screen improvements on macOS. Explore the new content source API, and learn how AVPictureInPictureController supports AVSampleBufferDisplayLayer, as well as recommended steps for an app to provide a seamless full screen experience on macOS or in a Mac Catalyst app.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10290-Whats-new-in-AVKit"},"https://developer.apple.com/videos/play/wwdc2021/10146":{"checksum":null,"type":"download","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10146","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2021\/10146"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-110379-Create-a-more-responsive-media-app":{"url":"\/documentation\/wwdcnotes\/wwdc22-110379-create-a-more-responsive-media-app","abstract":[{"type":"text","text":"Discover how you can use AVFoundation to keep people focused on your media app‚Äôs content ‚Äî not your loading spinner. We‚Äôll show you how to support a responsive and fluid interface in your app, all while you create rich audiovisual compositions, load audiovisual assets, and prepare media thumbnails. Find out how you can perform these tasks on your app‚Äôs main thread while I\/O processes in parallel, learn how to get top-notch playback performance when loading data from custom storage, and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-110379-Create-a-more-responsive-media-app","type":"topic","title":"Create a more responsive media app","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21":{"url":"\/documentation\/wwdcnotes\/wwdc21","title":"WWDC21","kind":"article","role":"collectionGroup","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21","images":[{"type":"icon","identifier":"WWDC21-Icon.png"},{"type":"card","identifier":"WWDC21.jpeg"}],"abstract":[{"type":"text","text":"Xcode 13, Swift 5.5, iOS 15, macOS 12 (Monterey), tvOS 15, watchOS 8."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"MusicKit"},{"type":"text","text":", "},{"type":"codeVoice","code":"DocC"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit 2"},{"type":"text","text":", and more."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10143-Explore-HLS-variants-in-AVFoundation":{"title":"Explore HLS variants in AVFoundation","url":"\/documentation\/wwdcnotes\/wwdc21-10143-explore-hls-variants-in-avfoundation","kind":"article","role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Discover how you can use AVFoundation APIs to highlight different variants of your content within your app. We‚Äôll show you how you can inspect HLS content using these APIs for different video characteristics, including attributes like SDR\/HDR, FPS, and the like. And we‚Äôll explore the AVAssetVariant, which represents streaming and offline content."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10143-Explore-HLS-variants-in-AVFoundation"},"WWDC21.jpeg":{"alt":null,"type":"image","identifier":"WWDC21.jpeg","variants":[{"url":"\/images\/WWDCNotes\/WWDC21.jpeg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10132-Meet-asyncawait-in-Swift":{"abstract":[{"type":"text","text":"Swift now supports asynchronous functions ‚Äî a pattern commonly known as async\/await. Discover how the new syntax can make your code easier to read and understand. Learn what happens when a function suspends, and find out how to adapt existing completion handlers to asynchronous functions."}],"url":"\/documentation\/wwdcnotes\/wwdc21-10132-meet-asyncawait-in-swift","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10132-Meet-asyncawait-in-Swift","type":"topic","title":"Meet async\/await in Swift","kind":"article","role":"sampleCode"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","titleInlineContent":[{"text":"Learn More‚Ä¶","type":"text"}],"url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10140-Explore-dynamic-prerolls-and-midrolls-in-HLS":{"title":"Explore dynamic pre-rolls and mid-rolls in HLS","url":"\/documentation\/wwdcnotes\/wwdc21-10140-explore-dynamic-prerolls-and-midrolls-in-hls","kind":"article","role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Learn how you can create seamless transitions between advertisements and your HLS streams. We‚Äôll show you how to incorporate HLS tags and AVFoundation APIs to create media experiences that move easily between your primary content and mid-rolls, and provide best practices for playing these streams in your app."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10140-Explore-dynamic-prerolls-and-midrolls-in-HLS"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10158-Explore-lowlatency-video-encoding-with-VideoToolbox":{"abstract":[{"text":"Supporting low latency encoders has become an important aspect of video application development process. Discover how VideoToolbox supports low-delay H.264 hardware encoding to minimize end-to-end latency and achieve new levels of performance for optimal real-time communication and high-quality video playback.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc21-10158-explore-lowlatency-video-encoding-with-videotoolbox","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10158-Explore-lowlatency-video-encoding-with-VideoToolbox","type":"topic","title":"Explore low-latency video encoding with VideoToolbox","kind":"article","role":"sampleCode"}}}