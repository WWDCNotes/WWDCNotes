{"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing"},"primaryContentSections":[{"content":[{"type":"heading","anchor":"ELI5-version","text":"ELI5 version","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"Windows (2D), Volumes (3D), and Spaces (amount of the user peripheral your app takes up) are the main considerations when building"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"RealityKit works with UIKit storyboards or SwiftUI interfaces"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"User privacy is protected through APIs giving the minimum required information to apps, unless they explicitly ask for additional info"}]},{"type":"paragraph","inlineContent":[{"text":"Getting your apps to run in visionOS is as simple as adding it as a target!","type":"text"}]},{"type":"heading","anchor":"Summary-of-WWDC-Session","level":2,"text":"Summary of WWDC Session"},{"type":"paragraph","inlineContent":[{"text":"Apps by default launch into a Shared Space, much like multiple apps on a macOS desktop. Apps can have one or more resizable windows containing 2D or 3D content, and users can reposition these as they wish.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Volumes (as in amount of space in a certain 3D object) allow for the display of 3D content in defined bounds, with SwiftUI scenes and RealityKit used to display your 3D content.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"The level of immersion in an app can be controlled through opening a dedicated Full Space, where only your app’s windows, volumes, and 3D objects appear. In the Full Space, you can use ARKit’s APIs, including Skeletal Hand Tracking.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Your app in Full Space can use the Passthrough mode, which blends the surroundings and sound continuously into the person’s surroundings, or the Fully Immersive space, which fills up the entire frame of view."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"A variety of gestures are detected by the system and delivered as touch events, such as taps, long presses, and drags. In addition, interactions with RealityKit entities, Skeletal hand tracking, and inputs from wireless devices are recognized as input as well."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Collaborations are enabled through SharePlay and the Group Activities framework, and any window can be shared between users."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"In terms of privacy, apps do not directly access data from the sensors. Instead, the system delivers events, visual cues, touch events to your app. If more sensitive data is needed, users are asked for their permission."}]},{"type":"paragraph","inlineContent":[{"text":"Xcode is used for app development, offering project management, visual UI editors, debugging tools, a simulator, and more. It also includes a SwiftUI preview provider and a 3D extension to visualize RealityKit code for a scene. An object mode is also available for quick previews of 3D layouts.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The simulator lets users move and look around in a scene using a keyboard, mouse, or compatible game controller, and interact with the app using simulated system gestures."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The Reality Composer Trace template was also added to Instruments, to find frame bottle-necks, other performance impacts."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Reality Composer Pro was introduced, a new developer tool that allows for the preview and preparation of 3D content. It offers features like particles, spatial audio preview, and more. The tool has standard materials, but also offers the open standard MaterialX to author custom materials for specific needs."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Testing and Iteration: One can send 3D scenes to their device and test content directly without having to build an app, which is advantageous for iteration times. Unity also offers the ability to write apps for spatial computing without needing any plugins."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Building New Apps: There are two ways to get started with building apps for spatial computing - designing a new app from scratch or converting an existing app to function in the spatial computing platform. For new apps, there are two app template options: Initial Scene Type (either ‘Window’ or ‘Volume’) and Immersive Scene Type (‘Space’). SwiftUI is used to generate a working app that integrates familiar buttons with 3D objects."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Converting Existing Apps: Existing iPhone and iPad apps can be easily brought into the spatial computing platform. The apps maintain their original look and feel but also adopt native spacing, sizing, and re-layout features of the platform."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The platform provides gesture recognizers for 3D interactions, and attachments can be used to position SwiftUI elements inside the 3D scene."}]},{"type":"paragraph","inlineContent":[{"text":"They’re an extension of a Window, ideal for 3D content, can host multiple views, and are built for Shared Space.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"From 20:00, there is an walkthrough of a Hello World app in Xcode. It showcases how different elements such as text, images, and buttons can be navigated using tap gestures, and how 3D content can be incorporated alongside 2D UI in a ‘window’. He also demonstrates the use of volumes and spaces, which are larger containers for 2D and 3D content, and can offer different levels of immersion depending on user preferences."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Additional Resources: For more advanced app development, watching sessions on the principles of spatial design, building apps with SwiftUI and RealityKit, and creating 3D content are recommended."}]},{"type":"heading","anchor":"Written-By","level":2,"text":"Written By"},{"numberOfColumns":5,"type":"row","columns":[{"size":1,"content":[{"inlineContent":[{"identifier":"JohnBaer3","type":"image"}],"type":"paragraph"}]},{"size":4,"content":[{"type":"heading","level":3,"anchor":"John-Baer","text":"John Baer"},{"type":"paragraph","inlineContent":[{"isActive":true,"type":"reference","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/JohnBaer3","overridingTitle":"Contributed Notes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"isActive":true,"type":"reference","identifier":"https:\/\/github.com\/JohnBaer3"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"isActive":true,"type":"reference","identifier":"https:\/\/"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}]},{"type":"heading","anchor":"Related-Sessions","level":2,"text":"Related Sessions"},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10088-Create-immersive-Unity-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10099-Meet-RealityKit-Trace","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10109-Meet-SwiftUI-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app"],"style":"list"},{"type":"small","inlineContent":[{"type":"strong","inlineContent":[{"text":"Legal Notice","type":"text"}]}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"sections":[],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10260-get-started-with-building-apps-for-spatial-computing"],"traits":[{"interfaceLanguage":"swift"}]}],"sampleCodeDownload":{"action":{"overridingTitle":"Watch Video (31 min)","type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10260"},"kind":"sampleDownload"},"schemaVersion":{"minor":3,"major":0,"patch":0},"kind":"article","metadata":{"modules":[{"name":"WWDC Notes"}],"role":"sampleCode","roleHeading":"WWDC23","title":"Get started with building apps for spatial computing"},"abstract":[{"text":"Get ready to develop apps and games for visionOS! Discover the fundamental building blocks that make up spatial computing — windows, volumes, and spaces — and find out how you can use these elements to build engaging and immersive experiences.","type":"text"}],"references":{"https://developer.apple.com/wwdc23/10260":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10260","url":"https:\/\/developer.apple.com\/wwdc23\/10260","type":"download","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"abstract":[{"text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio.","type":"text"}],"role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","title":"Build spatial experiences with RealityKit","url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10072-Principles-of-spatial-design":{"abstract":[{"text":"Discover the fundamentals of spatial design. Learn how to design with depth, scale, windows, and immersion, and apply best practices for creating comfortable, human-centered experiences that transform reality. Find out how you can use these spatial design principles to extend your existing app or bring a new idea to life.","type":"text"}],"role":"sampleCode","type":"topic","title":"Principles of spatial design","url":"\/documentation\/wwdcnotes\/wwdc23-10072-principles-of-spatial-design","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design"},"doc://WWDCNotes/documentation/WWDCNotes":{"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"type":"topic","url":"\/documentation\/wwdcnotes","role":"collection","title":"WWDC Notes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"kind":"symbol"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10203-Develop-your-first-immersive-app":{"abstract":[{"text":"Find out how you can build immersive apps for visionOS using Xcode and Reality Composer Pro. We’ll show you how to get started with a new visionOS project, use Xcode Previews for your SwiftUI development, and take advantage of RealityKit and RealityView to render 3D content.","type":"text"}],"role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app","title":"Develop your first immersive app","url":"\/documentation\/wwdcnotes\/wwdc23-10203-develop-your-first-immersive-app","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10109-Meet-SwiftUI-for-spatial-computing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10109-Meet-SwiftUI-for-spatial-computing","type":"topic","abstract":[{"type":"text","text":"Take a tour of the solar system with us and explore SwiftUI for visionOS! Discover how you can build an entirely new universe of apps with windows, volumes, and spaces. We’ll show you how to get started with SwiftUI on this platform as we build an astronomy app, add 3D content, and create a fully immersive experience to transport people to the stars."}],"role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10109-meet-swiftui-for-spatial-computing","title":"Meet SwiftUI for spatial computing"},"JohnBaer3.jpeg":{"identifier":"JohnBaer3.jpeg","alt":null,"variants":[{"url":"\/images\/JohnBaer3.jpeg","traits":["1x","light"]}],"type":"image"},"JohnBaer3":{"identifier":"JohnBaer3","alt":"Profile image of John Baer","variants":[{"url":"\/images\/JohnBaer3.jpeg","traits":["1x","light"]}],"type":"image"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!","type":"link","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/JohnBaer3":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/JohnBaer3","title":"John Baer (2 notes)","url":"\/documentation\/wwdcnotes\/johnbaer3","abstract":[{"type":"text","text":"No Bio on GitHub"}],"role":"sampleCode","kind":"article","images":[{"identifier":"JohnBaer3.jpeg","type":"card"},{"identifier":"JohnBaer3.jpeg","type":"icon"}],"type":"topic"},"https://github.com/JohnBaer3":{"identifier":"https:\/\/github.com\/JohnBaer3","url":"https:\/\/github.com\/JohnBaer3","title":"GitHub","type":"link","titleInlineContent":[{"text":"GitHub","type":"text"}]},"https://":{"identifier":"https:\/\/","url":"https:\/\/","title":"Blog","type":"link","titleInlineContent":[{"text":"Blog","type":"text"}]},"WWDC23.jpeg":{"identifier":"WWDC23.jpeg","alt":null,"variants":[{"url":"\/images\/WWDC23.jpeg","traits":["1x","light"]}],"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10099-Meet-RealityKit-Trace":{"abstract":[{"text":"Discover how you can use RealityKit Trace to improve the performance of your spatial computing apps. Explore performance profiling guidelines for this platform and learn how the RealityKit Trace template can help you optimize rendering for your apps. We’ll also provide guidance on profiling various types of content in your app to help pinpoint performance issues.","type":"text"}],"role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10099-Meet-RealityKit-Trace","title":"Meet RealityKit Trace","url":"\/documentation\/wwdcnotes\/wwdc23-10099-meet-realitykit-trace","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10083-Meet-Reality-Composer-Pro":{"url":"\/documentation\/wwdcnotes\/wwdc23-10083-meet-reality-composer-pro","title":"Meet Reality Composer Pro","role":"sampleCode","abstract":[{"type":"text","text":"Discover how to easily compose, edit, and preview 3D content with Reality Composer Pro. Follow along as we explore this developer tool by setting up a new project, composing scenes, adding particle emitters and audio, and even previewing content on device."}],"type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro"},"WWDC23-Icon.png":{"identifier":"WWDC23-Icon.png","alt":null,"variants":[{"url":"\/images\/WWDC23-Icon.png","traits":["1x","light"]}],"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"url":"\/documentation\/wwdcnotes\/wwdc23","title":"WWDC23","role":"collectionGroup","abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14 (Sonoma), tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"SwiftData"},{"type":"text","text":", "},{"type":"codeVoice","code":"Observation"},{"type":"text","text":", "},{"type":"codeVoice","code":"StoreKit"},{"text":" views, and more.","type":"text"}],"images":[{"identifier":"WWDC23-Icon.png","type":"icon"},{"identifier":"WWDC23.jpeg","type":"card"}],"type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"},"WWDCNotes.png":{"identifier":"WWDCNotes.png","alt":null,"variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"type":"image"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10088-Create-immersive-Unity-apps":{"role":"sampleCode","kind":"article","type":"topic","abstract":[{"text":"Explore how you can use Unity to create engaging and immersive experiences for visionOS. We’ll share how Unity integrates seamlessly with Apple frameworks, take you through the tools you can use to build natively for the platform, and show you how volume cameras can bring your existing scenes into visionOS windows, volumes, and spaces.","type":"text"}],"title":"Create immersive Unity apps","url":"\/documentation\/wwdcnotes\/wwdc23-10088-create-immersive-unity-apps","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10088-Create-immersive-Unity-apps"}}}