{"schemaVersion":{"patch":0,"minor":3,"major":0},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-426-Building-Activity-Classification-Models-in-Create-ML"},"seeAlsoSections":[{"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-509-AUv3-Extensions-User-Presets","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-257-Accessibility-Inspector","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-252-Advances-in-CarPlay-Systems","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-723-Advances-in-Foundation","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-256-Advances-in-Speech-Recognition","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-104-Apple-Design-Awards","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-258-Architecting-Your-App-for-Multiple-Windows","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-514-Auditing-Web-Content-with-Web-Inspector","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-805-Building-Great-Shortcuts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-248-Creating-an-Accessible-Reading-Experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-810-Designing-AudioHaptic-Experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-806-Designing-Great-Shortcuts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-809-Designing-iPad-Apps-for-Mac","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-262-Embedding-and-Sharing-Visually-Rich-Links","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-253-Exploring-Tinted-Graphic-Complications","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-615-Game-Center-Player-Identifiers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-506-HEVC-Video-with-Alpha","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-507-HLS-Authoring-for-AirPlay-2-Video","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-429-LLDB-Beyond-po","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-250-Making-Apps-More-Accessible-With-Custom-Actions","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-508-Modernizing-Your-Audio-App","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-716-Streaming-Audio-on-watchOS-6","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-511-Supporting-Dark-Mode-in-Your-Web-Content","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-616-Supporting-New-Game-Controllers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-259-Targeting-Content-with-Multiple-Windows","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-424-Training-Object-Detection-Models-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-427-Training-Recommendation-Models-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-425-Training-Sound-Classification-Models-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-428-Training-Text-Classifiers-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-513-Understanding-CPU-Usage-with-Web-Inspector","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-244-Visual-Design-and-Accessibility","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-518-Whats-New-for-Web-Developers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-246-Window-Management-in-Your-Multitasking-App","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-254-Writing-Great-Accessibility-Labels"],"generated":true,"title":"Deep Dives into Topics"}],"metadata":{"roleHeading":"WWDC19","role":"sampleCode","modules":[{"name":"WWDC Notes"}],"title":"Building Activity Classification Models in Create ML"},"sampleCodeDownload":{"kind":"sampleDownload","action":{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/wwdc19\/426","overridingTitle":"Watch Video (15 min)"}},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19"]]},"abstract":[{"type":"text","text":"Your iPhone and Apple Watch are loaded with a number of powerful sensors including an accelerometer and gyroscope. Activity Classifiers can be trained on data from these sensors to bring some magic to your app, such as knowing when someone is running or swinging a bat. Learn how the Create ML app makes it easy to train and evaluate one of these Core ML models. Gain a deeper understanding of how to collect the raw data needed for training. See the use of these models in action."}],"kind":"article","variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc19-426-building-activity-classification-models-in-create-ml"]}],"sections":[],"primaryContentSections":[{"content":[{"anchor":"Sensors","level":2,"type":"heading","text":"Sensors"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Our devices have tons of sensors:"}]},{"type":"paragraph","inlineContent":[{"identifier":"WWDC19-426-sensors","type":"image"}]},{"anchor":"What-is-an-Activity-Classification","level":2,"type":"heading","text":"What is an Activity Classification?"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Activity Classification is a task that allows us to recognize our pre-defined set of physical actions that the user does with their devices."}]},{"type":"paragraph","inlineContent":[{"text":"In the session, the presenter shows us an example of a Fressbee throws classifier.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"An example of activity data (it’s a csv table with time stamps and "},{"code":"x, y, z","type":"codeVoice"},{"type":"text","text":" values):"}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC19-426-training"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"In Create ML we can filter which axis of which acceleration\/rotation we should consider for the training, we can also define a Prediction Window Size to let Create ML know how much is the size of the sample to analyze (this way we can have multiple gestures\/measurements in one table)."}]},{"anchor":"Best-practices","level":2,"type":"heading","text":"Best practices"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use relevant sensor for your motion (understand your motion)"}]}]},{"content":[{"inlineContent":[{"text":"Collect irrelevant motions as “other”, to avoid false positive","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Provide balanced classes (same number of samples for each class\/category)"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Provide raw data instead of processed device motion data"}],"type":"paragraph"}]}]},{"anchor":"Written-By","level":2,"type":"heading","text":"Written By"},{"numberOfColumns":5,"columns":[{"content":[{"inlineContent":[{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/5277837?v=4","type":"image"}],"type":"paragraph"}],"size":1},{"content":[{"type":"heading","level":3,"text":"Federico Zanetello","anchor":"Federico-Zanetello"},{"type":"paragraph","inlineContent":[{"overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","isActive":true,"overridingTitle":"Contributed Notes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/github.com\/zntfdr","isActive":true},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"zntfdr.dev","isActive":true}]}],"size":4}],"type":"row"},{"anchor":"Related-Sessions","level":2,"type":"heading","text":"Related Sessions"},{"style":"list","type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-430-Introducing-the-Create-ML-App"]},{"type":"small","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Legal Notice"}]}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-253-Exploring-Tinted-Graphic-Complications":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-253-Exploring-Tinted-Graphic-Complications","url":"\/documentation\/wwdcnotes\/wwdc19-253-exploring-tinted-graphic-complications","abstract":[{"text":"Many Watch faces in watchOS 6 allow for customizing the tint color of content, allowing for even more personalization of Apple’s most personal device. Discover how you can use ClockKit data providers to offer full color and tint-ready options for each complication family type. This gives customers the ability to get up to date, important information at a glance, no matter which Watch face they choose.","type":"text"}],"kind":"article","type":"topic","title":"Exploring Tinted Graphic Complications","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-518-Whats-New-for-Web-Developers":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-518-Whats-New-for-Web-Developers","abstract":[{"type":"text","text":"WebKit provides a rich set of classes designed to load, display, and manage web content in your app. Discover how to integrate your web content into powerful platform features including Dark Mode, new presentation features in Share Sheet, JavaScript payment APIs for Apple Pay, and more."}],"url":"\/documentation\/wwdcnotes\/wwdc19-518-whats-new-for-web-developers","role":"sampleCode","title":"What’s New for Web Developers","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-262-Embedding-and-Sharing-Visually-Rich-Links":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-262-Embedding-and-Sharing-Visually-Rich-Links","abstract":[{"type":"text","text":"The new Link Presentation framework enables app developers to easily present URLs in a rich, beautiful, and consistent way. Learn how to use Link Presentation to retrieve metadata from a URL, present the rich link content inside your app, and provide link metadata to the new share sheet experience in iOS."}],"url":"\/documentation\/wwdcnotes\/wwdc19-262-embedding-and-sharing-visually-rich-links","role":"sampleCode","title":"Embedding and Sharing Visually Rich Links","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-429-LLDB-Beyond-po":{"type":"topic","abstract":[{"type":"text","text":"LLDB is a powerful tool for exploring and debugging your app at runtime. Discover the various ways to display values in your app, how to format custom data types, and how to extend LLDB using your own Python 3 scripts."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-429-LLDB-Beyond-po","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc19-429-lldb-beyond-po","title":"LLDB: Beyond “po”","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-430-Introducing-the-Create-ML-App":{"kind":"article","role":"sampleCode","title":"Introducing the Create ML App","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-430-Introducing-the-Create-ML-App","url":"\/documentation\/wwdcnotes\/wwdc19-430-introducing-the-create-ml-app","type":"topic","abstract":[{"type":"text","text":"Bringing the power of Core ML to your app begins with one challenge. How do you create your model? The new Create ML app provides an intuitive workflow for model creation. See how to train, evaluate, test, and preview your models quickly in this easy-to-use tool. Get started with one of the many available templates handling a number of powerful machine learning tasks. Learn more about the many features for continuous model improvement and experimentation."}]},"WWDCNotes.png":{"type":"image","identifier":"WWDCNotes.png","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}]},"https://avatars.githubusercontent.com/u/5277837?v=4":{"type":"image","identifier":"https:\/\/avatars.githubusercontent.com\/u\/5277837?v=4","alt":"Profile image of Federico Zanetello","variants":[{"traits":["1x","light"],"url":"https:\/\/avatars.githubusercontent.com\/u\/5277837?v=4"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-507-HLS-Authoring-for-AirPlay-2-Video":{"abstract":[{"text":"AirPlay 2 Video lets you share video from Apple devices to popular smart TVs. Learn about the special considerations for seamless delivery of high quality video to these TVs, and how to utilize the validation tools to ensure your content is ready for primetime.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-507-HLS-Authoring-for-AirPlay-2-Video","kind":"article","role":"sampleCode","title":"HLS Authoring for AirPlay 2 Video","url":"\/documentation\/wwdcnotes\/wwdc19-507-hls-authoring-for-airplay-2-video"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-508-Modernizing-Your-Audio-App":{"abstract":[{"text":"Apple platforms provide a comprehensive set of audio frameworks and technologies that are essential to creating a rich app experience. Learn about which frameworks and APIs are recommended to ensure that your app is well positioned for the future.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-508-Modernizing-Your-Audio-App","kind":"article","role":"sampleCode","title":"Modernizing Your Audio App","url":"\/documentation\/wwdcnotes\/wwdc19-508-modernizing-your-audio-app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-427-Training-Recommendation-Models-in-Create-ML":{"url":"\/documentation\/wwdcnotes\/wwdc19-427-training-recommendation-models-in-create-ml","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-427-Training-Recommendation-Models-in-Create-ML","kind":"article","title":"Training Recommendation Models in Create ML","type":"topic","abstract":[{"type":"text","text":"Recommendation models for Core ML can enable a very personal experience for the customers using your app. They power suggestions for what music to play or what movie to see in the apps you use every day. Learn how you can easily create a custom Recommendation model from all sorts of data sources using the Create ML app. Gain a deeper understanding of how this kind of personalization is possible while maintaining user privacy. See an example of one of these recommenders in action."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-258-Architecting-Your-App-for-Multiple-Windows":{"abstract":[{"text":"Dive into the details about what it means to support multitasking in iOS 13. Understand how previous best practices fit together with new ideas. Learn the nuances of structuring your application to support multiple windows, and how to instantiate your UI, handle windows coming and going, and manage your app’s underlying window resources.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-258-Architecting-Your-App-for-Multiple-Windows","kind":"article","role":"sampleCode","title":"Architecting Your App for Multiple Windows","url":"\/documentation\/wwdcnotes\/wwdc19-258-architecting-your-app-for-multiple-windows"},"https://developer.apple.com/wwdc19/426":{"type":"download","identifier":"https:\/\/developer.apple.com\/wwdc19\/426","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc19\/426"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-513-Understanding-CPU-Usage-with-Web-Inspector":{"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-513-Understanding-CPU-Usage-with-Web-Inspector","url":"\/documentation\/wwdcnotes\/wwdc19-513-understanding-cpu-usage-with-web-inspector","abstract":[{"type":"text","text":"As a developer of web content, you play an important role in fulfilling customer expectations for a high performance web experience while minimizing power use across all their devices. Discover new insights on how you can improve the power efficiency of your webpages in Safari, or embedded web content in your apps, by using this powerful new tool in Web Inspector. Learn new strategies to help you deliver dynamic experiences that use less CPU and save battery life."}],"kind":"article","title":"Understanding CPU Usage with Web Inspector"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-810-Designing-AudioHaptic-Experiences":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-810-Designing-AudioHaptic-Experiences","url":"\/documentation\/wwdcnotes\/wwdc19-810-designing-audiohaptic-experiences","abstract":[{"text":"Learn essential sound and haptic design principles and concepts for creating meaningful and delightful experiences that engage a wider range of human senses. Discover how to combine audio and haptics, using the Taptic Engine, to add a new level of realism and improve feedback in your app or game.","type":"text"}],"kind":"article","type":"topic","title":"Designing Audio-Haptic Experiences","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-509-AUv3-Extensions-User-Presets":{"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-509-AUv3-Extensions-User-Presets","url":"\/documentation\/wwdcnotes\/wwdc19-509-auv3-extensions-user-presets","abstract":[{"type":"text","text":"Audio Unit app extensions gives users a convenient way to create or modify audio in any iOS or macOS app that uses sound, including music production apps such as GarageBand or Logic Pro X. And now, with iOS 13, you can store user presets for your extensions that are accessible across applications."}],"kind":"article","title":"AUv3 Extensions User Presets"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19":{"kind":"article","abstract":[{"type":"text","text":"Xcode 11, Swift 5.1, iOS 12, macOS 10.15, tvOS 13, watchOS 6."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"type":"codeVoice","code":"Combine"},{"type":"text","text":", "},{"type":"codeVoice","code":"Core Haptics"},{"type":"text","text":", "},{"type":"codeVoice","code":"Create ML"},{"type":"text","text":", and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19","url":"\/documentation\/wwdcnotes\/wwdc19","title":"WWDC19","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"role":"collectionGroup","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-104-Apple-Design-Awards":{"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-104-Apple-Design-Awards","url":"\/documentation\/wwdcnotes\/wwdc19-104-apple-design-awards","abstract":[{"type":"text","text":"Join us for an unforgettable award ceremony celebrating developers and their outstanding work. The 2019 Apple Design Awards recognize state of the art iOS, macOS, watchOS, and tvOS apps that reflect excellence in design and innovation."}],"kind":"article","title":"Apple Design Awards"},"doc://WWDCNotes/documentation/WWDCNotes":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","title":"WWDC Notes","role":"collection","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"type":"topic","abstract":[{"text":"Session notes shared by the community for the community.","type":"text"}],"url":"\/documentation\/wwdcnotes","kind":"symbol"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-723-Advances-in-Foundation":{"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-723-Advances-in-Foundation","url":"\/documentation\/wwdcnotes\/wwdc19-723-advances-in-foundation","abstract":[{"type":"text","text":"The Foundation framework provides a base layer of functionality for apps and frameworks that’s used throughout the macOS, iOS, watchOS, and tvOS SDKs. Hear about valuable enhancements to Foundation collections, performance, internationalization features, and Swift integration."}],"kind":"article","title":"Advances in Foundation"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-716-Streaming-Audio-on-watchOS-6":{"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-716-Streaming-Audio-on-watchOS-6","url":"\/documentation\/wwdcnotes\/wwdc19-716-streaming-audio-on-watchos-6","abstract":[{"type":"text","text":"Streaming audio on Apple Watch allows customers to enjoy your content wherever they go without their iPhone. Learn about the streaming APIs brought over from iOS to allow watchOS apps to create independent audio consumption experiences. Find out how to set up your audio session for streaming and explore best practices to provide the best experience for people moving between different network conditions."}],"kind":"article","title":"Streaming Audio on watchOS 6"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-254-Writing-Great-Accessibility-Labels":{"type":"topic","title":"Writing Great Accessibility Labels","kind":"article","abstract":[{"type":"text","text":"Great accessibility labels are the difference between someone using and loving your app or someone deleting your app. Experience VoiceOver as demonstrated by an Apple Accessibility engineer as she navigates complex UI and demonstrates how descriptive labels are an easy way to ensure your app is for everyone."}],"url":"\/documentation\/wwdcnotes\/wwdc19-254-writing-great-accessibility-labels","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-254-Writing-Great-Accessibility-Labels","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-259-Targeting-Content-with-Multiple-Windows":{"url":"\/documentation\/wwdcnotes\/wwdc19-259-targeting-content-with-multiple-windows","title":"Targeting Content with Multiple Windows","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-259-Targeting-Content-with-Multiple-Windows","abstract":[{"text":"Learn how to target content for a specific window in your app. Find out how to identify which scene the system should open from a notification, a shortcut item, and other user activities.","type":"text"}],"kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/zntfdr":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","type":"topic","title":"Federico Zanetello (214 notes)","url":"\/documentation\/wwdcnotes\/zntfdr","role":"sampleCode","abstract":[{"type":"text","text":"Software engineer with a strong passion for well-written code, thought-out composable architectures, automation, tests, and more."}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-425-Training-Sound-Classification-Models-in-Create-ML":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-425-Training-Sound-Classification-Models-in-Create-ML","type":"topic","kind":"article","abstract":[{"text":"Learn how to quickly and easily create Core ML models capable of classifying the sounds heard in audio files and live audio streams. In addition to providing you the ability to train and evaluate these models, the Create ML app allows you to test the model performance in real-time using the microphone on your Mac. Leverage these on-device models in your app using the new Sound Analysis framework.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc19-425-training-sound-classification-models-in-create-ml","role":"sampleCode","title":"Training Sound Classification Models in Create ML"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-256-Advances-in-Speech-Recognition":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-256-Advances-in-Speech-Recognition","type":"topic","kind":"article","abstract":[{"text":"Speech Recognizer can now be used locally on iOS or macOS devices with no network connection. Learn how you can bring text-to-speech support to your app while maintaining privacy and eliminating the limitations of server-based processing. Speech recognition API has also been enhanced to provide richer analytics including speaking rate, pause duration, and voice quality.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc19-256-advances-in-speech-recognition","role":"sampleCode","title":"Advances in Speech Recognition"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-809-Designing-iPad-Apps-for-Mac":{"abstract":[{"text":"Discover how you can create a great Mac experience with your iPad app. Learn about essential techniques for adapting your iPad app’s layout and architecture for Mac, considerations for type and color, and how you can take advantage of macOS interfaces such as the menu bar, sidebar and window toolbar.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-809-Designing-iPad-Apps-for-Mac","kind":"article","role":"sampleCode","title":"Designing iPad Apps for Mac","url":"\/documentation\/wwdcnotes\/wwdc19-809-designing-ipad-apps-for-mac"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-615-Game-Center-Player-Identifiers":{"kind":"article","abstract":[{"type":"text","text":"Game Center now supports persistent player identifiers scoped to individual games or to a developer team ID. Understand how scoped identifiers enhance player privacy and see how to transition your apps and games onto the recommended API."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-615-Game-Center-Player-Identifiers","url":"\/documentation\/wwdcnotes\/wwdc19-615-game-center-player-identifiers","title":"Game Center Player Identifiers","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-248-Creating-an-Accessible-Reading-Experience":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-248-Creating-an-Accessible-Reading-Experience","abstract":[{"type":"text","text":"The styling and layout of text is a hallmark feature of an outstanding reading experience. Technologies such as CoreText and TextKit give you the tools you need to create a great text layout. Learn how to make an equally great accessible experience for VoiceOver by adopting the accessibility reading content protocol, adding automatic page turning, and customizing speech output."}],"url":"\/documentation\/wwdcnotes\/wwdc19-248-creating-an-accessible-reading-experience","role":"sampleCode","title":"Creating an Accessible Reading Experience","kind":"article","type":"topic"},"https://github.com/zntfdr":{"identifier":"https:\/\/github.com\/zntfdr","type":"link","url":"https:\/\/github.com\/zntfdr","title":"GitHub","titleInlineContent":[{"type":"text","text":"GitHub"}]},"WWDC19-426-sensors":{"identifier":"WWDC19-426-sensors","type":"image","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC19-426-sensors.png"}]},"zntfdr.dev":{"identifier":"zntfdr.dev","type":"link","url":"zntfdr.dev","title":"Blog","titleInlineContent":[{"type":"text","text":"Blog"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-252-Advances-in-CarPlay-Systems":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-252-Advances-in-CarPlay-Systems","url":"\/documentation\/wwdcnotes\/wwdc19-252-advances-in-carplay-systems","abstract":[{"text":"CarPlay is a smarter, safer way to use your iPhone in the car. Learn how to update your vehicle system to take advantage of new features in iOS 13. Add support for dynamically changing screen sizes, second screens such as instrument clusters, and even irregularly shaped displays. Learn how to support “Hey Siri” for hands-free voice activation.","type":"text"}],"kind":"article","type":"topic","title":"Advances in CarPlay Systems","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-250-Making-Apps-More-Accessible-With-Custom-Actions":{"kind":"article","abstract":[{"type":"text","text":"Custom Actions simplify the experience for people using assistive technologies with your app and they can help you reduce the number of swipes and taps that are required to navigate through your interface and perform interactions. Learn how to leverage custom actions for use in VoiceOver and Switch Control. New in iOS 13, bring custom actions to Full Keyboard Access and Voice Control on iOS."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-250-Making-Apps-More-Accessible-With-Custom-Actions","url":"\/documentation\/wwdcnotes\/wwdc19-250-making-apps-more-accessible-with-custom-actions","title":"Making Apps More Accessible With Custom Actions","role":"sampleCode","type":"topic"},"WWDC19-426-training":{"identifier":"WWDC19-426-training","type":"image","alt":null,"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC19-426-training.png"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-246-Window-Management-in-Your-Multitasking-App":{"role":"sampleCode","kind":"article","title":"Window Management in Your Multitasking App","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-246-Window-Management-in-Your-Multitasking-App","url":"\/documentation\/wwdcnotes\/wwdc19-246-window-management-in-your-multitasking-app","abstract":[{"text":"Dive into the details of window management in your Multitasking app, including how to properly handle creating, refreshing, and closing windows. Hear about best practices for when to refresh the content in your window and learn how to ensure your app’s visual state is up-to-date in the switcher.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-257-Accessibility-Inspector":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-257-Accessibility-Inspector","abstract":[{"type":"text","text":"The Accessibility Inspector enables you to identify parts of your app that are not accessible. It provides feedback on how you can make them accessible, as well as simulating voice-over to help you identify what a Voice Over user would experience. Watch a live-demo of an app being fully debugged in the Accessibility Inspector, and learn how to leverage this powerful tool to make your apps better for everyone."}],"url":"\/documentation\/wwdcnotes\/wwdc19-257-accessibility-inspector","role":"sampleCode","title":"Accessibility Inspector","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-806-Designing-Great-Shortcuts":{"role":"sampleCode","kind":"article","title":"Designing Great Shortcuts","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-806-Designing-Great-Shortcuts","url":"\/documentation\/wwdcnotes\/wwdc19-806-designing-great-shortcuts","abstract":[{"text":"Shortcuts allow people to access information and actions on the go or in the Shortcuts app. The best shortcuts take careful design planning to hone in on what can help expedite a person’s workflow with your app. Gain insights as to what makes a great shortcut and how to design the experience to be useful, beautiful, and responsive. See examples of how to map out the Siri dialog flow when using parameters to make your shortcuts flexible and helpful.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-616-Supporting-New-Game-Controllers":{"abstract":[{"text":"With iOS 13, macOS Catalina, and tvOS 13, the Game Controller framework adds support for several well-known console game controllers. Get briefed about the newly-added controllers and understand how their inputs are delivered. Learn recommended best practices for handling optional buttons, and understand the right approach for support on macOS.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-616-Supporting-New-Game-Controllers","kind":"article","role":"sampleCode","title":"Supporting New Game Controllers","url":"\/documentation\/wwdcnotes\/wwdc19-616-supporting-new-game-controllers"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-805-Building-Great-Shortcuts":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-805-Building-Great-Shortcuts","abstract":[{"type":"text","text":"Shortcuts enable people to quickly and easily accomplish actions or get things done hands-free using Siri and the Shortcuts app. Join us for a tour of where shortcuts can appear, how you can customize the experience, and how your app’s shortcuts can be used with variables and actions from other apps."}],"url":"\/documentation\/wwdcnotes\/wwdc19-805-building-great-shortcuts","role":"sampleCode","title":"Building Great Shortcuts","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-244-Visual-Design-and-Accessibility":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-244-Visual-Design-and-Accessibility","abstract":[{"type":"text","text":"Learn about the importance of supporting Large Text. Hear about Differentiate Without Color, a new API on iOS which can enable people with vision disorders such as color-blindness to easily use your app. Learn how to use it and how it can bring inclusivity to your app. Find out how to enable new Reduce Motion API to stop auto-play in your app for people who may be sensitive to motion."}],"url":"\/documentation\/wwdcnotes\/wwdc19-244-visual-design-and-accessibility","role":"sampleCode","title":"Visual Design and Accessibility","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-506-HEVC-Video-with-Alpha":{"abstract":[{"text":"With the addition of alpha channel support for HEVC video, you can now composite video over custom backgrounds in both your apps and on the web. Learn how to author compatible media, and the best practices for playback.","type":"text"}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-506-HEVC-Video-with-Alpha","kind":"article","role":"sampleCode","title":"HEVC Video with Alpha","url":"\/documentation\/wwdcnotes\/wwdc19-506-hevc-video-with-alpha"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-428-Training-Text-Classifiers-in-Create-ML":{"url":"\/documentation\/wwdcnotes\/wwdc19-428-training-text-classifiers-in-create-ml","title":"Training Text Classifiers in Create ML","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-428-Training-Text-Classifiers-in-Create-ML","abstract":[{"text":"Create ML now enables you to create models for Natural Language that are built on state-of-the-art techniques. Learn how these models can be easily trained and tested with the Create ML app. Gain insight into the powerful new options for transfer learning, word embeddings, and text catalogs.","type":"text"}],"kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-514-Auditing-Web-Content-with-Web-Inspector":{"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-514-Auditing-Web-Content-with-Web-Inspector","url":"\/documentation\/wwdcnotes\/wwdc19-514-auditing-web-content-with-web-inspector","abstract":[{"type":"text","text":"Discover a new way to ensure your web content meets team coding standards and that you can deliver better code even without reliance on automated test systems. Find out how to use the Audit tool in Web Inspector to quickly and easily audit your web content during development so important compliance details don’t slip by."}],"kind":"article","title":"Auditing Web Content with Web Inspector"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-511-Supporting-Dark-Mode-in-Your-Web-Content":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-511-Supporting-Dark-Mode-in-Your-Web-Content","abstract":[{"type":"text","text":"With system-wide Dark Mode support in iOS and macOS, you’ll want to make sure your web content is appropriately styled to reflect your users’  preference. Learn techniques to ensure your content looks its best when presented in Safari, embedded in other apps such as Mail, or when used in your apps. Discover the details and best practices for this new pillar in responsive web design."}],"url":"\/documentation\/wwdcnotes\/wwdc19-511-supporting-dark-mode-in-your-web-content","role":"sampleCode","title":"Supporting Dark Mode in Your Web Content","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-424-Training-Object-Detection-Models-in-Create-ML":{"url":"\/documentation\/wwdcnotes\/wwdc19-424-training-object-detection-models-in-create-ml","title":"Training Object Detection Models in Create ML","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-424-Training-Object-Detection-Models-in-Create-ML","abstract":[{"text":"Custom Core ML models for Object Detection offer you an opportunity to add some real magic to your app. Learn how the Create ML app in Xcode makes it easy to train and evaluate these models. See how you can test the model performance directly within the app by taking advantage of Continuity Camera. It’s never been easier to build and deploy great Object Detection models for Core ML.","type":"text"}],"kind":"article","role":"sampleCode"}}}