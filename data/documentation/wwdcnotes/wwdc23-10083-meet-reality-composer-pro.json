{"metadata":{"roleHeading":"WWDC23","role":"sampleCode","title":"Meet Reality Composer Pro","modules":[{"name":"WWDC Notes"}]},"kind":"article","identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10083-Meet-Reality-Composer-Pro","interfaceLanguage":"swift"},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"schemaVersion":{"minor":3,"major":0,"patch":0},"seeAlsoSections":[{"generated":true,"title":"New Tools & Frameworks","identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10184-Meet-ActivityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10032-Meet-Assistive-Access","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10147-Meet-Core-Location-Monitor","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10146-Meet-Core-Location-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10043-Meet-MapKit-for-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10191-Meet-Object-Capture-for-iOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10025-Meet-Push-Notifications-Console","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10099-Meet-RealityKit-Trace","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10279-Meet-Safari-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10013-Meet-StoreKit-for-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10171-Meet-Swift-OpenAPI-Generator","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10187-Meet-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10109-Meet-SwiftUI-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111215-Meet-UIKit-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10039-Meet-device-management-for-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10268-Meet-mergeable-libraries","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10026-Meet-watchOS-10"]}],"primaryContentSections":[{"content":[{"type":"heading","anchor":"Chapters","level":1,"text":"Chapters"},{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=0","type":"reference","isActive":true},{"text":"","type":"text"},{"text":"\n","type":"text"},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=75","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=167"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=248"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=428"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=803"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=1059"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=1166"},{"type":"text","text":""},{"type":"text","text":"\n"},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=1199"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Session is a walkthrough of Reality Composer Pro, using "},{"type":"reference","identifier":"https:\/\/developer.apple.com\/documentation\/visionos\/diorama","isActive":true},{"type":"text","text":"."}]},{"type":"paragraph","inlineContent":[{"text":"Can launch RCP directly from Xcode->Developer Tools menu.","type":"text"},{"text":" ","type":"text"},{"text":"Or can create a RCP project by creating a new Xcode xrOS project, which creates a Reality Composer Pro Package.","type":"text"}]},{"type":"heading","anchor":"Reality-Composer-Pro-UI-navigation","level":1,"text":"Reality Composer Pro UI navigation:"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"3D viewport (center): navigate with WASD and arrow keys, or with a paired game controller."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Hierarchy panel (left) for object selection and reorganizaation.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Inspector panel (right): edit properties of selected objects. “Add component” button at bottom shows available built-in objects.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Editor panel (bottom): Project browser, Shader Graph, Audio Mixer, Statistics.","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"3 ways to add assets:"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Import button in project browser: import existing assets (USDZ, wav, more)","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Content library (”+” button at top right): curated assets (USDZ, materials, more) from Apple.","type":"text"}]}]},{"content":[{"inlineContent":[{"text":"Object Capture. See ","type":"text"},{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10191\/","type":"reference"},{"text":".","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"isActive":true,"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=303","type":"reference"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Imported assets can be replaced with new version, e.g. change the style of "},{"type":"emphasis","inlineContent":[{"type":"text","text":"all"}]},{"type":"text","text":" location pins by updating one file."}]},{"type":"heading","anchor":"Particle-emitters","level":1,"text":"Particle emitters"},{"type":"paragraph","inlineContent":[{"text":"Demo: Clouds composition. Add article emitters (freestanding asset, or attach to an existing asset).","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Build a Cloud Chunk. Particle Emitter"},{"type":"text","text":" "},{"type":"text","text":"tinkering, starting with the “Impact” particle emitter preset."},{"type":"text","text":" "},{"type":"text","text":"Change 3D viewport background color. Live playback (top of inspector panel). Large number of particles slows performance."},{"type":"text","text":" "},{"type":"text","text":"Check “isLocalSpace” so that parent’s translation\/rotation\/scaling will also apply to the emitter."}]},{"type":"paragraph","inlineContent":[{"text":"New scene, Cloud A. Add Cloud Chunk multiple times, positioned for realism.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Back to diorama. Add group Clouds, which has Cloud A, Cloud B, Cloud C. Preview just the “Clouds” group with Playback."}]},{"level":1,"type":"heading","text":"Audio authoring","anchor":"Audio-authoring"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Audio files. Can be played on one or more objects. An object can play one or multiple audio files."}]},{"type":"paragraph","inlineContent":[{"text":"Audio sources: spatial (comes from a particular object), ambient (e.g. wind from the east, no matter how far east you travel), channel (background music).","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Example: animated bird (USDZ), with two bird call audio files attached as Spatial audio source. Audio File Group randomly selects one of its members to play back."},{"type":"text","text":" "},{"type":"text","text":"Preview: playback of animation and audio of all birds and calls in scene. Additional work needed to control from Swift; see "},{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/","isActive":true,"type":"reference"},{"type":"text","text":"."}]},{"level":1,"type":"heading","text":"Statistics","anchor":"Statistics"},{"type":"paragraph","inlineContent":[{"text":"For performance optimization.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Note that diorama base has many more triangles than the terrain itself. Replace base asset with much simpler version. Reduces triangle count by over half.","type":"text"}]},{"level":1,"type":"heading","text":"On-device preview","anchor":"On-device-preview"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Drop-down at upper right, select actual device. Object appears in AR, can pinch, drag, zoom the scene."}]},{"level":1,"type":"heading","text":"Wrap-up","anchor":"Wrap-up"},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"reference","overridingTitleInlineContent":[{"type":"text","text":"Explore materials in Reality Composer Pro (Shader Graph details)"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/","overridingTitle":"Explore materials in Reality Composer Pro (Shader Graph details)","isActive":true}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273\/","isActive":true}]}]}]},{"level":2,"type":"heading","text":"Written By","anchor":"Written-By"},{"columns":[{"size":1,"content":[{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/418007?v=4","type":"image"}]}]},{"size":4,"content":[{"level":3,"text":"Hal Mueller","anchor":"Hal-Mueller","type":"heading"},{"inlineContent":[{"overridingTitle":"Contributed Notes","type":"reference","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/halmueller","isActive":true,"overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}]},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","identifier":"https:\/\/github.com\/halmueller","isActive":true}],"type":"paragraph"}]}],"type":"row","numberOfColumns":5},{"type":"paragraph","inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"type":"text","text":"Contributions are welcome!"}]},{"level":2,"type":"heading","text":"Related Sessions","anchor":"Related-Sessions"},{"type":"links","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10096-Build-great-games-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10099-Meet-RealityKit-Trace","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10191-Meet-Object-Capture-for-iOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10129-Understand-USD-fundamentals","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10077-Create-3D-workflows-with-USD"],"style":"list"},{"type":"small","inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}]},{"type":"small","inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}]}],"kind":"content"}],"sections":[],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc23-10083-meet-reality-composer-pro"]}],"abstract":[{"type":"text","text":"Discover how to easily compose, edit, and preview 3D content with Reality Composer Pro. Follow along as we explore this developer tool by setting up a new project, composing scenes, adding particle emitters and audio, and even previewing content on device."}],"sampleCodeDownload":{"action":{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10083","type":"reference","isActive":true,"overridingTitle":"Watch Video (21 min)"},"kind":"sampleDownload"},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10147-Meet-Core-Location-Monitor":{"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10147-meet-core-location-monitor","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10147-Meet-Core-Location-Monitor","type":"topic","title":"Meet Core Location Monitor","abstract":[{"type":"text","text":"Discover how Core Location Monitor can help you better understand location and beacon events in your app. Learn how to use Core Location Conditions to describe and track the state of events in your app, and find out how you can better respond to transitions in your apps through Swift semantics and improved reliability."}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10203-Develop-your-first-immersive-app":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app","title":"Develop your first immersive app","type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10203-develop-your-first-immersive-app","abstract":[{"type":"text","text":"Find out how you can build immersive apps for visionOS using Xcode and Reality Composer Pro. We’ll show you how to get started with a new visionOS project, use Xcode Previews for your SwiftUI development, and take advantage of RealityKit and RealityView to render 3D content."}]},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=0":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=0","type":"link","title":"00:00 - Introduction","titleInlineContent":[{"type":"text","text":"00:00 - Introduction"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=0"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10082-Meet-ARKit-for-spatial-computing":{"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10082-meet-arkit-for-spatial-computing","abstract":[{"type":"text","text":"Discover how you can use ARKit’s tracking and scene understanding features to develop a whole new universe of immersive apps and games. Learn how visionOS and ARKit work together to help you create apps that understand a person’s surroundings — all while preserving privacy. Explore the latest updates to the ARKit API and follow along as we demonstrate how to take advantage of hand tracking and scene geometry in your apps."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10082-Meet-ARKit-for-spatial-computing","title":"Meet ARKit for spatial computing","type":"topic","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/halmueller":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/halmueller","type":"topic","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/halmueller","title":"Hal Mueller (2 notes)","abstract":[{"type":"text","text":"No Bio on GitHub"}]},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=428":{"title":"07:08 - Particle emitters","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=428","titleInlineContent":[{"text":"07:08 - Particle emitters","type":"text"}],"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=428","type":"link"},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=248":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=248","type":"link","title":"04:08 - Composing scenes","titleInlineContent":[{"text":"04:08 - Composing scenes","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=248"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10025-Meet-Push-Notifications-Console":{"url":"\/documentation\/wwdcnotes\/wwdc23-10025-meet-push-notifications-console","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10025-Meet-Push-Notifications-Console","title":"Meet Push Notifications Console","type":"topic","abstract":[{"type":"text","text":"The Push Notifications Console is the best way to quickly test user notifications in your app. Learn how you can iterate on new ideas quickly by sending notifications directly from the console and analyze delivery logs to learn more about your pushes. We’ll also show you how to generate and validate tokens to successfully authenticate with Apple Push Notification service (APNs)."}]},"https://developer.apple.com/documentation/visionos/diorama":{"title":"Diorama sample app","identifier":"https:\/\/developer.apple.com\/documentation\/visionos\/diorama","titleInlineContent":[{"type":"text","text":"Diorama sample app"}],"url":"https:\/\/developer.apple.com\/documentation\/visionos\/diorama","type":"link"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10096-Build-great-games-for-spatial-computing":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10096-Build-great-games-for-spatial-computing","title":"Build great games for spatial computing","type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10096-build-great-games-for-spatial-computing","abstract":[{"type":"text","text":"Find out how you can develop great gaming experiences for visionOS. We’ll share some of the key building blocks that help you create games for this platform, explore how your experiences can fluidly move between levels of immersion, and provide a roadmap for exploring ARKit, RealityKit, Reality Composer Pro, Unity, Metal, and Compositor."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10039-Meet-device-management-for-Apple-Watch":{"abstract":[{"text":"Organizations can now deploy and configure Apple Watch in addition to other Apple devices. Learn how to implement device management for watchOS to help organizations improve productivity, support wellness, and provide additional support for their employees.","type":"text"}],"title":"Meet device management for Apple Watch","url":"\/documentation\/wwdcnotes\/wwdc23-10039-meet-device-management-for-apple-watch","kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10039-Meet-device-management-for-Apple-Watch","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10184-Meet-ActivityKit":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10184-Meet-ActivityKit","abstract":[{"type":"text","text":"Live Activities are a glanceable way for someone to keep track of the progress of a task within your app. We’ll teach you how you can create helpful experiences for the Lock Screen, the Dynamic Island, and StandBy. Learn how to update your app’s Live Activities, monitor activity state, and take advantage of WidgetKit and SwiftUI to build richer experiences."}],"type":"topic","kind":"article","title":"Meet ActivityKit","url":"\/documentation\/wwdcnotes\/wwdc23-10184-meet-activitykit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10013-Meet-StoreKit-for-SwiftUI":{"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10013-meet-storekit-for-swiftui","abstract":[{"type":"text","text":"Discover how you can use App Store product metadata and Xcode Previews to add in-app purchases to your app with just a few lines of code. Explore a new collection of UI components in StoreKit and learn how you can easily merchandise your products, present subscriptions in a way that helps users make informed decisions, and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10013-Meet-StoreKit-for-SwiftUI","title":"Meet StoreKit for SwiftUI","type":"topic","role":"sampleCode"},"https://developer.apple.com/wwdc23/10083":{"url":"https:\/\/developer.apple.com\/wwdc23\/10083","type":"download","checksum":null,"identifier":"https:\/\/developer.apple.com\/wwdc23\/10083"},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=1166":{"title":"19:26 - On-device preview","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=1166","titleInlineContent":[{"type":"text","text":"19:26 - On-device preview"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=1166"},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=1199":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=1199","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=1199","type":"link","titleInlineContent":[{"type":"text","text":"19:59 - Wrap-up"}],"title":"19:59 - Wrap-up"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit","title":"Enhance your spatial computing app with RealityKit","type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10081-enhance-your-spatial-computing-app-with-realitykit","abstract":[{"type":"text","text":"Go beyond the window and learn how you can bring engaging and immersive 3D content to your apps with RealityKit. Discover how SwiftUI scenes work in tandem with RealityView and how you can embed your content into an entity hierarchy. We’ll also explore how you can blend virtual content and the real world using anchors, bring particle effects into your apps, add video content, and create more immersive experiences with portals."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10268-Meet-mergeable-libraries":{"url":"\/documentation\/wwdcnotes\/wwdc23-10268-meet-mergeable-libraries","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10268-Meet-mergeable-libraries","title":"Meet mergeable libraries","type":"topic","abstract":[{"type":"text","text":"Discover how mergeable libraries combine the best parts of static and dynamic libraries to help improve your app’s productivity and runtime performance. Learn how you can enable faster development while shipping the smallest app. We’ll show you how to adopt mergeable libraries in Xcode 15 and share best practices for working with your code."}]},"https://developer.apple.com/videos/play/wwdc2023/10202/":{"title":"Work with Reality Composer Pro content in Xcode","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/","titleInlineContent":[{"text":"Work with Reality Composer Pro content in","type":"text"},{"type":"text","text":" "},{"text":"Xcode","type":"text"}],"type":"link","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10202\/"},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","url":"\/documentation\/wwdcnotes","type":"topic","title":"WWDC Notes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"role":"collection","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10191-Meet-Object-Capture-for-iOS":{"url":"\/documentation\/wwdcnotes\/wwdc23-10191-meet-object-capture-for-ios","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10191-Meet-Object-Capture-for-iOS","title":"Meet Object Capture for iOS","role":"sampleCode","type":"topic","abstract":[{"text":"Discover how you can offer an end-to-end Object Capture experience directly in your iOS apps to help people turn their objects into ready-to-use 3D models. Learn how you can create a fully automated Object Capture scan flow with our sample app and how you can assist people in automatically capturing the best content for their model. We’ll also discuss LiDAR data and provide best practices for scanning objects.","type":"text"}],"kind":"article"},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=803":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=803","type":"link","title":"13:23 - Audio authoring","titleInlineContent":[{"text":"13:23 - Audio authoring","type":"text"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=803"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10109-Meet-SwiftUI-for-spatial-computing":{"url":"\/documentation\/wwdcnotes\/wwdc23-10109-meet-swiftui-for-spatial-computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10109-Meet-SwiftUI-for-spatial-computing","title":"Meet SwiftUI for spatial computing","role":"sampleCode","type":"topic","abstract":[{"text":"Take a tour of the solar system with us and explore SwiftUI for visionOS! Discover how you can build an entirely new universe of apps with windows, volumes, and spaces. We’ll show you how to get started with SwiftUI on this platform as we build an astronomy app, add 3D content, and create a fully immersive experience to transport people to the stars.","type":"text"}],"kind":"article"},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=167":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=167","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=167","type":"link","titleInlineContent":[{"type":"text","text":"02:47 - UI navigation"}],"title":"02:47 - UI navigation"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10146-Meet-Core-Location-for-spatial-computing":{"abstract":[{"text":"Discover how Core Location helps your app find its place in the world — literally. We’ll share how you can build a spatial computing app that uses a person’s location while respecting their privacy. You’ll also learn how your app can request location access and how Core Location adapts requests from compatible iPad and iPhone apps.","type":"text"}],"title":"Meet Core Location for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-10146-meet-core-location-for-spatial-computing","kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10146-Meet-Core-Location-for-spatial-computing","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10086-Explore-the-USD-ecosystem":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem","title":"Explore the USD ecosystem","type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10086-explore-the-usd-ecosystem","abstract":[{"type":"text","text":"Discover the latest updates to Universal Scene Description (USD) on Apple platforms and learn how you can deliver great 3D content for your apps, games, and websites. Get to know USD for visionOS, explore MaterialX shaders and color management, and find out about some of the other improvements to the USD ecosystem."}]},"https://avatars.githubusercontent.com/u/418007?v=4":{"type":"image","variants":[{"traits":["1x","light"],"url":"https:\/\/avatars.githubusercontent.com\/u\/418007?v=4"}],"alt":"Profile image of Hal Mueller","identifier":"https:\/\/avatars.githubusercontent.com\/u\/418007?v=4"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","title":"WWDC23","type":"topic","role":"collectionGroup","url":"\/documentation\/wwdcnotes\/wwdc23","abstract":[{"type":"text","text":"Xcode 15, Swift 5.9, iOS 17, macOS 14, tvOS 17, visionOS 1, watchOS 10."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"SwiftData","type":"codeVoice"},{"type":"text","text":", "},{"code":"Observation","type":"codeVoice"},{"type":"text","text":", "},{"code":"StoreKit","type":"codeVoice"},{"type":"text","text":" views, and more."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10032-Meet-Assistive-Access":{"url":"\/documentation\/wwdcnotes\/wwdc23-10032-meet-assistive-access","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10032-Meet-Assistive-Access","title":"Meet Assistive Access","type":"topic","abstract":[{"type":"text","text":"Learn how Assistive Access can help people with cognitive disabilities more easily use iPhone and iPad. Discover the design principles that guide Assistive Access and find out how the system experience adapts to lighten cognitive load. We’ll show you how Assistive Access works and what you can do to support this experience in your app."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10187-Meet-SwiftData":{"url":"\/documentation\/wwdcnotes\/wwdc23-10187-meet-swiftdata","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10187-Meet-SwiftData","title":"Meet SwiftData","type":"topic","abstract":[{"type":"text","text":"SwiftData is a powerful and expressive persistence framework built for Swift. We’ll show you how you can model your data directly from Swift code, use SwiftData to work with your models, and integrate with SwiftUI."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10099-Meet-RealityKit-Trace":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10099-meet-realitykit-trace","title":"Meet RealityKit Trace","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10099-Meet-RealityKit-Trace","abstract":[{"type":"text","text":"Discover how you can use RealityKit Trace to improve the performance of your spatial computing apps. Explore performance profiling guidelines for this platform and learn how the RealityKit Trace template can help you optimize rendering for your apps. We’ll also provide guidance on profiling various types of content in your app to help pinpoint performance issues."}],"role":"sampleCode","kind":"article"},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=1059":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=1059","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=1059","type":"link","titleInlineContent":[{"text":"17:39 - Statistics","type":"text"}],"title":"17:39 - Statistics"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences","title":"Evolve your ARKit app for spatial experiences","type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10091-evolve-your-arkit-app-for-spatial-experiences","abstract":[{"type":"text","text":"Discover how you can bring your app’s AR experience to visionOS. Learn how ARKit and RealityKit have evolved for spatial computing: We’ll highlight conceptual and API changes for those coming from iPadOS and iOS and guide you to sessions with more details to help you bring your AR experience to this platform."}]},"https://developer.apple.com/videos/play/wwdc2023/10273/":{"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273\/","type":"link","title":"Work with Reality Composer Pro content in Xcode (make scene interactive)","titleInlineContent":[{"type":"text","text":"Work with Reality Composer Pro content in Xcode (make scene interactive)"}],"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10273\/"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10026-Meet-watchOS-10":{"url":"\/documentation\/wwdcnotes\/wwdc23-10026-meet-watchos-10","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10026-Meet-watchOS-10","title":"Meet watchOS 10","type":"topic","abstract":[{"type":"text","text":"Discover some of the most significant changes to Apple Watch since its introduction as we tour the redesigned user interface and the new Smart Stack. Learn how Apple designers approached the design of watchOS 10 as we explore layout, navigation, and visual style, and find out how you can apply them to create a great app for Apple Watch."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10129-Understand-USD-fundamentals":{"url":"\/documentation\/wwdcnotes\/wwdc22-10129-understand-usd-fundamentals","kind":"article","role":"sampleCode","title":"Understand USD fundamentals","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10129-Understand-USD-fundamentals","abstract":[{"text":"Discover the fundamentals of Pixar’s Universal Scene Description (USD) and learn how it can help you build great 3D assets and workflows. We’ll introduce you to the core concepts behind USD and explore how you can integrate the format into your content creation pipeline. We’ll also show you how to harness the power of USD by using composition to create flexible and versatile assets.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10279-Meet-Safari-for-spatial-computing":{"abstract":[{"text":"Discover the web for visionOS and learn how people can experience your web content in a whole new way. Explore the unique input model powering this platform and learn how you can optimize your website for spatial computing. We’ll also share how emerging standards are helping shape 3D experiences for the web.","type":"text"}],"title":"Meet Safari for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-10279-meet-safari-for-spatial-computing","kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10279-Meet-Safari-for-spatial-computing","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-111215-Meet-UIKit-for-spatial-computing":{"abstract":[{"text":"Learn how to bring your UIKit app to visionOS. We’ll show you how to build for a new destination, explore APIs and best practices for spatial computing, and take your content into the third dimension when you use SwiftUI with UIKit in visionOS.","type":"text"}],"title":"Meet UIKit for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-111215-meet-uikit-for-spatial-computing","kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111215-Meet-UIKit-for-spatial-computing","role":"sampleCode"},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=75":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=75","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=75","type":"link","titleInlineContent":[{"text":"01:15 - Project setup","type":"text"}],"title":"01:15 - Project setup"},"WWDCNotes.png":{"type":"image","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"alt":null,"identifier":"WWDCNotes.png"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10077-Create-3D-workflows-with-USD":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10077-Create-3D-workflows-with-USD","title":"Create 3D workflows with USD","url":"\/documentation\/wwdcnotes\/wwdc21-10077-create-3d-workflows-with-usd","type":"topic","abstract":[{"text":"Discover the flexibility, versatility and power of Pixar’s Universal Scene Description (USD) for your 3D workflows. Learn how you can use the USD file format in your professional workflows for macOS: Scan 3D models of your real-world objects using Object Capture, utilize the potential of third-party digital content creation tools, and build high-quality rendered sequences.","type":"text"}],"role":"sampleCode"},"https://developer.apple.com/videos/play/wwdc2023/10191/":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10191\/","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10191\/","type":"link","titleInlineContent":[{"text":"“Meet Object Capture for iOS” session","type":"text"}],"title":"“Meet Object Capture for iOS” session"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"type":"topic","abstract":[{"type":"text","text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","title":"Build spatial experiences with RealityKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro","title":"Explore materials in Reality Composer Pro","type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10202-explore-materials-in-reality-composer-pro","abstract":[{"type":"text","text":"Learn how Reality Composer Pro can help you alter the appearance of your 3D objects using RealityKit materials. We’ll introduce you to MaterialX and physically-based (PBR) shaders, show you how to design dynamic materials using the shader graph editor, and explore adding custom inputs to a material so that you can control it in your visionOS app."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode":{"kind":"article","title":"Work with Reality Composer Pro content in Xcode","url":"\/documentation\/wwdcnotes\/wwdc23-10273-work-with-reality-composer-pro-content-in-xcode","type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","abstract":[{"type":"text","text":"Learn how to bring content from Reality Composer Pro to life in Xcode. We’ll show you how to load 3D scenes into Xcode, integrate your content with your code, and add interactivity to your app. We’ll also share best practices and tips for using these tools together in your development workflow."}]},"https://github.com/halmueller":{"url":"https:\/\/github.com\/halmueller","type":"link","title":"GitHub","titleInlineContent":[{"text":"GitHub","type":"text"}],"identifier":"https:\/\/github.com\/halmueller"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10171-Meet-Swift-OpenAPI-Generator":{"abstract":[{"text":"Discover how Swift OpenAPI Generator can help you work with HTTP server APIs whether you’re extending an iOS app or writing a server in Swift. We’ll show you how this package plugin can streamline your workflow and simplify your codebase by generating code from an OpenAPI document.","type":"text"}],"title":"Meet Swift OpenAPI Generator","url":"\/documentation\/wwdcnotes\/wwdc23-10171-meet-swift-openapi-generator","kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10171-Meet-Swift-OpenAPI-Generator","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing":{"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","title":"Get started with building apps for spatial computing","type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10260-get-started-with-building-apps-for-spatial-computing","abstract":[{"type":"text","text":"Get ready to develop apps and games for visionOS! Discover the fundamental building blocks that make up spatial computing — windows, volumes, and spaces — and find out how you can use these elements to build engaging and immersive experiences."}]},"https://developer.apple.com/videos/play/wwdc2023/10083/?time=303":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=303","url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10083\/?time=303","type":"link","titleInlineContent":[{"type":"text","text":"05:03: Walkthrough of building diorama from imported assets, plus library assets."}],"title":"05:03: Walkthrough of building diorama from imported assets, plus library assets."},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10043-Meet-MapKit-for-SwiftUI":{"abstract":[{"text":"Discover how expanded SwiftUI support for MapKit has made it easier than ever for you to integrate Maps into your app. We’ll show you how to use SwiftUI to add annotations and overlays to a map, control the camera, and more.","type":"text"}],"title":"Meet MapKit for SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10043-meet-mapkit-for-swiftui","kind":"article","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10043-Meet-MapKit-for-SwiftUI","role":"sampleCode"}}}