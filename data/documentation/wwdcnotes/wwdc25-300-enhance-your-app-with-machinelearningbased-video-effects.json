{"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25-300-Enhance-your-app-with-machinelearningbased-video-effects"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/wwdcnotes\/wwdc25-300-enhance-your-app-with-machinelearningbased-video-effects"]}],"sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"type":"reference","identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/300","overridingTitle":"Watch Video (16 min)"}},"kind":"article","hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25"]]},"abstract":[{"type":"text","text":"Discover how to add effects like frame rate conversion, super resolution, and noise filtering to improve video editing and live streaming experiences. We‚Äôll explore the ML-based video processing algorithms optimized for Apple Silicon available in the Video Toolbox framework. Learn how to integrate these effects to enhance the capabilities of your app for real-world use cases."}],"metadata":{"role":"sampleCode","roleHeading":"WWDC25","title":"Enhance your app with machine-learning-based video effects","modules":[{"name":"WWDC Notes"}]},"schemaVersion":{"minor":3,"major":0,"patch":0},"sections":[],"primaryContentSections":[{"kind":"content","content":[{"text":"Overview","anchor":"overview","level":2,"type":"heading"},{"inlineContent":[{"type":"text","text":"üò± ‚ÄúNo Overview Available!‚Äù"}],"type":"paragraph"},{"inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It‚Äôs super easy:","type":"text"},{"text":" ","type":"text"},{"type":"reference","isActive":true,"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"}],"type":"paragraph"}]}],"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC25":{"images":[{"identifier":"WWDC25-Icon.png","type":"icon"},{"identifier":"WWDC25.jpg","type":"card"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC25","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc25","type":"topic","abstract":[{"type":"text","text":"Xcode 26, Swift 6.2, iOS\/macOS\/tvOS\/visionOS 26."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"Foundation Models","type":"codeVoice"},{"type":"text","text":", "},{"code":"AlarmKit","type":"codeVoice"},{"type":"text","text":", "},{"code":"PermissionKit","type":"codeVoice"},{"type":"text","text":", and more."}],"title":"WWDC25","role":"collectionGroup"},"https://developer.apple.com/videos/play/wwdc2025/300":{"identifier":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/300","checksum":null,"url":"https:\/\/developer.apple.com\/videos\/play\/wwdc2025\/300","type":"download"},"WWDC25.jpg":{"type":"image","identifier":"WWDC25.jpg","alt":null,"variants":[{"url":"\/images\/WWDCNotes\/WWDC25.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes":{"url":"\/documentation\/wwdcnotes","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","role":"collection","title":"WWDC Notes","type":"topic","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"kind":"symbol"},"WWDCNotes.png":{"identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes\/WWDCNotes.png","traits":["1x","light"]}],"type":"image","alt":null},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Learn More‚Ä¶","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","titleInlineContent":[{"type":"text","text":"Learn More‚Ä¶"}]},"WWDC25-Icon.png":{"type":"image","identifier":"WWDC25-Icon.png","alt":null,"variants":[{"url":"\/images\/WWDCNotes\/WWDC25-Icon.png","traits":["1x","light"]}]}}}