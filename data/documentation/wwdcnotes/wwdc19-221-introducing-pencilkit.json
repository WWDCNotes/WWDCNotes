{"schemaVersion":{"major":0,"minor":3,"patch":0},"metadata":{"roleHeading":"WWDC19","modules":[{"name":"WWDC Notes"}],"role":"sampleCode","title":"Introducing PencilKit"},"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19"]]},"abstract":[{"type":"text","text":"Meet PencilKit, Apple’s feature-rich drawing and annotation framework. With just a few lines of code, you can add a full drawing experience to your app — with access to a canvas, responsive inks, rich tool palette and drawing model. Hear the technical details that make a great Apple Pencil experience. Learn about the new screenshot editor and how you can adopt just a few small APIs to enable your full content to be captured beyond the size of the screen, with or without your app’s user interface."}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-221-Introducing-PencilKit"},"kind":"article","primaryContentSections":[{"kind":"content","content":[{"level":2,"type":"heading","anchor":"Before-PencilKit","text":"Before `PencilKit`"},{"type":"paragraph","inlineContent":[{"type":"text","text":"How to use the pencil at full:"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Force, azimuth, and altitude allow expressive marks"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Pencil taps switch modes (for pencil 2nd gen)","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"image","identifier":"WWDC19-221-pencilChart"}]},{"level":2,"type":"heading","text":"Pencil behind the scenes","anchor":"Pencil-behind-the-scenes"},{"type":"paragraph","inlineContent":[{"text":"The Pencil gives us:","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"a uniquely, precise "},{"type":"strong","inlineContent":[{"type":"text","text":"touch location"}]},{"type":"text","text":" on the screen, 240 times\/second."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"an "},{"type":"strong","inlineContent":[{"text":"azimuth","type":"text"}]},{"type":"text","text":", which is the angle around the perpendicular of the iPad. And it gives us "},{"type":"strong","inlineContent":[{"text":"altitude or tilt","type":"text"}]},{"type":"text","text":", which is the steepness at which the user is holding the Pencil. The Pencil generates a second hit and touchpoint on the surface of the iPad. And using trigonometry, it uses that to calculate azimuth and altitude. This is a "},{"type":"emphasis","inlineContent":[{"text":"hidden","type":"text"}]},{"type":"text","text":" sensor in the pencil."},{"type":"text","text":" "},{"type":"image","identifier":"WWDC19-221-az"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"A ","type":"text"},{"inlineContent":[{"text":"force\/press","type":"text"}],"type":"strong"},{"text":" value, the Pencil has an axial force sensor that detects the pressure and it sends that data over Bluetooth.","type":"text"}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"There are a few consequences of all of this:"}]},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Azimuth\/altitude may be estimated (when users covers this second point with their hands)","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Azimuth is imprecise when the pencil is perpendicular"}]}]},{"content":[{"inlineContent":[{"text":"Force data is delayed (as Bluetooth is slower than whatever the Pencil uses to transfer the rest of the data)","type":"text"}],"type":"paragraph"}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Because the force data is delayed, when we lift the pencil there’s the last region of the stroke that’s still waiting for those final force values:"},{"type":"text","text":" "},{"type":"text","text":"we need to keep listening to them even after touch has ended."}]},{"inlineContent":[{"type":"text","text":"It’s possible that the user starts drawing the next stroke before the last stroke has gotten all the final press values."},{"type":"text","text":"\n"},{"type":"text","text":"Apple suggests to use a serial queue to only be handling one stroke at a time. The time is short enough that the user won’t notice."}],"type":"paragraph"},{"inlineContent":[{"text":"How to work for best latency:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"text":"Render with metal","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Use predicted touches"}],"type":"paragraph"}]}],"type":"unorderedList"},{"anchor":"What-is-PencilKit","type":"heading","level":2,"text":"What is `PencilKit`?"},{"inlineContent":[{"type":"codeVoice","code":"PencilKit"},{"type":"text","text":" makes it easy to incorporate hand-drawn content into your iOS or macOS apps quickly and easily. PencilKit provides a drawing environment for your iOS app that takes input from Apple Pencil, or the user’s finger, and turns it into high quality images you display in either iOS or macOS. The environment comes with tools for creating, erasing, and selecting lines."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"In short, "},{"type":"codeVoice","code":"PencilKit"},{"type":"text","text":" lets 3rd party apps use the annotation interface that we use when taking a screenshot."},{"type":"text","text":" "},{"type":"text","text":"Three lines of code to start doodling:"}],"type":"paragraph"},{"code":["let canvas = PKCanvasView(frame: bounds)","view.addSubview(canvas) ","canvas.tool = PKInkingTool(.pen, color: .black, width: 30) "],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"code":"PKCanvasView","type":"codeVoice"},{"text":" provides (we provide) the drawable region of the app.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"It’s a scrollview (can pan and zoom), from the session is not clear how we can manage this.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"code":"PKDrawing","type":"codeVoice"},{"text":" model captures the user strokes: it’s the data model of PencilKit.","type":"text"},{"text":" ","type":"text"},{"text":"It has a data format and it allows us to load and store drawings to data.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"codeVoice","code":"PKTools"},{"type":"text","text":" are the tools that we let users to use in the canvas (think like pen, pencil, brush..). We can enable\/disable tools, even choose the available colors."}],"type":"paragraph"},{"anchor":"Screenshots","type":"heading","level":2,"text":"Screenshots"},{"inlineContent":[{"type":"text","text":"When taking a screenshot, we can now provide a better version of the current screen as a pdf (like in safari, we can choose to get the current screen screenshot, limited by the screen boundaries, or we can ask Safari to give us the whole web page, not just the screen crop, without all the unnecessary safari UI)."}],"type":"paragraph"},{"inlineContent":[{"text":"We do this by setting the property ","type":"text"},{"identifier":"https:\/\/developer.apple.com\/documentation\/uikit\/uiwindowscene\/3213938-screenshotservice","type":"reference","isActive":true},{"text":" of the new ","type":"text"},{"type":"codeVoice","code":"UIWindowScene"},{"text":".","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We must return a "},{"type":"codeVoice","code":".pdf"}],"type":"paragraph"},{"anchor":"Written-By","type":"heading","level":2,"text":"Written By"},{"columns":[{"content":[{"type":"paragraph","inlineContent":[{"identifier":"zntfdr","type":"image"}]}],"size":1},{"content":[{"type":"heading","level":3,"text":"Federico Zanetello","anchor":"Federico-Zanetello"},{"type":"paragraph","inlineContent":[{"type":"reference","overridingTitleInlineContent":[{"text":"Contributed Notes","type":"text"}],"isActive":true,"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","overridingTitle":"Contributed Notes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/github.com\/zntfdr"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/zntfdr.dev"}]}],"size":4}],"type":"row","numberOfColumns":5},{"inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"type":"reference","identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","isActive":true}],"type":"paragraph"},{"anchor":"Related-Sessions","type":"heading","level":2,"text":"Related Sessions"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10089-Whats-new-in-PDFKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10107-Whats-new-in-PencilKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10148-Inspect-modify-and-construct-PencilKit-drawings","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-212-Introducing-Multiple-Windows-on-iPad","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC17-706-Modernizing-Grand-Central-Dispatch-Usage"],"type":"links","style":"list"},{"inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}],"type":"small"},{"inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}],"type":"small"}]}],"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc19-221-introducing-pencilkit"],"traits":[{"interfaceLanguage":"swift"}]}],"sections":[],"sampleCodeDownload":{"kind":"sampleDownload","action":{"identifier":"https:\/\/developer.apple.com\/wwdc19\/221","overridingTitle":"Watch Video (34 min)","type":"reference","isActive":true}},"references":{"WWDC19.jpeg":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC19.jpeg"}],"type":"image","alt":null,"identifier":"WWDC19.jpeg"},"WWDCNotes.png":{"variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}],"type":"image","alt":null,"identifier":"WWDCNotes.png"},"zntfdr":{"variants":[{"traits":["1x","light"],"url":"\/images\/zntfdr.jpeg"}],"type":"image","alt":"Profile image of Federico Zanetello","identifier":"zntfdr"},"https://wwdcnotes.com/documentation/wwdcnotes/contributing":{"type":"link","titleInlineContent":[{"type":"text","text":"Contributions are welcome!"}],"identifier":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!","url":"https:\/\/wwdcnotes.com\/documentation\/wwdcnotes\/contributing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC17-706-Modernizing-Grand-Central-Dispatch-Usage":{"type":"topic","abstract":[{"type":"text","text":"macOS 10.13 and iOS 11 have reinvented how Grand Central Dispatch and the Darwin kernel collaborate, enabling your applications to run concurrent workloads more efficiently. Learn how to modernize your code to take advantage of these improvements and make optimal use of hardware resources."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC17-706-Modernizing-Grand-Central-Dispatch-Usage","title":"Modernizing Grand Central Dispatch Usage","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc17-706-modernizing-grand-central-dispatch-usage"},"WWDC19-221-az":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDC19-221-az.png"}],"type":"image","alt":null,"identifier":"WWDC19-221-az"},"WWDC19-Icon.png":{"variants":[{"url":"\/images\/WWDC19-Icon.png","traits":["1x","light"]}],"type":"image","alt":null,"identifier":"WWDC19-Icon.png"},"doc://WWDCNotes/documentation/WWDCNotes/zntfdr":{"type":"topic","images":[{"identifier":"zntfdr.jpeg","type":"card"},{"identifier":"zntfdr.jpeg","type":"icon"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/zntfdr","title":"Federico Zanetello (332 notes)","url":"\/documentation\/wwdcnotes\/zntfdr","role":"sampleCode","abstract":[{"text":"Software engineer with a strong passion for well-written code, thought-out composable architectures, automation, tests, and more.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC22-10089-Whats-new-in-PDFKit":{"role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc22-10089-whats-new-in-pdfkit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC22-10089-Whats-new-in-PDFKit","title":"What’s new in PDFKit","type":"topic","abstract":[{"text":"Discover PDFKit — a full-featured framework that helps your app view, edit, and save PDF documents. We’ll take you through the latest features in PDFKit, including support for live text and forms, creating PDFs from images, building interactive overlays, and saving annotations.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"type":"topic","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"images":[{"type":"icon","identifier":"WWDCNotes.png"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","kind":"symbol","url":"\/documentation\/wwdcnotes","title":"WWDC Notes","role":"collection"},"https://zntfdr.dev":{"type":"link","titleInlineContent":[{"text":"Blog","type":"text"}],"identifier":"https:\/\/zntfdr.dev","title":"Blog","url":"https:\/\/zntfdr.dev"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19":{"type":"topic","images":[{"identifier":"WWDC19-Icon.png","type":"icon"},{"identifier":"WWDC19.jpeg","type":"card"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19","title":"WWDC19","url":"\/documentation\/wwdcnotes\/wwdc19","role":"collectionGroup","abstract":[{"type":"text","text":"Xcode 11, Swift 5.1, iOS 13, macOS 10.15 (Catalina), tvOS 13, watchOS 6."},{"type":"text","text":" "},{"type":"text","text":"New APIs: "},{"code":"Combine","type":"codeVoice"},{"type":"text","text":", "},{"code":"Core Haptics","type":"codeVoice"},{"type":"text","text":", "},{"code":"Create ML","type":"codeVoice"},{"type":"text","text":", and more."}],"kind":"article"},"WWDC19-221-pencilChart":{"variants":[{"url":"\/images\/WWDC19-221-pencilChart.png","traits":["1x","light"]}],"type":"image","alt":null,"identifier":"WWDC19-221-pencilChart"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10107-Whats-new-in-PencilKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10107-Whats-new-in-PencilKit","url":"\/documentation\/wwdcnotes\/wwdc20-10107-whats-new-in-pencilkit","abstract":[{"text":"PencilKit helps power creativity, writing, drawing, and animation in your iPad apps. Explore the latest improvements to our drawing and annotation framework, and discover how you can take advantage of APIs like PKToolPicker, PKCanvasView, and PKStroke to support new features in illustration and writing apps.","type":"text"}],"title":"What’s new in PencilKit","type":"topic","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC20-10148-Inspect-modify-and-construct-PencilKit-drawings":{"role":"sampleCode","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc20-10148-inspect-modify-and-construct-pencilkit-drawings","abstract":[{"text":"Make Apple Pencil an even more useful tool for drawing and writing within your app. With PencilKit, you can delve into the strokes, inks, paths, and points that comprise a drawing, use these to build features that use recognition, and modify drawings in response to input. Discover how you can dynamically generate shapes and drawings and learn more about APIs like PKDrawings and PKStrokes.","type":"text"}],"kind":"article","title":"Inspect, modify, and construct PencilKit drawings","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC20-10148-Inspect-modify-and-construct-PencilKit-drawings"},"https://github.com/zntfdr":{"type":"link","titleInlineContent":[{"text":"GitHub","type":"text"}],"identifier":"https:\/\/github.com\/zntfdr","title":"GitHub","url":"https:\/\/github.com\/zntfdr"},"https://developer.apple.com/wwdc19/221":{"type":"download","checksum":null,"url":"https:\/\/developer.apple.com\/wwdc19\/221","identifier":"https:\/\/developer.apple.com\/wwdc19\/221"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC19-212-Introducing-Multiple-Windows-on-iPad":{"url":"\/documentation\/wwdcnotes\/wwdc19-212-introducing-multiple-windows-on-ipad","abstract":[{"type":"text","text":"Multitasking is an exciting way to add power to your iPad app. It is easy to enable your app to run two instances of your interface side-by-side, and your customers will love it. Learn how to take your existing features like drag and drop and use them to easily create a second window. Find out how supporting multiple windows changes the app lifecycle and what that means for all applications. Hear about some common mistakes and how to solve them, setting you and your customers up for a fantastic experience."}],"type":"topic","kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC19-212-Introducing-Multiple-Windows-on-iPad","title":"Introducing Multiple Windows on iPad"},"zntfdr.jpeg":{"alt":null,"identifier":"zntfdr.jpeg","variants":[{"url":"\/images\/zntfdr.jpeg","traits":["1x","light"]}],"type":"image"},"https://developer.apple.com/documentation/uikit/uiwindowscene/3213938-screenshotservice":{"url":"https:\/\/developer.apple.com\/documentation\/uikit\/uiwindowscene\/3213938-screenshotservice","title":"screenshotService","identifier":"https:\/\/developer.apple.com\/documentation\/uikit\/uiwindowscene\/3213938-screenshotservice","titleInlineContent":[{"type":"codeVoice","code":"screenshotService"}],"type":"link"}}}