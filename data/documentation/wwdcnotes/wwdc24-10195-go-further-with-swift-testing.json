{"sections":[],"kind":"article","sampleCodeDownload":{"kind":"sampleDownload","action":{"isActive":true,"overridingTitle":"Watch Video","identifier":"https:\/\/developer.apple.com\/wwdc24\/10195","type":"reference"}},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc24-10195-go-further-with-swift-testing"],"traits":[{"interfaceLanguage":"swift"}]}],"schemaVersion":{"patch":0,"major":0,"minor":3},"abstract":[{"type":"text","text":"Learn how to write a sweet set of (test) suites using Swift Testing’s baked-in features. Discover how to take the building blocks further and use them to help expand tests to cover more scenarios, organize your tests across different suites, and optimize your tests to run in parallel."}],"hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24"]]},"seeAlsoSections":[{"title":"Deep Dives into Topics","identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10184-A-Swift-Tour-Explore-Swifts-features-and-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10218-Accelerate-machine-learning-with-Metal","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10140-Add-personality-to-your-app-through-UX-writing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10173-Analyze-heap-memory","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10172-Break-into-the-RealityKit-debugger","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10067-Bring-context-to-todays-weather","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10220-Bring-expression-to-your-app-with-Genmoji","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10068-Bring-your-Live-Activity-to-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10133-Bring-your-app-to-Siri","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10210-Bring-your-apps-core-features-to-users-with-App-Intents","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10093-Bring-your-iOS-or-iPadOS-game-to-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10159-Bring-your-machine-learning-and-AI-models-to-Apple-silicon","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10069-Broadcast-updates-to-your-Live-Activities","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10204-Build-a-great-Lock-Screen-camera-capture-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10104-Build-a-spatial-drawing-app-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10166-Build-compelling-spatial-photo-and-video-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10084-Build-custom-swimming-workouts-with-WorkoutKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10066-Build-immersive-web-experiences-with-WebXR","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10185-Build-multilingualready-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10088-Capture-HDR-content-with-ScreenCaptureKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10073-Catch-up-on-accessibility-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10102-Compose-interactive-3D-content-in-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10170-Consume-noncopyable-types-in-Swift","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10138-Create-a-custom-data-store-with-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10087-Create-custom-environments-for-your-immersive-apps-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10152-Create-custom-hover-effects-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10151-Create-custom-visual-effects-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10100-Create-enhanced-spatial-computing-experiences-with-ARKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10070-Customize-feature-discovery-with-TipKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10201-Customize-spatial-Persona-templates-in-SharePlay","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10146-Demystify-SwiftUI-containers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10171-Demystify-explicitly-built-modules","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10161-Deploy-machine-learning-and-AI-models-ondevice-with-Core-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10176-Design-App-Intents-for-system-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10098-Design-Live-Activities-for-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10085-Design-advanced-games-for-Apple-platforms","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10086-Design-great-visionOS-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10096-Design-interactive-experiences-for-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10103-Discover-RealityKit-APIs-for-iOS-macOS-and-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10163-Discover-Swift-enhancements-in-the-Vision-framework","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10107-Discover-area-mode-for-Object-Capture","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10113-Discover-media-performance-metrics-in-AVFoundation","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10153-Dive-deep-into-volumes-and-immersive-spaces","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10147-Elevate-your-tab-and-sidebar-experience-in-iPadOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10114-Enhance-ad-experiences-with-HLS-interstitials","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10115-Enhance-the-immersion-of-media-viewing-in-custom-environments","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10145-Enhance-your-UI-animations-and-transitions","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-111801-Enhance-your-spatial-computing-app-with-RealityKit-audio","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10209-Enhanced-suggestions-for-your-journaling-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10132-Evolve-your-document-launch-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10062-Explore-App-Store-server-APIs-for-InApp-Purchase","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10217-Explore-Swift-performance","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10094-Explore-game-input-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10223-Explore-machine-learning-on-Apple-platforms","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10116-Explore-multiview-video-playback-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10101-Explore-object-tracking-for-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10216-Explore-the-Swift-on-Server-ecosystem","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10109-Explore-wellbeing-APIs-in-HealthKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10200-Extend-your-Xcode-Cloud-workflows","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10157-Extend-your-apps-controls-across-the-system","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10074-Get-started-with-Dynamic-Type","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10083-Get-started-with-HealthKit-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10168-Get-started-with-Writing-Tools","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10197-Go-small-with-Embedded-Swift","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10110-Implement-App-Store-Offers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10162-Keep-colors-consistent-across-captures","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10207-Migrate-your-TVML-app-to-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10169-Migrate-your-app-to-Swift-6","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10065-Optimize-for-the-spatial-web","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10186-Optimize-your-3D-assets-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10089-Port-advanced-games-to-Apple-platforms","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10092-Render-Metal-with-passthrough-in-visionOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10198-Run-Break-Inspect-Explore-effective-debugging-in-LLDB","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10112-Say-hello-to-the-next-generation-of-CarPlay-design-system","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10214-Squeeze-the-most-out-of-Apple-Pencil","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10125-Streamline-signin-with-passkey-upgrades-and-credential-managers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10131-Support-semantic-search-with-Core-Spotlight","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10155-Swift-Charts-Vectorized-and-function-plots","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10150-SwiftUI-essentials","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10148-Tailor-macOS-windows-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10075-Track-model-changes-with-SwiftData-history","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10160-Train-your-machine-learning-and-AI-models-on-Apple-GPUs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10097-Unlock-the-power-of-places-with-MapKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10122-Use-CloudKit-Console-to-monitor-and-optimize-database-activity","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10177-Use-HDR-for-dynamic-image-experiences-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10149-Work-with-windows-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10181-Xcode-essentials"],"generated":true}],"primaryContentSections":[{"content":[{"anchor":"overview","level":2,"type":"heading","text":"Overview"},{"type":"paragraph","inlineContent":[{"text":"😱 “No Overview Available!”","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Be the hero to change that by watching the video and providing notes! It’s super easy:","type":"text"},{"text":" ","type":"text"},{"isActive":true,"identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","type":"reference"}]},{"anchor":"Related-Sessions","level":2,"type":"heading","text":"Related Sessions"},{"items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10179-Meet-Swift-Testing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10132-Meet-asyncawait-in-Swift"],"style":"list","type":"links"},{"type":"small","inlineContent":[{"inlineContent":[{"type":"text","text":"Legal Notice"}],"type":"strong"}]},{"inlineContent":[{"type":"text","text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved."},{"type":"text","text":" "},{"type":"text","text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries."},{"type":"text","text":" "},{"type":"text","text":"This website is not made by, affiliated with, nor endorsed by Apple."}],"type":"small"}],"kind":"content"}],"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10195-Go-further-with-Swift-Testing","interfaceLanguage":"swift"},"metadata":{"modules":[{"name":"WWDC Notes"}],"role":"sampleCode","title":"Go further with Swift Testing","roleHeading":"WWDC24"},"references":{"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10094-Explore-game-input-in-visionOS":{"abstract":[{"type":"text","text":"Discover how to design and implement great input for your game in visionOS. Learn how system gestures let you provide frictionless ways for players to interact with your games. And explore best practices for supporting custom gestures and game controllers."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10094-Explore-game-input-in-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10094-explore-game-input-in-visionos","type":"topic","role":"sampleCode","title":"Explore game input in visionOS","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10101-Explore-object-tracking-for-visionOS":{"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10101-Explore-object-tracking-for-visionOS","title":"Explore object tracking for visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10101-explore-object-tracking-for-visionos","kind":"article","abstract":[{"type":"text","text":"Find out how you can use object tracking to turn real-world objects into virtual anchors in your visionOS app. Learn how you can build spatial experiences with object tracking from start to finish. Find out how to create a reference object using machine learning in Create ML and attach content relative to your target object in Reality Composer Pro, RealityKit or ARKit APIs."}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10116-Explore-multiview-video-playback-in-visionOS":{"title":"Explore multiview video playback in visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10116-explore-multiview-video-playback-in-visionos","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10116-Explore-multiview-video-playback-in-visionOS","abstract":[{"type":"text","text":"Learn how AVExperienceController can enable playback of multiple videos on Apple Vision Pro. Review best practices for adoption and explore great use cases, like viewing a sports broadcast from different angles or watching multiple games simultaneously. And discover how to design a compelling and intuitive multiview experience in your app."}],"role":"sampleCode","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10220-Bring-expression-to-your-app-with-Genmoji":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10220-Bring-expression-to-your-app-with-Genmoji","url":"\/documentation\/wwdcnotes\/wwdc24-10220-bring-expression-to-your-app-with-genmoji","type":"topic","title":"Bring expression to your app with Genmoji","kind":"article","role":"sampleCode","abstract":[{"text":"Discover how to bring Genmoji to life in your app. We’ll go over how to render, store, and communicate text that includes Genmoji. If your app features a custom text engine, we’ll also cover techniques for adding support for Genmoji.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10074-Get-started-with-Dynamic-Type":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10074-Get-started-with-Dynamic-Type","url":"\/documentation\/wwdcnotes\/wwdc24-10074-get-started-with-dynamic-type","type":"topic","title":"Get started with Dynamic Type","kind":"article","role":"sampleCode","abstract":[{"text":"Dynamic Type lets people choose their preferred text size across the system and all of their apps. To help you get started supporting Dynamic Type, we’ll cover the fundamentals: How it works, how to find issues with scaling text in your app, and how to take practical steps using SwiftUI and UIKit to create a great Dynamic Type experience. We’ll also show how you can best use the Large Content Viewer to make navigation controls accessible to everyone.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10088-Capture-HDR-content-with-ScreenCaptureKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10088-Capture-HDR-content-with-ScreenCaptureKit","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10088-capture-hdr-content-with-screencapturekit","kind":"article","abstract":[{"type":"text","text":"Learn how to capture high dynamic colors using ScreenCaptureKit, and explore new features like HDR support, microphone capture, and straight-to-file recording."}],"type":"topic","title":"Capture HDR content with ScreenCaptureKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10157-Extend-your-apps-controls-across-the-system":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10157-Extend-your-apps-controls-across-the-system","url":"\/documentation\/wwdcnotes\/wwdc24-10157-extend-your-apps-controls-across-the-system","type":"topic","title":"Extend your app’s controls across the system","kind":"article","role":"sampleCode","abstract":[{"text":"Bring your app’s controls to Control Center, the Lock Screen, and beyond. Learn how you can use WidgetKit to extend your app’s controls to the system experience. We’ll cover how you can to build a control, tailor its appearance, and make it configurable.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10146-Demystify-SwiftUI-containers":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10146-Demystify-SwiftUI-containers","url":"\/documentation\/wwdcnotes\/wwdc24-10146-demystify-swiftui-containers","type":"topic","title":"Demystify SwiftUI containers","kind":"article","role":"sampleCode","abstract":[{"text":"Learn about the capabilities of SwiftUI container views and build a mental model for how subviews are managed by their containers. Leverage new APIs to build your own custom containers, create modifiers to customize container content, and give your containers that extra polish that helps your apps stand out.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10152-Create-custom-hover-effects-in-visionOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10152-Create-custom-hover-effects-in-visionOS","role":"sampleCode","type":"topic","abstract":[{"type":"text","text":"Learn how to develop custom hover effects that update views when people look at them. Find out how to build an expanding button effect that combines opacity, scale, and clip effects. Discover best practices for creating effects that are comfortable and respect people’s accessibility needs."}],"kind":"article","title":"Create custom hover effects in visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10152-create-custom-hover-effects-in-visionos"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10201-Customize-spatial-Persona-templates-in-SharePlay":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10201-Customize-spatial-Persona-templates-in-SharePlay","url":"\/documentation\/wwdcnotes\/wwdc24-10201-customize-spatial-persona-templates-in-shareplay","type":"topic","title":"Customize spatial Persona templates in SharePlay","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how to use custom spatial Persona templates in your visionOS SharePlay experience to fine-tune the placement of Personas relative to your app. We’ll show you how to adopt custom spatial Persona templates in a sample app with SharePlay, move participants between seats, and test your changes in Simulator. We’ll also share best practices for designing custom spatial templates that will make your experience shine.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10068-Bring-your-Live-Activity-to-Apple-Watch":{"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10068-Bring-your-Live-Activity-to-Apple-Watch","title":"Bring your Live Activity to Apple Watch","url":"\/documentation\/wwdcnotes\/wwdc24-10068-bring-your-live-activity-to-apple-watch","kind":"article","abstract":[{"type":"text","text":"Bring Live Activities into the Smart Stack on Apple Watch with iOS 18 and watchOS 11. We’ll cover how Live Activities are presented on Apple Watch, as well as how you can enhance their presentation for the Smart Stack. We’ll also explore additional considerations to ensure Live Activities on Apple Watch always present up-to-date information."}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10170-Consume-noncopyable-types-in-Swift":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10170-Consume-noncopyable-types-in-Swift","url":"\/documentation\/wwdcnotes\/wwdc24-10170-consume-noncopyable-types-in-swift","type":"topic","title":"Consume noncopyable types in Swift","kind":"article","role":"sampleCode","abstract":[{"text":"Get started with noncopyable types in Swift. Discover what copying means in Swift, when you might want to use a noncopyable type, and how value ownership lets you state your intentions clearly.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10155-Swift-Charts-Vectorized-and-function-plots":{"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10155-Swift-Charts-Vectorized-and-function-plots","title":"Swift Charts: Vectorized and function plots","url":"\/documentation\/wwdcnotes\/wwdc24-10155-swift-charts-vectorized-and-function-plots","kind":"article","abstract":[{"type":"text","text":"The plot thickens! Learn how to render beautiful charts representing math functions and extensive datasets using function and vectorized plots in your app. Whether you’re looking to display functions common in aerodynamics, magnetism, and higher order field theory, or create large interactive heat maps, Swift Charts has you covered."}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10131-Support-semantic-search-with-Core-Spotlight":{"type":"topic","title":"Support semantic search with Core Spotlight","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10131-Support-semantic-search-with-Core-Spotlight","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10131-support-semantic-search-with-core-spotlight","abstract":[{"text":"Learn how to provide semantic search results in your app using Core Spotlight. Understand how to make your app’s content available in the user’s private, on-device index so people can search for items using natural language. We’ll also share how to optimize your app’s performance by scheduling indexing activities.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10140-Add-personality-to-your-app-through-UX-writing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10140-Add-personality-to-your-app-through-UX-writing","type":"topic","abstract":[{"text":"Every app has a personality that comes across in what you say — and how you say it. Learn how to define your app’s voice and modulate your tone for every situation, from celebratory notifications to error messages. We’ll help you get specific about your app’s purpose and audience and practice writing in different tones.","type":"text"}],"title":"Add personality to your app through UX writing","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10140-add-personality-to-your-app-through-ux-writing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10107-Discover-area-mode-for-Object-Capture":{"abstract":[{"type":"text","text":"Discover how area mode for Object Capture enables new 3D capture possibilities on iOS by extending the functionality of Object Capture to support capture and reconstruction of an area. Learn how to optimize the quality of iOS captures using the new macOS sample app for reconstruction, and find out how to view the final results with Quick Look on Apple Vision Pro, iPhone, iPad or Mac. Learn about improvements to 3D reconstruction, including a new API that allows you to create your own custom image processing pipelines."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10107-discover-area-mode-for-object-capture","kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10107-Discover-area-mode-for-Object-Capture","title":"Discover area mode for Object Capture"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10085-Design-advanced-games-for-Apple-platforms":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10085-design-advanced-games-for-apple-platforms","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how to adapt your high-end game so it feels at home on Mac, iPad, and iPhone. We’ll go over how to make your game look stunning on different displays, tailor your input and controls to be intuitive on each device, and take advantage of Apple technologies that deliver great player experiences.","type":"text"}],"title":"Design advanced games for Apple platforms","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10085-Design-advanced-games-for-Apple-platforms"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10207-Migrate-your-TVML-app-to-SwiftUI":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10207-migrate-your-tvml-app-to-swiftui","kind":"article","abstract":[{"type":"text","text":"SwiftUI helps you build great apps on all Apple platforms and is the preferred toolkit for bringing your content into the living room with tvOS 18. Learn how to use SwiftUI to create familiar layouts and controls from TVMLKit, and get tips and best practices."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10207-Migrate-your-TVML-app-to-SwiftUI","title":"Migrate your TVML app to SwiftUI"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10148-Tailor-macOS-windows-with-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10148-Tailor-macOS-windows-with-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc24-10148-tailor-macos-windows-with-swiftui","type":"topic","title":"Tailor macOS windows with SwiftUI","kind":"article","role":"sampleCode","abstract":[{"text":"Make your windows feel tailor-made for macOS. Fine-tune your app’s windows for focused purposes, ease of use, and to express functionality. Use SwiftUI to style window toolbars and backgrounds. Arrange your windows with precision, and make smart decisions about restoration and minimization.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10185-Build-multilingualready-apps":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10185-Build-multilingualready-apps","url":"\/documentation\/wwdcnotes\/wwdc24-10185-build-multilingualready-apps","type":"topic","title":"Build multilingual-ready apps","kind":"article","role":"sampleCode","abstract":[{"text":"Ensure your app works properly and effectively for multilingual users. Learn best practices for text input, display, search, and formatting. Get details on typing in multiple languages without switching between keyboards. And find out how the latest advances in the String Catalog can make localization even easier.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10204-Build-a-great-Lock-Screen-camera-capture-experience":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10204-Build-a-great-Lock-Screen-camera-capture-experience","url":"\/documentation\/wwdcnotes\/wwdc24-10204-build-a-great-lock-screen-camera-capture-experience","type":"topic","title":"Build a great Lock Screen camera capture experience","kind":"article","role":"sampleCode","abstract":[{"text":"Find out how the LockedCameraCapture API can help you bring your capture application’s most useful information directly to the Lock Screen. Examine the API’s features and functionality, learn how to get started creating a capture extension, and find out how that extension behaves when the device is locked.","type":"text"}]},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"type":"link","url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","title":"Learn More…","titleInlineContent":[{"type":"text","text":"Learn More…"}]},"https://developer.apple.com/wwdc24/10195":{"type":"download","url":"https:\/\/developer.apple.com\/wwdc24\/10195","identifier":"https:\/\/developer.apple.com\/wwdc24\/10195","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10070-Customize-feature-discovery-with-TipKit":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10070-customize-feature-discovery-with-tipkit","kind":"article","abstract":[{"type":"text","text":"Focused on feature discovery, the TipKit framework makes it easy to display tips in your app. Now you can group tips so features are discovered in the ideal order, make tips reusable with custom tip identifiers, match the look and feel to your app, and sync tips using CloudKit. Learn how you can use the latest advances in TipKit to help people discover everything your app has to offer."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10070-Customize-feature-discovery-with-TipKit","title":"Customize feature discovery with TipKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10093-Bring-your-iOS-or-iPadOS-game-to-visionOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10093-Bring-your-iOS-or-iPadOS-game-to-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10093-bring-your-ios-or-ipados-game-to-visionos","type":"topic","title":"Bring your iOS or iPadOS game to visionOS","kind":"article","role":"sampleCode","abstract":[{"text":"Discover how to transform your iOS or iPadOS game into a uniquely visionOS experience. Increase the immersion (and fun factor!) with a 3D frame or an immersive background. And invite players further into your world by adding depth to the window with stereoscopy or head tracking.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10097-Unlock-the-power-of-places-with-MapKit":{"url":"\/documentation\/wwdcnotes\/wwdc24-10097-unlock-the-power-of-places-with-mapkit","abstract":[{"type":"text","text":"Discover powerful new ways to integrate maps into your apps and websites with MapKit and MapKit JS.  Learn how to save and reference unique places using Place ID. Check out improvements to search that make it more efficient to find relevant places.  Get introduced to the new Place Card API that lets you display rich information about places so customers can explore destinations right in your app. And, we’ll show you quick ways to embed maps in your website with our simplified token provisioning and Web Embed API."}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10097-Unlock-the-power-of-places-with-MapKit","role":"sampleCode","title":"Unlock the power of places with MapKit","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10104-Build-a-spatial-drawing-app-with-RealityKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10104-Build-a-spatial-drawing-app-with-RealityKit","url":"\/documentation\/wwdcnotes\/wwdc24-10104-build-a-spatial-drawing-app-with-realitykit","type":"topic","title":"Build a spatial drawing app with RealityKit","kind":"article","role":"sampleCode","abstract":[{"text":"Harness the power of RealityKit through the process of building a spatial drawing app. As you create an eye-catching spatial experience that integrates RealityKit with ARKit and SwiftUI, you’ll explore how resources work in RealityKit and how to use features like low-level mesh and texture APIs to achieve fast updates of the users’ brush strokes.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10197-Go-small-with-Embedded-Swift":{"type":"topic","role":"sampleCode","abstract":[{"type":"text","text":"Embedded Swift brings the safety and expressivity of Swift to constrained environments. Explore how Embedded Swift runs on a variety of microcontrollers through a demonstration using an off-the-shelf Matter device. Learn how the Embedded Swift subset packs the benefits of Swift into a tiny footprint with no runtime, and discover plenty of resources to start your own Embedded Swift adventure."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10197-go-small-with-embedded-swift","kind":"article","title":"Go small with Embedded Swift","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10197-Go-small-with-Embedded-Swift"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10122-Use-CloudKit-Console-to-monitor-and-optimize-database-activity":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10122-Use-CloudKit-Console-to-monitor-and-optimize-database-activity","url":"\/documentation\/wwdcnotes\/wwdc24-10122-use-cloudkit-console-to-monitor-and-optimize-database-activity","type":"topic","title":"Use CloudKit Console to monitor and optimize database activity","kind":"article","role":"sampleCode","abstract":[{"text":"Discover the new observability features in CloudKit Console. Learn how to use Telemetry and Logging to troubleshoot and optimize your app. Find out how to set up alerts to monitor your application’s behavior and notifications to stay on top of the container events that are most important to you.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10062-Explore-App-Store-server-APIs-for-InApp-Purchase":{"role":"sampleCode","kind":"article","abstract":[{"text":"Learn how to leverage your server to build great In-App Purchase experiences with the latest updates to the App Store Server API, App Store Server Notifications, and the open source App Store Server Library. After a recap of current APIs, we’ll introduce updated endpoint functionality, new transaction fields, and a new notification type. We’ll also discuss best practices for the purchase lifecycle, delivering content, and targeting offers, so you can become a server power user.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10062-Explore-App-Store-server-APIs-for-InApp-Purchase","type":"topic","title":"Explore App Store server APIs for In-App Purchase","url":"\/documentation\/wwdcnotes\/wwdc24-10062-explore-app-store-server-apis-for-inapp-purchase"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10073-Catch-up-on-accessibility-in-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10073-Catch-up-on-accessibility-in-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc24-10073-catch-up-on-accessibility-in-swiftui","type":"topic","title":"Catch up on accessibility in SwiftUI","kind":"article","role":"sampleCode","abstract":[{"text":"SwiftUI makes it easy to build amazing experiences that are accessible to everyone. We’ll discover how assistive technologies understand and navigate your app through the rich accessibility elements provided by SwiftUI. We’ll also discuss how you can further customize these experiences by providing more information about your app’s content and interactions by using accessibility modifiers.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10173-Analyze-heap-memory":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10173-Analyze-heap-memory","url":"\/documentation\/wwdcnotes\/wwdc24-10173-analyze-heap-memory","type":"topic","title":"Analyze heap memory","kind":"article","role":"sampleCode","abstract":[{"text":"Dive into the basis for your app’s dynamic memory: the heap! Explore how to use Instruments and Xcode to measure, analyze, and fix common heap issues. We’ll also cover some techniques and best practices for diagnosing transient growth, persistent growth, and leaks in your app.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10177-Use-HDR-for-dynamic-image-experiences-in-your-app":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10177-Use-HDR-for-dynamic-image-experiences-in-your-app","url":"\/documentation\/wwdcnotes\/wwdc24-10177-use-hdr-for-dynamic-image-experiences-in-your-app","type":"topic","title":"Use HDR for dynamic image experiences in your app","kind":"article","role":"sampleCode","abstract":[{"text":"Discover how to read and write HDR images and process HDR content in your app. Explore the new supported HDR image formats and advanced methods for displaying HDR images. Find out how HDR content can coexist with your user interface — and what to watch out for when adding HDR image support to your app.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10216-Explore-the-Swift-on-Server-ecosystem":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10216-explore-the-swift-on-server-ecosystem","title":"Explore the Swift on Server ecosystem","abstract":[{"type":"text","text":"Swift is a great language for writing your server applications, and powers critical services across Apple’s cloud products. We’ll explore tooling, delve into the Swift server package ecosystem, and demonstrate how to interact with databases and add observability to applications."}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10216-Explore-the-Swift-on-Server-ecosystem","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10086-Design-great-visionOS-apps":{"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10086-Design-great-visionOS-apps","title":"Design great visionOS apps","url":"\/documentation\/wwdcnotes\/wwdc24-10086-design-great-visionos-apps","kind":"article","abstract":[{"type":"text","text":"Find out how to create compelling spatial computing apps by embracing immersion, designing for eyes and hands, and taking advantage of depth, scale, and space. We’ll share several examples of great visionOS apps and explore how their designers approached creating new experiences for the platform."}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10214-Squeeze-the-most-out-of-Apple-Pencil":{"abstract":[{"type":"text","text":"New in iOS 18, iPadOS 18, and visionOS 2, the PencilKit tool picker gains the ability to have completely custom tools, with custom attributes. Learn how to express your custom drawing experience in the tool picker using the same great tool picking experience available across the system. Discover how to access the new features of the Apple Pencil Pro, including roll angle, the squeeze gesture, and haptic feedback."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10214-Squeeze-the-most-out-of-Apple-Pencil","url":"\/documentation\/wwdcnotes\/wwdc24-10214-squeeze-the-most-out-of-apple-pencil","type":"topic","role":"sampleCode","title":"Squeeze the most out of Apple Pencil","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10168-Get-started-with-Writing-Tools":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10168-Get-started-with-Writing-Tools","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10168-get-started-with-writing-tools","kind":"article","abstract":[{"text":"Learn how Writing Tools help users proofread, rewrite, and transform text in your app. Get the details on how Writing Tools interact with your app so users can refine what they have written in any text view. Understand how text is retrieved and processed, and how to support Writing Tools in custom text views.","type":"text"}],"type":"topic","title":"Get started with Writing Tools"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10103-Discover-RealityKit-APIs-for-iOS-macOS-and-visionOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10103-Discover-RealityKit-APIs-for-iOS-macOS-and-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10103-discover-realitykit-apis-for-ios-macos-and-visionos","type":"topic","title":"Discover RealityKit APIs for iOS, macOS and visionOS","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how new cross-platform APIs in RealityKit can help you build immersive apps for iOS, macOS, and visionOS. Check out the new hover effects, lights and shadows, and portal crossing features, and view them in action through real examples.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10067-Bring-context-to-todays-weather":{"abstract":[{"type":"text","text":"Harness the power of WeatherKit to get detailed weather forecast data such as precipitation amounts by type, cloud cover by altitude, or maximum wind speed. Find out how you can summarize weather by different parts of the day and highlight significant upcoming changes to temperature or precipitation. Understand how you can compare current weather to the past through our Historical Comparisons dataset and dive into historical weather statistics for any location in the world. We’ll also explore how you can do all of this faster with our Swift and REST APIs."}],"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10067-bring-context-to-todays-weather","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10067-Bring-context-to-todays-weather","kind":"article","type":"topic","title":"Bring context to today’s weather"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10198-Run-Break-Inspect-Explore-effective-debugging-in-LLDB":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10198-Run-Break-Inspect-Explore-effective-debugging-in-LLDB","url":"\/documentation\/wwdcnotes\/wwdc24-10198-run-break-inspect-explore-effective-debugging-in-lldb","type":"topic","title":"Run, Break, Inspect: Explore effective debugging in LLDB","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how to use LLDB to explore and debug codebases. We’ll show you how to make the most of crashlogs and backtraces, and how to supercharge breakpoints with actions and complex stop conditions. We’ll also explore how the “p” command and the latest features in Swift 6 can enhance your debugging experience.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"title":"WWDC Notes","type":"topic","url":"\/documentation\/wwdcnotes","kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}],"role":"collection"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10200-Extend-your-Xcode-Cloud-workflows":{"abstract":[{"type":"text","text":"Discover how Xcode Cloud can adapt to your development needs. We’ll show you how to streamline your workflows, automate testing and distribution with start conditions, custom aliases, custom scripts, webhooks, and the App Store Connect API."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10200-extend-your-xcode-cloud-workflows","kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10200-Extend-your-Xcode-Cloud-workflows","title":"Extend your Xcode Cloud workflows"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10114-Enhance-ad-experiences-with-HLS-interstitials":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10114-Enhance-ad-experiences-with-HLS-interstitials","abstract":[{"text":"Explore how HLS Interstitials can help you seamlessly insert advertisements into your HLS content. We’ll also show you how to use integrated timeline to tune your UI experience and build SharePlay for interstitials.","type":"text"}],"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10114-enhance-ad-experiences-with-hls-interstitials","title":"Enhance ad experiences with HLS interstitials","type":"topic","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10089-Port-advanced-games-to-Apple-platforms":{"url":"\/documentation\/wwdcnotes\/wwdc24-10089-port-advanced-games-to-apple-platforms","abstract":[{"type":"text","text":"Discover how simple it can be to reach players on Apple platforms worldwide. We’ll show you how to evaluate your Windows executable on Apple silicon, start your game port with code samples, convert your shader code to Metal, and bring your game to Mac, iPhone, and iPad. Explore enhanced Metal tools that understand HLSL shaders to validate, debug, and profile your ported shaders on Metal."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10089-Port-advanced-games-to-Apple-platforms","kind":"article","role":"sampleCode","title":"Port advanced games to Apple platforms"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10087-Create-custom-environments-for-your-immersive-apps-in-visionOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10087-Create-custom-environments-for-your-immersive-apps-in-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10087-create-custom-environments-for-your-immersive-apps-in-visionos","type":"topic","title":"Create custom environments for your immersive apps in visionOS","kind":"article","role":"sampleCode","abstract":[{"text":"Discover how to create visually rich and performant customized app environments for Apple Vision Pro. Learn design guidelines, get expert recommendations, and explore techniques you can use in any digital content creation tool to begin building your immersive environment.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10100-Create-enhanced-spatial-computing-experiences-with-ARKit":{"abstract":[{"type":"text","text":"Learn how to create captivating immersive experiences with ARKit’s latest features. Explore ways to use room tracking and object tracking to further engage with your surroundings. We’ll also share how your app can react to changes in your environment’s lighting on this platform. Discover improvements in hand tracking and plane detection which can make your spatial experiences more intuitive."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10100-create-enhanced-spatial-computing-experiences-with-arkit","kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10100-Create-enhanced-spatial-computing-experiences-with-ARKit","title":"Create enhanced spatial computing experiences with ARKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-111801-Enhance-your-spatial-computing-app-with-RealityKit-audio":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-111801-Enhance-your-spatial-computing-app-with-RealityKit-audio","type":"topic","abstract":[{"text":"Elevate your spatial computing experience using RealityKit audio. Discover how spatial audio can make your 3D immersive experiences come to life. From ambient audio, reverb, to real-time procedural audio that can add character to your 3D content, learn how RealityKit audio APIs can help make your app more engaging.","type":"text"}],"title":"Enhance your spatial computing app with RealityKit audio","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-111801-enhance-your-spatial-computing-app-with-realitykit-audio"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10172-Break-into-the-RealityKit-debugger":{"abstract":[{"type":"text","text":"Meet the RealityKit debugger and discover how this new tool lets you inspect the entity hierarchy of spatial apps, debug rogue transformations, find missing entities, and detect which parts of your code are causing problems for your systems."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10172-break-into-the-realitykit-debugger","kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10172-Break-into-the-RealityKit-debugger","title":"Break into the RealityKit debugger"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10112-Say-hello-to-the-next-generation-of-CarPlay-design-system":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10112-Say-hello-to-the-next-generation-of-CarPlay-design-system","url":"\/documentation\/wwdcnotes\/wwdc24-10112-say-hello-to-the-next-generation-of-carplay-design-system","type":"topic","title":"Say hello to the next generation of CarPlay design system","kind":"article","role":"sampleCode","abstract":[{"text":"Explore the design system at the heart of the next generation of CarPlay that allows each automaker to express your vehicle’s character and brand. Learn how gauges, layouts, dynamic content, and more are deeply customizable and adaptable, allowing you to express your own design philosophy and create an iconic, tailored look. This session is intended for automakers, system developers, and anyone designing a system that supports the next generation of CarPlay.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10159-Bring-your-machine-learning-and-AI-models-to-Apple-silicon":{"abstract":[{"type":"text","text":"Learn how to optimize your machine learning and AI models to leverage the power of Apple silicon. Review model conversion workflows to prepare your models for on-device deployment. Understand model compression techniques that are compatible with Apple silicon, and at what stages in your model deployment workflow you can apply them. We’ll also explore the tradeoffs between storage size, latency, power usage and accuracy."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10159-bring-your-machine-learning-and-ai-models-to-apple-silicon","kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10159-Bring-your-machine-learning-and-AI-models-to-Apple-silicon","title":"Bring your machine learning and AI models to Apple silicon"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10153-Dive-deep-into-volumes-and-immersive-spaces":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10153-Dive-deep-into-volumes-and-immersive-spaces","url":"\/documentation\/wwdcnotes\/wwdc24-10153-dive-deep-into-volumes-and-immersive-spaces","type":"topic","title":"Dive deep into volumes and immersive spaces","kind":"article","role":"sampleCode","abstract":[{"text":"Discover powerful new ways to customize volumes and immersive spaces in visionOS. Learn to fine-tune how volumes resize and respond to people moving around them. Make volumes and immersive spaces interact through the power of coordinate conversions. Find out how to make your app react when people adjust immersion with the Digital Crown, and use a surrounding effect to dynamically customize the passthrough tint in your immersive space experience.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24":{"url":"\/documentation\/wwdcnotes\/wwdc24","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"abstract":[{"text":"Xcode 16, Swift 6, iOS 18, macOS 15, tvOS 18, visionOS 2, watchOS 11.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: Swift Testing, ","type":"text"},{"type":"codeVoice","code":"FinanceKit"},{"text":", ","type":"text"},{"type":"codeVoice","code":"TabletopKit"},{"type":"text","text":", and more."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24","kind":"article","type":"topic","role":"collectionGroup","title":"WWDC24"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10160-Train-your-machine-learning-and-AI-models-on-Apple-GPUs":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10160-Train-your-machine-learning-and-AI-models-on-Apple-GPUs","url":"\/documentation\/wwdcnotes\/wwdc24-10160-train-your-machine-learning-and-ai-models-on-apple-gpus","type":"topic","title":"Train your machine learning and AI models on Apple GPUs","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how to train your models on Apple Silicon with Metal for PyTorch, JAX and TensorFlow. Take advantage of new attention operations and quantization support for improved transformer model performance on your devices.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10125-Streamline-signin-with-passkey-upgrades-and-credential-managers":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10125-Streamline-signin-with-passkey-upgrades-and-credential-managers","url":"\/documentation\/wwdcnotes\/wwdc24-10125-streamline-signin-with-passkey-upgrades-and-credential-managers","type":"topic","title":"Streamline sign-in with passkey upgrades and credential managers","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how to automatically upgrade existing, password-based accounts to use passkeys. We’ll share why and how to improve account security and ease of sign-in, information about new features available for credential manager apps, and how to make your app information shine in the new Passwords app.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10169-Migrate-your-app-to-Swift-6":{"title":"Migrate your app to Swift 6","url":"\/documentation\/wwdcnotes\/wwdc24-10169-migrate-your-app-to-swift-6","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10169-Migrate-your-app-to-Swift-6","abstract":[{"type":"text","text":"Experience Swift 6 migration in action as we update an existing sample app. Learn how to migrate incrementally, module by module, and how the compiler helps you identify code that’s at risk of data races.  Discover different techniques for ensuring clear isolation boundaries and eliminating concurrent access to shared mutable state."}],"role":"sampleCode","kind":"article","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10161-Deploy-machine-learning-and-AI-models-ondevice-with-Core-ML":{"title":"Deploy machine learning and AI models on-device with Core ML","abstract":[{"type":"text","text":"Learn new ways to optimize speed and memory performance when you convert and run machine learning and AI models through Core ML. We’ll cover new options for model representations, performance insights, execution, and model stitching which can be used together to create compelling and private on-device experiences."}],"kind":"article","role":"sampleCode","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10161-deploy-machine-learning-and-ai-models-ondevice-with-core-ml","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10161-Deploy-machine-learning-and-AI-models-ondevice-with-Core-ML"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC21-10132-Meet-asyncawait-in-Swift":{"kind":"article","title":"Meet async\/await in Swift","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC21-10132-Meet-asyncawait-in-Swift","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc21-10132-meet-asyncawait-in-swift","abstract":[{"text":"Swift now supports asynchronous functions — a pattern commonly known as async\/await. Discover how the new syntax can make your code easier to read and understand. Learn what happens when a function suspends, and find out how to adapt existing completion handlers to asynchronous functions.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10166-Build-compelling-spatial-photo-and-video-experiences":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10166-build-compelling-spatial-photo-and-video-experiences","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how to adopt spatial photos and videos in your apps. Explore the different types of stereoscopic media and find out how to capture spatial videos in your iOS app on iPhone 15 Pro. Discover the various ways to detect and present spatial media, including the new QuickLook Preview Application API in visionOS. And take a deep dive into the metadata and stereo concepts that make a photo or video spatial.","type":"text"}],"title":"Build compelling spatial photo and video experiences","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10166-Build-compelling-spatial-photo-and-video-experiences"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10110-Implement-App-Store-Offers":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10110-Implement-App-Store-Offers","url":"\/documentation\/wwdcnotes\/wwdc24-10110-implement-app-store-offers","type":"topic","title":"Implement App Store Offers","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how to engage customers with App Store Offers using App Store Connect, as well as the latest StoreKit features and APIs. Discover how you can set up win-back offers (a new way to re-engage previous subscribers) and generate offer codes for Mac apps. And find out how to test offers in sandbox and Xcode to make sure they work smoothly.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10162-Keep-colors-consistent-across-captures":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10162-keep-colors-consistent-across-captures","title":"Keep colors consistent across captures","abstract":[{"text":"Meet the Constant Color API and find out how it can help people use your app to determine precise colors. You’ll learn how to adopt the API, explore its scientific and marketing potential, and discover best practices for making the most of the technology.","type":"text"}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10162-Keep-colors-consistent-across-captures","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10138-Create-a-custom-data-store-with-SwiftData":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10138-Create-a-custom-data-store-with-SwiftData","url":"\/documentation\/wwdcnotes\/wwdc24-10138-create-a-custom-data-store-with-swiftdata","type":"topic","title":"Create a custom data store with SwiftData","kind":"article","role":"sampleCode","abstract":[{"text":"Combine the power of SwiftData’s expressive, declarative modeling API with your own persistence backend. Learn how to build a custom data store and explore how to progressively add persistence features in your app. To get the most out of this session, watch “Meet SwiftData” and “Model your schema with SwiftData” from WWDC23.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10150-SwiftUI-essentials":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10150-SwiftUI-essentials","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10150-swiftui-essentials","kind":"article","abstract":[{"text":"Join us on a tour of SwiftUI, Apple’s declarative user interface framework. Learn essential concepts for building apps in SwiftUI, like views, state variables, and layout. Discover the breadth of APIs for building fully featured experiences and crafting unique custom components. Whether you’re brand new to SwiftUI or an experienced developer, you’ll learn how to take advantage of what SwiftUI has to offer when building great apps.","type":"text"}],"type":"topic","title":"SwiftUI essentials"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10210-Bring-your-apps-core-features-to-users-with-App-Intents":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10210-Bring-your-apps-core-features-to-users-with-App-Intents","url":"\/documentation\/wwdcnotes\/wwdc24-10210-bring-your-apps-core-features-to-users-with-app-intents","type":"topic","title":"Bring your app’s core features to users with App Intents","kind":"article","role":"sampleCode","abstract":[{"text":"Learn the principles of the App Intents framework, like intents, entities, and queries, and how you can harness them to expose your app’s most important functionality right where people need it most. Find out how to build deep integration between your app and the many system features built on top of App Intents, including Siri, controls and widgets, Apple Pencil, Shortcuts, the Action button, and more. Get tips on how to build your App Intents integrations efficiently to create the best experiences in every surface while still sharing code and core functionality.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10133-Bring-your-app-to-Siri":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10133-Bring-your-app-to-Siri","url":"\/documentation\/wwdcnotes\/wwdc24-10133-bring-your-app-to-siri","type":"topic","title":"Bring your app to Siri","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how to use App Intents to expose your app’s functionality to Siri. Understand which intents are already available for your use, and how to create custom intents to integrate actions from your app into the system. We’ll also cover what metadata to provide, making your entities searchable via Spotlight, annotating onscreen references, and much more.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10184-A-Swift-Tour-Explore-Swifts-features-and-design":{"abstract":[{"type":"text","text":"Learn the essential features and design philosophy of the Swift programming language. We’ll explore how to model data, handle errors, use protocols, write concurrent code, and more while building up a Swift package that has a library, an HTTP server, and a command line client. Whether you’re just beginning your Swift journey or have been with us from the start, this talk will help you get the most out of the language."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10184-a-swift-tour-explore-swifts-features-and-design","kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10184-A-Swift-Tour-Explore-Swifts-features-and-design","title":"A Swift Tour: Explore Swift’s features and design"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10223-Explore-machine-learning-on-Apple-platforms":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10223-Explore-machine-learning-on-Apple-platforms","url":"\/documentation\/wwdcnotes\/wwdc24-10223-explore-machine-learning-on-apple-platforms","type":"topic","title":"Explore machine learning on Apple platforms","kind":"article","role":"sampleCode","abstract":[{"text":"Get started with an overview of machine learning frameworks on Apple platforms. Whether you’re implementing your first ML model, or an ML expert, we’ll offer guidance to help you select the right framework for your app’s needs.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10113-Discover-media-performance-metrics-in-AVFoundation":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10113-discover-media-performance-metrics-in-avfoundation","title":"Discover media performance metrics in AVFoundation","abstract":[{"text":"Discover how you can monitor, analyze, and improve user experience with the new media performance APIs. Explore how to monitor AVPlayer performance for HLS assets using different AVMetricEvents, and learn how to use these metrics to understand and triage player performance issues.","type":"text"}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10113-Discover-media-performance-metrics-in-AVFoundation","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10115-Enhance-the-immersion-of-media-viewing-in-custom-environments":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10115-Enhance-the-immersion-of-media-viewing-in-custom-environments","url":"\/documentation\/wwdcnotes\/wwdc24-10115-enhance-the-immersion-of-media-viewing-in-custom-environments","type":"topic","title":"Enhance the immersion of media viewing in custom environments","kind":"article","role":"sampleCode","abstract":[{"text":"Extend your media viewing experience using Reality Composer Pro components like Docking Region, Reverb, and Virtual Environment Probe. Find out how to further enhance immersion using Reflections, Tint Surroundings Effect, SharePlay, and the Immersive Environment Picker.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10145-Enhance-your-UI-animations-and-transitions":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10145-Enhance-your-UI-animations-and-transitions","type":"topic","abstract":[{"text":"Explore how to adopt the zoom transition in navigation and presentations to increase the sense of continuity in your app, and learn how to animate UIKit views with SwiftUI animations to make it easier to build animations that feel continuous.","type":"text"}],"title":"Enhance your UI animations and transitions","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10145-enhance-your-ui-animations-and-transitions"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10171-Demystify-explicitly-built-modules":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10171-Demystify-explicitly-built-modules","type":"topic","abstract":[{"text":"Explore how builds are changing in Xcode 16 with explicitly built modules. Discover how modules are used to build your code, how explicitly built modules improve transparency in compilation tasks, and how you can optimize your build by sharing modules across targets.","type":"text"}],"title":"Demystify explicitly built modules","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10171-demystify-explicitly-built-modules"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10181-Xcode-essentials":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10181-xcode-essentials","title":"Xcode essentials","abstract":[{"text":"Edit, debug, commit, repeat. Explore the suite of tools in Xcode that help you iterate quickly when developing apps. Discover tips and tricks to help optimize and boost your development workflow.","type":"text"}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10181-Xcode-essentials","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10092-Render-Metal-with-passthrough-in-visionOS":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10092-render-metal-with-passthrough-in-visionos","title":"Render Metal with passthrough in visionOS","abstract":[{"text":"Get ready to extend your Metal experiences for visionOS. Learn best practices for integrating your rendered content with people’s physical environments with passthrough. Find out how to position rendered content to match the physical world, reduce latency with trackable anchor prediction, and more.","type":"text"}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10092-Render-Metal-with-passthrough-in-visionOS","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10065-Optimize-for-the-spatial-web":{"role":"sampleCode","kind":"article","type":"topic","title":"Optimize for the spatial web","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10065-Optimize-for-the-spatial-web","abstract":[{"text":"Discover how to make the most of visionOS capabilities on the web. Explore recent updates like improvements to selection highlighting, and the ability to present spatial photos and panorama images in fullscreen. Learn to take advantage of existing web standards for dictation and text-to-speech with WebSpeech, spatial soundscapes with WebAudio, and immersive experiences with WebXR.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc24-10065-optimize-for-the-spatial-web"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10066-Build-immersive-web-experiences-with-WebXR":{"abstract":[{"type":"text","text":"Discover how WebXR empowers you to add fully immersive experiences to your website in visionOS. Find out how to build WebXR experiences that take full advantage of the input capabilities of visionOS, and learn how you can use Simulator to test WebXR experiences on macOS."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10066-Build-immersive-web-experiences-with-WebXR","title":"Build immersive web experiences with WebXR","url":"\/documentation\/wwdcnotes\/wwdc24-10066-build-immersive-web-experiences-with-webxr","role":"sampleCode","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10217-Explore-Swift-performance":{"url":"\/documentation\/wwdcnotes\/wwdc24-10217-explore-swift-performance","abstract":[{"type":"text","text":"Discover how Swift balances abstraction and performance. Learn what elements of performance to consider and how the Swift optimizer affects them. Explore the different features of Swift and how they’re implemented to further understand the tradeoffs available that can impact performance."}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10217-Explore-Swift-performance","role":"sampleCode","title":"Explore Swift performance","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10179-Meet-Swift-Testing":{"url":"\/documentation\/wwdcnotes\/wwdc24-10179-meet-swift-testing","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10179-Meet-Swift-Testing","title":"Meet Swift Testing","abstract":[{"text":"Introducing Swift Testing: a new package for testing your code using Swift. Explore the building blocks of its powerful new API, discover how it can be applied in common testing workflows, and learn how it relates to XCTest and open source Swift.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10163-Discover-Swift-enhancements-in-the-Vision-framework":{"abstract":[{"type":"text","text":"The Vision Framework API has been redesigned to leverage modern Swift features like concurrency, making it easier and faster to integrate a wide array of Vision algorithms into your app. We’ll tour the updated API and share sample code, along with best practices, to help you get the benefits of this framework with less coding effort. We’ll also demonstrate two new features: image aesthetics and holistic body pose."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10163-discover-swift-enhancements-in-the-vision-framework","kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10163-Discover-Swift-enhancements-in-the-Vision-framework","title":"Discover Swift enhancements in the Vision framework"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10098-Design-Live-Activities-for-Apple-Watch":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10098-Design-Live-Activities-for-Apple-Watch","url":"\/documentation\/wwdcnotes\/wwdc24-10098-design-live-activities-for-apple-watch","type":"topic","title":"Design Live Activities for Apple Watch","kind":"article","role":"sampleCode","abstract":[{"text":"Starting in watchOS 11, Live Activities from your iOS app will automatically appear in the Smart Stack on a connected Apple Watch. Learn how to optimize the layout of your Live Activity for the wrist, and provide the right level of information and interactivity at the right time.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10083-Get-started-with-HealthKit-in-visionOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10083-Get-started-with-HealthKit-in-visionOS","abstract":[{"text":"Discover how to use HealthKit to create experiences that take full advantage of the spatial canvas. Learn the capabilities of HealthKit on the platform, find out how to bring an existing iPadOS app to visionOS, and explore the special considerations governing HealthKit during a Guest User session. You’ll also learn ways to use SwiftUI, Swift Charts, and Swift concurrency to craft innovative experiences with HealthKit.","type":"text"}],"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10083-get-started-with-healthkit-in-visionos","title":"Get started with HealthKit in visionOS","type":"topic","kind":"article"},"WWDCNotes.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/WWDCNotes.png"}],"type":"image","identifier":"WWDCNotes.png","alt":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10209-Enhanced-suggestions-for-your-journaling-app":{"url":"\/documentation\/wwdcnotes\/wwdc24-10209-enhanced-suggestions-for-your-journaling-app","abstract":[{"type":"text","text":"Find out how your journaling app can display journaling suggestions with richer content from the system. Explore new types of available content like state of mind data, reflection prompts, and support for third-party media content and motion-based activities."}],"kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10209-Enhanced-suggestions-for-your-journaling-app","role":"sampleCode","title":"Enhanced suggestions for your journaling app","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10109-Explore-wellbeing-APIs-in-HealthKit":{"url":"\/documentation\/wwdcnotes\/wwdc24-10109-explore-wellbeing-apis-in-healthkit","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10109-Explore-wellbeing-APIs-in-HealthKit","abstract":[{"type":"text","text":"Learn how to incorporate mental health and wellbeing into your app using HealthKit. There are new APIs for State of Mind, as well as for Depression Risk and Anxiety Risk. We’ll dive into principles of emotion science to cover how reflecting on feelings can be beneficial, and how State of Mind can be used to represent different types of mood and emotion."}],"role":"sampleCode","title":"Explore wellbeing APIs in HealthKit","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10075-Track-model-changes-with-SwiftData-history":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10075-Track-model-changes-with-SwiftData-history","url":"\/documentation\/wwdcnotes\/wwdc24-10075-track-model-changes-with-swiftdata-history","type":"topic","title":"Track model changes with SwiftData history","kind":"article","role":"sampleCode","abstract":[{"text":"Reveal the history of your model’s changes with SwiftData! Use the history API to understand when data store changes occurred, and learn how to use this information to build features like remote server sync and out-of-process change handing in your app. We’ll also cover how you can build support for the history API into a custom data store.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10132-Evolve-your-document-launch-experience":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10132-Evolve-your-document-launch-experience","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10132-evolve-your-document-launch-experience","kind":"article","abstract":[{"type":"text","text":"Make your document-based app stand out, and bring its unique identity into focus with the new document launch experience. Learn how to leverage the new API to customize the first screen people see when they launch your app. Utilize the new system-provided design, and amend it with custom actions, delightful decorative views, and impressive animations."}],"type":"topic","title":"Evolve your document launch experience"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10151-Create-custom-visual-effects-with-SwiftUI":{"type":"topic","title":"Create custom visual effects with SwiftUI","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10151-Create-custom-visual-effects-with-SwiftUI","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc24-10151-create-custom-visual-effects-with-swiftui","abstract":[{"text":"Discover how to create stunning visual effects in SwiftUI. Learn to build unique scroll effects, rich color treatments, and custom transitions. We’ll also explore advanced graphic effects using Metal shaders and custom text rendering.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10069-Broadcast-updates-to-your-Live-Activities":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc24-10069-broadcast-updates-to-your-live-activities","kind":"article","role":"sampleCode","abstract":[{"text":"With broadcast push notifications, your app can send updates to thousands of Live Activities with a single request. We’ll discover how broadcast push notifications work between an app, a server, and the Apple Push Notification service, then we’ll walk through best practices for this capability and how to implement it.","type":"text"}],"title":"Broadcast updates to your Live Activities","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10069-Broadcast-updates-to-your-Live-Activities"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10084-Build-custom-swimming-workouts-with-WorkoutKit":{"role":"sampleCode","kind":"article","type":"topic","title":"Build custom swimming workouts with WorkoutKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10084-Build-custom-swimming-workouts-with-WorkoutKit","abstract":[{"text":"Check out the latest in creating, customizing, and scheduling workouts using WorkoutKit. Sprint through the latest in pace and power alerts and expanded support for distance goals. And keep the momentum going with the benefits of custom step names.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc24-10084-build-custom-swimming-workouts-with-workoutkit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10147-Elevate-your-tab-and-sidebar-experience-in-iPadOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10147-Elevate-your-tab-and-sidebar-experience-in-iPadOS","url":"\/documentation\/wwdcnotes\/wwdc24-10147-elevate-your-tab-and-sidebar-experience-in-ipados","type":"topic","title":"Elevate your tab and sidebar experience in iPadOS","kind":"article","role":"sampleCode","abstract":[{"text":"iPadOS 18 introduces a new navigation system that gives people the flexibility to choose between using a tab bar or sidebar. The newly redesigned tab bar provides more space for content and other functionality. Learn how to use SwiftUI and UIKit to enable customization features – like adding, removing and reordering tabs – to enable a more personal touch in your app.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU":{"abstract":[{"type":"text","text":"Discover how you can use BNNSGraph to accelerate the execution of your machine learning model on the CPU. We will show you how to use BNNSGraph to compile and execute a machine learning model on the CPU and share how it provides real-time guarantees such as no runtime memory allocation and single-threaded running for audio or signal processing models."}],"url":"\/documentation\/wwdcnotes\/wwdc24-10211-support-realtime-ml-inference-on-the-cpu","kind":"article","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10211-Support-realtime-ML-inference-on-the-CPU","title":"Support real-time ML inference on the CPU"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10149-Work-with-windows-in-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10149-Work-with-windows-in-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc24-10149-work-with-windows-in-swiftui","type":"topic","title":"Work with windows in SwiftUI","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how to create great single and multi-window apps in visionOS, macOS, and iPadOS. Discover tools that let you programmatically open and close windows, adjust position and size, and even replace one window with another. We’ll also explore design principles for windows that help people use your app within their workflows.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10176-Design-App-Intents-for-system-experiences":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10176-Design-App-Intents-for-system-experiences","type":"topic","abstract":[{"text":"App Intents power system experiences in controls, Spotlight, Siri, and more. Find out how to identify the functionality that’s best for App Intents, and how to use parameters to make these intents flexible. Learn how to use App Intents to allow people to take action outside your app, and see examples of when to navigate into your app to show contextual information.","type":"text"}],"title":"Design App Intents for system experiences","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10176-design-app-intents-for-system-experiences"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10096-Design-interactive-experiences-for-visionOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10096-Design-interactive-experiences-for-visionOS","url":"\/documentation\/wwdcnotes\/wwdc24-10096-design-interactive-experiences-for-visionos","type":"topic","title":"Design interactive experiences for visionOS","kind":"article","role":"sampleCode","abstract":[{"text":"Learn how you can design a compelling interactive narrative experience for Apple Vision Pro from the designers of Encounter Dinosaurs. Discover how these types of experiences differ from existing apps, media, and games, and explore how to design narratives that bring audiences into new worlds. Find out how you can create stories that adapt to any space and size, provide multiple levels of interaction to make them accessible to all, and use animation, spatial audio, and custom gestures to further immerse people in your experience.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10186-Optimize-your-3D-assets-for-spatial-computing":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10186-optimize-your-3d-assets-for-spatial-computing","kind":"article","abstract":[{"type":"text","text":"Dive into an end-to-end workflow for optimized 3D asset creation. Discover best practices for optimizing meshes, materials, and textures in your digital content creation tool. Learn how to harness shader graph, baking, and material instances to enhance your 3D scene while optimizing performance. Take advantage of native tools to work more effectively with your assets and improve your app’s performance."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10186-Optimize-your-3D-assets-for-spatial-computing","title":"Optimize your 3D assets for spatial computing"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10218-Accelerate-machine-learning-with-Metal":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10218-Accelerate-machine-learning-with-Metal","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10218-accelerate-machine-learning-with-metal","kind":"article","abstract":[{"text":"Learn how to accelerate your machine learning transformer models with new features in Metal Performance Shaders Graph. We’ll also cover how to improve your model’s compute bandwidth and quality, and visualize it in the all new MPSGraph viewer.","type":"text"}],"type":"topic","title":"Accelerate machine learning with Metal"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC24-10102-Compose-interactive-3D-content-in-Reality-Composer-Pro":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC24-10102-Compose-interactive-3D-content-in-Reality-Composer-Pro","type":"topic","abstract":[{"text":"Discover how the Timeline view in Reality Composer Pro can bring your 3D content to life. Learn how to create an animated story in which characters and objects interact with each other and the world around them using inverse kinematics, blend shapes, and skeletal poses. We’ll also show you how to use built-in and custom actions, sequence your actions, apply triggers, and implement natural movements.","type":"text"}],"title":"Compose interactive 3D content in Reality Composer Pro","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc24-10102-compose-interactive-3d-content-in-reality-composer-pro"}}}