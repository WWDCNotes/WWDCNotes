{"primaryContentSections":[{"content":[{"level":2,"anchor":"overview","text":"Overview","type":"heading"},{"inlineContent":[{"type":"text","text":"SwiftUI animations are interruptible, physics-based, and integrated throughout the framework."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"First: A quick review of the animation tools in SwiftUI"}],"type":"paragraph"},{"level":3,"anchor":"Scale-Animation","text":"Scale Animation","type":"heading"},{"code":["struct Avatar: View {","    var petImage: Image","    @State private var selected: Bool = false","","    var body: some View {","        petImage","            .scaleEffect(selected ? 1.5 : 1.0)","            .onTapGesture {","                withAnimation {","                    selected.toggle()","                }","            }","    }","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"text","text":"Adding animation is as easy as using “withAnimation” or adding an “animation” modifier."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"After the state of the application changes, SwiftUI applies animations that interpolate from the previous state to the new state."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10157-first","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"But some animations don’t simply animate from a previous state into a new state."}],"type":"paragraph"},{"inlineContent":[{"text":"Rather than animating between two states, these animations can define multiple steps that happen in sequence.","type":"text"},{"text":" ","type":"text"},{"text":"Especially great in two situations:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"repeating animations, that loop continuously while a view is visible…"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"and with event-driven animations, such as a view that pulses when an event occurs."}],"type":"paragraph"}]}],"type":"unorderedList"},{"inlineContent":[{"type":"text","text":"There a new family of APIs that makes animations easier to build."}],"type":"paragraph"},{"inlineContent":[{"text":"In this session:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Animation phases, which let SwiftUI automatically advance through a set of pre-planned states that make up your animation.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Keyframes"}]}]},{"content":[{"inlineContent":[{"text":"Some tips and tricks to get the most out of this API.","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"},{"level":1,"anchor":"Animation-phases","text":"Animation phases","type":"heading"},{"inlineContent":[{"type":"text","text":"Ex with trail running."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Trail races can be very long. Ultramarathons can take a whole day, or even multiple days to finish, so he is showing an app to plan events."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-app"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Here, the reminder at the bottom of the screen is letting know that it is time for a meal. We want to give it an animated highlight effect to make it extra visible."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"To make this view animate, we can apply the "},{"type":"codeVoice","code":".phaseAnimator"},{"type":"text","text":" modifier."}],"type":"paragraph"},{"code":["OverdueReminderView()","        .phaseAnimator([false, true]) { content, phase in","            content","        } "],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"text","text":"Using the phase animator modifier, we need to provide a sequence of states that define the individual steps in a multipart animation. SwiftUI then animates between these states automatically."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"In this case, we’ll just be animating between two states: highlighted, and not highlighted, so we can simply use a boolean values."}],"type":"paragraph"},{"inlineContent":[{"text":"Next, we’ll apply an opacity modifier: This will make the view fully opaque when highlighted, and 50% transparent otherwise.","type":"text"}],"type":"paragraph"},{"code":["OverdueReminderView()","        .phaseAnimator([false, true]) { content, phase in","            content","                .opacity(phase ? 1.0 : 0.5)","        } "],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"identifier":"WWDC23-10157-phaseAnimator","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We provided two phases to the phase animator modifier: false, and true."}],"type":"paragraph"},{"inlineContent":[{"text":"When the view first appears, the first phase is active, causing the view to be 50% transparent. SwiftUI then immediately begins an animated transition to the next phase, where the view is fully opaque.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-phaseAnimator2"}],"type":"paragraph"},{"inlineContent":[{"text":"Then when that animation is finished, SwiftUI advances again.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-phaseAnimator3"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"There are only have two phases, so this causes the animation to cycle between the two states. Of course, we can also define animations that include more than two phases, and any number of additional view modifiers."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-phaseAnimator4"}],"type":"paragraph"},{"inlineContent":[{"text":"Now, instead of changing the opacity, this changes the foreground style, using red when highlighted, and otherwise the primary foreground style.","type":"text"}],"type":"paragraph"},{"code":["OverdueReminderView()","        .phaseAnimator([false, true]) { content, phase in","            content","                .foregroundStyle(phase ? .red : .primary)","        } "],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"text":"By default, SwiftUI uses a spring animation. And while springs are great for handling dynamic state changes, in this case we can change the animation by adding a trailing “animation” closure.","type":"text"}],"type":"paragraph"},{"code":["OverdueReminderView()","        .phaseAnimator([false, true]) { content, phase in","            content","                .foregroundStyle(value ? .red : .primary)","        } animation: { phase in","            .easeInOut(duration: 1.0)","        }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-phaseAnimator6"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"The phase that is being animated to is passed in, in case we want to use a different animation for each phase."}],"type":"paragraph"},{"level":1,"anchor":"Animations-that-are-triggered-by-events","text":"Animations that are triggered by events.","type":"heading"},{"inlineContent":[{"text":"Animating the emoji show reactions left by others.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-reactions"}],"type":"paragraph"},{"inlineContent":[{"text":"Unlike in the previous example that simply alternated between two states, we want a more complex animation. An enum is a great way to define a list of steps for the animation.","type":"text"}],"type":"paragraph"},{"code":["ReactionView()","","enum Phase: CaseIterable {","    case initial   ","    case move  ","    case scale  ","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"text","text":"Three cases:"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"for the initial appearance,"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"to move the view up,"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"and scale it up .","type":"text"}]}]}],"type":"unorderedList"},{"inlineContent":[{"type":"text","text":"To simplify the view body, we will add computed properties to this enum that define the different effects that we will apply. for instance a computed vertical offset property. We switch over the enum to return the right offset for each case."}],"type":"paragraph"},{"inlineContent":[{"text":"Likewise, there are two additional computed properties to determine the view’s scale and foreground style.","type":"text"}],"type":"paragraph"},{"code":["ReactionView()","","enum Phase: CaseIterable {","    case initial   ","    case move  ","    case scale  ","","    var verticalOffset: Double {","        switch self {","        case .initial: 0","        case .move, .scale: -64","        }","    }","","    var scale: Double {","        switch self {","        case .initial: 1.0","        case .move: 1.1","        case .scale: 1.8","        }","    }","    ","    var foregroundStyle: Color {","        switch self {","        case .initial: .white","        case .move, .scale: .red","        }","    }","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-reactionsPhases"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"We add the phaseAnimator modifier, but this time, we give it a “trigger” value which observes the value that we specify for changes. And when a change occurs, it begins animating through the phases."},{"type":"text","text":" "},{"type":"text","text":"Using the computed properties that we defined on the phase type, we apply modifiers to the view."}],"type":"paragraph"},{"code":["ReactionView()","    .phaseAnimator","        Phase.allCases, ","        trigger: reactionCount","    ) { content, phase in","        content","            .scaleEffect(phase.scale)","            .offset(y: phase.verticalOffset)","            .foregroundStyle(phase.foregroundStyle)","    } ","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"identifier":"WWDC23-10157-reactionsPhases2","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Customizing the animation for each transition to get the effect that we want…","type":"text"}],"type":"paragraph"},{"code":["ReactionView()","    .phaseAnimator","        Phase. allCases, ","        trigger: reactionCount","    ) { content, phase in","        content","            .scaleEffect(phase.scale)","            .offset(y: phase.verticalOffset)","            .foregroundStyle(phase.foregroundStyle)","    } animation: { phase in","        switch phase {","        case initial: .smooth","        case .move: .easeInOut(duration: 0.3)","        case .scale: .spring(","            duration: 0.3, bounce: 0.7)","        }","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"identifier":"WWDC23-10157-reactionsPhases3","type":"image"}],"type":"paragraph"},{"level":1,"anchor":"Keyframes","text":"Keyframes","type":"heading"},{"inlineContent":[{"text":"Keyframes provide complex, coordinated animations with complete control over timing and movement.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Keyframes are different from phases. Phases define discrete states that are provided to your view one at a time. And SwiftUI animates between those states, using the same animation types that we already know. When a state transition occurs, all of the properties are animated at the same time."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-keyframes"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"And then, when that animation is finished, SwiftUI animates to the next state."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-keyframes2"}],"type":"paragraph"},{"inlineContent":[{"text":"And this continues across all of the phases of the animation.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Keyframes allow us to animate each property independently, defining values at specific times within an animation."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"The dots here indicate keyframes: angles to use at each point during the animation."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-dots"}],"type":"paragraph"},{"inlineContent":[{"text":"When the animation plays back, SwiftUI interpolates values in between these keyframes, which we can then use to apply modifiers to the view.","type":"text"},{"text":"\n","type":"text"},{"text":"And keyframes allow to independently animate multiple effects at the same time by defining separate tracks, each with their own unique timing.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-keyframes3"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"In this example, keyframes are driving several other tracks, including vertical stretch, scale, and translation."}],"type":"paragraph"},{"inlineContent":[{"text":"Getting back to the code:","type":"text"}],"type":"paragraph"},{"code":["ReactionView()","","struct AnimationValues {","    var scale = 1.0","    var verticalStretch = 1.0","    var verticalTranslation = 0.0","    var angle = Angle.zero","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"identifier":"WWDC23-10157-keyframes4","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Keyframes can animate any value conforming to the “Animatable” protocol.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Unlike phases, keyframes generate interpolated values of the type that we specify."},{"type":"text","text":" "},{"type":"text","text":"While an animation is in progress, SwiftUI will provide us with a value of this type on every frame so that we can update the view."}],"type":"paragraph"},{"inlineContent":[{"text":"Next, we add the keyframeAnimator modifier.","type":"text"}],"type":"paragraph"},{"code":["ReactionView()","    .keyframeAnimator(","        initialValue: AnimationValues(), ","        trigger: reactionCount","    ) { content, value in","        content","    } keyframes: {_ in","       \/\/ ...","    }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"text","text":"This modifier is similar to the phase animator that we used earlier, but accepts keyframes."},{"type":"text","text":"\n"},{"type":"text","text":"We provide an instance of the struct to use as the initial value. The keyframes that we define will apply animations onto this value. Next, we’ll apply modifiers to the view for each of the properties on the struct."}],"type":"paragraph"},{"code":["ReactionView()","    .keyframeAnimator(","        initialValue: AnimationValues(), ","        trigger: reactionCount","    ) { content, value in","        content","            .rotationEffect(value.angle)","            .scaleEffect(value.scale)","            .scaleEffect(y: value.verticalStretch)","            .offset(y: value.verticalTranslation)","    } keyframes: {_ in","       \/\/ ...","    }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"text":"And finally, defining keyframes:","type":"text"}],"type":"paragraph"},{"code":["ReactionView()","    .keyframeAnimator(","        initialValue: AnimationValues(), ","        trigger: reactionCount","    ) { ... } keyframes: {_ in","        KeyframeTrack(\\.scale) {","            \/\/...","    }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"text":"Keyframes are organized into tracks. Each track controls a different property of the type that we are animating, which is specified by the key path that we provide when creating the track.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Here, We first add a linear keyframe, repeating the initial scale value and holding it for 0.36 seconds."}],"type":"paragraph"},{"code":["ReactionView()","    .keyframeAnimator(","        initialValue: AnimationValues(), ","        trigger: reactionCount","    ) { content, value in","        content","    } keyframes: {_ in","        KeyframeTrack(\\.scale) {","            Linearkeyframe(1.0, duration: 0.36)","    }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-keyframes5"}],"type":"paragraph"},{"inlineContent":[{"text":"Previews in Xcode can be a great way to fine-tune animations…","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Adding a “SpringKeyframe.”. This uses a spring function to pull the value toward the target."}],"type":"paragraph"},{"code":["ReactionView()","    .keyframeAnimator(","        initialValue: AnimationValues(), ","        trigger: reactionCount","    ) { content, value in","        content","    } keyframes: {_ in","        KeyframeTrack(\\.scale) {","            Linearkeyframe(1.0, duration: 0.36)","            SpringKeyframe(1.5, duration: 0.8,","                spring: bouncy)","    }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"text","text":"Then adding another spring keyframe that animates the scale back to 1.0."}],"type":"paragraph"},{"code":["ReactionView()","    .keyframeAnimator(","        initialValue: AnimationValues(), ","        trigger: reactionCount","    ) { content, value in","        content","    } keyframes: {_ in","        KeyframeTrack(\\.scale) {","            Linearkeyframe(1.0, duration: 0.36)","            SpringKeyframe(1.5, duration: 0.8,","                spring: bouncy)","            SpringKeyframe (1.0, spring: .bouncy)","    }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"identifier":"WWDC23-10157-keyframes6","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"There are actually four different types of keyframes."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-moreKeyframes"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"LinearKeyframe interpolates linearly in vector space from the previous keyframe.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"SpringKeyframe, as its name suggests, uses a spring function to interpolate to the target value from the previous keyframe.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"CubicKeyframe uses a cubic Bézier curve to interpolate between keyframes. Combiniung multiple cubic keyframes in sequence, the resulting curve is equivalent to a Catmull-Rom spline."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"MoveKeyframe immediately jumps to a value without interpolation."}]}]}],"type":"unorderedList"},{"inlineContent":[{"type":"text","text":"Each kind of keyframe supports customization and we can mix and match different kinds of keyframes within an animation."},{"type":"text","text":"\n"},{"type":"text","text":"SwiftUI maintains velocity between keyframes."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Using linear and spring keyframes to animate the vertical translation."}],"type":"paragraph"},{"code":["ReactionView()","    .keyframeAnimator(","        initialValue: AnimationValues(), ","        trigger: reactionCount","    ) { content, value in","        content","    } keyframes: {_ in","        KeyframeTrack(\\.scale) { \/\/... }","        ","        KeyframeTrack(\\.verticalTranslation) {","            LinearKeyframe(0.0, duration: 0.1)","            SpringKeyframe(20.0, duration: 0.15,","                spring: .bouncy)","            SpringKeyframe(-60.0, duration: 1.0,","                spring: .bouncy)","            SpringKeyframe(0.0, spring: .bouncy)","            }","    }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"identifier":"WWDC23-10157-moreKeyframes2","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Right before the view jumps up, it pulls back."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"This starts with vertical stretch, with a cubic keyframe."}],"type":"paragraph"},{"code":["ReactionView()","    .keyframeAnimator(","        initialValue: AnimationValues(), ","        trigger: reactionCount","    ) { content, value in","        content","    } keyframes: {_ in","        KeyframeTrack(\\.scale) { \/\/... }","        ","        KeyframeTrack(\\.verticalTranslation) { \/\/... }","        ","        KeyframeTrack(\\.verticalStretch) {","            CubicKeyframe(1.0, duration: 0.1)","            CubicKeyframe(0.6, duration: 0.15)","            CubicKeyframe(1.5, duration: 0.1)","            CubicKeyframe(1.05, duration: 0.15)","            CubicKeyframe(1.0, duration: 0.88)","            CubicKeyframe(0.8, duration: 0.1)","            CubicKeyframe(1.04, duration: 0.4)","            CubicKeyframe(1.0, duration: 0.22)","        } ","    }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-moreKeyframes3"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Finally, the rotation will be animated."}],"type":"paragraph"},{"code":["ReactionView()","    .keyframeAnimator(","        initialValue: AnimationValues(), ","        trigger: reactionCount","    ) { content, value in","        content","    } keyframes: {_ in","        KeyframeTrack(\\.scale) { \/\/... }","        ","        KeyframeTrack(\\.verticalTranslation) { \/\/... }","        ","        KeyframeTrack(\\.verticalStretch) { \/\/... }","            ","        KeyframeTrack(\\.angle) {","            CubicKeyframe(.zero, duration: 0.58)","            CubicKeyframe(.degrees(16), duration: 0.125)","            CubicKeyframe(.degrees(-16), duration: 0.125)","            CubicKeyframe(.degrees(16), duration: 0.125)","            CubicKeyframe(.zero, duration: 0.125)","            }","    }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"identifier":"WWDC23-10157-moreKeyframes4","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"And those curves? Those are a visualization of the animation","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10157-moreKeyframes5","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"Keyframes are like video clips that can be played. They give you a ton of control, but there’s a tradeoff. Keyframe animations can’t gracefully retarget the way that springs can, so it’s generally best to avoid changing keyframes mid-animation.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10157-remember","type":"image"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Updates happen on every frame, so we should avoid performing any expensive operations while applying a keyframe animation to the view."}],"type":"paragraph"},{"level":1,"anchor":"Tips-and-tricks","text":"Tips and tricks","type":"heading"},{"inlineContent":[{"type":"text","text":"The race map example, showing the route."},{"type":"text","text":"\n"},{"type":"text","text":"lets add an animation that automatically zooms in and follows the course. MapKit now allows to use keyframes to move the camera!"}],"type":"paragraph"},{"code":["struct RaceMap: View {","    let route: Route","    ","    var body: some View {","        Map(initialPosition: .rect(route.rect)) {","            MapPolyline (coordinates: route.coordinates)","                .stroke(.orange, lineWidth: 4.0)","            Marker(\"Start\", coordinate: route.start)","                .tint(.green)","            Marker (\"End\", coordinate: route.end)","                .tint (.red)","        }","    }","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"text","text":"Here, we use a “Map” view to show the course."},{"type":"text","text":"\n"},{"type":"text","text":"The view already has a route, which is a model that contains all of the coordinates along one leg of the race."},{"type":"text","text":"\n"},{"type":"text","text":"To build the tour, we’ll add a state property and a button to change it."}],"type":"paragraph"},{"code":["struct RaceMap: View {","    let route: Route","    ","    @State private var trigger = false","    ","    var body: some View {","        Map(initialPosition: .rect(route.rect)) {","            MapPolyline (coordinates: route.coordinates)","                .stroke(.orange, lineWidth: 4.0)","            Marker(\"Start\", coordinate: route.start)","                .tint(.green)","            Marker (\"End\", coordinate: route.end)","                .tint (.red)","        }","        .toolbar {","            Button(\"Tour\") { trigger.toggle() }","        }","    }","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"image","identifier":"WWDC23-10157-race"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"Lets use the new “mapCameraKeyframeAnimator” modifier, giving the trigger value to it, then adding keyframes."}],"type":"paragraph"},{"code":["struct RaceMap: View {","    let route: Route","    ","    @State private var trigger = false","    ","    var body: some View {","        Map(initialPosition: .rect(route.rect)) {...} ","            .toolbar {...}","            .mapCameraKeyframeAnimator(trigger: trigger) {","                KeyframeTrack(\\.centerCoordinate) {...}","                KeyframeTrack(\\.heading) {...}","                KeyframeTrack(\\.distance) {...}","        }","    }","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"text","text":"Every time the trigger value changes, maps will use these keyframes to animate."},{"type":"text","text":"\n"},{"type":"text","text":"The final value of the keyframes determines the camera value that is used at the end of the animation."}],"type":"paragraph"},{"inlineContent":[{"identifier":"WWDC23-10157-mapAnimation","type":"image"}],"type":"paragraph"},{"inlineContent":[{"text":"If the user performs a gesture while animating, the animation will be removed and the user will have full control over the camera.","type":"text"},{"text":"\n","type":"text"},{"text":"We can independently animate the center coordinate, heading, and distance.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"There is more. We’ve seen the “keyframeAnimator” modifier. Outside of the modifier, we can use the “KeyframeTimeline” type to capture a set of keyframes and tracks. We initialize this type with an initial value, and the keyframe tracks that define the animation, just like with the view modifier.","type":"text"}],"type":"paragraph"},{"code":["\/\/ Keyframes","let myKeyframes = KeyframeTimeline(initialValue: CGPoint.zero) {","    KeyframeTrack(\\.x) {...}","    KeyframeTrack(\\.y) {...}","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"text":"KeyframeTimeline provides API that gives the duration, which is equal to the duration of the longest track.","type":"text"}],"type":"paragraph"},{"code":["\/\/ Duration in seconds","let duration: TimeInterval = myKeyframes.duration"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"type":"text","text":"And we can calculate values for any time within the range of the animation."}],"type":"paragraph"},{"code":["\/\/ Value for time","let value = myKeyframes.value (time: 1.2)"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"text":"This makes it easy to visualize keyframes with Swift Charts, This also means that we can use keyframe-defined curves however you want, or to creatively combine keyframes with other APIs, for example, with a geometry proxy to scrub keyframe-driven effects using scroll position, or with a “TimelineView” to update based on time.","type":"text"}],"type":"paragraph"},{"level":1,"anchor":"Conclusion","text":"Conclusion","type":"heading"},{"inlineContent":[{"text":"Use keyframes for more complex animations where we need complete control.","type":"text"}],"type":"paragraph"},{"level":1,"anchor":"Check-out-also","text":"Check out also","type":"heading"},{"inlineContent":[{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10148","type":"reference","isActive":true},{"type":"text","text":""},{"type":"text","text":"\n"},{"identifier":"https:\/\/developer.apple.com\/wwdc23\/10156","type":"reference","isActive":true}],"type":"paragraph"},{"level":1,"anchor":"Some-of-the-code-examples-included-in-the-talk","text":"Some of the code examples included in the talk","type":"heading"},{"inlineContent":[{"type":"text","text":"Boolean Phases"}],"type":"paragraph"},{"code":["OverdueReminderView()","        .phaseAnimator([false, true]) { content, value in","            content","                .foregroundStyle(value ? .red : .primary)","        } animation: { _ in","            .easeInOut(duration: 1.0)","        }"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"text":"Custom Phases","type":"text"}],"type":"paragraph"},{"code":["ReactionView()","    .phaseAnimator(","        Phase.allCases, ","        trigger: reactionCount","    ) { content, phase in","        content","            .scaleEffect(phase.scale)","            .offset(y: phase.verticalOffset)","    } animation: { phase in","        switch phase {","        case .initial: .smooth","        case .move: .easeInOut(duration: 0.3)","        case .scale: .spring(","            duration: 0.3, bounce: 0.7)","        } ","    }","    ","enum Phase: CaseIterable {","    case initial","    case move","    case scale","","    var verticalOffset: Double {","        switch self {","        case .initial: 0","        case .move, .scale: -64","        }","    }","","    var scale: Double {","        switch self {","        case .initial: 1.0","        case .move: 1.1","        case .scale: 1.8","        }","    }","}"],"type":"codeListing","syntax":"swift"},{"code":["ReactionView()","    .keyframeAnimator(initialValue: AnimationValues()) { content, value in","        content","            .foregroundStyle(.red)","            .rotationEffect(value.angle)","            .scaleEffect(value.scale)","            .scaleEffect(y: value.verticalStretch)","            .offset(y: value.verticalTranslation)","        } keyframes: { _ in","            KeyframeTrack(\\.angle) {","                CubicKeyframe(.zero, duration: 0.58)","                CubicKeyframe(.degrees(16), duration: 0.125)","                CubicKeyframe(.degrees(-16), duration: 0.125)","                CubicKeyframe(.degrees(16), duration: 0.125)","                CubicKeyframe(.zero, duration: 0.125)","            }","","            KeyframeTrack(\\.verticalStretch) {","                CubicKeyframe(1.0, duration: 0.1)","                CubicKeyframe(0.6, duration: 0.15)","                CubicKeyframe(1.5, duration: 0.1)","                CubicKeyframe(1.05, duration: 0.15)","                CubicKeyframe(1.0, duration: 0.88)","                CubicKeyframe(0.8, duration: 0.1)","                CubicKeyframe(1.04, duration: 0.4)","                CubicKeyframe(1.0, duration: 0.22)","            }","            ","            KeyframeTrack(\\.scale) {","                LinearKeyframe(1.0, duration: 0.36)","                SpringKeyframe(1.5, duration: 0.8, spring: .bouncy)","                SpringKeyframe(1.0, spring: .bouncy)","            }","            KeyframeTrack(\\.verticalTranslation) {","                LinearKeyframe(0.0, duration: 0.1)","                SpringKeyframe(20.0, duration: 0.15, spring: .bouncy)","                SpringKeyframe(-60.0, duration: 1.0, spring: .bouncy)","                SpringKeyframe(0.0, spring: .bouncy)","            }","        }","","struct AnimationValues {","    var scale = 1.0","    var verticalStretch = 1.0","    var verticalTranslation = 0.0","    var angle = Angle.zero","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"text":"map keyframes","type":"text"}],"type":"paragraph"},{"code":["struct RaceMap: View {","    let route: Route","","    @State private var trigger = false","","    var body: some View {","        Map(initialPosition: .rect(route.rect)) {","            MapPolyline(coordinates: route.coordinates)","                .stroke(.orange, lineWidth: 4.0)","            Marker(\"Start\", coordinate: route.start)","                .tint(.green)","            Marker(\"End\", coordinate: route.end)","                .tint(.red)","        }","        .toolbar {","            Button(\"Tour\") { trigger.toggle() }","        }","        .mapCameraKeyframeAnimation(trigger: playTrigger) { initialCamera in","            KeyframeTrack(\\MapCamera.centerCoordinate) {","                let points = route.points","                for point in points {","                    CubicKeyframe(point.coordinate, duration: 16.0 \/ Double(points.count))","                }","                CubicKeyframe(initialCamera.centerCoordinate, duration: 4.0)","            }","            KeyframeTrack(\\.heading) {","                CubicKeyframe(heading(from: route.start.coordinate, to: route.end.coordinate), duration: 6.0)","                CubicKeyframe(heading(from: route.end.coordinate, to: route.end.coordinate), duration: 8.0)","                CubicKeyframe(initialCamera.heading, duration: 6.0)","            }","            KeyframeTrack(\\.distance) {","                CubicKeyframe(24000, duration: 4)","                CubicKeyframe(18000, duration: 12)","                CubicKeyframe(initialCamera.distance, duration: 4)","            }","        }","    }","}"],"type":"codeListing","syntax":"swift"},{"inlineContent":[{"text":"keyframe timeline","type":"text"}],"type":"paragraph"},{"code":["\/\/ Keyframes","let myKeyframes = KeyframeTimeline(initialValue: CGPoint.zero) {","    KeyframeTrack(\\.x) {...}","    KeyframeTrack(\\.y) {...}","}","","\/\/ Duration in seconds","let duration: TimeInterval = myKeyframes.duration","","\/\/ Value for time","let value = myKeyframes.value(time: 1.2)"],"type":"codeListing","syntax":"swift"},{"level":2,"anchor":"Written-By","text":"Written By","type":"heading"},{"numberOfColumns":5,"columns":[{"content":[{"type":"paragraph","inlineContent":[{"identifier":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4","type":"image"}]}],"size":1},{"content":[{"type":"heading","anchor":"laurent-b","text":"laurent b","level":3},{"inlineContent":[{"overridingTitleInlineContent":[{"type":"text","text":"Contributed Notes"}],"type":"reference","overridingTitle":"Contributed Notes","isActive":true,"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/github.com\/multitudes"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/laurentbrusa.hashnode.dev\/"},{"type":"text","text":" "},{"type":"text","text":"|"},{"type":"text","text":" "},{"type":"reference","isActive":true,"identifier":"https:\/\/x.com\/wrmultitudes"}],"type":"paragraph"}],"size":4}],"type":"row"},{"inlineContent":[{"type":"text","text":"Missing anything? Corrections? "},{"isActive":true,"type":"reference","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing"}],"type":"paragraph"},{"level":2,"anchor":"Related-Sessions","text":"Related Sessions","type":"heading"},{"style":"list","items":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10148-Whats-new-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10156-Explore-SwiftUI-animation"],"type":"links"},{"inlineContent":[{"inlineContent":[{"text":"Legal Notice","type":"text"}],"type":"strong"}],"type":"small"},{"inlineContent":[{"text":"All content copyright © 2012 – 2024 Apple Inc. All rights reserved.","type":"text"},{"text":" ","type":"text"},{"text":"Swift, the Swift logo, Swift Playgrounds, Xcode, Instruments, Cocoa Touch, Touch ID, FaceID, iPhone, iPad, Safari, Apple Vision, Apple Watch, App Store, iPadOS, watchOS, visionOS, tvOS, Mac, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries.","type":"text"},{"text":" ","type":"text"},{"text":"This website is not made by, affiliated with, nor endorsed by Apple.","type":"text"}],"type":"small"}],"kind":"content"}],"seeAlsoSections":[{"title":"Deep Dives into Topics","generated":true,"identifiers":["doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10239-Add-SharePlay-to-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10248-Analyze-hangs-with-Instruments","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10258-Animate-symbols-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10158-Animate-with-springs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10159-Beyond-scroll-views","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10170-Beyond-the-basics-of-structured-concurrency","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10028-Bring-widgets-to-life","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10027-Bring-widgets-to-new-places","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10093-Bring-your-Unity-VR-app-to-a-fully-immersive-space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10123-Bring-your-game-to-Mac-Part-1-Make-a-game-plan","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10124-Bring-your-game-to-Mac-Part-2-Compile-your-shaders","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10125-Bring-your-game-to-Mac-Part-3-Render-with-Metal","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10023-Build-a-multidevice-workout-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10036-Build-accessible-apps-with-SwiftUI-and-UIKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10154-Build-an-app-with-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10056-Build-better-documentbased-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10016-Build-custom-workouts-with-WorkoutKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10096-Build-great-games-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10252-Build-programmatic-UI-with-Xcode-Previews","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10006-Build-robust-and-resumable-file-transfers","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10087-Build-spatial-SharePlay-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10029-Build-widgets-for-the-Smart-Stack-on-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10051-Create-a-great-ShazamKit-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10070-Create-a-great-spatial-playback-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10105-Create-a-more-responsive-camera-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10034-Create-accessible-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10257-Create-animated-symbols","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10088-Create-immersive-Unity-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10278-Create-practical-workflows-in-Xcode-Cloud","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10244-Create-rich-documentation-with-SwiftDocC","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10007-Create-seamless-experiences-with-Virtualization","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10101-Customize-ondevice-speech-recognition","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10226-Debug-with-structured-logging","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10160-Demystify-SwiftUI-performance","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10263-Deploy-passkeys-at-work","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10193-Design-Shortcuts-for-Spotlight","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10138-Design-and-build-apps-for-watchOS-10","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10078-Design-considerations-for-vision-and-motion","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10073-Design-for-spatial-input","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10075-Design-spatial-SharePlay-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10309-Design-widgets-for-the-Smart-Stack-on-Apple-Watch","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10115-Design-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10052-Discover-Calendar-and-EventKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10256-Discover-Continuity-Camera-for-tvOS","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10089-Discover-Metal-for-immersive-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10149-Discover-Observation-in-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10085-Discover-Quick-Look-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10155-Discover-String-Catalogs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10180-Discover-streamlined-location-updates","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10196-Dive-deeper-into-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10254-Do-more-with-Managed-Apple-IDs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10107-Embed-the-Photos-Picker-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10094-Enhance-your-iPad-and-iPhone-apps-for-the-Shared-Space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10167-Expand-on-Swift-macros","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10275-Explore-AirPlay-with-interstitials","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10012-Explore-App-Store-Connect-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10156-Explore-SwiftUI-animation","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10103-Explore-enhancements-to-App-Intents","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10192-Explore-enhancements-to-RoomPlan","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10271-Explore-immersive-sound-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10122-Explore-media-formats-for-the-web","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10037-Explore-pie-charts-and-interactivity-in-Swift-Charts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10095-Explore-rendering-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10142-Explore-testing-inapp-purchases","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10175-Fix-failures-faster-with-Xcode-test-reports","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10168-Generalize-APIs-with-parameter-packs","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10060-Get-started-with-privacy-manifests","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10161-Inspectors-in-SwiftUI-Discover-the-details","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10104-Integrate-your-media-app-with-HomePod","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10281-Keep-up-with-the-keyboard","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10176-Lift-subjects-from-images-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10229-Make-features-discoverable-with-TipKit","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10189-Migrate-to-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10172-Mix-Swift-and-C++","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10195-Model-your-schema-with-SwiftData","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10127-Optimize-GPU-renderers-with-Metal","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10050-Optimize-machine-learning-for-Metal-apps","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10035-Perform-accessibility-audits-for-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10266-Protect-your-Mac-app-with-environment-constraints","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10250-Prototype-with-Xcode-Playgrounds","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10002-Ready-set-relay-Protect-app-traffic-with-network-relays","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10262-Rediscover-Safari-developer-features","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10004-Reduce-network-delays-with-L4S","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10241-Share-files-with-SharePlay","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10224-Simplify-distribution-in-Xcode-and-Xcode-Cloud","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10102-Spotlight-your-app-with-App-Shortcuts","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10137-Support-Cinematic-mode-videos-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10181-Support-HDR-images-in-your-app","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10188-Sync-to-iCloud-with-CKSyncEngine","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10162-The-SwiftUI-cookbook-for-focus","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10238-Tune-up-your-AirPlay-audio-experience","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10057-Unleash-the-UIKit-trait-system","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10153-Unlock-the-power-of-grammatical-agreement","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10185-Update-Live-Activities-with-push-notifications","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10031-Update-your-app-for-watchOS-10","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10061-Verify-app-dependencies-with-digital-signatures","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10058-Whats-new-with-text-and-text-interactions","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10166-Write-Swift-macros","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10128-Your-guide-to-Metal-ray-tracing"]}],"sections":[],"schemaVersion":{"minor":3,"patch":0,"major":0},"identifier":{"url":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10157-Wind-your-way-through-advanced-animations-in-SwiftUI","interfaceLanguage":"swift"},"variants":[{"paths":["\/documentation\/wwdcnotes\/wwdc23-10157-wind-your-way-through-advanced-animations-in-swiftui"],"traits":[{"interfaceLanguage":"swift"}]}],"abstract":[{"type":"text","text":"Discover how you can take animation to the next level with the latest updates to SwiftUI. Join us as we wind our way through animation and build out multiple steps, use keyframes to add coordinated multi-track animated effects, and combine APIs in unique ways to make your app spring to life."}],"kind":"article","hierarchy":{"paths":[["doc:\/\/WWDCNotes\/documentation\/WWDCNotes","doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23"]]},"sampleCodeDownload":{"action":{"isActive":true,"overridingTitle":"Watch Video (18 min)","identifier":"https:\/\/developer.apple.com\/wwdc23\/10157","type":"reference"},"kind":"sampleDownload"},"metadata":{"roleHeading":"WWDC23","title":"Wind your way through advanced animations in SwiftUI","role":"sampleCode","modules":[{"name":"WWDC Notes"}]},"references":{"WWDC23-10157-phaseAnimator3":{"type":"image","alt":"the “.phaseAnimator” modifier","identifier":"WWDC23-10157-phaseAnimator3","variants":[{"url":"\/images\/WWDC23-10157-phaseAnimator3.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision":{"url":"\/documentation\/wwdcnotes\/wwdc23-111241-explore-3d-body-pose-and-person-segmentation-in-vision","kind":"article","abstract":[{"text":"Discover how to build person-centric features with Vision. Learn how to detect human body poses and measure individual joint locations in 3D space. We’ll also show you how to take advantage of person segmentation APIs to distinguish and segment up to four individuals in an image.","type":"text"}],"title":"Explore 3D body pose and person segmentation in Vision","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-111241-Explore-3D-body-pose-and-person-segmentation-in-Vision","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10023-Build-a-multidevice-workout-app":{"abstract":[{"type":"text","text":"Learn how you can get iPhone involved in your Apple Watch-based workout apps with HealthKit. We’ll show you how to mirror workouts between devices and take a ride with cycling data types. Plus, get to know HealthKit for iPad."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10023-Build-a-multidevice-workout-app","title":"Build a multi-device workout app","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10023-build-a-multidevice-workout-app","type":"topic","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression":{"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10047-use-core-ml-tools-for-machine-learning-model-compression","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10047-Use-Core-ML-Tools-for-machine-learning-model-compression","title":"Use Core ML Tools for machine learning model compression","kind":"article","abstract":[{"text":"Discover how to reduce the footprint of machine learning models in your app with Core ML Tools. Learn how to use techniques like palettization, pruning, and quantization to dramatically reduce model size while still achieving great accuracy. Explore comparisons between compression during the training stages and on fully trained models, and learn how compressed models can run even faster when your app takes full advantage of the Apple Neural Engine.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes":{"kind":"symbol","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes","type":"topic","title":"WWDC Notes","role":"collection","abstract":[{"type":"text","text":"Session notes shared by the community for the community."}],"url":"\/documentation\/wwdcnotes","images":[{"type":"icon","identifier":"WWDCNotes.png"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction":{"url":"\/documentation\/wwdcnotes\/wwdc23-10049-improve-core-ml-integration-with-async-prediction","kind":"article","abstract":[{"type":"text","text":"Learn how to speed up machine learning features in your app with the latest Core ML execution engine improvements and find out how aggressive asset caching can help with inference and faster model loads. We’ll show you some of the latest options for async prediction and discuss considerations for balancing performance with overall memory usage to help you create a highly responsive app. Discover APIs to help you understand and maximize hardware utilization for your models."}],"title":"Improve Core ML integration with async prediction","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10049-Improve-Core-ML-integration-with-async-prediction","type":"topic"},"WWDC23-10157-app":{"type":"image","alt":"the app","identifier":"WWDC23-10157-app","variants":[{"url":"\/images\/WWDC23-10157-app.jpg","traits":["1x","light"]}]},"https://laurentbrusa.hashnode.dev/":{"type":"link","titleInlineContent":[{"text":"Blog","type":"text"}],"url":"https:\/\/laurentbrusa.hashnode.dev\/","identifier":"https:\/\/laurentbrusa.hashnode.dev\/","title":"Blog"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10148-Whats-new-in-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10148-Whats-new-in-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10148-whats-new-in-swiftui","kind":"article","title":"What’s new in SwiftUI","type":"topic","role":"sampleCode","abstract":[{"type":"text","text":"Learn how you can use SwiftUI to build great apps for all Apple platforms. Explore the latest updates to SwiftUI and discover new scene types for visionOS. Simplify your data models with the latest data flow options and learn about the Inspector view. We’ll also take you through enhanced animation APIs, powerful ScrollView improvements, and a host of refinements to help you make tidier tables, improve focus and keyboard input, and so much more."}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23":{"url":"\/documentation\/wwdcnotes\/wwdc23","images":[{"identifier":"WWDCNotes.png","type":"icon"}],"type":"topic","role":"collectionGroup","title":"WWDC23","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23","abstract":[{"text":"Xcode 15, Swift 5.9, iOS 17, macOS 14, tvOS 17, visionOS 1, watchOS 10.","type":"text"},{"text":" ","type":"text"},{"text":"New APIs: ","type":"text"},{"code":"SwiftData","type":"codeVoice"},{"text":", ","type":"text"},{"code":"Observation","type":"codeVoice"},{"text":", ","type":"text"},{"code":"StoreKit","type":"codeVoice"},{"text":" views, and more.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10175-Fix-failures-faster-with-Xcode-test-reports":{"abstract":[{"text":"Discover how you can find, debug, and fix test failures faster with the test report in Xcode and Xcode Cloud. Learn how Xcode identifies failure patterns to help you find the right place to start investigating. We’ll also show you how to use the UI automation explorer and video recordings to understand the events that led up to your UI test failure.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10175-Fix-failures-faster-with-Xcode-test-reports","type":"topic","kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10175-fix-failures-faster-with-xcode-test-reports","title":"Fix failures faster with Xcode test reports"},"https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing":{"type":"link","titleInlineContent":[{"text":"Contributions are welcome!","type":"text"}],"url":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","identifier":"https:\/\/wwdcnotes.github.io\/WWDCNotes\/documentation\/wwdcnotes\/contributing","title":"Contributions are welcome!"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10149-Discover-Observation-in-SwiftUI":{"url":"\/documentation\/wwdcnotes\/wwdc23-10149-discover-observation-in-swiftui","type":"topic","role":"sampleCode","title":"Discover Observation in SwiftUI","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10149-Discover-Observation-in-SwiftUI","abstract":[{"text":"Simplify your SwiftUI data models with Observation. We’ll share how the Observable macro can help you simplify models and improve your app’s performance. Get to know Observation, learn the fundamentals of the macro, and find out how to migrate from ObservableObject to Observable.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10248-Analyze-hangs-with-Instruments":{"kind":"article","role":"sampleCode","abstract":[{"type":"text","text":"User interface elements often mimic real-world interactions, including real-time responses. Apps with a noticeable delay in user interaction — a hang — can break that illusion and create frustration. We’ll show you how to use Instruments to analyze, understand, and fix hangs in your apps on all Apple platforms. Discover how you can efficiently navigate an Instruments trace document, interpret trace data, and record additional profiling data to better understand your specific hang."}],"type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10248-Analyze-hangs-with-Instruments","url":"\/documentation\/wwdcnotes\/wwdc23-10248-analyze-hangs-with-instruments","title":"Analyze hangs with Instruments"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10233-Enhance-your-apps-audio-experience-with-AirPods","url":"\/documentation\/wwdcnotes\/wwdc23-10233-enhance-your-apps-audio-experience-with-airpods","title":"Enhance your app’s audio experience with AirPods","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can create transformative audio experiences in your app using AirPods. Learn how to incorporate AirPods Automatic Switching, use AVAudioApplication to support Mute Control, and take advantage of Spatial Audio to create immersive soundscapes in your app or game.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10196-Dive-deeper-into-SwiftData":{"title":"Dive deeper into SwiftData","url":"\/documentation\/wwdcnotes\/wwdc23-10196-dive-deeper-into-swiftdata","type":"topic","role":"sampleCode","abstract":[{"text":"Learn how you can harness the power of SwiftData in your app. Find out how ModelContext and ModelContainer work together to persist your app’s data. We’ll show you how to track and make your changes manually and use SwiftData at scale with FetchDescriptor, SortDescriptor, and enumerate.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10196-Dive-deeper-into-SwiftData","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10170-Beyond-the-basics-of-structured-concurrency":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10170-Beyond-the-basics-of-structured-concurrency","url":"\/documentation\/wwdcnotes\/wwdc23-10170-beyond-the-basics-of-structured-concurrency","title":"Beyond the basics of structured concurrency","role":"sampleCode","kind":"article","abstract":[{"text":"It’s all about the task tree: Find out how structured concurrency can help your apps manage automatic task cancellation, task priority propagation, and useful task-local value patterns. Learn how to manage resources in your app with useful patterns and the latest task group APIs. We’ll show you how you can leverage the power of the task tree and task-local values to gain insight into distributed systems.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10002-Ready-set-relay-Protect-app-traffic-with-network-relays":{"type":"topic","abstract":[{"type":"text","text":"Learn how relays can make your app’s network traffic more private and secure without the overhead of a VPN. We’ll show you how to integrate relay servers in your own app and explore how enterprise networks can use relays to securely access internal resources."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10002-Ready-set-relay-Protect-app-traffic-with-network-relays","url":"\/documentation\/wwdcnotes\/wwdc23-10002-ready-set-relay-protect-app-traffic-with-network-relays","role":"sampleCode","kind":"article","title":"Ready, set, relay: Protect app traffic with network relays"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10167-Expand-on-Swift-macros":{"url":"\/documentation\/wwdcnotes\/wwdc23-10167-expand-on-swift-macros","type":"topic","role":"sampleCode","title":"Expand on Swift macros","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10167-Expand-on-Swift-macros","abstract":[{"text":"Discover how Swift macros can help you reduce boilerplate in your codebase and adopt complex features more easily. Learn how macros can analyze code, emit rich compiler errors to guide developers towards correct usage, and generate new code that is automatically incorporated back into your project. We’ll also take you through important concepts like macro roles, compiler plugins, and syntax trees.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10111-Go-beyond-the-window-with-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10111-Go-beyond-the-window-with-SwiftUI","kind":"article","type":"topic","abstract":[{"text":"Get ready to launch into space — a new SwiftUI scene type that can help you make great immersive experiences for visionOS. We’ll show you how to create a new scene with ImmersiveSpace, place 3D content, and integrate RealityView. Explore how you can use the immersionStyle scene modifier to increase the level of immersion in an app and learn best practices for managing spaces, adding virtual hands with ARKit, adding support for SharePlay, and building an “out of this world” experience!","type":"text"}],"role":"sampleCode","title":"Go beyond the window with SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10111-go-beyond-the-window-with-swiftui"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10050-Optimize-machine-learning-for-Metal-apps":{"url":"\/documentation\/wwdcnotes\/wwdc23-10050-optimize-machine-learning-for-metal-apps","type":"topic","role":"sampleCode","title":"Optimize machine learning for Metal apps","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10050-Optimize-machine-learning-for-Metal-apps","abstract":[{"text":"Discover the latest enhancements to accelerated ML training in Metal. Find out about updates to PyTorch and TensorFlow, and learn about Metal acceleration for JAX. We’ll show you how MPS Graph can support faster ML inference when you use both the GPU and Apple Neural Engine, and share how the same API can rapidly integrate your Core ML and ONNX models.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10238-Tune-up-your-AirPlay-audio-experience":{"url":"\/documentation\/wwdcnotes\/wwdc23-10238-tune-up-your-airplay-audio-experience","abstract":[{"text":"Learn how you can upgrade your app’s AirPlay audio experience to be more robust and responsive. We’ll show you how to adopt enhanced audio buffering with AVQueuePlayer, explore alternatives when building a custom player in your app, and share best practices.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10238-Tune-up-your-AirPlay-audio-experience","type":"topic","title":"Tune up your AirPlay audio experience","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10244-Create-rich-documentation-with-SwiftDocC":{"url":"\/documentation\/wwdcnotes\/wwdc23-10244-create-rich-documentation-with-swiftdocc","type":"topic","role":"sampleCode","title":"Create rich documentation with Swift-DocC","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10244-Create-rich-documentation-with-SwiftDocC","abstract":[{"text":"Learn how you can take advantage of the latest features in Swift-DocC to create rich and detailed documentation for your app or framework. We’ll show you how to use the Xcode 15 Documentation Preview editor to efficiently iterate on your existing project’s documentation, and explore expanded authoring capabilities like grid-based layouts, video support, and custom themes.","type":"text"}],"kind":"article"},"https://developer.apple.com/wwdc23/10148":{"type":"link","titleInlineContent":[{"text":"What’s new in SwiftUI","type":"text"}],"url":"https:\/\/developer.apple.com\/wwdc23\/10148","identifier":"https:\/\/developer.apple.com\/wwdc23\/10148","title":"What’s new in SwiftUI"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10185-Update-Live-Activities-with-push-notifications":{"url":"\/documentation\/wwdcnotes\/wwdc23-10185-update-live-activities-with-push-notifications","kind":"article","abstract":[{"type":"text","text":"Discover how you can remotely update Live Activities in your app when you push content through Apple Push Notification service (APNs). We’ll show you how to configure your first Live Activity push locally so you can quickly iterate on your implementation. Learn best practices for determining your push priority and configuring alerting updates, and explore how to further improve your Live Activities with relevance score and stale date."}],"title":"Update Live Activities with push notifications","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10185-Update-Live-Activities-with-push-notifications","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10278-Create-practical-workflows-in-Xcode-Cloud":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10278-Create-practical-workflows-in-Xcode-Cloud","title":"Create practical workflows in Xcode Cloud","type":"topic","abstract":[{"type":"text","text":"Learn how Xcode Cloud can help teams of all shapes and sizes in their development process. We’ll share different ways to configure actions to help you create simple yet powerful workflows, and show you how to extend Xcode Cloud when you integrate with additional tools."}],"role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10278-create-practical-workflows-in-xcode-cloud","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing":{"title":"Optimize app power and performance for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-10100-optimize-app-power-and-performance-for-spatial-computing","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10100-Optimize-app-power-and-performance-for-spatial-computing","type":"topic","abstract":[{"type":"text","text":"Learn how you can create powerful apps and games for visionOS by optimizing for performance and efficiency. We’ll cover the unique power characteristics of the platform, explore building a performance plan, and share some of the tools and strategies to test and optimize your apps."}],"role":"sampleCode"},"WWDC23-10157-keyframes3":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-keyframes3","variants":[{"url":"\/images\/WWDC23-10157-keyframes3.jpg","traits":["1x","light"]}]},"https://avatars.githubusercontent.com/u/29355828?v=4":{"type":"image","alt":"Profile image of laurent b","identifier":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4","variants":[{"url":"https:\/\/avatars.githubusercontent.com\/u\/29355828?v=4","traits":["1x","light"]}]},"WWDC23-10157-race":{"type":"image","alt":"race","identifier":"WWDC23-10157-race","variants":[{"url":"\/images\/WWDC23-10157-race.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10103-Explore-enhancements-to-App-Intents":{"url":"\/documentation\/wwdcnotes\/wwdc23-10103-explore-enhancements-to-app-intents","kind":"article","abstract":[{"text":"Bring your widgets to life with App Intents! Explore the latest updates and learn how you can take advantage of dynamic options and user interactivity to build better experiences for your App Shortcuts. We’ll share how you can integrate with Apple Pay, structure your code more efficiently, and take your Shortcuts app integration to the next level.","type":"text"}],"title":"Explore enhancements to App Intents","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10103-Explore-enhancements-to-App-Intents","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10161-Inspectors-in-SwiftUI-Discover-the-details":{"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10161-inspectors-in-swiftui-discover-the-details","role":"sampleCode","title":"Inspectors in SwiftUI: Discover the details","abstract":[{"text":"Meet Inspectors — a structural API that can help bring a new level of detail to your apps. We’ll take you through the fundamentals of the API and show you how to adopt it. Learn about the latest updates to sheet presentation customizations and find out how you can combine the two to create perfect presentation experiences.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10161-Inspectors-in-SwiftUI-Discover-the-details"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10142-Explore-testing-inapp-purchases":{"title":"Explore testing in-app purchases","type":"topic","abstract":[{"text":"Learn how you can test in-app purchases throughout development with StoreKit Testing in Xcode, App Store sandbox, and TestFlight. Explore how each tool functions and how you can combine them to build the right workflow for testing your apps and games. We’ll also share a sneak preview of how you can test Family Sharing for in-app purchases & subscriptions in the App Store sandbox.","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10142-Explore-testing-inapp-purchases","url":"\/documentation\/wwdcnotes\/wwdc23-10142-explore-testing-inapp-purchases","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10158-Animate-with-springs":{"title":"Animate with springs","url":"\/documentation\/wwdcnotes\/wwdc23-10158-animate-with-springs","type":"topic","role":"sampleCode","abstract":[{"text":"Discover how you can bring life to your app with animation! We’ll show you how to create amazing animations when you take advantage of springs and help you learn how to use them in your app.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10158-Animate-with-springs","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10004-Reduce-network-delays-with-L4S":{"type":"topic","abstract":[{"type":"text","text":"Streaming video, multiplayer games, and other real-time experiences depend on responsive, low latency networking. Learn how Low Latency, Low Loss, Scalable throughput (L4S) can reduce network delays and improve the overall experience in your app. We’ll show you how to set up and test your app, network, and server with L4S."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10004-Reduce-network-delays-with-L4S","url":"\/documentation\/wwdcnotes\/wwdc23-10004-reduce-network-delays-with-l4s","role":"sampleCode","kind":"article","title":"Reduce network delays with L4S"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10088-Create-immersive-Unity-apps":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10088-Create-immersive-Unity-apps","url":"\/documentation\/wwdcnotes\/wwdc23-10088-create-immersive-unity-apps","title":"Create immersive Unity apps","role":"sampleCode","kind":"article","abstract":[{"text":"Explore how you can use Unity to create engaging and immersive experiences for visionOS. We’ll share how Unity integrates seamlessly with Apple frameworks, take you through the tools you can use to build natively for the platform, and show you how volume cameras can bring your existing scenes into visionOS windows, volumes, and spaces.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems":{"url":"\/documentation\/wwdcnotes\/wwdc23-10150-optimize-carplay-for-vehicle-systems","type":"topic","role":"sampleCode","title":"Optimize CarPlay for vehicle systems","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10150-Optimize-CarPlay-for-vehicle-systems","abstract":[{"text":"Discover how you can integrate CarPlay into modern vehicle systems. We’ll show you how to adjust CarPlay for any high-resolution display — regardless of configuration or size. Learn how you can use CarPlay-supplied metadata and video streams to show information on additional displays, and find out how advances in wireless connectivity, audio, and video encoding can help prepare your vehicle system for the next generation of CarPlay.","type":"text"}],"kind":"article"},"WWDC23-10157-phaseAnimator":{"type":"image","alt":"the “.phaseAnimator” modifier","identifier":"WWDC23-10157-phaseAnimator","variants":[{"url":"\/images\/WWDC23-10157-phaseAnimator.jpg","traits":["1x","light"]}]},"https://github.com/multitudes":{"type":"link","titleInlineContent":[{"text":"GitHub","type":"text"}],"url":"https:\/\/github.com\/multitudes","identifier":"https:\/\/github.com\/multitudes","title":"GitHub"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10031-Update-your-app-for-watchOS-10":{"title":"Update your app for watchOS 10","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10031-update-your-app-for-watchos-10","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10031-Update-your-app-for-watchOS-10","abstract":[{"text":"Join us as we update an Apple Watch app to take advantage of the latest features in watchOS 10. In this code-along, we’ll show you how to use the latest SwiftUI APIs to maximize glanceability and reorient app navigation around the Digital Crown.","type":"text"}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10155-Discover-String-Catalogs":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10155-Discover-String-Catalogs","url":"\/documentation\/wwdcnotes\/wwdc23-10155-discover-string-catalogs","title":"Discover String Catalogs","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how Xcode 15 makes it easy to localize your app by managing all of your strings in one place. We’ll show you how to extract, edit, export, and build strings in your project using String Catalogs. We’ll also share how you can adopt String Catalogs in existing projects at your own pace by choosing which files to migrate.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10271-Explore-immersive-sound-design":{"type":"topic","role":"sampleCode","kind":"article","title":"Explore immersive sound design","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10271-Explore-immersive-sound-design","abstract":[{"text":"Discover how you can use sound to enhance the experience of your visionOS apps and games. Learn how Apple designers select sounds and build soundscapes to create textural, immersive experiences. We’ll share how you can enrich basic interactions in your app with sound when you place audio cues spatially, vary repetitive sounds, and build moments of sonic delight into your app.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10271-explore-immersive-sound-design"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10239-Add-SharePlay-to-your-app":{"url":"\/documentation\/wwdcnotes\/wwdc23-10239-add-shareplay-to-your-app","type":"topic","role":"sampleCode","title":"Add SharePlay to your app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10239-Add-SharePlay-to-your-app","abstract":[{"text":"Discover how your app can take advantage of SharePlay to turn any activity into a shareable experience with friends! We’ll share the latest updates to SharePlay, explore the benefits of creating shared activities, dive into some exciting use cases, and take you through best practices to create engaging and fun moments of connection in your app.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10105-Create-a-more-responsive-camera-experience":{"url":"\/documentation\/wwdcnotes\/wwdc23-10105-create-a-more-responsive-camera-experience","abstract":[{"text":"Discover how AVCapture and PhotoKit can help you create more responsive and delightful apps. Learn about the camera capture process and find out how deferred photo processing can help create the best quality photo. We’ll show you how zero shutter lag uses time travel to capture the perfect action photo, dive into building a responsive capture pipeline, and share how you can adopt the Video Effects API to recognize pre-defined gestures that trigger real-time video effects.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10105-Create-a-more-responsive-camera-experience","type":"topic","title":"Create a more responsive camera experience","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10113-Take-SwiftUI-to-the-next-dimension":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10113-Take-SwiftUI-to-the-next-dimension","url":"\/documentation\/wwdcnotes\/wwdc23-10113-take-swiftui-to-the-next-dimension","title":"Take SwiftUI to the next dimension","role":"sampleCode","kind":"article","abstract":[{"text":"Get ready to add depth and dimension to your visionOS apps. Find out how to bring three-dimensional objects to your app using volumes, get to know the Model 3D API, and learn how to position and animate content. We’ll also show you how to use UI attachments in RealityView and support gestures in your content.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10089-Discover-Metal-for-immersive-apps":{"title":"Discover Metal for immersive apps","url":"\/documentation\/wwdcnotes\/wwdc23-10089-discover-metal-for-immersive-apps","type":"topic","role":"sampleCode","abstract":[{"text":"Find out how you can use Metal to render fully immersive experiences for visionOS. We’ll show you how to set up a rendering session on the platform and create a basic render loop, and share how you can make your experience interactive by incorporating spatial input.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10089-Discover-Metal-for-immersive-apps","kind":"article"},"WWDC23-10157-keyframes2":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-keyframes2","variants":[{"url":"\/images\/WWDC23-10157-keyframes2.jpg","traits":["1x","light"]}]},"WWDC23-10157-keyframes6":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-keyframes6","variants":[{"url":"\/images\/WWDC23-10157-keyframes6.jpg","traits":["1x","light"]}]},"WWDC23-10157-moreKeyframes":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-moreKeyframes","variants":[{"url":"\/images\/WWDC23-10157-moreKeyframes.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10093-Bring-your-Unity-VR-app-to-a-fully-immersive-space":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10093-Bring-your-Unity-VR-app-to-a-fully-immersive-space","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10093-bring-your-unity-vr-app-to-a-fully-immersive-space","abstract":[{"type":"text","text":"Discover how you can bring your existing Unity VR apps and games to visionOS. We’ll explore workflows that can help you get started and show you how to build for eyes and hands in your apps and games with the Unity Input System. Learn about Unity’s XR Interaction Toolkit, tips for foveated rendering, and best practices."}],"type":"topic","title":"Bring your Unity VR app to a fully immersive space"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10072-Principles-of-spatial-design":{"type":"topic","kind":"article","abstract":[{"text":"Discover the fundamentals of spatial design. Learn how to design with depth, scale, windows, and immersion, and apply best practices for creating comfortable, human-centered experiences that transform reality. Find out how you can use these spatial design principles to extend your existing app or bring a new idea to life.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10072-Principles-of-spatial-design","title":"Principles of spatial design","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10072-principles-of-spatial-design"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10034-Create-accessible-spatial-experiences":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10034-Create-accessible-spatial-experiences","url":"\/documentation\/wwdcnotes\/wwdc23-10034-create-accessible-spatial-experiences","title":"Create accessible spatial experiences","role":"sampleCode","kind":"article","abstract":[{"text":"Learn how you can make spatial computing apps that work well for everyone. Like all Apple platforms, visionOS is designed for accessibility: We’ll share how we’ve reimagined assistive technologies like VoiceOver and Pointer Control and designed features like Dwell Control to help people interact in the way that works best for them. Learn best practices for vision, motor, cognitive, and hearing accessibility and help everyone enjoy immersive experiences for visionOS.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10257-Create-animated-symbols":{"kind":"article","title":"Create animated symbols","url":"\/documentation\/wwdcnotes\/wwdc23-10257-create-animated-symbols","abstract":[{"type":"text","text":"Discover animation presets and learn how to use them with SF Symbols and custom symbols. We’ll show you how to experiment with different options and configurations to find the perfect animation for your app. Learn how to update custom symbols for animation using annotation features, find out how to modify your custom symbols with symbol components, and explore the redesigned export process to help keep symbols looking great on all platforms."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10257-Create-animated-symbols","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10107-Embed-the-Photos-Picker-in-your-app":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10107-Embed-the-Photos-Picker-in-your-app","url":"\/documentation\/wwdcnotes\/wwdc23-10107-embed-the-photos-picker-in-your-app","title":"Embed the Photos Picker in your app","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can simply, safely, and securely access the Photos Library in your app. Learn how to get started with the embedded picker and explore the options menu and HDR still image support. We’ll also show you how to take advantage of UI customization options to help the picker blend into your existing interface.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10016-Build-custom-workouts-with-WorkoutKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10016-Build-custom-workouts-with-WorkoutKit","kind":"article","type":"topic","abstract":[{"text":"WorkoutKit makes it easy to create, preview, and schedule planned workouts for the Workout app on Apple Watch. Learn how to build custom intervals, create alerts, and use the built-in preview UI to send your own workout routines to Apple Watch.","type":"text"}],"role":"sampleCode","title":"Build custom workouts with WorkoutKit","url":"\/documentation\/wwdcnotes\/wwdc23-10016-build-custom-workouts-with-workoutkit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10304-Integrate-with-motorized-iPhone-stands-using-DockKit","role":"sampleCode","kind":"article","title":"Integrate with motorized iPhone stands using DockKit","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10304-integrate-with-motorized-iphone-stands-using-dockkit","abstract":[{"text":"Discover how you can create incredible photo and video experiences in your camera app when integrating with DockKit-compatible motorized stands. We’ll show how your app can automatically track subjects in live video across a 360-degree field of view, take direct control of the stand to customize framing, directly control the motors, and provide your own inference model for tracking other objects. Finally, we’ll demonstrate how to create a sense of emotion through dynamic device animations.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10193-Design-Shortcuts-for-Spotlight":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10193-Design-Shortcuts-for-Spotlight","url":"\/documentation\/wwdcnotes\/wwdc23-10193-design-shortcuts-for-spotlight","title":"Design Shortcuts for Spotlight","role":"sampleCode","kind":"article","abstract":[{"text":"Learn about the latest updates to the visual language of App Shortcuts and find out how to design your shortcut to appear as a top hit in Spotlight. We’ll share how shortcuts can appear on iOS or iPadOS, and show you how to customize the visual appearance of a shortcut, personalize its order, select its correct behavior, and increase discoverability.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10027-Bring-widgets-to-new-places":{"url":"\/documentation\/wwdcnotes\/wwdc23-10027-bring-widgets-to-new-places","type":"topic","role":"sampleCode","title":"Bring widgets to new places","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10027-Bring-widgets-to-new-places","abstract":[{"text":"The widget ecosystem is expanding: Discover how you can use the latest WidgetKit APIs to make your widget look great everywhere. We’ll show you how to identify your widget’s background, adjust layout dynamically, and prepare colors for vibrant rendering so that your widget can sit seamlessly in any environment.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10058-Whats-new-with-text-and-text-interactions":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10058-Whats-new-with-text-and-text-interactions","url":"\/documentation\/wwdcnotes\/wwdc23-10058-whats-new-with-text-and-text-interactions","title":"What’s new with text and text interactions","type":"topic","kind":"article","role":"sampleCode","abstract":[{"text":"Text is an absolutely critical component of every app. Discover the latest features and enhancements for creating rich text experiences on Apple platforms. We’ll show you how to take advantage of common text elements and create entirely custom interactions for your app. Learn about updates to dictation, text loupe, and text selection, and explore improvements to text clipping, line wrapping, and hyphenation.","type":"text"}]},"WWDC23-10157-phaseAnimator2":{"type":"image","alt":"the “.phaseAnimator” modifier","identifier":"WWDC23-10157-phaseAnimator2","variants":[{"url":"\/images\/WWDC23-10157-phaseAnimator2.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10166-Write-Swift-macros":{"kind":"article","abstract":[{"text":"Discover how you can use Swift macros to make your codebase more expressive and easier to read. Code along as we explore how macros can help you avoid writing repetitive code and find out how to use them in your app. We’ll share the building blocks of a macro, show you how to test it, and take you through how you can emit compilation errors from macros.","type":"text"}],"title":"Write Swift macros","type":"topic","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10166-write-swift-macros","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10166-Write-Swift-macros"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10181-Support-HDR-images-in-your-app":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10181-Support-HDR-images-in-your-app","url":"\/documentation\/wwdcnotes\/wwdc23-10181-support-hdr-images-in-your-app","abstract":[{"type":"text","text":"Learn how to identify, load, display, and create High Dynamic Range (HDR) still images in your app. Explore common HDR concepts and find out about the latest updates to the ISO specification. Learn how to identify and display HDR images with SwiftUI and UIKit, create them from ProRAW and RAW captures, and display them in CALayers. We’ll also take you through CoreGraphics support for ISO HDR and share best practices for HDR adoption."}],"kind":"article","type":"topic","title":"Support HDR images in your app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10162-The-SwiftUI-cookbook-for-focus":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10162-The-SwiftUI-cookbook-for-focus","abstract":[{"type":"text","text":"The SwiftUI team is back in the coding “kitchen” with powerful tools to shape your app’s focus experience. Join us and learn about the staple ingredients that support focus-driven interactions in your app. Discover focus interactions for custom views, find out about key-press handlers for keyboard input, and learn how to support movement and hierarchy with focus sections. We’ll also go through some tasty recipes for common focus patterns in your app."}],"kind":"article","type":"topic","title":"The SwiftUI cookbook for focus","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10162-the-swiftui-cookbook-for-focus"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10224-Simplify-distribution-in-Xcode-and-Xcode-Cloud":{"type":"topic","role":"sampleCode","kind":"article","title":"Simplify distribution in Xcode and Xcode Cloud","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10224-Simplify-distribution-in-Xcode-and-Xcode-Cloud","abstract":[{"text":"Discover how to share your app using Xcode’s streamlined distribution, which allows you to submit your app to TestFlight or the App Store with one click. We’ll also show you how to use Xcode Cloud to simplify your distribution process by automatically including notes for testers in TestFlight, and use post-action to automatically notarize your Mac apps.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10224-simplify-distribution-in-xcode-and-xcode-cloud"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10115-Design-with-SwiftUI":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10115-Design-with-SwiftUI","url":"\/documentation\/wwdcnotes\/wwdc23-10115-design-with-swiftui","title":"Design with SwiftUI","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how SwiftUI can help you quickly iterate and explore design ideas. Learn from Apple designers as they share how working with SwiftUI influenced the design of the Maps app in watchOS 10 and other elements of their work, and find out how you can incorporate these workflows in your own process.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10153-Unlock-the-power-of-grammatical-agreement":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10153-Unlock-the-power-of-grammatical-agreement","url":"\/documentation\/wwdcnotes\/wwdc23-10153-unlock-the-power-of-grammatical-agreement","title":"Unlock the power of grammatical agreement","type":"topic","kind":"article","role":"sampleCode","abstract":[{"text":"Discover how you can use automatic grammatical agreement in your apps and games to create inclusive and more natural-sounding expressions. We’ll share best practices for working with Foundation, showcase examples in multiple languages, and demonstrate how to use these APIs to enhance the user experience for your apps.","type":"text"}]},"WWDC23-10157-reactionsPhases2":{"type":"image","alt":"emoji show reactions left by others","identifier":"WWDC23-10157-reactionsPhases2","variants":[{"url":"\/images\/WWDC23-10157-reactionsPhases2.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10087-Build-spatial-SharePlay-experiences":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10087-Build-spatial-SharePlay-experiences","url":"\/documentation\/wwdcnotes\/wwdc23-10087-build-spatial-shareplay-experiences","title":"Build spatial SharePlay experiences","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can use the GroupActivities framework to build unique sharing and collaboration experiences for visionOS. We’ll introduce you to SharePlay on this platform, learn how to create experiences that make people feel present as if they were in the same space, and explore how immersive apps can respect shared context between participants.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10101-Customize-ondevice-speech-recognition":{"url":"\/documentation\/wwdcnotes\/wwdc23-10101-customize-ondevice-speech-recognition","abstract":[{"text":"Find out how you can improve on-device speech recognition in your app by customizing the underlying model with additional vocabulary. We’ll share how speech recognition works on device and show you how to boost specific words and phrases for more predictable transcription. Learn how you can provide specific pronunciations for words and use template support to quickly generate a full set of custom phrases — all at runtime.","type":"text"}],"type":"topic","title":"Customize on-device speech recognition","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10101-Customize-ondevice-speech-recognition"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10122-Explore-media-formats-for-the-web":{"abstract":[{"type":"text","text":"Learn about the latest image formats and video technologies supported in Safari 17. Discover how you can use JPEG XL, AVIF, and HEIC in your websites and experiences and learn how they differ from previous formats. We’ll also show you how the Managed Media Source API draws less power than Media Source Extensions (MSE) and explore how you can use it to more efficiently manage streaming video over 5G."}],"url":"\/documentation\/wwdcnotes\/wwdc23-10122-explore-media-formats-for-the-web","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10122-Explore-media-formats-for-the-web","role":"sampleCode","title":"Explore media formats for the web","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10241-Share-files-with-SharePlay":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10241-Share-files-with-SharePlay","url":"\/documentation\/wwdcnotes\/wwdc23-10241-share-files-with-shareplay","title":"Share files with SharePlay","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how to work with files and attachments in a SharePlay activity. We’ll explain how to use the GroupSessionJournal API to sync large amounts of data faster and show you how to adopt it in a demo of the sample app DrawTogether.","type":"text"}],"type":"topic"},"WWDC23-10157-remember":{"type":"image","alt":"remember","identifier":"WWDC23-10157-remember","variants":[{"url":"\/images\/WWDC23-10157-remember.jpg","traits":["1x","light"]}]},"WWDC23-10157-dots":{"type":"image","alt":"dots diagram","identifier":"WWDC23-10157-dots","variants":[{"url":"\/images\/WWDC23-10157-dots.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10057-Unleash-the-UIKit-trait-system":{"kind":"article","title":"Unleash the UIKit trait system","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10057-unleash-the-uikit-trait-system","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10057-Unleash-the-UIKit-trait-system","abstract":[{"text":"Discover powerful enhancements to the trait system in UIKit. Learn how you can define custom traits to add your own data to UITraitCollection, modify the data propagated to view controllers and views with trait override APIs, and adopt APIs to improve flexibility and performance. We’ll also show you how to bridge UIKit traits with SwiftUI environment keys to seamlessly access data from both UIKit and SwiftUI components in your app.","type":"text"}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10309-Design-widgets-for-the-Smart-Stack-on-Apple-Watch":{"kind":"article","title":"Design widgets for the Smart Stack on Apple Watch","url":"\/documentation\/wwdcnotes\/wwdc23-10309-design-widgets-for-the-smart-stack-on-apple-watch","abstract":[{"type":"text","text":"Bring your widgets to watchOS with the new Smart Stack. We’ll show you how to use standard design layouts, color and iconography, and signal-based relevancy to ensure your app’s widgets are glanceable, distinctive and smart."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10309-Design-widgets-for-the-Smart-Stack-on-Apple-Watch","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10042-Explore-Natural-Language-multilingual-models":{"title":"Explore Natural Language multilingual models","type":"topic","role":"sampleCode","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10042-explore-natural-language-multilingual-models","abstract":[{"type":"text","text":"Learn how to create custom Natural Language models for text classification and word tagging using multilingual, transformer-based embeddings. We’ll show you how to train with less data and support up to 27 different languages across three scripts. Find out how to use these embeddings to fine-tune complex models trained in PyTorch and TensorFlow."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10042-Explore-Natural-Language-multilingual-models"},"WWDC23-10157-keyframes5":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-keyframes5","variants":[{"url":"\/images\/WWDC23-10157-keyframes5.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10250-Prototype-with-Xcode-Playgrounds":{"url":"\/documentation\/wwdcnotes\/wwdc23-10250-prototype-with-xcode-playgrounds","type":"topic","role":"sampleCode","title":"Prototype with Xcode Playgrounds","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10250-Prototype-with-Xcode-Playgrounds","abstract":[{"text":"Speed up feature development by prototyping new code with Xcode Playgrounds, eliminating the need to keep rebuilding and relaunching your project to verify your changes. We’ll show you how using a playground in your project or package can help you try out your code in various scenarios and take a close look at the returned values, including complex structures and user interface elements, so you can quickly iterate on a feature before integrating it into your project.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10256-Discover-Continuity-Camera-for-tvOS":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10256-Discover-Continuity-Camera-for-tvOS","url":"\/documentation\/wwdcnotes\/wwdc23-10256-discover-continuity-camera-for-tvos","title":"Discover Continuity Camera for tvOS","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can bring AVFoundation, AVFAudio, and AudioToolbox to your apps on tvOS and create camera and microphone experiences for the living room. Find out how to support tvOS in your existing iOS camera experience with the Device Discovery API, build apps that use iPhone as a webcam or FaceTime source, and explore special considerations when developing for tvOS. We’ll also show you how to enable audio recording for tvOS, and how to use echo cancellation to create great voice-driven experiences.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10124-Bring-your-game-to-Mac-Part-2-Compile-your-shaders":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10124-Bring-your-game-to-Mac-Part-2-Compile-your-shaders","type":"topic","title":"Bring your game to Mac, Part 2: Compile your shaders","kind":"article","abstract":[{"text":"Discover how the Metal shader converter streamlines the process of bringing your HLSL shaders to Metal as we continue our three-part series on bringing your game to Mac. Find out how to build a fast, end-to-end shader pipeline from DXIL that supports all shader stages and allows you to leverage the advanced features of Apple GPUs. We’ll also show you how to reduce app launch time and stutters by generating GPU binaries with the offline compiler.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10124-bring-your-game-to-mac-part-2-compile-your-shaders","role":"sampleCode"},"WWDC23-10157-mapAnimation":{"type":"image","alt":"mapAnimation","identifier":"WWDC23-10157-mapAnimation","variants":[{"url":"\/images\/WWDC23-10157-mapAnimation.jpg","traits":["1x","light"]}]},"WWDC23-10157-phaseAnimator6":{"type":"image","alt":"the “.phaseAnimator” modifier","identifier":"WWDC23-10157-phaseAnimator6","variants":[{"url":"\/images\/WWDC23-10157-phaseAnimator6.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10052-Discover-Calendar-and-EventKit":{"url":"\/documentation\/wwdcnotes\/wwdc23-10052-discover-calendar-and-eventkit","abstract":[{"text":"Discover how you can bring Calendar into your app and help people better manage their time. Find out how to create new events from your app, fetch events, and implement a virtual conference extension. We’ll also take you through some of the changes to calendar access levels that help your app stay connected without compromising the privacy of someone’s calendar data.","type":"text"}],"type":"topic","title":"Discover Calendar and EventKit","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10052-Discover-Calendar-and-EventKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10156-Explore-SwiftUI-animation":{"url":"\/documentation\/wwdcnotes\/wwdc23-10156-explore-swiftui-animation","type":"topic","role":"sampleCode","title":"Explore SwiftUI animation","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10156-Explore-SwiftUI-animation","abstract":[{"text":"Explore SwiftUI’s powerful animation capabilities and find out how these features work together to produce impressive visual effects. Learn how SwiftUI refreshes the rendering of a view, determines what to animate, interpolates values over time, and propagates context for the current transaction.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10138-Design-and-build-apps-for-watchOS-10":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10138-Design-and-build-apps-for-watchOS-10","url":"\/documentation\/wwdcnotes\/wwdc23-10138-design-and-build-apps-for-watchos-10","title":"Design and build apps for watchOS 10","role":"sampleCode","kind":"article","abstract":[{"text":"Dive into the details of watchOS design principles and learn how to apply them in your app using SwiftUI. We’ll show you how to build an app for the redesigned user interface to surface timely information, communicate focused content at a glance, and make navigation consistent and predictable.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10104-Integrate-your-media-app-with-HomePod":{"type":"topic","role":"sampleCode","kind":"article","title":"Integrate your media app with HomePod","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10104-Integrate-your-media-app-with-HomePod","abstract":[{"text":"Learn how people can interact with your media app directly from HomePod. We’ll show you how to add a media intent to your iPhone or iPad app and help people stream your content to a HomePod speaker over AirPlay simply by using their voice. Explore implementation details and get tips and best practices on how to create a great experience for music, audiobooks, podcasts, meditations, or other media types.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10104-integrate-your-media-app-with-homepod"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10254-Do-more-with-Managed-Apple-IDs":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10254-Do-more-with-Managed-Apple-IDs","url":"\/documentation\/wwdcnotes\/wwdc23-10254-do-more-with-managed-apple-ids","title":"Do more with Managed Apple IDs","role":"sampleCode","kind":"article","abstract":[{"text":"Explore the latest updates to Managed Apple IDs and learn how you can use them in your organization. Take advantage of additional apps and services available to Managed Apple IDs, discover the Account-Driven Device Enrollment flow, and find out how to use access management controls to limit the devices and Apple services that Managed Apple IDs can access. We’ll also show you how to federate with your identity provider to automate creation and sync with your directory.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10012-Explore-App-Store-Connect-for-spatial-computing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10012-Explore-App-Store-Connect-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc23-10012-explore-app-store-connect-for-spatial-computing","title":"Explore App Store Connect for spatial computing","role":"sampleCode","kind":"article","abstract":[{"text":"App Store Connect provides the tools you need to test, submit, and manage your visionOS apps on the App Store. Explore basics and best practices for deploying your first spatial computing app, adding support for visionOS to an existing app, and managing compatibility. We’ll also show you how TestFlight for visionOS can help you test your apps and collect valuable feedback as you iterate.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10159-Beyond-scroll-views":{"title":"Beyond scroll views","url":"\/documentation\/wwdcnotes\/wwdc23-10159-beyond-scroll-views","type":"topic","role":"sampleCode","abstract":[{"text":"Find out how you can take your scroll views to the next level with the latest APIs in SwiftUI. We’ll show you how to customize scroll views like never before. Explore the relationship between safe areas and a scroll view’s margins, learn how to interact with the content offset of a scroll view, and discover how you can add a bit of flair to your content with scroll transitions.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10159-Beyond-scroll-views","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10226-Debug-with-structured-logging":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10226-Debug-with-structured-logging","url":"\/documentation\/wwdcnotes\/wwdc23-10226-debug-with-structured-logging","title":"Debug with structured logging","abstract":[{"type":"text","text":"Discover the debug console in Xcode 15 and learn how you can improve your diagnostic experience through logging. Explore how you can navigate your logs easily and efficiently using advanced filtering and improved visualization. We’ll also show you how to use the dwim-print command to evaluate expressions in your code while debugging."}],"kind":"article","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10195-Model-your-schema-with-SwiftData":{"url":"\/documentation\/wwdcnotes\/wwdc23-10195-model-your-schema-with-swiftdata","type":"topic","role":"sampleCode","title":"Model your schema with SwiftData","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10195-Model-your-schema-with-SwiftData","abstract":[{"text":"Learn how to use schema macros and migration plans with SwiftData to build more complex features for your app. We’ll show you how to fine-tune your persistence with @Attribute and @Relationship options. Learn how to exclude properties from your data model with @Transient and migrate from one version of your schema to the next with ease.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10202-Explore-materials-in-Reality-Composer-Pro","url":"\/documentation\/wwdcnotes\/wwdc23-10202-explore-materials-in-reality-composer-pro","role":"sampleCode","abstract":[{"text":"Learn how Reality Composer Pro can help you alter the appearance of your 3D objects using RealityKit materials. We’ll introduce you to MaterialX and physically-based (PBR) shaders, show you how to design dynamic materials using the shader graph editor, and explore adding custom inputs to a material so that you can control it in your visionOS app.","type":"text"}],"type":"topic","kind":"article","title":"Explore materials in Reality Composer Pro"},"WWDC23-10157-first":{"type":"image","alt":"scale animation","identifier":"WWDC23-10157-first","variants":[{"url":"\/images\/WWDC23-10157-first.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10160-Demystify-SwiftUI-performance":{"title":"Demystify SwiftUI performance","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10160-demystify-swiftui-performance","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10160-Demystify-SwiftUI-performance","abstract":[{"text":"Learn how you can build a mental model for performance in SwiftUI and write faster, more efficient code. We’ll share some of the common causes behind performance issues and help you triage hangs and hitches in SwiftUI to create more responsive views in your app.","type":"text"}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10035-Perform-accessibility-audits-for-your-app":{"url":"\/documentation\/wwdcnotes\/wwdc23-10035-perform-accessibility-audits-for-your-app","abstract":[{"text":"Discover how you can test your app for accessibility with every build. Learn how to perform automated audits for accessibility using XCTest and find out how to interpret the results. We’ll also share enhancements to the accessibility API that can help you improve UI test coverage.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10035-Perform-accessibility-audits-for-your-app","type":"topic","title":"Perform accessibility audits for your app","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10260-Get-started-with-building-apps-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc23-10260-get-started-with-building-apps-for-spatial-computing","title":"Get started with building apps for spatial computing","role":"sampleCode","kind":"article","abstract":[{"text":"Get ready to develop apps and games for visionOS! Discover the fundamental building blocks that make up spatial computing — windows, volumes, and spaces — and find out how you can use these elements to build engaging and immersive experiences.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/multitudes":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/multitudes","role":"sampleCode","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/multitudes","abstract":[{"type":"text","text":"student at 42Berlin 🐬 | 🍎 Swift(UI) app dev  | speciality coffee ☕️ & cycling 🚴🏻‍♂️"}],"title":"laurent b (32 notes)"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10154-Build-an-app-with-SwiftData":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10154-Build-an-app-with-SwiftData","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10154-build-an-app-with-swiftdata","abstract":[{"type":"text","text":"Discover how SwiftData can help you persist data in your app. Code along with us as we bring SwiftData to a multi-platform SwiftUI app. Learn how to convert existing model classes into SwiftData models, set up the environment, reflect model layer changes in UI, and build document-based applications backed by SwiftData storage."}],"type":"topic","title":"Build an app with SwiftData"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10070-Create-a-great-spatial-playback-experience":{"title":"Create a great spatial playback experience","type":"topic","abstract":[{"text":"Get ready to support video in your visionOS app! Take a tour of the frameworks and APIs that power video playback and learn how you can update your app to play 3D content. We’ll also share tips for customizing playback to create a more immersive watching experience.","type":"text"}],"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10070-Create-a-great-spatial-playback-experience","url":"\/documentation\/wwdcnotes\/wwdc23-10070-create-a-great-spatial-playback-experience","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10266-Protect-your-Mac-app-with-environment-constraints":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10266-Protect-your-Mac-app-with-environment-constraints","kind":"article","type":"topic","abstract":[{"text":"Learn how to improve the security of your Mac app by adopting environment constraints. We’ll show you how to set limits on how processes are launched, make sure your Launch Agents and Launch Daemons aren’t tampered with, and prevent unwanted code from running in your address space.","type":"text"}],"role":"sampleCode","title":"Protect your Mac app with environment constraints","url":"\/documentation\/wwdcnotes\/wwdc23-10266-protect-your-mac-app-with-environment-constraints"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10006-Build-robust-and-resumable-file-transfers":{"title":"Build robust and resumable file transfers","abstract":[{"text":"Find out how URLSession can help your apps transfer large files and recover from network interruptions. Learn how to pause and resume HTTP file transfers and support resumable uploads, and explore best practices for using URLSession to transfer files even when your app is suspended in the background.","type":"text"}],"kind":"article","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10006-build-robust-and-resumable-file-transfers","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10006-Build-robust-and-resumable-file-transfers","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10262-Rediscover-Safari-developer-features":{"kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10262-rediscover-safari-developer-features","abstract":[{"type":"text","text":"Get ready to explore Safari’s rich set of tools for web developers and designers. Learn how you can inspect web content, find out about Responsive Design Mode and WebDriver, and get started with simulators and devices. We’ll also show you how to pair with Vision Pro, make content inspectable in your apps, and use Open with Simulator in Responsive Design Mode to help you test your websites on any device."}],"type":"topic","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10262-Rediscover-Safari-developer-features","title":"Rediscover Safari developer features"},"WWDC23-10157-keyframes4":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-keyframes4","variants":[{"url":"\/images\/WWDC23-10157-keyframes4.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10125-Bring-your-game-to-Mac-Part-3-Render-with-Metal":{"url":"\/documentation\/wwdcnotes\/wwdc23-10125-bring-your-game-to-mac-part-3-render-with-metal","abstract":[{"text":"Discover how you can support Metal in your rendering code as we close out our three-part series on bringing your game to Mac. Once you’ve evaluated your existing Windows binary with the game porting toolkit and brought your HLSL shaders over to Metal, learn how you can optimally implement the features that high-end, modern games require. We’ll show you how to manage GPU resource bindings, residency, and synchronization. Find out how to optimize GPU commands submission, render rich visuals with MetalFX Upscaling, and more.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10125-Bring-your-game-to-Mac-Part-3-Render-with-Metal","type":"topic","title":"Bring your game to Mac, Part 3: Render with Metal","kind":"article","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit":{"abstract":[{"type":"text","text":"Go beyond the window and learn how you can bring engaging and immersive 3D content to your apps with RealityKit. Discover how SwiftUI scenes work in tandem with RealityView and how you can embed your content into an entity hierarchy. We’ll also explore how you can blend virtual content and the real world using anchors, bring particle effects into your apps, add video content, and create more immersive experiences with portals."}],"kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10081-Enhance-your-spatial-computing-app-with-RealityKit","title":"Enhance your spatial computing app with RealityKit","url":"\/documentation\/wwdcnotes\/wwdc23-10081-enhance-your-spatial-computing-app-with-realitykit","type":"topic"},"WWDC23-10157-phaseAnimator4":{"type":"image","alt":"the “.phaseAnimator” modifier","identifier":"WWDC23-10157-phaseAnimator4","variants":[{"url":"\/images\/WWDC23-10157-phaseAnimator4.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10275-Explore-AirPlay-with-interstitials":{"kind":"article","abstract":[{"type":"text","text":"Learn how you can use HLS Interstitials with AirPlay to create seamless transitions for your video content between advertisements. We’ll share best practices and tips for creating a great experience when sharing content from Apple devices to popular smart TVs."}],"title":"Explore AirPlay with interstitials","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10275-Explore-AirPlay-with-interstitials","url":"\/documentation\/wwdcnotes\/wwdc23-10275-explore-airplay-with-interstitials","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10060-Get-started-with-privacy-manifests":{"type":"topic","kind":"article","abstract":[{"text":"Meet privacy manifests: a new tool that helps you accurately identify the privacy practices of your app’s dependencies. Find out how third-party SDK developers can use these manifests to share privacy practices for their frameworks. We’ll also share how Xcode can produce a full privacy report to help you more easily represent the privacy practices of all the code in your app.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10060-Get-started-with-privacy-manifests","title":"Get started with privacy manifests","role":"sampleCode","url":"\/documentation\/wwdcnotes\/wwdc23-10060-get-started-with-privacy-manifests"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10229-Make-features-discoverable-with-TipKit":{"role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10229-Make-features-discoverable-with-TipKit","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10229-make-features-discoverable-with-tipkit","abstract":[{"text":"Teach people how to use your app with TipKit! Learn how you can create effective educational moments through tips. We’ll share how you can build eligibility rules to reach the ideal audience, control tip frequency, and strategies for testing to ensure successful interactions.","type":"text"}],"type":"topic","title":"Make features discoverable with TipKit"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10180-Discover-streamlined-location-updates":{"title":"Discover streamlined location updates","url":"\/documentation\/wwdcnotes\/wwdc23-10180-discover-streamlined-location-updates","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10180-Discover-streamlined-location-updates","role":"sampleCode","abstract":[{"type":"text","text":"Move into the future with Core Location! Meet the CLLocationUpdate class, designed for modern Swift concurrency, and learn how it simplifies getting location updates. We’ll show you how this class works with your apps when they run in the foreground or background and share some best practices."}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10168-Generalize-APIs-with-parameter-packs":{"url":"\/documentation\/wwdcnotes\/wwdc23-10168-generalize-apis-with-parameter-packs","title":"Generalize APIs with parameter packs","type":"topic","role":"sampleCode","abstract":[{"text":"Swift parameter packs are a powerful tool to expand what is possible in your generic code while also enabling you to simplify common generic patterns. We’ll show you how to abstract over types as well as the number of arguments in generic code and simplify common generic patterns to avoid overloads.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10168-Generalize-APIs-with-parameter-packs","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10086-Explore-the-USD-ecosystem":{"url":"\/documentation\/wwdcnotes\/wwdc23-10086-explore-the-usd-ecosystem","type":"topic","role":"sampleCode","title":"Explore the USD ecosystem","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10086-Explore-the-USD-ecosystem","abstract":[{"text":"Discover the latest updates to Universal Scene Description (USD) on Apple platforms and learn how you can deliver great 3D content for your apps, games, and websites. Get to know USD for visionOS, explore MaterialX shaders and color management, and find out about some of the other improvements to the USD ecosystem.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10110-elevate-your-windowed-app-for-spatial-computing","role":"sampleCode","abstract":[{"type":"text","text":"Discover how you can bring your multiplatform SwiftUI app to visionOS and the Shared Space. We’ll show you how to add the visionOS destination to an existing app and view your app in the Simulator. Explore how your SwiftUI code automatically adapts to support the unique context and presentation of the visionOS platform. Learn how you can update custom views, improve your app’s UI, and add features and controls specific to this platform."}],"title":"Elevate your windowed app for spatial computing","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10110-Elevate-your-windowed-app-for-spatial-computing","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10029-Build-widgets-for-the-Smart-Stack-on-Apple-Watch":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10029-Build-widgets-for-the-Smart-Stack-on-Apple-Watch","url":"\/documentation\/wwdcnotes\/wwdc23-10029-build-widgets-for-the-smart-stack-on-apple-watch","title":"Build widgets for the Smart Stack on Apple Watch","role":"sampleCode","kind":"article","abstract":[{"type":"text","text":"Follow along as we build a widget for the Smart Stack on watchOS 10 using the latest SwiftUI and WidgetKit APIs. Learn tips, techniques, and best practices for creating widgets that show relevant information on Apple Watch."}],"type":"topic"},"WWDC23-10157-reactionsPhases":{"type":"image","alt":"emoji show reactions left by others","identifier":"WWDC23-10157-reactionsPhases","variants":[{"url":"\/images\/WWDC23-10157-reactionsPhases.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10036-Build-accessible-apps-with-SwiftUI-and-UIKit":{"title":"Build accessible apps with SwiftUI and UIKit","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10036-Build-accessible-apps-with-SwiftUI-and-UIKit","url":"\/documentation\/wwdcnotes\/wwdc23-10036-build-accessible-apps-with-swiftui-and-uikit","kind":"article","abstract":[{"text":"Discover how advancements in UI frameworks make it easier to build rich, accessible experiences. Find out how technologies like VoiceOver can better interact with your app’s interface through accessibility traits and actions. We’ll share the latest updates to SwiftUI that help you refine your accessibility experience and show you how to keep accessibility information up-to-date in your UIKit apps.","type":"text"}]},"WWDC23-10157-keyframes":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-keyframes","variants":[{"url":"\/images\/WWDC23-10157-keyframes.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10076-Design-for-spatial-user-interfaces":{"title":"Design for spatial user interfaces","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10076-design-for-spatial-user-interfaces","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10076-Design-for-spatial-user-interfaces","abstract":[{"text":"Learn how to design great interfaces for spatial computing apps. We’ll share how your existing screen-based knowledge easily translates into creating great experiences for visionOS. Explore guidelines for UI components, materials, and typography and find out how you can design experiences that are familiar, legible, and easy to use.","type":"text"}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10172-Mix-Swift-and-C++":{"url":"\/documentation\/wwdcnotes\/wwdc23-10172-mix-swift-and-c++","kind":"article","abstract":[{"type":"text","text":"Learn how you can use Swift in your C++ and Objective-C++ projects to make your code safer, faster, and easier to develop. We’ll show you how to use C++ and Swift APIs to incrementally incorporate Swift into your app."}],"title":"Mix Swift and C++","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10172-Mix-Swift-and-C++","type":"topic"},"WWDC23-10157-reactions":{"type":"image","alt":"emoji show reactions left by others","identifier":"WWDC23-10157-reactions","variants":[{"url":"\/images\/WWDC23-10157-reactions.jpg","traits":["1x","light"]}]},"WWDC23-10157-reactionsPhases3":{"type":"image","alt":"emoji show reactions left by others","identifier":"WWDC23-10157-reactionsPhases3","variants":[{"url":"\/images\/WWDC23-10157-reactionsPhases3.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10127-Optimize-GPU-renderers-with-Metal":{"kind":"article","title":"Optimize GPU renderers with Metal","url":"\/documentation\/wwdcnotes\/wwdc23-10127-optimize-gpu-renderers-with-metal","abstract":[{"type":"text","text":"Discover how to optimize your GPU renderer using the latest Metal features and best practices. We’ll show you how to use function specialization and parallel shader compilation to maintain responsive authoring workflows and the fastest rendering speeds, and help you tune your compute shaders for optimal performance."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10127-Optimize-GPU-renderers-with-Metal","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10044-Discover-machine-learning-enhancements-in-Create-ML","url":"\/documentation\/wwdcnotes\/wwdc23-10044-discover-machine-learning-enhancements-in-create-ml","title":"Discover machine learning enhancements in Create ML","role":"sampleCode","kind":"article","abstract":[{"text":"Find out how Create ML can help you do even more with machine learning models. Learn about the latest updates to image understanding and text-based tasks with multilingual BERT embeddings. Discover how easy it is to train models that can understand the content of images using multi-label classification. We’ll also share information about interactive model evaluation and the latest APIs for custom training data augmentations.","type":"text"}],"type":"topic"},"WWDCNotes.png":{"type":"image","alt":null,"identifier":"WWDCNotes.png","variants":[{"url":"\/images\/WWDCNotes.png","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10073-Design-for-spatial-input":{"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10073-design-for-spatial-input","role":"sampleCode","title":"Design for spatial input","abstract":[{"text":"Learn how to design great interactions for eyes and hands. We’ll share the design principles for spatial input, explore best practices around input methods, and help you create spatial experiences that are comfortable, intuitive, and satisfying.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10073-Design-for-spatial-input"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10281-Keep-up-with-the-keyboard":{"url":"\/documentation\/wwdcnotes\/wwdc23-10281-keep-up-with-the-keyboard","type":"topic","role":"sampleCode","title":"Keep up with the keyboard","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10281-Keep-up-with-the-keyboard","abstract":[{"text":"Each year, the keyboard evolves to support an increasing range of languages, sizes, and features. Discover how you can design your app to keep up with the keyboard, regardless of how it appears on a device. We’ll show you how to create frictionless text entry and share important architectural changes to help you understand how the keyboard works within the system.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices":{"url":"\/documentation\/wwdcnotes\/wwdc23-10033-extend-speech-synthesis-with-personal-and-custom-voices","kind":"article","abstract":[{"type":"text","text":"Bring the latest advancements in Speech Synthesis to your apps. Learn how you can integrate your custom speech synthesizer and voices into iOS and macOS. We’ll show you how SSML is used to generate expressive speech synthesis, and explore how Personal Voice can enable your augmentative and assistive communication app to speak on a person’s behalf in an authentic way."}],"title":"Extend Speech Synthesis with personal and custom voices","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10033-Extend-Speech-Synthesis-with-personal-and-custom-voices","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10085-Discover-Quick-Look-for-spatial-computing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10085-Discover-Quick-Look-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc23-10085-discover-quick-look-for-spatial-computing","title":"Discover Quick Look for spatial computing","role":"sampleCode","kind":"article","abstract":[{"text":"Learn how to use Quick Look on visionOS to add powerful previews for 3D content, spatial images and videos, and much more. We’ll show you the different ways that the system presents these experiences, demonstrate how someone can drag and drop Quick Look content from an app or website to create a separate window with that content, and explore how you can present Quick Look directly within an app.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10007-Create-seamless-experiences-with-Virtualization":{"type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10007-create-seamless-experiences-with-virtualization","role":"sampleCode","abstract":[{"type":"text","text":"Discover the latest updates to the Virtualization framework. We’ll show you how to configure a virtual machine (VM) to automatically resize its display, take you through saving and restoring a running VM, and explore storage and performance options for Virtualization apps running on the desktop or in the data center."}],"title":"Create seamless experiences with Virtualization","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10007-Create-seamless-experiences-with-Virtualization","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10128-Your-guide-to-Metal-ray-tracing":{"url":"\/documentation\/wwdcnotes\/wwdc23-10128-your-guide-to-metal-ray-tracing","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10128-Your-guide-to-Metal-ray-tracing","abstract":[{"type":"text","text":"Discover how you can enhance the visual quality of your games and apps with Metal ray tracing. We’ll take you through the fundamentals of the Metal ray tracing API. Explore the latest enhancements and techniques that will enable you to create larger and more complex scenes, reduce memory usage and build times, and efficiently render visual content like hair and fur."}],"title":"Your guide to Metal ray tracing","type":"topic","role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10252-Build-programmatic-UI-with-Xcode-Previews":{"abstract":[{"type":"text","text":"Learn how you can use the #Preview macro on Xcode 15 to quickly iterate on your UI code written in SwiftUI, UIKit, or AppKit. Explore a collage of unique workflows for interacting with views right in the canvas, find out how to view multiple variations of UI simultaneously, and discover how you can travel through your widget’s timeline in seconds to test the transitions between entries. We’ll also show you how to add previews to libraries, provide sample assets, and preview your views in your physical devices to leverage their capabilities and existing data."}],"kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10252-Build-programmatic-UI-with-Xcode-Previews","title":"Build programmatic UI with Xcode Previews","url":"\/documentation\/wwdcnotes\/wwdc23-10252-build-programmatic-ui-with-xcode-previews","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10080-Build-spatial-experiences-with-RealityKit":{"url":"\/documentation\/wwdcnotes\/wwdc23-10080-build-spatial-experiences-with-realitykit","type":"topic","role":"sampleCode","title":"Build spatial experiences with RealityKit","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10080-Build-spatial-experiences-with-RealityKit","abstract":[{"text":"Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We’ll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we’ll explore combining RealityKit with spatial input, animation, and spatial audio.","type":"text"}],"kind":"article"},"WWDC23-10157-moreKeyframes4":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-moreKeyframes4","variants":[{"url":"\/images\/WWDC23-10157-moreKeyframes4.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences":{"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10091-evolve-your-arkit-app-for-spatial-experiences","role":"sampleCode","title":"Evolve your ARKit app for spatial experiences","abstract":[{"text":"Discover how you can bring your app’s AR experience to visionOS. Learn how ARKit and RealityKit have evolved for spatial computing: We’ll highlight conceptual and API changes for those coming from iPadOS and iOS and guide you to sessions with more details to help you bring your AR experience to this platform.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10091-Evolve-your-ARKit-app-for-spatial-experiences"},"https://developer.apple.com/wwdc23/10157":{"type":"download","url":"https:\/\/developer.apple.com\/wwdc23\/10157","identifier":"https:\/\/developer.apple.com\/wwdc23\/10157","checksum":null},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10203-Develop-your-first-immersive-app":{"url":"\/documentation\/wwdcnotes\/wwdc23-10203-develop-your-first-immersive-app","abstract":[{"text":"Find out how you can build immersive apps for visionOS using Xcode and Reality Composer Pro. We’ll show you how to get started with a new visionOS project, use Xcode Previews for your SwiftUI development, and take advantage of RealityKit and RealityView to render 3D content.","type":"text"}],"type":"topic","title":"Develop your first immersive app","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10203-Develop-your-first-immersive-app"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10094-Enhance-your-iPad-and-iPhone-apps-for-the-Shared-Space":{"title":"Enhance your iPad and iPhone apps for the Shared Space","role":"sampleCode","type":"topic","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10094-Enhance-your-iPad-and-iPhone-apps-for-the-Shared-Space","url":"\/documentation\/wwdcnotes\/wwdc23-10094-enhance-your-ipad-and-iphone-apps-for-the-shared-space","kind":"article","abstract":[{"text":"Get ready to enhance your iPad and iPhone apps for the Shared Space! We’ll show you how to optimize your experience to make it feel great on visionOS and explore Designed for iPad app interaction, visual treatments, and media.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10061-Verify-app-dependencies-with-digital-signatures":{"kind":"article","title":"Verify app dependencies with digital signatures","url":"\/documentation\/wwdcnotes\/wwdc23-10061-verify-app-dependencies-with-digital-signatures","abstract":[{"type":"text","text":"Discover how you can help secure your app’s dependencies. We’ll show you how Xcode can automatically verify any signed XCFrameworks you include within a project. Learn how code signatures work, the benefits they provide to help protect your software supply chain, and how SDK developers can sign their XCFrameworks to help keep your apps secure."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10061-Verify-app-dependencies-with-digital-signatures","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10071-Deliver-video-content-for-spatial-experiences":{"title":"Deliver video content for spatial experiences","url":"\/documentation\/wwdcnotes\/wwdc23-10071-deliver-video-content-for-spatial-experiences","type":"topic","role":"sampleCode","abstract":[{"text":"Learn how to prepare and deliver video content for visionOS using HTTP Live Streaming (HLS). Discover the current HLS delivery process for media and explore how you can expand your delivery pipeline to support 3D content. Get up to speed with tips and techniques for spatial media streaming and adapting your existing caption production workflows for 3D. And find out how to share audio tracks across video variants and add spatial audio to make your video content more immersive.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10071-Deliver-video-content-for-spatial-experiences","kind":"article"},"WWDC23-10157-moreKeyframes5":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-moreKeyframes5","variants":[{"url":"\/images\/WWDC23-10157-moreKeyframes5.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10263-Deploy-passkeys-at-work":{"kind":"article","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10263-Deploy-passkeys-at-work","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10263-deploy-passkeys-at-work","title":"Deploy passkeys at work","abstract":[{"type":"text","text":"Discover how you can take advantage of passkeys in managed environments at work. We’ll explore how passkeys can work well in enterprise environments through Managed Apple ID support for iCloud Keychain. We’ll also share how administrators can manage passkeys for specific devices using Access Management controls in Apple Business Manager and Apple School Manager."}]},"https://developer.apple.com/wwdc23/10156":{"type":"link","titleInlineContent":[{"text":"Explore SwiftUI animations","type":"text"}],"url":"https:\/\/developer.apple.com\/wwdc23\/10156","identifier":"https:\/\/developer.apple.com\/wwdc23\/10156","title":"Explore SwiftUI animations"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10078-Design-considerations-for-vision-and-motion":{"url":"\/documentation\/wwdcnotes\/wwdc23-10078-design-considerations-for-vision-and-motion","type":"topic","role":"sampleCode","title":"Design considerations for vision and motion","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10078-Design-considerations-for-vision-and-motion","abstract":[{"text":"Learn how to design engaging immersive experiences for visionOS that respect the limitations of human vision and motion perception. We’ll show you how you can use depth cues, contrast, focus, and motion to keep people comfortable as they enjoy your apps and games.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10192-Explore-enhancements-to-RoomPlan":{"type":"topic","kind":"article","url":"\/documentation\/wwdcnotes\/wwdc23-10192-explore-enhancements-to-roomplan","role":"sampleCode","title":"Explore enhancements to RoomPlan","abstract":[{"text":"Join us for an exciting update to RoomPlan as we explore MultiRoom support and enhancements to room representations. Learn how you can scan areas with more detail, capture multiple rooms, and merge individual scans into one larger structure. We’ll also share workflows and best practices when working with RoomPlan results that you want to combine into your existing 3D model library.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10192-Explore-enhancements-to-RoomPlan"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode":{"title":"Work with Reality Composer Pro content in Xcode","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10273-work-with-reality-composer-pro-content-in-xcode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10273-Work-with-Reality-Composer-Pro-content-in-Xcode","abstract":[{"text":"Learn how to bring content from Reality Composer Pro to life in Xcode. We’ll show you how to load 3D scenes into Xcode, integrate your content with your code, and add interactivity to your app. We’ll also share best practices and tips for using these tools together in your development workflow.","type":"text"}],"role":"sampleCode"},"WWDC23-10157-moreKeyframes3":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-moreKeyframes3","variants":[{"url":"\/images\/WWDC23-10157-moreKeyframes3.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10188-Sync-to-iCloud-with-CKSyncEngine":{"title":"Sync to iCloud with CKSyncEngine","kind":"article","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10188-sync-to-icloud-with-cksyncengine","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10188-Sync-to-iCloud-with-CKSyncEngine","abstract":[{"text":"Discover how CKSyncEngine can help you sync people’s CloudKit data to iCloud. Learn how you can reduce the amount of code in your app when you let the system handle scheduling for your sync operations. We’ll share how you can automatically benefit from enhanced performance as CloudKit evolves, explore testing for your sync implementation, and more.","type":"text"}],"role":"sampleCode"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10258-Animate-symbols-in-your-app":{"url":"\/documentation\/wwdcnotes\/wwdc23-10258-animate-symbols-in-your-app","abstract":[{"text":"Bring delight to your app with animated symbols. Explore the new Symbols framework, which features a unified API to create and configure symbol effects. Learn how SwiftUI, AppKit, and UIKit make it easy to animate symbols in user interfaces. Discover tips and tricks to seamlessly integrate the new animations alongside other app content. To get the most from this session, we recommend first watching “What’s new in SF Symbols 5.”","type":"text"}],"type":"topic","title":"Animate symbols in your app","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10258-Animate-symbols-in-your-app"},"WWDC23-10157-moreKeyframes2":{"type":"image","alt":"keyframes","identifier":"WWDC23-10157-moreKeyframes2","variants":[{"url":"\/images\/WWDC23-10157-moreKeyframes2.jpg","traits":["1x","light"]}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10090-Run-your-iPad-and-iPhone-apps-in-the-Shared-Space","url":"\/documentation\/wwdcnotes\/wwdc23-10090-run-your-ipad-and-iphone-apps-in-the-shared-space","title":"Run your iPad and iPhone apps in the Shared Space","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can run your existing iPad and iPhone apps on Vision Pro. Learn how iPadOS and iOS apps operate on this platform, find out about the Designed for iPad experience, and explore the paths available for enhancing your app experience on visionOS.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10045-Detect-animal-poses-in-Vision":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10045-Detect-animal-poses-in-Vision","url":"\/documentation\/wwdcnotes\/wwdc23-10045-detect-animal-poses-in-vision","title":"Detect animal poses in Vision","role":"sampleCode","kind":"article","abstract":[{"text":"Go beyond detecting cats and dogs in images. We’ll show you how to use Vision to detect the individual joints and poses of these animals as well — all in real time — and share how you can enable exciting features like animal tracking for a camera app, creative embellishment on an animal photo, and more. We’ll also explore other important enhancements to Vision and share best practices.","type":"text"}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10102-Spotlight-your-app-with-App-Shortcuts":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10102-Spotlight-your-app-with-App-Shortcuts","role":"sampleCode","kind":"article","title":"Spotlight your app with App Shortcuts","type":"topic","url":"\/documentation\/wwdcnotes\/wwdc23-10102-spotlight-your-app-with-app-shortcuts","abstract":[{"text":"Discover how to use App Shortcuts to surface frequently used features from your app in Spotlight or through Siri. Find out how to configure search results for your app and learn best practices for creating great App Shortcuts. We’ll also show you how to build great visual and voice experiences and extend to other Apple devices like Apple Watch and HomePod.","type":"text"}]},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10028-Bring-widgets-to-life":{"url":"\/documentation\/wwdcnotes\/wwdc23-10028-bring-widgets-to-life","abstract":[{"text":"Learn how to make animated and interactive widgets for your apps and games. We’ll show you how to tweak animations for entry transitions and add interactivity using SwiftUI Button and Toggle so that you can create powerful moments right from the Home Screen and Lock Screen.","type":"text"}],"type":"topic","title":"Bring widgets to life","role":"sampleCode","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10028-Bring-widgets-to-life"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10095-Explore-rendering-for-spatial-computing":{"kind":"article","title":"Explore rendering for spatial computing","url":"\/documentation\/wwdcnotes\/wwdc23-10095-explore-rendering-for-spatial-computing","abstract":[{"type":"text","text":"Find out how you can take control of RealityKit rendering to improve the look and feel of your apps and games on visionOS. Discover how you can customize lighting, add grounding shadows, and control tone mapping for your content. We’ll also go over best practices for two key treatments on the platform: rasterization rate maps and dynamic content scaling."}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10095-Explore-rendering-for-spatial-computing","role":"sampleCode","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10137-Support-Cinematic-mode-videos-in-your-app":{"url":"\/documentation\/wwdcnotes\/wwdc23-10137-support-cinematic-mode-videos-in-your-app","type":"topic","role":"sampleCode","title":"Support Cinematic mode videos in your app","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10137-Support-Cinematic-mode-videos-in-your-app","abstract":[{"text":"Discover how the Cinematic Camera API helps your app work with Cinematic mode videos captured in the Camera app. We’ll share the fundamentals — including Decision layers — that make up Cinematic mode video, show you how to access and update Decisions in your app, and help you save and load those changes.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10037-Explore-pie-charts-and-interactivity-in-Swift-Charts":{"title":"Explore pie charts and interactivity in Swift Charts","url":"\/documentation\/wwdcnotes\/wwdc23-10037-explore-pie-charts-and-interactivity-in-swift-charts","kind":"article","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10037-Explore-pie-charts-and-interactivity-in-Swift-Charts","role":"sampleCode","abstract":[{"type":"text","text":"Swift Charts has come full circle: Get ready to bake up pie and donut charts in your app with the latest improvements to the framework. Learn how to make your charts scrollable, explore the chart selection API for revealing additional details in your data, and find out how enabling additional interactivity can make your charts even more delightful."}],"type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10189-Migrate-to-SwiftData":{"type":"topic","abstract":[{"text":"Discover how you can start using SwiftData in your apps. We’ll show you how to use Xcode to generate model classes from your existing Core Data object models, use SwiftData alongside your previous implementation, or even completely replace your existing solution.","type":"text"}],"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10189-Migrate-to-SwiftData","role":"sampleCode","title":"Migrate to SwiftData","url":"\/documentation\/wwdcnotes\/wwdc23-10189-migrate-to-swiftdata","kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10051-Create-a-great-ShazamKit-experience":{"url":"\/documentation\/wwdcnotes\/wwdc23-10051-create-a-great-shazamkit-experience","type":"topic","role":"sampleCode","title":"Create a great ShazamKit experience","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10051-Create-a-great-ShazamKit-experience","abstract":[{"text":"Discover how your app can offer a great audio matching experience with the latest updates to ShazamKit. We’ll take you through matching features, updates to audio recognition, and interactions with the Shazam library. Learn tips and best practices for using ShazamKit in your audio apps.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10075-Design-spatial-SharePlay-experiences":{"url":"\/documentation\/wwdcnotes\/wwdc23-10075-design-spatial-shareplay-experiences","type":"topic","role":"sampleCode","title":"Design spatial SharePlay experiences","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10075-Design-spatial-SharePlay-experiences","abstract":[{"text":"Explore the types of shared activities you can create in your visionOS apps and find out how your apps can use Spatial Persona templates to support meaningful interactions between people. Discover how to design your UI around a shared context, handle immersive content in a shared activity, and more.","type":"text"}],"kind":"article"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10056-Build-better-documentbased-apps":{"url":"\/documentation\/wwdcnotes\/wwdc23-10056-build-better-documentbased-apps","kind":"article","abstract":[{"type":"text","text":"Discover how you can use the latest features in iPadOS to improve your document-based apps. We’ll show you how to take advantage of UIDocument as well as existing desktop-class iPad and document-based APIs to add new features in your app. Find out how to convert data models to UIDocument, present documents with UIDocumentViewController, learn how to migrate your apps to the latest APIs, and explore best practices."}],"title":"Build better document-based apps","role":"sampleCode","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10056-Build-better-documentbased-apps","type":"topic"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10096-Build-great-games-for-spatial-computing":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10096-Build-great-games-for-spatial-computing","url":"\/documentation\/wwdcnotes\/wwdc23-10096-build-great-games-for-spatial-computing","title":"Build great games for spatial computing","abstract":[{"type":"text","text":"Find out how you can develop great gaming experiences for visionOS. We’ll share some of the key building blocks that help you create games for this platform, explore how your experiences can fluidly move between levels of immersion, and provide a roadmap for exploring ARKit, RealityKit, Reality Composer Pro, Unity, Metal, and Compositor."}],"kind":"article","role":"sampleCode","type":"topic"},"https://x.com/wrmultitudes":{"type":"link","titleInlineContent":[{"text":"X\/Twitter","type":"text"}],"url":"https:\/\/x.com\/wrmultitudes","identifier":"https:\/\/x.com\/wrmultitudes","title":"X\/Twitter"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10123-Bring-your-game-to-Mac-Part-1-Make-a-game-plan":{"type":"topic","role":"sampleCode","kind":"article","title":"Bring your game to Mac, Part 1: Make a game plan","identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10123-Bring-your-game-to-Mac-Part-1-Make-a-game-plan","abstract":[{"text":"Bring modern, high-end games to Mac and iPad with the powerful features of Metal and Apple silicon. Discover the game porting toolkit and learn how it can help you evaluate your existing Windows game for graphics feature compatibility and performance. We’ll share best practices and technical resources for handling audio, input, and advanced display features.","type":"text"}],"url":"\/documentation\/wwdcnotes\/wwdc23-10123-bring-your-game-to-mac-part-1-make-a-game-plan"},"doc://WWDCNotes/documentation/WWDCNotes/WWDC23-10176-Lift-subjects-from-images-in-your-app":{"identifier":"doc:\/\/WWDCNotes\/documentation\/WWDCNotes\/WWDC23-10176-Lift-subjects-from-images-in-your-app","url":"\/documentation\/wwdcnotes\/wwdc23-10176-lift-subjects-from-images-in-your-app","title":"Lift subjects from images in your app","role":"sampleCode","kind":"article","abstract":[{"text":"Discover how you can easily pull the subject of an image from its background in your apps. Learn how to lift the primary subject or to access the subject at a given point with VisionKit. We’ll also share how you can lift subjects using Vision and combine that with lower-level frameworks like Core Image to create fun image effects and more complex compositing pipelines.","type":"text"}],"type":"topic"}}}