# What's new in Vision

Learn about the latest updates to Vision APIs that help your apps recognize text, detect faces and face landmarks, and implement optical flow. We‚Äôll take you through the capabilities of optical flow for video-based apps, show you how to update your apps with revisions to the machine learning models that drive these APIs, and explore how you can visualize your Vision tasks with Quick Look Preview support in Xcode.

To get the most out of this session, we recommend watching ‚ÄúDetect people, faces, and poses using Vision‚Äù from WWDC21.

@Metadata {
   @TitleHeading("WWDC22")
   @PageKind(sampleCode)
   @CallToAction(url: "https://developer.apple.com/wwdc22/10024", purpose: link, label: "Watch Video (19 min)")

   @Contributors {
      @GitHubUser(<replace this with your GitHub handle>)
   }
}

üò± "No Overview Available!"

Be the hero to change that by watching the video and providing notes! It's super easy:
 [Learn More‚Ä¶](https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing)
