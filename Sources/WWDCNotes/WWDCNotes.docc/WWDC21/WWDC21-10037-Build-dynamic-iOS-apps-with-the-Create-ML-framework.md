# Build dynamic iOS apps with the Create ML framework

Discover how your app can train Core ML models fully on device with the Create ML framework, enabling adaptive and customized app experiences, all while preserving data privacy. We'll explore the types of models that can be created on-the-fly for image-based tasks like Style Transfer and Image Classification, audio tasks like custom Sound Classification, or tasks that build on a rich set of Text Classification, Tabular Data Classification, and Tabular Regressors. And we'll take you through the many opportunities these models offer to make your app more personal and dynamic.

For even more inspiration, check out ‚ÄúClassify hand poses and actions with Create ML‚Äù and ‚ÄúDiscover built-in sound classification in SoundAnalysis‚Äù from WWDC21.

@Metadata {
   @TitleHeading("WWDC21")
   @PageKind(sampleCode)
   @CallToAction(url: "https://developer.apple.com/wwdc21/10037", purpose: link, label: "Watch Video")

   @Contributors {
      @GitHubUser(<replace this with your GitHub handle>)
   }
}

üò± "No Overview Available!"

Be the hero to change that by watching the video and providing notes! It's super easy:
 [Learn More‚Ä¶](https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing)
