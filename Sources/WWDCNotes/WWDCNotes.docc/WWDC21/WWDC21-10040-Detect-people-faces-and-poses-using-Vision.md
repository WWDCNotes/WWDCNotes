# Detect people, faces, and poses using Vision

Discover the latest updates to the Vision framework to help your apps detect people, faces, and poses. Meet the Person Segmentation API, which helps your app separate people in images from their surroundings, and explore the latest contiguous metrics for tracking pitch, yaw, and the roll of the human head. And learn how these capabilities can be combined with other APIs like Core Image to deliver anything from simple virtual backgrounds to rich offline compositing in an image-editing app.

To get the most out of this session, we recommend watching â€œDetect Body and Hand Pose with Visionâ€ from WWDC20 and â€œUnderstanding Images in Vision Frameworkâ€ from WWDC19.
To learn even more about people analysis, see â€œDetect Body and Hand Pose with Visionâ€ from WWDC20 and â€œUnderstanding Images in Vision Frameworkâ€ from WWDC19.

@Metadata {
   @TitleHeading("WWDC21")
   @PageKind(sampleCode)
   @CallToAction(url: "https://developer.apple.com/wwdc21/10040", purpose: link, label: "Watch Video (17 min)")

   @Contributors {
      @GitHubUser(<replace this with your GitHub handle>)
   }
}

ğŸ˜± "No Overview Available!"

Be the hero to change that by watching the video and providing notes! It's super easy:
 [Learn Moreâ€¦](https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing)
