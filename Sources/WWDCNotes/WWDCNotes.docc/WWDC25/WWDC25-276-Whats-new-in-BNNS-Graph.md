# Whatâ€™s new in BNNS Graph

The BNNS Graph Builder API now enables developers to write graphs of operations using the familiar Swift language to generate pre- and post-processing routines and small machine-learning models. BNNS compiles graphs ahead of execution and supports real-time and latency-sensitive use cases such as audio processing. In this session, we revisit last yearâ€™s bit-crusher example and simplify the Swift component by removing the reliance on a separate Python file and instead implement the audio effect entirely in Swift. The BNNS Graph Builder API is also suited to pre-processing image data before passing that data to a machine learning model. The session also includes a demonstration of clipping the transparent pixels from an image with an alpha channel.

@Metadata {
   @TitleHeading("WWDC25")
   @PageKind(sampleCode)
   @CallToAction(url: "https://developer.apple.com/videos/play/wwdc2025/276", purpose: link, label: "Watch Video (23 min)")

   @Contributors {
      @GitHubUser(<replace this with your GitHub handle>)
   }
}

ðŸ˜± "No Overview Available!"

Be the hero to change that by watching the video and providing notes! It's super easy:
 [Learn Moreâ€¦](https://wwdcnotes.com/documentation/wwdcnotes/contributing)
